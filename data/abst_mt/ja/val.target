本論文では、マウストラッキングを利用したデータベースやコンテキストアノテーションなど、この分野における最近の進歩を評価することで、視覚的顕著性の予測を再検討する。モデルのトレーニングと評価のためのマウストラッキングとアイトラッキングの質を含むいくつかの新しい課題に対して、批判的かつ定量的なアプローチを追求する。また、テキスト、顔、オブジェクトの属性などの文脈要素を考慮した評価方法を提案し、文脈情報を取り入れるためにモデルの定量的評価を拡張する。提案された文脈評価スキームは、モデルの詳細な分析を容易にし、モデルの長所と短所を特定するのに役立つ。いくつかの実験を通して、(1)マウス・トラッキング・データは、アイトラッキング・データと比較して、参加者間の視覚的整合性が低く、分散性が高いこと、(2)マウス・トラッキング・データは、一般的にはアイトラッキングと完全には一致しないこと、特定の異なる文脈領域に関しては一致しないこと、(3)マウス・トラッキング・データは、現在の既存モデルのトレーニングにおいて許容できる結果をもたらすこと、(4)マウス・トラッキング・データは、モデルの選択と評価において信頼性が低いこと、を明らかにしました。また、文脈評価の結果、研究されたモデルの中で、テストされたすべてのアノテーションに対して最高の性能を発揮する単一のモデルは存在しないことが明らかになった。
MILABOTは、Montreal Institute for Learning Algorithms (MILA)がAmazon Alexa Prizeコンテストのために開発した深層強化学習チャットボットです。MILABOTは、人気のある世間話のトピックについて、音声とテキストの両方で人間と会話することができます。このシステムは、テンプレートベースのモデル、Bag-of-Wordsモデル、sequence-to-sequenceニューラルネットワーク、latent variableニューラルネットワークモデルなどの自然言語生成・検索モデルのアンサンブルで構成されています。クラウドソースのデータや実際のユーザーとの対話に強化学習を適用することで、システムはアンサンブル内のモデルから適切な応答を選択するように学習されています。このシステムは、実世界のユーザーを対象としたA/Bテストで評価され、多くの競合システムよりも大幅に優れた性能を発揮しました。本システムは、機械学習アーキテクチャを採用しているため、データを追加することで改善する可能性があります。
一般的なリカレント・ニューラル・アーキテクチャは、状態計算の並列化が本質的に困難であるため、スケールが小さくなってしまいます。本研究では、モデルの容量とスケーラビリティのバランスがとれた軽量のリカレントユニット、Simple Recurrent Unit (SRU)を提案する。SRUは、表現力豊かな再帰関数を提供し、高度に並列化された実装を可能にするように設計されており、ディープモデルのトレーニングを容易にするために慎重な初期化が行われる。我々は、複数のNLPタスクでSRUの有効性を実証した。SRUは、分類や質問応答のデータセットにおいて、cuDNNで最適化されたLSTMの5～9倍の速度を達成し、LSTMや畳み込みモデルよりも強力な結果を得た。また、SRUをアーキテクチャに組み込むことで、翻訳においてTransformerモデルよりも平均0.7BLEUの向上が得られました。
畳み込みニューラルネットワーク（CNN）は、コンピュータビジョンの分野で広く利用されており、技術的にも大きく進歩しています。多くのCNNでは、ソフトマックス損失関数が、ディープモデルを学習するための監視信号として使用されています。本論文では、顔認識タスクのために、深層学習された特徴の識別力を強化するために、center lossと呼ばれる新しい監視信号を提案する。具体的には、center lossは、各クラスの深層特徴の中心を同時に学習し、深層特徴とその対応するクラス中心との間の距離にペナルティを与える。さらに重要なことは、提案された中心損失関数が学習可能であり、CNNでの最適化が容易であることを証明することである。ソフトマックス損失とセンター損失の共同監視により、顔認識に非常に重要な2つの学習目標であるクラス間の距離とクラス内のコンパクトさをできるだけ維持した深層特徴を得るために、ロバストなCNNを学習することができる。我々のCNNは、Labeled Faces in the Wild (LFW)、YouTube Faces (YTF)、MegaFace Challengeといった重要な顔認識ベンチマークにおいて、最先端の精度を達成していることは心強い。特に、MegaFace (最大のパブリックドメイン顔認証ベンチマーク)では、50万枚以下の画像と20000人以下の人物を含む少量の学習セットの下で最高の結果を達成し、従来の結果を大幅に改善し、顔認証と顔検証の両方のタスクで新たな最先端を確立しました。
ニューラル機械翻訳（NMT）は、ここ数年で目覚ましい発展を遂げており、現在では生産システムがエンドユーザーに配備されています。現在のアーキテクチャの大きな欠点は、学習コストが高いことであり、通常、収束するまでに数日から数週間のGPU時間を必要とします。このため、他のニューラルネットワークアーキテクチャで一般的に行われているハイパーパラメータの網羅的な探索は、非常に高価なものとなっています。本研究では、NMTアーキテクチャのハイパーパラメータの初の大規模解析を行いました。標準的なWMT英独翻訳タスクで250,000GPU時間以上に相当する数百回の実験結果と分散数を報告します。この実験により、NMTアーキテクチャを構築・拡張するための新たな洞察と実用的なアドバイスを得ることができました。この貢献の一環として、私たちはオープンソースのNMTフレームワークを公開し、研究者が新しい技術を簡単に試し、最先端の結果を再現できるようにしています。
本論文では、推薦システムにおける評価予測タスクのための新しいモデルを提案します。このモデルは、時分割のNetflixデータセットにおいて、これまでの最先端モデルを大幅に上回る性能を発揮します。我々のモデルは、6層の深層自己エンコーダーに基づいており、層ごとの事前学習を行わずにエンドツーエンドで学習される。その結果、次のことが実証されました。a) 深いオートエンコーダーモデルは、浅いモデルよりもはるかに優れた汎化能力を持つこと、b) 深いモデルの学習には、負の部分を持つ非線形活性化関数が重要であること、c) 過剰なファイティングを防ぐために、ドロップアウトなどの正則化技術を多用することが必要であること。また、協調フィルタリングの自然な疎密を克服するために、反復的な出力再供給に基づく新しい学習アルゴリズムを提案しています。この新しいアルゴリズムは，学習を大幅に高速化し，モデルの性能を向上させる．我々のコードは以下のURLから入手可能です。
顔画像の自動生成は、Generative Adversarial Network (GAN)が登場して以来、よく研究されています。アニメキャラクターの顔画像を生成する問題にGANモデルを適用する試みもあるが、既存の研究では有望な結果は得られていない。本研究では、アニメの顔画像データセットに特化したGANモデルの学習について検討する。よりクリーンで適したデータセットを収集し、DRAGANを適切かつ実証的に適用することで、データとモデルの両面からこの問題に取り組みます。定量的な分析とケーススタディにより、我々の努力が安定した高品質のモデルにつながることを実証します。さらに、アニメのキャラクターデザインを支援するために、事前に学習させたモデルをオンラインで公開するウェブサイト（http://make.girls.moe）を構築し、一般の人々がモデルに容易にアクセスできるようにしている。
本論文では、例示画像のスタイルをコンテンツ画像に転送する自動画像合成手法を紹介しています。標準的なニューラルスタイル転写アプローチを使用した場合、スタイル画像の異なる意味領域のテクスチャや色がコンテンツ画像に不適切に適用されることが多く、コンテンツ画像の意味的レイアウトが無視され、転写結果が台無しになってしまう。このような影響を軽減・回避するために、スタイル画像とコンテンツ画像から自動的にオブジェクトをセグメント化し、そのソフトセマンティックマスクを抽出することで、スタイルを転送しながらコンテンツ画像の構造を維持するという新しい手法を提案します。スタイル画像の各ソフトマスクは、スタイル画像の特定の部分を表し、同じセマンティクスを持つコンテンツ画像のソフトマスクに対応しています。ソフトマスクとソース画像は、マルチチャンネルの入力として、生成的なマルコフ・ランダム・フィールド（MRF）モデルを組み込んだスタイル移行用の拡張ディープCNNフレームワークに提供される。様々な画像を対象とした結果、我々の手法が最新の技術を上回ることが示された。
大規模なグラフにおけるノードの低次元埋め込みは、コンテンツの推薦やタンパク質の機能の特定など、さまざまな予測タスクにおいて非常に有用であることがわかっています。しかし、既存のアプローチのほとんどは、埋め込みの学習時に、グラフのすべてのノードが存在することを必要とする。GraphSAGEは、ノードの特徴情報（例：テキスト属性）を利用して、未見のデータに対するノード埋め込みを効率的に生成する、一般的な帰納的フレームワークである。各ノードに対して個別に埋め込みを学習する代わりに，ノードのローカルな近傍から特徴をサンプリングして集約することで埋め込みを生成する関数を学習する．我々のアルゴリズムは、3つの帰納的ノード分類ベンチマークにおいて、強力なベースラインを凌駕する。すなわち、引用とRedditの投稿データに基づいて、進化する情報グラフにおける見たことのないノードのカテゴリを分類し、タンパク質-タンパク質相互作用のマルチグラフデータセットを用いて、我々のアルゴリズムが全く見たことのないグラフに一般化することを示す。
この論文は、音楽コンテンツを生成するためにディープラーニング（深層人工ニューラルネットワーク）を使用するさまざまな方法の調査と分析です。分析のために、5つの次元に基づいた方法論を提案する。目的 - どのような音楽コンテンツを生成するのか？例えば、メロディ、ポリフォニー、伴奏、対位法などです。- 目的 - どのような目的で、どのように使用するのか？人間が演奏するのか（楽譜の場合）、機械が演奏するのか（オーディオファイルの場合）。表現 - 操作される概念は何か？例としては、波形、スペクトログラム、音符、和音、メーター、ビートなどがあります。- どのようなフォーマットを使用するのか？例を挙げます。MIDI、ピアノロール、テキストなど。- 表現をどのように符号化するか。例：スカラー、ワンショット、マルチショットなど。アーキテクチャ - どのようなタイプのディープニューラルネットワークを使用するのか。例：フィードフォワードネットワーク、リカレントネットワーク、オートエンコーダー、ジェネレーティブアドバーサリアルネットワーク。課題 - 制限や未解決の課題は何か？例：可変性、双方向性、創造性。戦略 - 生成のプロセスをどのようにモデル化し、制御するか？例としては、シングルステップ・フィードフォワード、反復フィードフォワード、サンプリング、入力操作などがあります。各次元について、様々なモデルや技術の比較分析を行い、いくつかの暫定的な多次元タイポロジーを提案します。この類型化は、関連文献から選ばれた多くの既存の深層学習ベースの音楽生成システムの分析に基づいたボトムアップ型である。これらのシステムを説明し、目的、表現、アーキテクチャ、課題、戦略の様々な選択を例示するために使用します。最後のセクションでは、いくつかの議論と展望を含みます。
正確なエンティティーリンクを行うためには、KBでの記述、そのエンティティーが言及されている文脈、構造化された知識など、エンティティーの様々な情報の側面を捉える必要がある。さらに、リンクシステムは、ドメイン固有の学習データや手作業で作成した特徴量を必要とせずに、異なるドメインのテキストに対して動作する必要がある。本研究では、ニューラルなモジュール式のエンティティリンクシステムを提案する。このシステムは、エンティティの説明、言及されている文脈、細かいタイプなどの複数の情報源を用いて、各エンティティの統一された密な表現を学習する。その結果、これらの情報源を効果的に組み合わせることができ、ドメイン固有の学習データや手作業で作成した特徴量を必要とせずに、様々なデータセットにおいて現在の最先端のシステムを凌駕する競争力のある性能を発揮することが示された。また、このモデルは、KBに新規に追加されたエンティティを効果的に「埋め込む」ことができ、その言及を正確にリンクすることができることを示しています。
畳み込みニューラルネットワーク（CNN）の中心的な構成要素である畳み込み演算子は、各層の局所的な受容野内の空間的な情報とチャネル的な情報の両方を融合することで、ネットワークが情報的な特徴を構築することを可能にする。先行研究では、この関係の空間的な要素を調査し、CNNの表現力を強化するために、特徴階層全体の空間エンコーディングの質を高めようとするものが多い。本研究では、チャネルの関係に着目し、チャネル間の相互依存性を明示的にモデル化することでチャネルごとの特徴応答を適応的に再調整する、「Squeeze-and-Excitation」（SE）ブロックと呼ぶ新しいアーキテクチャユニットを提案する。我々は、これらのブロックを積み重ねることで、異なるデータセット間で非常に効果的に一般化するSENETのアーキテクチャを形成できることを示します。さらに、SEブロックは、既存の最先端のCNNに対して、わずかな計算コストの追加で、パフォーマンスの大幅な向上をもたらすことを示します。Squeeze-and-Excitation Networksは、ILSVRC 2017に提出した分類の基礎を形成し、1位を獲得し、トップ5エラーを2.251%に減少させ、2016年の受賞エントリーを25%の相対的な改善によって上回りました。モデルとコードはこのhttpsのURLで公開されています。
データ補強は、クラスラベルを保持するタスク固有のデータ変換を活用することで、ラベル付きトレーニングセットのサイズを大きくするユビキタスな手法です。分野の専門家が個々の変換を指定することは容易であるが，最先端の結果を得るために必要なより洗練された合成を構築し調整することは，実際には時間のかかる手動の作業である．本論文では，生成的逆説法を用いて，ユーザが指定した変換関数に対する生成的シーケンスモデルを学習することで，このプロセスを自動化する手法を提案する．本手法は、任意の非決定論的な変換関数を利用することができ、ユーザの誤った入力に対しても頑健であり、ラベルのないデータで学習することができる。学習された変換モデルは、任意の最終的な識別モデルのためのデータ補強を行うために使用することができます。実験では，画像とテキストの両方のデータセットを対象に，標準的なヒューリスティック拡張アプローチと比較して，CIFAR-10では4.0精度ポイント，ACE関係性抽出タスクでは1.4F1ポイント，医用画像データセットでドメイン固有の変換操作を用いた場合には3.4精度ポイントの向上を達成し，本アプローチの有効性を示した．
畳み込みニューラルネットワーク（CNN）は、2次元画像の視覚認識に大きな影響を与え、現在では最先端のアプローチで広く使われています。CNNは、データが長方形のグリッドで構成されているオーディオやビデオなどの他のドメインにも自然に拡張されるが、3D形状メッシュ、ソーシャルネットワークグラフ、分子グラフなどの他のタイプのデータには容易に一般化できない。このようなデータを扱うために、我々は、フィルタの重みと畳み込みの中心付近のデータ要素との間の1対1対応を緩和した一般的な定式化をベースにした、新しいグラフ畳み込みネットワークアーキテクチャを提案する。我々のアーキテクチャの主な新規性は、フィルタの形状が前のネットワーク層の特徴の関数であり、ニューラルネットワークの不可欠な部分として学習される点である。数字認識、半教師付き文書分類、3次元形状対応の実験評価では、最先端の結果が得られ、形状対応では従来の研究よりも大幅に改善された。
深層ニューラルネットワークの学習には、大量の学習サンプルが必要であることが知られています。しかし、多くのアプリケーションでは、わずかな学習サンプルしか利用できません。本研究では、利用可能な学習サンプルが少ない場合に、分類タスクのためにニューラルネットワークを学習するという問題に取り組みます。本研究では、ニューラルネットワークの隠れた層がクラスに応じた不変な表現を学習することを制約する新しい正則化項を提案することで、この問題の解決を試みる。我々の正則化フレームワークでは、不変表現の学習は、同じクラスのサンプルが同じ表現を持つべきであるというクラスメンバーシップに一般化される。MNISTとその変種を対象とした数値実験により，我々の提案は，特に少数のサンプルで学習した場合に，ニューラルネットワークの一般化を向上させるのに役立つことが示された．我々のフレームワークのソースコードはこちらのhttps URLで提供されています。
私たちは、自然な音声でテキストを音声に変換することができる新しいニューラル音声合成（TTS）手法を提案します。他のシステムとは異なり、我々のソリューションは、音素や言語的特徴を必要とせず、制約のない音声サンプルを扱うことができます。ネットワークアーキテクチャは、既存の文献にあるものよりもシンプルで、新しいシフトバッファワーキングメモリに基づいています。このバッファは、注目度の推定、出力音声の計算、バッファ自体の更新にも使用されています。入力文は、文字や音素ごとに1つのエントリを含む文脈フリーのルックアップテーブルを用いてエンコードされる。話者も同様に短いベクトルで表現され、わずかなサンプル数でも新しいIDに適合させることができます。生成された音声のばらつきは，音声を生成する前にバッファをプライミングすることで実現される．いくつかのデータセットでの実験結果は、納得のいく性能を示しており、TTSはより幅広いアプリケーションに利用できるようになっている。再現性を高めるために、ソースコードとモデルを公開しています。
近年の機械学習の目覚ましい発展に伴い、機械学習が依拠するデータのプライバシーに対する関心が高まり、プライバシーを保護するための新しい技術が登場しました。しかし、プライバシーに関する古い考え方も十分に有効で有用である。このノートでは、初期の文献、特に1970年代にSaltzerとSchroederが導き出した原則に照らして、プライバシーに関する最近の2つの作品をレビューする。
ナレッジグラフ」の形で整理された関係性のある知識は、多くのアプリケーションにとって重要である。しかし、文書から自動的に抽出された事実を知識ベースに投入する能力は、苛立たしいほどゆっくりと改善されてきた。本論文では、先行研究を妨げていた2つの問題を同時に解決する。まず、効果的な新しいモデルを提案する。このモデルは、LSTMシーケンスモデルと、関係性の抽出に適したエンティティの位置を意識した注意のフォームを組み合わせたものである。次に、TACREDを構築する。TACREDは、TAC KBP関係を対象とした、クラウドソーシングで得られた大規模な（119,474例の）教師付き関係抽出データセットである。より優れた教師付きデータと、より適切な大容量モデルを組み合わせることで、関係性抽出の性能が格段に向上する。この新しいデータセットで学習されたモデルが、TAC KBP 2015の最優秀スロットフィリングシステムの従来の関係抽出コンポーネントに置き換わると、そのF1スコアは22.2%から26.7%へと顕著に増加します。
世界の知識のかなりの部分は、リレーショナル・データベースに保存されています。しかし、ユーザーがデータベースから事実を検索する能力は、SQLなどの問い合わせ言語を理解していないために制限されています。我々は、自然言語による質問を対応するSQLクエリに変換するための深層ニューラルネットワークであるSeq2SQLを提案する。我々のモデルは、SQLクエリの構造を利用して、生成されたクエリの出力空間を大幅に削減します。さらに、データベース上でのループ内のクエリ実行から得られる報酬を利用して、クエリの順序付けされていない部分を生成するポリシーを学習し、クロスエントロピー損失による最適化にあまり適していないことを示します。さらに、ウィキペディアの24241のテーブルに格納された80654のハンドアノテーションされた質問とSQLクエリのデータセットであるWikiSQLを公開します。このデータセットは、我々のモデルを学習するために必要なものであり、他のデータセットと比べて桁違いに大きいものです。WikiSQLにクエリ実行環境を備えたポリシーベースの強化学習を適用することで、我々のモデルSeq2SQLは、注意力のあるシーケンス対シーケンスモデルを上回り、実行精度を35.9%から59.4%に、論理形式精度を23.4%から48.3%に向上させた。
標準的な精度指標は、読解システムが急速に進歩していることを示していますが、これらのシステムがどの程度本当に言語を理解しているかはまだ不明です。そこで、本研究では、Stanford Question Answering Dataset (SQuAD)を用いた敵対的評価手法を提案する。本手法では、コンピュータシステムの注意をそらすために自動的に生成された、敵対的に挿入された文を含む段落についての質問に、システムが正解を変えずに、また人間を惑わせることなく回答できるかどうかをテストする。敵対的な設定では、16の公開モデルの精度は、F1スコアの平均75％から36％に低下し、さらに、敵が非文法的な単語の並びを追加すると、4つのモデルの平均精度は7％に低下しました。私たちの洞察が、言語をより正確に理解する新しいモデルの開発の動機となることを期待しています。
この記事では、最近のDeep Learningの進歩を、ファーストパーソン・シューティングゲーム、アーケードゲーム、リアルタイムストラテジーゲームなど、さまざまな種類のビデオゲームのプレイにどのように適用されているかという文脈でレビューします。異なるゲームジャンルがディープラーニングシステムにもたらす独自の要件を分析し、一般的なゲームのプレイ、極めて大きな決定空間や疎な報酬の取り扱いなど、これらの機械学習手法をビデオゲームに適用するという文脈において、重要な未解決の課題を明らかにします。
抽出型文書要約のためのセントロイドベースモデルは、セントロイドベクトルとの類似性に基づいて文章をランク付けする、シンプルで高速なベースラインです。本論文では、このランキングを文の代わりに可能な要約に適用し、単純なグレディアルゴリズムを用いて最適な要約を見つける。さらに、要約を構築する前に、各文書から少量の文を選択することで、より大きな入力文書コレクションにスケールアップできる可能性を示す。DUC2004データセットを用いて、複数文書の要約の実験を行った。その結果、従来のモデルよりも高い性能を示し、より複雑な最先端の手法と同等の性能を得ることができた。
深層学習を用いた手法は、様々な認識・分類タスクにおいて最先端の性能を達成してきました。そのため、多くのユーザーは学習手順をクラウドに委託したり、事前に学習したモデルを特定のタスクに合わせて微調整したりしています。本論文では、外部委託された学習が新たなセキュリティリスクをもたらすことを示します。すなわち、敵対者は、悪意を持って学習されたネットワーク（Backdoored neural network, or a ˶ˆ꒳ˆ˵）を作成することができます。このネットワークは、ユーザの学習および検証サンプルに対しては最先端の性能を発揮しますが、攻撃者が選んだ特定の入力に対しては不適切な動作をします。本研究では、まず、バックドアを施した手書き数字分類器を作成し、おもちゃの例でBadNetの特性を調べます。次に、より現実的なシナリオでバックドアを実証するために、米国の道路標識の分類器を作成しました。この分類器は、特別なステッカーが道路標識に追加された場合に、停止標識を速度制限として識別します。さらに、米国の道路標識検出器のバックドアは、ネットワークが後に別のタスクのために再学習された場合でも存続し、バックドアのトリガーが存在する場合には、平均で{25}%の精度低下を引き起こすことを示しました。これらの結果は、ニューラルネットワークのバックドアが強力であると同時に、ニューラルネットワークの動作を説明することが困難であるため、秘密裏に行われることを示しています。本研究は、ソフトウェアを検証・デバッグするためのツールを開発したように、ニューラルネットワークを検証・検査するための技術をさらに研究する動機となります。
オンライン音楽ストリーミング・プラットフォームには膨大な量のコンテンツがありますが、ほとんどのユーザーはこれらのコンテンツのごく一部にしかアクセスしていません。このようなユーザーにコンテンツを開放するためのアプリケーションとして、推薦システムが選ばれています。協調フィルタリングは、利用できないことが多い明示的な評価に依存し、一般的に音楽消費の時間的性質を無視するという欠点があります。一方、最近登場したword2vecベースのレコメンダーのようなアイテム共起アルゴリズムは、一般的に効果的なユーザー表現がないまま放置されている。本論文では、消費されたアイテムを逐次処理することで、リカレントニューラルネットワークを用いてユーザをモデル化する新しいアプローチを提案する。このようにして、意味的に豊かなユーザー表現を得て、ユーザーの音楽的嗜好を時系列で捉えることができる。大規模なユーザーデータを用いた実験では、このモデルを用いて、ユーザーが短期的にも長期的にも将来聞くであろう曲を予測できることが示された。
我々は、単一の深層ニューラルネットワークを用いて画像中の物体を検出する手法を提案します。SSDと名付けられた我々のアプローチは、バウンディングボックスの出力空間を、特徴マップの位置ごとに異なるアスペクト比とスケールのデフォルトボックスのセットに離散化します。予測時には、ネットワークは各デフォルトボックス内の各オブジェクトカテゴリの存在に対するスコアを生成し、オブジェクトの形状とより一致するようにボックスを調整します。さらに、解像度の異なる複数の特徴量マップからの予測値を組み合わせることで、様々なサイズの物体を自然に扱うことができます。SSDのモデルは、物体の提案を必要とする手法に比べてシンプルです。なぜなら、提案の生成とそれに続くピクセルまたは特徴のリサンプリング段階を完全に排除し、すべての計算を単一のネットワークにカプセル化しているからです。これにより、SSDは学習しやすく、検出コンポーネントを必要とするシステムに簡単に組み込むことができます。PASCAL VOC、MS COCO、ILSVRCのデータセットを用いた実験の結果、SSDは追加の物体提案段階を利用する手法と同等の精度を持ち、学習と推論の両方に統一されたフレームワークを提供しながら、はるかに高速であることが確認されました。SSDは、他のシングルステージ手法と比較して、入力画像サイズが小さくても、精度が大幅に向上しています。300枚の入力画像では、SSDはVOC2007テストにおいて72.1%のmAPを達成しました。また、500枚の入力画像では、SSDは75.1%のmAPを達成し、同等の最新モデルであるFaster R-CNNを上回りました。コードはこちらのhttpsのURLから入手できます。
スタンス分類は、（通常は短い）テキスト中の姿勢（スタンス）を決定するものである。このタスクは、フェイクニュースの検出や、メディア内のエンティティやイベントに対する態度の自動抽出など、強力なアプリケーションがあります。本論文では、噂や信憑性の分類のために、Twitterにおけるオープンスタンス分類のための、驚くほどシンプルで効率的な分類アプローチについて述べる。このアプローチは、自動的に識別可能な問題固有の特徴の新規セットを利用しており、分類器の精度を大幅に向上させ、最近のベンチマークデータセットで最先端の結果を達成している。これは、複雑で洗練されたモデルをスタンス分類に使用する際に、最初に情報に基づいた特徴抽出を行わないことの価値を疑問視するものである。
深層学習法は、複数の処理層を用いてデータの階層的な表現を学習するもので、多くの領域で最先端の結果を出している。最近では、自然言語処理（NLP）の分野でも、様々なモデルデザインや手法が登場しています。本論文では、数多くのNLPタスクに採用されてきた深層学習関連の重要なモデルと手法をレビューし、その進化の様子を紹介します。また、様々なモデルを要約、比較、対照し、NLPにおける深層学習の過去、現在、未来についての詳細な理解を提示します。
クリックスルー率の予測は、オンライン広告などの産業用途では必須のタスクです。最近では、Embedding\&MLPのパラダイムに類似した、深層学習に基づくモデルが提案されています。これらの手法では、大規模で疎な入力特徴は、まず低次元の埋め込みベクトルにマッピングされ、次にグループごとに固定長のベクトルに変換され、最後に連結されて多層パーセプトロン（MLP）に入力され、特徴間の非線形関係を学習します。このようにして、広告の候補に関わらず、ユーザーの特徴が固定長の表現ベクトルに圧縮されます。しかし、固定長のベクトルを用いることがボトルネックとなり、Embedding\&MLP法では、ユーザーの多様な興味を、豊富な過去の行動から効果的に捉えることが困難となる。この論文では、新しいモデルを提案します。本論文では、Deep Interest Network (DIN)という新しいモデルを提案しています。この表現ベクトルは異なる広告間で変化するため、モデルの表現力が大幅に向上します。さらに、ミニバッチを意識した正則化とデータ適応型活性化関数という2つの技術を開発し、数億個のパラメータを持つ産業用ディープネットワークの学習に役立てています。2つの公開データセットおよび20億以上のサンプルを含むAlibabaの実生産データセットを用いた実験により、提案されたアプローチの有効性が実証され、最先端の手法と比較して優れた性能が得られました。DINは現在、アリババのオンラインディスプレイ広告システムへの導入に成功しており、主要なトラフィックにサービスを提供しています。
深層学習の発展を妨げる長年の障害は、消失および爆発する勾配の問題です。しかし、highwayやresnetsのようなスキップ結合を含むアーキテクチャは、初期化やバッチの正規化を十分に選択したにもかかわらず、標準的なフィードフォワードアーキテクチャよりもはるかに優れた性能を示します。本論文では、shattered gradients問題を明らかにしました。具体的には、標準的なフィードフォワードネットワークの勾配間の相関は深さに応じて指数関数的に減衰し、ホワイトノイズのような勾配になるのに対し、スキップ結合を用いたアーキテクチャの勾配ははるかに砕けにくく、副次的に減衰することを示している。この分析を裏付ける詳細な経験的証拠が、完全結合ネットワークとコンボネットの両方で示されています。最後に、シャッタリングを防ぐ新しい「ルックス・リニア」（LL）初期化を提示し、この新しい初期化によって、スキップ結合を追加せずに非常に深いネットワークを学習できることを予備実験で示した。
1枚の画像から3Dを再構成することは、ロボット操作やAR（拡張現実）など、様々なアプリケーションで重要な問題となっています。これまでの手法では、3D再構成をボクセルや点群として予測する生成モデルによってこの問題に取り組んできました。しかし、これらの手法は、計算コストが高く、細かい部分を見逃してしまう可能性があります。我々は、3Dデータ変形のための新しい微分可能な層を導入し、DeformNetでそれを使用して、変形による3D再構築のためのモデルを学習する。DeformNetは、画像を入力し、データベースから最も近い形状テンプレートを検索し、クエリ画像にマッチするようにテンプレートを変形させる。このアプローチをShapeNetデータセットで評価し、以下のことを示しました。(a) 自由形状変形レイヤーは、3Dデータを操作するDeep Learningモデルのための強力な新しい構成要素である。(b) DeformNetは、このFFDレイヤーを形状検索と組み合わせて使用し、単一のクエリ画像に関して定性的にもっともらしい点群の、滑らかでディテールを保持した3D再構築を行う。(c) 他の最先端の3D再構築手法と比較して、DeformNetは定量的にベンチマークと一致するか、または大幅に上回る。詳細については、このhttpsのURLをご覧ください。
ニューラルタスク指向の対話システムは、知識ベースとのスムーズなインターフェースに苦労することが多い。本研究では、この問題を解決するために、新しいキーバリュー検索メカニズムを用いて、根拠のある複数ドメインの談話を効果的に維持することができる新しいニューラル対話エージェントを提案します。このモデルはエンド・ツー・エンドで微分可能であり、対話状態や信念トラッカーを明示的にモデル化する必要はない。また、3,031件の対話を収録した新しいデータセットを公開しました。これらの対話は、基礎的な知識ベースを介してグラウンディングされており、車内パーソナルアシスタントの分野における3つの異なるタスク（カレンダーのスケジューリング、天気情報の検索、興味のある場所のナビゲーション）にまたがっています。本研究では、すべての領域のデータを同時に学習し、ルールベースのシステムや他の既存のニューラルダイアログアーキテクチャを、自動評価と人間の評価の両方で大幅に上回る結果を得た。
我々は、構造化予測のための「探索学習」（L2S）アプローチにヒントを得た、リカレントニューラルネットワーク（RNN）のための新しい学習アルゴリズムであるSEARNNを提案する。RNNは、機械翻訳や構文解析などの構造化予測アプリケーションで広く成功しており、一般的に最尤推定（MLE）を用いて学習されます。残念ながら、この学習損失は、テストエラーの適切な代替とは限りません。グランドトゥルース確率を最大化するだけで、構造化損失が提供する豊富な情報を利用できません。さらに、トレーニングと予測の間に矛盾が生じ（露出バイアスなど）、テストのパフォーマンスを低下させる可能性があります。その代わりに、SEARNNはテストに似た探索空間を利用して、テストエラーに近いグローバル・ローカルな損失を導入します。我々はまず、2つの異なるタスクにおいて、MLEに比べて性能が向上したことを実証する。まず、OCRとスペル修正という2つの異なるタスクにおいて、MLEを上回る性能を実証する。次に、SEARNNが大規模な語彙サイズに対応できるように、サブサンプリング戦略を提案します。これにより、機械翻訳タスクにおいて、我々のアプローチの利点を検証することができる。
長短期記憶ネットワーク（LSTM）などの再帰型ニューラルネットワーク（RNN）は、機械翻訳、言語モデリング、質問応答などの多くのシーケンス学習タスクにおいて、基本的な構成要素として機能しています。本論文では，単語レベルの言語モデリングという特殊な問題を検討し，LSTMベースのモデルを正則化および最適化するための戦略を検討する．本論文では、再帰的正則化の一形態として、隠れた部分の重みにDropConnectを用いるweight-droped LSTMを提案する。さらに、平均化確率的勾配法の一種であるNT-ASGDを導入し、ユーザーが調整するのではなく、非単調な条件で平均化トリガーを決定する。これらの正則化戦略やその他の正則化戦略を用いて、2つのデータセットで最先端の単語レベルのパープレキシティを達成しました：Penn Treebankでは57.3、WikiText-2では65.8です。また、ニューラルキャッシュの有効性を検討した結果、Penn Treebankでは52.8、WikiText-2では52.0という最先端のパープレキシティを達成しました。
この論文では、テキスト分類のために、中国語、日本語、韓国語（CJK）、英語の言語をエンコードする方法の違いについて、実証的な研究を行っています。UTF-8のバイト、文字、単語、ローマ字の文字、ローマ字の単語など、さまざまなエンコーディングレベルについて調べました。すべてのエンコーディングレベルについて、必要に応じて、線形モデル、FastText、および畳み込みネットワークとの比較を行っています。畳み込みネットワークについては、文字のグリフ画像を用いた符号化メカニズム、ワンショット（またはone-of-n）符号化、埋め込みを比較しています。中国語、英語、日本語、韓国語の4つの言語による14の大規模テキスト分類データセットを用いて、合計473のモデルを作成しました。これらの結果から、UTF-8に基づくバイトレベルのワンショット符号化は、畳み込みネットワークに対して常に競争力のある結果をもたらすこと、単語レベルのn-grams線形モデルは、完璧な単語分割がなくても競争力があること、fastTextは文字レベルのn-gram符号化を用いて最良の結果をもたらすが、特徴が過度に豊富な場合はオーバーフィットする可能性があること、などの結論が得られました。
グラフィックデザインとデータビジュアライゼーションのための視覚的重要性の学習
深層畳み込みニューラルネットワークを用いて、音声や音楽などの信号のサンプリングレートを向上させる新しい音声処理技術を紹介します。我々のモデルは、低品質と高品質のオーディオ例のペアで学習され、テスト時には、画像のスーパーレゾリューションに似た補間プロセスで低解像度信号内の欠落したサンプルを予測します。実験では、2倍、4倍、6倍のアップスケール率で、標準的な音声および音楽のベンチマークにおいて、ベースラインよりも優れた性能を示しました。この手法は、テレフォニー、圧縮、音声合成などの分野で実用化されており、音声生成タスクにおけるフィードフォワード型の畳み込みアーキテクチャの有効性を実証しています。
ブラックボックスモデルの予測をどのように説明すればよいのでしょうか。本論文では，ロバスト統計学の古典的な手法である影響関数を用いて，モデルの予測が学習アルゴリズムを経て学習データに戻ってくる様子を追跡し，与えられた予測に対して最も責任のある学習ポイントを特定します．影響関数を最新の機械学習に適用するために、勾配とヘシアンベクトル積へのオラクルアクセスのみを必要とするシンプルで効率的な実装を開発した。理論が破綻するような非凸・非微分モデルであっても、影響関数の近似値は貴重な情報を提供できることを示している。線形モデルと畳み込みニューラルネットワークにおいて、影響関数は、モデルの挙動の理解、モデルのデバッグ、データセットのエラーの検出、さらには視覚的に区別できないトレーニングセットの攻撃など、複数の目的に役立つことを示します。
NLPのタスクは、手動でアノテーションされたデータが少ないために制限されることが多い。そのため、ソーシャルメディアの感情分析や関連するタスクでは、研究者は2値化された顔文字や特定のハッシュタグを遠隔監視の形態として使用してきました。本論文では、遠隔監視をより多様なノイズラベルに拡張することで、モデルがより豊かな表現を学習できることを示している。64個の一般的な絵文字のうちの1つを含む1億2,460万のツイートからなるデータセットに対する絵文字予測により、1つの事前学習済みモデルを用いて、感情、情動、皮肉の検出に関する8つのベンチマークデータセットにおいて最先端の性能を得ることができた。分析の結果、感情ラベルの多様性により、これまでの遠隔監視アプローチよりも性能が向上することが確認されました。
小規模で浅いフィードフォワードニューラルネットワークは、非構造化および構造化された言語処理タスクにおいて、最先端に近い結果を得ることができることを示しています。また、深層リカレントモデルに比べて、メモリや計算量を大幅に削減できます。本論文では、携帯電話のようなリソースに制約のある環境を想定し、このような小型のニューラルネットワークモデルを得るための簡単な手法を紹介するとともに、少ないメモリ予算をどのように割り当てるかを決定する際のさまざまなトレードオフを検討しています。
コンピュータビジョンでは、ImageNetのような大規模な教師付きトレーニングセットで事前に学習した重みを用いて複数の深層を初期化することが有効です。一方，自然言語処理（NLP）では，ディープモデルの最下層のみを事前に学習した単語ベクトルで初期化するのが一般的です．本論文では、機械翻訳（MT）のために訓練された注意力のあるsequence-to-sequenceモデルの深層LSTMエンコーダを用いて、単語ベクトルに文脈を与えます。感情分析（SST, IMDb）、質問分類（TREC）、エンテーリング（SNLI）、質問応答（SQuAD）など、様々な一般的なNLPタスクにおいて、これらの文脈ベクトル（CoVe）を追加することで、教師なしの単語・文字ベクトルのみを使用した場合よりも性能が向上することを示す。細かい感情分析とエンテーリングについては、CoVeはベースラインモデルの性能を最先端まで向上させています。
最近の研究では、最先端のディープニューラルネットワーク（DNN）は、入力に加えられた小さな摂動に起因する敵対的な例に対して脆弱であることが示されています。したがって、物理的な世界における敵対的な例を理解することは、回復力のある学習アルゴリズムを開発するための重要なステップです。本研究では、様々な物理的条件の下でロバストな視覚的敵対的摂動を生成する一般的な攻撃アルゴリズム「Robust Physical Perturbations (RP2)」を提案する。道路標識の分類という実世界のケースを用いて、RP2を用いて生成された敵対的な例は、視点を含む様々な環境条件下の物理的世界において、標準的なアーキテクチャの道路標識分類器に対して高い目標誤分類率を達成することを示す。現在、標準化されたテスト方法がないため、我々は、ラボテストとフィールドテストからなる2段階のロバストな物理的敵対例の評価方法を提案する。この方法論を用いて、実物に対する物理的な敵対的操作の有効性を評価します。白と黒のステッカーを用いて実在する一時停止標識を攻撃したところ，実験室で得られた画像の100%と，移動中の車両で撮影されたビデオフレームの84.8%において，対象となる分類器に誤った分類を引き起こした（フィールドテスト）．
現在、機械学習システムを構築するプロセスは、機械学習に関する深い知識を持つ実務者を必要とします。そのため、作成できる機械学習システムの数が大幅に制限されており、機械学習システムの需要と組織が構築する能力の間にミスマッチが生じています。私たちは、機械学習システムに対する需要の高まりに応えるためには、機械に教えることのできる個人の数を大幅に増やす必要があると考えています。この目標を達成するためには、機械を教えるプロセスを簡単かつ迅速に、そして何よりも誰もが利用できるようにする必要があると考えています。機械学習が新しいアルゴリズムの作成と「学習者」の精度の向上に焦点を当てているのに対し、機械教育の分野では「教師」の有効性に焦点を当てています。ディシプリンとしてのマシンティーチングは、ソフトウェア工学やプログラミング言語の原理を踏襲し、それを拡張したパラダイムシフトです。我々は、教師と教師のデータとのインタラクションに加え、インタラクションやビジュアライゼーションの技術や設計原理などの重要な要素に重点を置いている。本論文では、機械教育の分野に関する我々の立場を示し、機械教育の基本原則を明確にします。また、機械学習アルゴリズムに関する知識をティーチングのプロセスから切り離すことで、イノベーションを加速し、何百万もの機械学習モデルの新たな利用法を可能にする方法についても述べています。
深層強化学習（RL）手法は、一般的に行動空間にノイズを注入することで探索的な行動をとります。もう一つの方法は、エージェントのパラメータに直接ノイズを追加することで、より一貫性のある探索と豊かな行動のセットを得ることができます。進化的戦略のような方法は、パラメータの摂動を使用しますが、その過程ですべての時間的構造を破棄し、かなり多くのサンプルを必要とします。パラメータノイズと従来のRL手法を組み合わせることで、両者の長所を組み合わせることができる。本研究では、DQN、DDPG、TRPOを高次元離散行動環境および連続制御タスクで実験的に比較することにより、オフポリシーおよびオンポリシーの両方の手法がこのアプローチから恩恵を受けることを実証する。その結果、パラメータノイズを用いたRLは、行動空間ノイズを用いた従来のRLや進化的戦略を個別に学習するよりも効率的に学習することがわかった。
敵対的学習では、一組のモデルが、通常は単一のデータインスタンス上で定義される競合する目標を追求することで共に学習する。しかし、関係学習やその他の非i.i.d.ドメインでは、ゴールはインスタンスのセットで定義することもできる。例えば、is-a関係のリンク予測器は、推移性の性質と一致する必要がある。is-a(x_1, x_2)とis-a(x_2, x_3)が成立する場合、is-a(x_1, x_3)も成立する必要がある。ここでは、このような仮定を用いて、不整合損失を導き出し、敵対的に生成された例のセットでモデルが仮定に違反する度合いを測定する。学習目的はミニマックス問題として定義されており、敵対者は不整合損失を最大化することで最も問題のある敵対例を見つけ、モデルは教師付き損失と敵対例の不整合損失を共同で最小化することで学習される。これにより、関数なしのホーン節（Datalogのような）を用いて、ドメインサイズに依存しない複雑さで、任意のニューラルリンク予測器を正則化することができる初めての手法が得られる。いくつかのリンク予測モデルについて、敵対者が直面する最適化問題が効率的な閉形式解を持つことを示す。リンク予測ベンチマークを用いた実験では、適切な事前知識があれば、本手法はすべての関連指標においてニューラルリンク予測器を大幅に改善できることが示された。
本論文では、強化学習エージェントが受け取るランダムなリターンの分布である値の分布の基本的な重要性を主張します。これは、強化学習の一般的なアプローチが、このリターンの期待値、つまり価値をモデル化することとは対照的である。価値分布を研究した文献は数多くありますが、これまでのところ、価値分布は常に、リスクを認識した行動の実装といった特定の目的のために使用されてきました。まず、政策評価とコントロールの両方の設定で理論的な結果を得て、後者では重大な分布の不安定さを露呈します。次に、分布の観点を用いて、ベルマンの方程式を近似値分布の学習に適用する新しいアルゴリズムを設計する。このアルゴリズムを、Arcade Learning Environmentのゲーム群を用いて評価した。その結果、最先端の結果と、近似強化学習における価値分布の重要性を示す逸話的な証拠が得られた。最後に、理論的な証拠と経験的な証拠を組み合わせて、価値分布が近似的な設定での学習に影響を与える方法を強調する。
本論文では、100万件以上の料理レシピと1,300万枚以上の料理画像を収録した大規模で構造化された新しいコーパスであるRecipe1M+を紹介する。レシピデータの最大の公開コレクションであるRecipe1M+は、整列したマルチモーダルなデータを用いて大容量のモデルを学習することが可能である。これらのデータを用いてニューラルネットワークを学習し、レシピと画像の共同埋め込みを学習することで、画像-レシピ検索タスクにおいて素晴らしい結果を得ることができた。さらに、高レベルの分類目的を追加して正則化することで、検索性能が人間に匹敵するほど向上し、セマンティック・ベクトル演算が可能になることを実証した。これらのエンベッディングは、Recipe1M+データセットや、食べ物や料理全般についてのさらなる研究の基盤となると考えている。コード、データ、モデルは公開されています。
強化学習のための政策勾配法の新しいファミリーを提案する。これは、環境との相互作用によるデータのサンプリングと、確率的勾配上昇法を用いた「代理」目的関数の最適化を交互に行うものである。標準的な政策勾配法はデータサンプルごとに1回の勾配更新を行うが、我々はミニバッチ更新の複数のエポックを可能にする新しい目的関数を提案する。近似政策最適化(PPO)と呼ぶこの新しい手法は、信頼領域政策最適化(TRPO)の利点をいくつか備えていますが、実装がはるかに簡単で、より一般的で、サンプルの複雑さも改善されています(経験的に)。我々の実験では、ロボットの運動シミュレーションやAtariゲームのプレイなどのベンチマークタスクのコレクションでPPOをテストし、PPOが他のオンラインポリシー勾配法よりも優れており、全体的にサンプルの複雑さ、シンプルさ、ウォールタイムのバランスが取れていることを示している。
Generative Adversarial Networks (GAN)は、リアルな自然画像を生成するタスクで目覚ましい成果を上げています。それは、生成器と識別器の間の敵対的なゲームとして解釈される困難な鞍点最適化問題を解くことと、生成器と識別器を深層畳み込みニューラルネットワークとしてパラメータ化することです。この論文の目的は、GANの成功に対するこの2つの要素の貢献を分離することです。具体的には、Generative Latent Optimization（GLO）という、単純な再構成損失を用いて深い畳み込みニューラルネットワークを学習するフレームワークを紹介します。GLOは、様々な実験を通して、GANの望ましい特性の多くを享受していることを示しています。例えば、視覚的に魅力的なサンプルを合成したり、サンプル間で意味のある補間を行ったり、ノイズベクトルで線形演算を行ったりしていますが、これらはすべて、敵対的な最適化スキームを使用していません。
リカレント・ニューラル・ネットワーク・アーキテクチャーの技術革新により、言語モデリング・ベンチマークにおける最新の結果が続々と発表されています。しかし，これらの結果は，異なるコードベースと限られた計算資源を用いて評価されており，実験のばらつきの原因となっています．本研究では、いくつかの一般的なアーキテクチャと正則化手法を、大規模なブラックボックスによるハイパーパラメータの自動調整を用いて再評価し、標準的なLSTMアーキテクチャが適切に正則化された場合には、最近のモデルよりも優れているという、やや意外な結論を得ました。我々は、Penn TreebankとWikitext-2のコーパス、およびHutter Prizeデータセットの強力なベースラインにおいて、新しい技術水準を確立しました。
深層強化学習（RL）は、難しい制御問題でいくつかの注目すべき成功を収めています。しかし、これらのアルゴリズムは、妥当な性能に到達するまでに膨大な量のデータを必要とします。実際、学習中のパフォーマンスは非常に低いことがあります。これは、シミュレータでは許容できるかもしれないが、エージェントが実環境で学習しなければならない多くの実世界の課題へのディープRLの適用を大きく制限する。本論文では、エージェントがシステムを以前に制御した時のデータにアクセスできる設定を研究する。我々は、このデータを活用して、比較的少量のデモデータからでも学習プロセスを大幅に加速するアルゴリズム「Deep Q-learning from Demonstrations（DQfD）」を発表する。DQfDは、時間的な差分の更新と、実演家の行動の大まかな分類を組み合わせることで機能する。我々は、DQfDがDeep Q-Networks（DQN）よりも初期性能が優れていることを示し、42のAtariゲームのうち27のゲームでDQNよりも多くの平均報酬を獲得した。また、劣悪なデモデータが与えられた場合でも、DQfDはDQNよりも高速に学習することを実証しました。
ドメイン類似性測定は、適応性を評価し、伝達学習に適したデータを選択するために使用することができるが、既存のアプローチでは、それぞれのタスクに適していると考えられるアドホックな測定を定義している。本研究では、カリキュラム学習にヒントを得て、ベイズ最適化を用いてデータ選択尺度を学習し、モデル、ドメイン、タスク間で評価することを提案します。我々の学習した尺度は、感情分析、品詞タグ付け、構文解析の3つのタスクにおいて、既存のドメイン類似性尺度を大幅に上回る。我々は、類似性を多様性で補完することの重要性を示し、学習された測定値がモデル、ドメイン、さらにはタスクを超えてある程度伝達可能であることを示した。
本研究では、softmaxのような飽和した出力活性化関数が、多くの標準的な分類タスクでの学習を妨げることを示しています。さらに、ソフトマックスの有用性は、一部の人が推測しているように、正規化に起因するものではないことを示す結果を示します。実際には、正規化は状況を悪化させます。むしろ、誤差の勾配を指数関数的に増加させることに利点があるのです。この指数関数的な勾配ブーストは、収束を速め、一般化を向上させることが示されています。具体的には，CIFAR-10とImageNetを用いた画像分類，およびPASCAL VOC 2012を用いたセマンティック・セグメンテーションという多様な分類タスクにおいて，収束の速さと性能の向上を実証している．後者では、最新のニューラルネットワークアーキテクチャを用いた場合、標準的なソフトマックスを用いた場合と比較して、我々の手法ではモデルの収束が33%早く（学習期間が約2日短く）、さらに性能もわずかに向上しました。
機械学習は、明確な目標を持つ多くの分野で優れた成果を上げています。しかし、写真のような芸術分野では、明確なゴールは通常ありません。写真の成功は、その美的価値によって評価されますが、これは非常に主観的な概念です。このことが、機械学習によるアプローチの課題となっています。私たちは、芸術的なコンテンツ制作のための深層学習システムであるCreatismを紹介します。我々のシステムでは、美学を複数の側面に分解し、それぞれがプロの例の共有データセットから個別に学習できるようにしています。各アスペクトは、効率的に最適化できる画像操作に対応しています。新しい編集ツールであるドラマチック・マスクは、写真の劇的な照明を改善する操作の一つとして紹介されています。本システムの学習には、撮影前と撮影後の画像ペアを含むデータセットや、美学上の異なる側面を示すラベルは必要ありません。このシステムを使って、風景写真家のワークフローを模倣します。最高の構図を作るためのフレーミングから、さまざまな後処理の実行まで。バーチャルフォトグラファーの環境は、Google Street Viewのパノラマ画像の集合体でシミュレートされています。また、プロの写真家が、異なるソースの写真をブラインドで評価する「チューリングテスト」のような実験を行い、作品の品質を客観的に評価します。実験の結果、ロボットの作品の一部がプロの作品と混同されることがわかりました。
ほとんどの機械学習アルゴリズムは、敵対的な摂動の影響を受けやすいことがわかっている。画像空間内で慎重に選んだ方向に画像をわずかに擾乱すると、訓練されたニューラルネットワークモデルがその画像を誤って分類してしまうことがあります。最近では、物理的な敵対的事例が存在することが示されました。摂動を与えた画像を印刷して、その写真を撮ると、やはり誤分類されてしまいます。これは、セキュリティや安全性に関わる問題です。しかし、これらの実験は、物理的な物体の重要な特性を無視しています。つまり、カメラは異なる距離と角度から物体を見ることができます。本論文では、現在の物理的な敵対例の構造では、動いているプラットフォームからの物体検出が妨げられないことを示唆する実験結果を示します。それどころか、学習したニューラルネットワークは、擾乱された画像の異なる距離と角度から撮影された写真のほとんどを正しく分類する。これは、摂動の敵対特性が摂動画像を見るスケールに敏感であるため、（例えば）自律走行車が停止標識を誤って分類するのは、わずかな距離の範囲に限られるからだと考えている。私たちの研究は、多くの、あるいはほとんどの視聴条件において敵対的な例を構築することができるのか、という重要な問題を提起しています。もし可能であれば、深層ネットワークによるパターンの内部表現について、非常に重要な洞察が得られるはずです。もしそうでなければ、敵対的な例は実用的な影響の少ない好奇心に過ぎなくなる可能性が高いです。
ディープニューラルネットワークは、大量のデータがある場合には優れた性能を発揮しますが、データが少ない場合やタスクの変化に素早く適応する必要がある場合には苦戦する傾向があります。最近のメタ学習は、類似したタスクの分布に対してメタ学習者を訓練することで、この欠点を克服しようとしている。メタ学習者は、解決を求められている問題の本質を捉えた高レベルの戦略を学習することで、新規だが関連性のあるタスクに一般化することを目指している。しかし、最近のメタ学習のアプローチは、特定のアプリケーションに特化したアーキテクチャを使用するか、タスクを解決する方法をメタ学習者に伝えるアルゴリズムコンポーネントをハードコーディングするか、広範囲に渡って手作業で設計されている。我々は、時間的な畳み込みに基づいた、シンプルで汎用的なメタ学習器のアーキテクチャを提案する。時間的コンボリューションに基づくメタ学習器(TCML)を、教師付き学習と強化学習の両方に関する実験で検証し、一般性が低く複雑な最先端の手法よりも優れていることを示した。
注意メカニズムを備えたリカレントニューラルネットワークモデルは、様々な配列対配列の問題に対して非常に有効であることが証明されています。しかし、ソフトアテンションメカニズムは、出力シーケンスの各要素を生成する際に、入力シーケンス全体に対してパスを実行するという事実から、オンライン設定での使用は不可能であり、二次的な時間の複雑さをもたらします。本論文では、多くの問題で入力配列と出力配列の間のアライメントが単調であるという洞察に基づいて、単調なアライメントを学習するためのエンドツーエンドの微分可能な方法を提案する。文章要約、機械翻訳、オンライン音声認識などの問題で本手法を検証し、既存の sequence-to-sequence モデルと競合する結果を得た。
多くの教師付き学習タスクは、英語からフランス語への翻訳とフランス語から英語への翻訳、音声認識と音声合成、画像分類と画像生成などのように、二重の形式で出現します。2つのデュアルタスクは、モデル間の確率的な相関関係により、お互いに本質的なつながりを持っています。しかし、通常、2つのデュアルタスクのモデルを別々に訓練するため、この関係は今日では効果的に利用されていません。本研究では、2つのデュアルタスクのモデルを同時に学習し、それらの間の確率的相関を明示的に利用して学習プロセスを正則化することを提案する。本研究では，2つのタスクのモデルを同時に学習し，その間の確率的な相関関係を利用して学習プロセスを正則化することを提案する．本論文では，機械翻訳，画像処理，感情分析などの様々なアプリケーションにおいて，双対教師付き学習が両タスクの実用的な性能を向上させることを実証する．
シーケンス・ツー・シークエンス・モデルで使用される標準的なコンテンツ・ベースのアテンション・メカニズムは、各時間ステップで大規模なエンコーダとデコーダの状態を比較する必要があるため、計算量が多くなります。本研究では、より効率的な、固定サイズのメモリ表現に基づく代替的な注目メカニズムを提案する。この手法では、エンコーディング時にK個のアテンションコンテキストを予測し、デコーダではメモリを参照しない効率的なルックアップを計算する。本手法は、標準的なアテンションメカニズムと同等の性能を発揮する一方で、実世界の翻訳タスクでは20％、より長いシーケンスのタスクではそれ以上の推論速度を得ることができることを示す。また、アテンションスコアを可視化することで、我々のモデルが明確で意味のあるアライメントを学習していることを示す。
NoisyNetは、重みにパラメトリックなノイズを付加した深層強化学習エージェントであり、エージェントのポリシーに誘起される確率を利用して、効率的な探索を行うことができることを示しています。ノイズのパラメータは、ネットワークの残りの重みと一緒に勾配降下法で学習されます。NoisyNetは簡単に実装でき、計算上のオーバーヘッドもほとんどありません。我々は、A3C、DQN、決闘エージェントの従来の探索ヒューリスティックス（それぞれentropy rewardと\epsilon-greedy）をNoisyNetに置き換えることで、広範囲のAtariゲームのスコアが大幅に向上し、場合によってはエージェントをサブから超人的なパフォーマンスにまで高めることができることを発見した。
多くの実世界のシナリオでは、特定の機械学習タスクのためのラベル付きデータを取得するにはコストがかかります。半教師付き学習法は、豊富にあるラベルなしのデータと、より少ない数のラベル付きの例を利用する。我々は、人間の学習にヒントを得て、ディープニューラルネットワークを半教師付きで学習するための新しいフレームワークを提案する。このフレームワークでは、ラベル付きサンプルのエンベッディングとラベルなしサンプルのエンベッディングとの間に「関連付け」が行われる。最適化スケジュールは、連想が開始されたクラスと同じクラスで終わる正しい連想サイクルを奨励し、異なるクラスで終わる間違った連想にペナルティを与えます。この実装は使いやすく、既存のエンド・ツー・エンドの学習セットアップに追加することができます。我々は、いくつかのデータセットで関連付け学習の機能を実証し、追加で利用可能なラベルのないデータを利用することで、分類タスクのパフォーマンスを大幅に向上させることができることを示した。特に、ラベル付きデータが少ないケースでは、我々の学習スキームは、SVHNに関する現在の技術水準を上回る。
本論文は、ディープ・ニューラル・ネットワーク・モデルを解釈し、その予測を説明するという問題への入り口を提供するものです。これは、ICASSP 2017で行われたチュートリアルに基づいています。最近提案された解釈のテクニックを、理論、トリック、推奨事項とともに紹介しており、実際のデータでこれらのテクニックを最も効率的に利用することができます。また、いくつかの実用的なアプリケーションについても説明しています。
この論文では、レストラン領域におけるエンドツーエンドのデータ駆動型自然言語生成システムをトレーニングするための新しいデータセットであるE2Eデータについて説明しています。このデータセットは、この領域で頻繁に使用されている既存のデータセットの10倍の大きさです。E2Eデータセットには新たな課題があります。(1)人間の参照テキストは、談話現象を含めて、より多くの語彙の豊かさと構文のバリエーションを示しています。そのため、このデータセットから学習することで、より自然で変化に富み、テンプレートのようなシステム発話ではなくなることが期待できます。また、このデータセットでベースラインを確立し、このデータに関連するいくつかの困難を説明しています。
ハイパーパラメータのチューニングは、深層学習において最も時間のかかる作業の1つです。AdaGrad、RMSProp、Adamなどの最先端のオプティマイザーは、各変数に対して個別の学習率を適応的にチューニングすることで、この労力を軽減しています。最近、研究者たちは、より良いテスト指標を得られる可能性があるとして、モメンタムSGDのような単純な手法に再び関心を示している。この傾向に触発され、我々は「SGDに基づく単純な適応手法は、同等以上の性能を発揮できるのか？我々はmomentum SGDアルゴリズムを再検討し、単一の学習率とmomentumをハンドチューンすることで、Adamと競合することを示す。また、学習率の誤指定や目的曲率の変化に対するSGDの頑健性を分析します。これらの洞察に基づいて、SGDにおける運動量と学習率の自動調整機能であるYellowFinを設計する。YellowFinはオプションで負帰還ループを使用し、非同期設定での運動量のダイナミクスをオンザフライで補正する。画像認識、言語モデリング、構文解析において、YellowFinはAdamよりも少ない反復回数で収束させることができ、同期時には最大3.28倍、非同期時には最大2.69倍のスピードアップが可能であることを実証的に示しています。
GANS(Generative Adversarial Nets)は実際にターゲットの分布を学習するのか？Goodfellow et al 2014）の基礎論文では、十分に大きなディープネット、サンプルサイズ、計算時間が与えられれば、学習することが示唆されていました。Aroraらの最近の理論的分析（ICML 2017に掲載予定）では、識別器が有限サイズの場合に同じことが成り立つかどうか疑問を呈しています。それによると、生成された分布の支持率が非常に低くても、学習目的は最適値に近づくことができる、つまり、学習目的はモード崩壊を防ぐことができないことが示された。本論文では、このような問題が単に理論的なものではないことを示唆する実験結果を報告する。よく知られているGANsアプローチは、かなり低い支持率の分布を学習するため、目標とする分布を学習していないと推測される実証的な証拠を示している。主な技術的貢献は、生成された分布のサポートサイズを推定するための、有名なバースデーパラドックスに基づいた新しいテストの提案です。
我々は、形式言語で表現された宣言的プログラムを実行する深層RLエージェントを構築した。エージェントは、この言語の用語を環境中で学習し、テスト時には、学習時には参照されなかったオブジェクトを参照する新しいプログラムを実行するように行動を一般化することができる。このようにしてエージェントは、様々なゼロショットの意味論的タスクに一般化することができる、分離した解釈可能な表現を開発する。
本研究では、深層学習における記憶の役割を検討し、容量、一般化、敵対的頑健性との関連を示した。深層ネットワークは、ノイズデータを記憶することができるが、我々の結果は、深層ネットワークはまず単純なパターンを学習することを優先する傾向があることを示唆している。実験では、ノイズデータと実データに対するディープニューラルネットワーク（DNN）の勾配ベースの最適化の質的な違いを明らかにしました。また、明示的な正則化（ドロップアウトなど）を適切に調整することで、実データでの一般化を損なうことなく、ノイズデータでのDNNの学習性能を低下させることができることを示した。また、データセットに依存しない有効容量の概念は、学習データ自体が記憶の度合いを決定する上で重要な役割を果たすため、勾配法で学習した場合のディープネットワークの汎化性能を説明することはできないことを示唆している。
日本の漫画は「マンガ」と呼ばれ、世界中で親しまれています。マンガは伝統的に白黒で制作されており、カラー化には時間とコストがかかります。自動カラー化の方法は、一般的にグレースケールの値に依存しますが、これはマンガには存在しません。さらに、著作権保護のため、トレーニングに利用できるカラー化されたマンガはほとんどありません。我々は、条件付き生成アドバーサリア・ネットワーク（cGAN）に基づいたマンガの色付け手法を提案する。従来のcGAN手法では，数百から数千の学習画像を使用していたが，本手法では，学習に必要なのは1枚の着色された参照画像のみであり，大規模なデータセットを必要としない．cGANを使ってマンガをカラー化すると、アーチファクトのあるぼやけた結果になり、解像度も限られてしまう。そこで、これらの問題を軽減するために、セグメンテーションと色補正の方法も提案しています。最終的な結果は、シャープでクリアな高解像度のものとなり、キャラクターのオリジナルの配色に忠実なものとなりました。
過去5年間で、視覚関連のタスクのために教師ありきで訓練された、信じられないほど性能の高いフィードフォワード・ニューラルネットワークが台頭してきました。これらのモデルは、静止画中の物体認識、位置特定、および検出において超人的な性能を達成しています。しかし、これらのネットワークを時間的な視覚入力に適用し、ビデオデータのロバストで安定した表現を得るための最適な戦略を特定する必要があります。本研究では、人間の視覚システムにヒントを得て、ボトムアップ型のフィードフォワード接続だけでなく、視覚野に存在するトップダウン型のフィードバック接続やラテラル接続もモデル化した深層ニューラルネットワークCortexNetを提案する。本研究では、教師なしのMatchNetモードと教師ありのTempoNetモードの2つの学習方式を導入し、自己運動の手がかりを学習することで、ビデオクリップの次のフレームや主な被写体の身元を正しく予測する方法や、現在のシーンで複数の物体を自動的に追跡する方法を学習します。プロジェクトのウェブサイトはこちらのhttps URLからご覧いただけます。
本研究では、物体のインスタンスを半自動的にアノテーションする手法を提案する。現在の多くの手法では、オブジェクトのセグメンテーションをピクセルのラベリング問題として扱っているが、ここではポリゴンの予測タスクとして扱っている。具体的には、画像の切り抜きを入力とし、物体の輪郭を示す多角形の頂点を順次生成する。これにより、人間のアノテーターがいつでも介入し、必要に応じて頂点を修正することができ、アノテーターが望むような正確なセグメンテーションを生成することができます。その結果、Cityscapesの全クラスにおいて、アノテーション作業を4.7倍高速化することができました。また、IoUにおいては、オリジナルのグランドトゥルースと78.4%の一致率を達成し、人間のアノテーター間の典型的な一致率と一致しました。また，自動車では，7.3倍の高速化を実現し，82.2%の一致率を達成しました．さらに、我々のアプローチが未知のデータセットに対して一般化できることを示しました。
歌の合成のための新しいモデルを、WaveNetアーキテクチャの修正バージョンに基づいて発表しました。生の波形をモデル化する代わりに，音程と音色の影響を分離したパラメトリック・ボコーダによって生成された特徴をモデル化する．これにより、任意のターゲットメロディに合わせてピッチを簡単に変更することができ、より小さいサイズのデータセットでのトレーニングが容易になり、トレーニングおよび生成時間が大幅に短縮されます。このモデルは、必要なパラメータ数を減らすために、カテゴリ出力ではなく混合密度出力を用いてフレームごとの予測を行います。実験で使用した比較的小さなデータセットではオーバーフィッティングが問題となったため，モデルを正則化し，自己回帰生成プロセスを予測誤差に対してよりロバストにする方法を提案した．シンプルなマルチストリーム・アーキテクチャを用いて，高調波成分，非周期成分，有声/無声成分のすべてを一貫して予測することができる。この方法を、定量的な指標とリスニングテストを用いて、既存のパラメトリック統計的手法や最新の連結的手法と比較しました。自己回帰生成アルゴリズムの素朴な実装は非効率的な傾向があるが、スマートなアルゴリズムを用いることでプロセスを大幅に高速化し、速度と品質の両方で競争力のあるシステムを得ることができる。
本論文では、GAN（generative adversarial network）を用いて、初心者のユーザーが実世界の形状をデザインするのを簡単なインターフェースで支援するというアイデアを提案している。ユーザーは、（Minecraftのような）ペイントインターフェースでボクセルグリッドを編集します。このコマンドは、学習された投影演算子を用いて、現在のボクセルグリッドを潜在的な形状多様体に投影し、学習された生成ネットワークを用いて、似ているがより現実的な形状を生成します。その後、ユーザーは結果の形状を編集し、満足のいく結果が得られるまで再度スナップすることができる。このアプローチの主な利点は、投影演算子と生成演算子によって、初心者のユーザーが、オブジェクト形状の背景分布に特徴的な3Dモデルを、すべての詳細を指定することなく作成できることです。このアプリケーションをサポートするためにGANを使用するというのが、新しい研究アイデアの核心です。3D GANはこれまで、形状の生成、補間、補完などに使われてきましたが、インタラクティブなモデリングには使われていませんでした。このアプリケーションの新しい課題は、任意の3Dボクセルモデルを受け取り、形状多様体上の潜在的なベクトルを生成し、そこから類似した現実的な形状を生成することができる投影演算子を学習することです。我々は、SNAP処理パイプラインのこのステップと他のステップのためのアルゴリズムを開発し、それらをシンプルなモデリングツールに統合した。これらのアルゴリズムとツールを用いた実験により、GANがコンピュータ支援によるインタラクティブなモデリングに有望なアプローチを提供することが示唆された。
ディープラーニングは、音声認識、画像分類、翻訳など、様々な分野で素晴らしい結果をもたらします。しかし、それぞれの問題に対して、ディープモデルをうまく機能させるには、アーキテクチャの研究と長い期間のチューニングが必要です。本研究では、複数のドメインにまたがる多くの問題で良好な結果をもたらす単一のモデルを紹介します。具体的には、ImageNet、複数の翻訳タスク、画像キャプション（COCOデータセット）、音声認識コーパス、英語構文解析タスクにおいて、この単一モデルを同時に学習します。このモデルのアーキテクチャには、複数のドメインの構成要素が組み込まれています。このモデルには、畳み込み層、アテンション・メカニズム、スパースリー・ゲーテッド層が含まれています。これらの計算ブロックはそれぞれ、学習対象となるタスクのサブセットに不可欠なものです。興味深いことに、あるタスクにとって重要でないブロックであっても、それを追加することで性能が低下することはなく、ほとんどの場合、すべてのタスクで性能が向上することがわかりました。また、データ量の少ないタスクでは、他のタスクとの共同学習が大きな効果を発揮しますが、大規模なタスクでは、パフォーマンスの低下はわずかであることを示しています。
学習ベースの手法は、1枚の画像から深度を推定するタスクで非常に有望な結果を示している。しかし、既存の手法のほとんどは、深度予測を教師付き回帰問題として扱っており、その結果、トレーニングのために膨大な量の対応するグランドトゥルース深度データが必要となります。様々な環境下で高品質の深度データを記録することは、困難な問題です。この論文では、既存のアプローチを革新し、学習時に明示的な深度データを使用する代わりに、より簡単に入手できる両眼ステレオ映像を使用します。
深層ニューラルネットワークは、大規模なデータ領域では大きな成功を収めていますが、一般的には、各クラスのごく少数の例を見ただけでモデルを迅速に一般化しなければならないような、少数ショットの学習タスクでは性能が低いと言われています。一般的には、大容量モデルにおける勾配ベースの最適化は、良好な性能を発揮するために多くの例を用いて多くの反復ステップを必要とすると考えられています。ここでは、LSTMベースのメタ学習モデルを提案し、少数ショット領域で別の学習者ニューラルネットワークを学習するために使用される正確な最適化アルゴリズムを学習する。我々のモデルのパラメータ化により、設定された量の更新が行われるシナリオに特化した適切なパラメータ更新を学習することができ、同時に学習の迅速な収束を可能にする学習者ネットワークの一般的な初期化を学習することができる。我々は、このメタ学習モデルが、数ショットの学習を行う深層メトリック学習技術と競合することを実証する。
変分オートエンコーダーや生成的敵対ネットワークを用いて学習される深層潜在変数モデルは、現在、連続構造の表現学習の重要な手法となっている。しかし、同様の手法をテキスト列や離散化された画像などの離散的な構造に適用することは、より困難であることが判明している。本研究では、離散構造の深層潜在変数モデルを学習するための柔軟な方法を提案する。我々のアプローチは、最近提案されたWasserstein autoencoder (WAE)に基づいており、これはAdversarial autoencoder (AAE)を最適輸送問題として形式化したものである。まず、このフレームワークを離散的なシーケンスをモデル化するように拡張し、制御可能な表現をターゲットとした様々な学習されたプライヤーをさらに探求します。この敵対的正則化自動符号化器(ARAE)により、自然なテキスト出力を生成することができ、また潜在空間を操作して出力空間に変化を与えることもできる。最後に、この潜在表現を訓練することで、既存の手法と比較して、自動評価と人間評価の両方で改善が得られることを示す。
背景 深層学習モデルは一般的に、確率的勾配降下法またはその亜種の一つを用いて学習されます。これらの手法では、学習データのごく一部から推定した勾配を用いて重みを更新します。しかし、大きなバッチサイズを使用した場合、「汎化ギャップ」現象として知られる汎化性能の持続的な低下が観察されています。このギャップの原因を特定し、それを解消することが課題となっていました。貢献度 本研究では，学習率の高い初期の学習段階について検討した．その結果，初期値からの重みの距離は，重みの更新回数に応じて対数的に増加することがわかった．そこで、同様の「超低速」な拡散挙動を示すことが知られている「ランダムウォーク・オン・ランダム・ランドスケープ」という統計モデルを提案します。この仮説に基づいて実験を行い、「汎化ギャップ」はバッチサイズではなく更新回数が比較的少ないことに起因しており、使用する学習レジームを適応することで完全に排除できることを実証的に示した。さらに、大規模なバッチ体制でモデルを学習するためのさまざまな手法を検討し、「Ghost Batch Normalization」という新しいアルゴリズムを発表しました。このアルゴリズムは、更新回数を増やすことなく、一般化ギャップを大幅に減少させることができます。さらに、我々の発見を検証するために、MNIST、CIFAR-10、CIFAR-100、ImageNetを用いていくつかの実験を行った。最後に、深層モデルの学習に関する一般的な慣習や信念を再評価し、良好な汎化を達成するためには最適ではない可能性を示唆する。
確率的勾配降下法（SGD）とその亜種は、多くの深層学習タスクで選択されるアルゴリズムです。これらの手法は、学習データの一部（例えば32～512個のデータポイント）をサンプリングして、勾配の近似値を計算するスモールバッチ方式で動作します。しかし、実際には、より大きなバッチを使用すると、一般化能力によって測定されるモデルの品質が低下することが観察されています。我々は、ラージバッチ領域での汎化能力低下の原因を調査し、ラージバッチ法はトレーニング関数とテスト関数の急激な最小化に収束する傾向があるという見解を支持する数値的証拠を提示した。対照的に、スモールバッチ法は一貫して平坦な最小化器に収束し、我々の実験は、これが勾配推定に内在するノイズによるものであるという一般的な見解を支持するものである。我々は、大規模バッチ法がこの汎化ギャップを解消するためのいくつかの戦略を議論する。
強化学習（RL）における主な課題の1つは、汎化です。典型的な深層学習手法では、深層ネットワークを用いて、最適な価値関数を低次元の表現で近似することで達成される。この手法は多くの領域で有効であるが、最適価値関数を低次元表現に容易に還元できない領域では、学習が非常に遅く不安定になる可能性がある。本論文では、Hybrid Reward Architecture (HRA)と呼ばれる新しい手法を提案することで、このような困難な領域への取り組みに貢献します。HRAは、分解された報酬関数を入力とし、各構成要素の報酬関数に対して個別の価値関数を学習する。各成分は通常、すべての特徴のサブセットにしか依存しないため、対応する価値関数は低次元の表現でより簡単に近似することができ、より効果的な学習が可能となる。HRAは、おもちゃの問題とAtari社のゲーム「Ms.Pac-Man」でデモンストレーションを行い、人間以上の性能を達成しました。
ディープネットワークの出力を説明することは、依然として難しい課題です。画像分類器の場合、説明の1つのタイプは、最終的な決定に強く影響するピクセルを特定することです。この戦略の出発点となるのは、入力画像に対するクラススコア関数の勾配です。この勾配は、感度マップとして解釈することができ、この基本的なアイデアを詳しく説明するいくつかのテクニックがあります。この論文では、2つの貢献をしています。1つは、勾配に基づく感度マップを視覚的にシャープにするのに役立つ簡単な方法であるSmoothGradを紹介し、もう1つは、これらのマップの視覚化における教訓について論じています。また、実験のためのコードと、結果を掲載したウェブサイトを公開します。
洗練された強化学習（RL）システムが実世界の環境と有用に相互作用するためには、これらのシステムに複雑な目標を伝える必要がある。本研究では、軌道セグメントのペアに対する（専門家ではない）人間の好みで定義されるゴールを探求する。このアプローチは、Atariゲームやロボットの運動シミュレーションなど、報酬関数にアクセスできない複雑なRLタスクを効果的に解決できることを示した。これにより、人間による監視のコストが大幅に削減され、最先端のRLシステムに実用的に適用できるようになりました。このアプローチの柔軟性を示すために、人間が1時間程度の時間をかけて複雑な新しい行動を訓練することに成功しました。これらの行動や環境は、これまで人間のフィードバックから学習されたものよりもかなり複雑なものです。
主なシーケンス変換モデルは、複雑なリカレントニューラルネットワークまたはコンボリューショナルニューラルネットワークをベースにした、エンコーダーとデコーダーの構成になっています。また、最も優れたモデルでは、エンコーダとデコーダをアテンションメカニズムで接続している。我々は、再帰や畳み込みを一切使わず、注目メカニズムのみに基づいた新しいシンプルなネットワークアーキテクチャ「Transformer」を提案する。2つの機械翻訳タスクを用いた実験では、これらのモデルが優れた品質を持つ一方で、並列化が可能であり、学習に必要な時間も大幅に短縮されることがわかった。WMT 2014の英独翻訳タスクにおいて、我々のモデルは28.4BLEUを達成し、アンサンブルを含む既存の最良の結果よりも2BLEU以上向上しました。WMT 2014の英仏翻訳タスクでは、8つのGPUを用いて3.5日間の学習を行った結果、単一モデルで41.8という最先端のBLEUスコアを新たに確立しました。このトランスフォーマーは、大規模および限定的な学習データを用いた英語の構文解析に適用することで、他のタスクへの汎用性が高いことを示しています。
Deep Learningは、畳み込みニューラルネットワーク(CNN)による視覚の革命と、リカレントニューラルネットワーク(RNN)による自然言語処理の革命をもたらしました。しかし、標準的なフィード・フォワード・ニューラル・ネットワーク（FNN）を用いたDeep Learningの成功例は稀である。FNNは一般的に浅い表現であるため、多くのレベルの抽象的な表現を利用することができません。我々は、自己正規化ニューラルネットワーク（SNN）を導入し、高レベルの抽象表現を可能にする。バッチ正規化では明示的な正規化が必要ですが、SNNのニューロン活性化は自動的にゼロ平均と単位分散に収束します。SNNの活性化関数は「スケールド・エクスポネンシャル・リニア・ユニット（SELU）」と呼ばれ、自己正規化の性質を持っています。バナッハの定理を用いて、平均値と単位分散がゼロに近い活性化関数が、多くのネットワーク層に伝搬されると、ノイズや摂動があっても、平均値と単位分散がゼロに向かって収束することを証明した。SNNのこの収束特性により、(1)層数の多いディープネットワークの学習、(2)強い正則化の採用、(3)学習のロバスト性の向上が可能になる。さらに、単位分散に近くない活性化に対しては、分散の上界と下界が証明されているため、勾配の消失や爆発は起こりえない。SNNは、UCIの機械学習リポジトリに登録されている121のタスク、（b）創薬のベンチマーク、（c）天文学のタスクにおいて、標準的なFNNや、ランダムフォレストやサポートベクターマシンなどの他の機械学習手法と比較した。SNNは、UCIの121のタスクにおいて、競合するすべてのFNN手法を大幅に上回り、Tox21データセットでは競合するすべての手法を上回り、天文学データセットでは新記録を達成した。勝利したSNNアーキテクチャは、しばしば非常に深いものとなっています。実装は以下のURLで公開されています：このhttpのURL。
マルチエージェント領域のための深層強化学習法を研究しています。まず、従来のアルゴリズムがマルチエージェントのケースでは難しいことを分析します。Q-learningは、環境の本質的な非定常性に悩まされ、policy gradientは、エージェントの数が増えると分散が大きくなるという問題がある。我々は、他のエージェントの行動方針を考慮するアクター批判法の適応を提案し、複雑なマルチエージェントの協調を必要とする方針をうまく学習することができる。さらに、各エージェントの政策のアンサンブルを利用した学習方法を導入し、よりロバストなマルチエージェント政策を実現する。本研究では、協力的なシナリオや競争的なシナリオにおいて、エージェント集団が様々な物理的および情報的な協調戦略を発見することができ、既存の手法と比較して本アプローチの強みを示した。
関係推論は、一般的な知的行動の中心的な要素であるが、ニューラルネットワークでは学習が困難であることがわかっている。本論文では、関係性推論に根本的に依存する問題を解決するために、関係性ネットワーク（RN）をシンプルなプラグアンドプレイ・モジュールとして使用する方法を説明する。CLEVRと呼ばれる難解なデータセットを用いた視覚的な質問応答、bAbIタスク群を用いたテキストベースの質問応答、動的物理システムに関する複雑な推論という3つのタスクについて、RNで補強したネットワークをテストしたところ、最先端の超人的な性能を達成した。さらに、「Sort-of-CLEVR」と呼ばれる精選されたデータセットを用いて、強力な畳み込みネットワークは関係性のある質問を解決する一般的な能力を持っていないが、RNで補強するとこの能力を獲得できることを示している。我々の研究は、RNモジュールを搭載した深層学習アーキテクチャが、エンティティとその関係について暗黙的に発見し、推論を学ぶことができることを示している。
本論文では、Wikipediaをユニークな知識源として、オープンドメインの質問応答に取り組むことを提案します。大規模な機械読解のこのタスクは、文書検索の課題（関連する記事を見つける）とテキストの機械理解の課題（それらの記事からの回答スパンを識別する）を組み合わせたものです。我々のアプローチは、ビグラムハッシュとTF-IDFマッチングに基づいた検索コンポーネントと、Wikipediaの段落内の回答を検出するように訓練された多層リカレントニューラルネットワークモデルを組み合わせたものです。複数の既存のQAデータセットを用いた実験により、(1)両モジュールは既存の対応するモジュールに対して高い競争力を持ち、(2)両モジュールの組み合わせに対する遠隔監視を用いたマルチタスク学習は、この困難なタスクに対して効果的な完全なシステムであることが示された。
モバイルアプリケーションでは、ピクセル単位のセマンティックセグメンテーションをリアルタイムで実行できることが最も重要です。この課題に取り組む最近のディープニューラルネットワークは、大量の浮動小数点演算を必要とし、ランタイムが長く、使い勝手が悪いという欠点があります。本論文では、低遅延動作を必要とするタスクのために特別に開発された、ENet（efficient neural network）と名付けられた新しいディープニューラルネットワークアーキテクチャを提案します。ENetは、最大で18倍の速度、75倍のFLOPs、79倍のパラメータを必要とせず、既存のモデルと同等以上の精度を実現します。CamVid」「Cityscapes」「SUN」の各データセットでテストを行い、既存の最先端手法との比較や、ネットワークの精度と処理時間のトレードオフについて報告しています。また、提案されたアーキテクチャの組み込みシステムでの性能測定結果を示し、ENetをさらに高速化するために可能なソフトウェアの改善点を提案します。
DeepMind Kineticsのヒューマンアクションビデオデータセットについて説明します。このデータセットには、400の人間の行動クラスが含まれており、各行動に対して少なくとも400のビデオクリップがある。各クリップは10秒程度で、異なるYouTubeの動画から取得されています。アクションは人間に焦点を当てており、楽器の演奏などの人間と物体のインタラクションや、握手などの人間と人間のインタラクションなど、幅広いクラスをカバーしています。このデータセットの統計、収集方法を説明し、このデータセットで人間の行動を分類するために訓練・テストされたニューラルネットワークアーキテクチャの基本的な性能を示します。また、データセットの不均衡が分類器の偏りにつながるかどうかについて、予備的な分析を行いました。
ResNetのようなスキップ結合を持つディープニューラルネットワークは、様々な画像分類ベンチマークにおいて優れた性能を示します。しかし、より深いネットワークを学習するという当初の動機は実際には当てはまらず、深さではなく容量の増加によって利益が得られることが観察されています。そこで我々は、ResNetからヒントを得て、単純なDiracウェイトのパラメータ化を提案する。これにより、明示的なスキップ結合を持たない非常に深いプレーンネットワークを学習しても、ほぼ同じ性能を得ることができる。このパラメータ化は、学習時にはわずかな計算コストしかかかりませんが、推論時には全くコストがかかりません。なぜなら、Diracパラメータ化とバッチ正規化の両方が畳み込みフィルタに折り込まれるため、ネットワークは畳み込み-ReLUペアの単純なチェーンになるからです。我々は、CIFAR-10のResNet-1001の精度を、28層のより広いプレーンなDiracNetで実現し、ImageNetのResNetsとほぼ一致させることができました。また、我々のパラメータ化により、残差ネットワークや非残差ネットワークにおける慎重な初期化の必要性がほとんどなくなりました。我々の実験のためのコードとモデルは、このhttpsのURLから入手可能です。
本論文は、情報検索モデリングにおける2つの考え方、すなわち、クエリが与えられたときに関連文書を予測することに焦点を当てた生成的検索と、クエリと文書のペアが与えられたときに関連性を予測することに焦点を当てた識別的検索について、統一的な説明を行う。我々は、ゲーム理論に基づくミニマックスゲームを提案し、両モデルを反復的に最適化する。一方、識別モデルは、ラベル付きおよびラベルなしのデータから信号を抽出することを目的としており、クエリが与えられた文書に対する基本的な関連性分布の適合に向けて生成モデルを訓練するためのガイダンスを提供する。一方、生成モデルは、現在の判別モデルに対する攻撃者として機能し、判別目的を最小化することで、敵対的な方法で判別モデルのための難しい例を生成します。この2つのモデルの競争において、統一されたフレームワークは両方の考え方を利用していることを示します。(i)生成モデルは、識別モデルからの信号を介して文書の関連性分布を適合させることを学習し、(ii)識別モデルは、生成モデルによって選択されたラベルのないデータを利用して、文書ランキングのためのより良い推定値を得ることができる。我々の実験結果では、ウェブ検索、アイテム推薦、質問応答などの様々なアプリケーションにおいて、強力なベースラインと比較して、Precision@5で23.96%、MAPで15.50%という大幅な性能向上が実証されている。
大規模な教師付きデータセットで学習したディープニューラルネットワークは、画像分類などのタスクで素晴らしい結果をもたらしている。しかし、十分な注釈付きのデータセットは収集に時間と費用がかかるため、より簡単に入手できる大規模だがノイズの多いデータセットへの関心が高まっている。本論文では、ディープニューラルネットワークが、真のラベルと誤ったラベルの数が圧倒的に多い学習データから一般化できることを示します。本論文では，MNIST，CIFAR，ImageNetのデータを用いて学習を行ったところ，非常に高いテスト性能が得られた．例えば，MNISTでは，きれいな学習例を100個のランダムにラベルを付けた例で希釈した後でも，90%以上のテスト精度が得られた．このような挙動は、ラベルのノイズが複数のパターンにまたがっており、誤ったラベルが紛らわしいクラスに偏っている場合でも維持される。この体制で学習するためには、データセットのサイズを大きくする必要があるが、それは正しいラベルが希釈された要因に関連しており、管理可能であることを示す。最後に、ノイズが増えると有効なバッチサイズが減少することを示す結果の分析を行う。
ニューラルネットワークにおける自然な勾配降下を近似するための効率的な方法を提案し、Kronecker-Factored Approximate Curvature (K-FAC)と呼ぶ。K-FACは、ニューラルネットワークのフィッシャー情報行列の効率的に反転可能な近似に基づいています。このフィッシャー情報行列は、対角線でも低ランクでもなく、場合によっては完全に非スパースでもあります。K-FACは、対角線でも低ランクでもなく、場合によっては完全に非疎なニューラルネットワークのフィッシャー情報行列の様々な大きなブロック（層全体に相当）を、より小さな2つの行列のクロネッカー積として近似することで導き出されます。K-FACの計算コストは通常の確率的勾配よりも数倍高いだけですが、K-FACによって生成された更新は、目的を最適化するためにはるかに多くの進展をもたらし、その結果、実際には勢いのある確率的勾配降下法よりもはるかに速いアルゴリズムとなります。また、高品質の非対角曲率行列を使用する以前に提案されたいくつかの近似自然勾配/ニュートン法（ヘシアンフリー最適化など）とは異なり、K-FACは高度に確率的な最適化レジームで非常によく機能します。これは、K-FACの曲率行列への近似値の保存と反転のコストが、曲率行列の推定に使用されるデータ量に依存しないためで、これは一般的に曲率行列の対角近似や低ランク近似にのみ見られる特徴である。
Generative Adversarial Networks (GAN) は、コンピュータビジョンの分野で注目を集めており、画像生成において素晴らしい結果をもたらしています。しかし、ノイズから自然言語を生成する逆問題ネットワークの進歩は、画像生成の進歩には及ばず、尤度ベースの手法にはまだ遠く及ばない。本論文では、GANの目的のみで自然言語を生成するための一歩を踏み出します。勾配推定器に頼らずに離散出力空間問題に対処する単純なベースラインを導入し、漢詩生成データセットで最先端の結果を達成できることを示す。文脈自由文法および確率的文脈自由文法からの文の生成に関する定量的な結果と、定性的な言語モデリングの結果を示す。また、文の特徴を条件として配列を生成する条件付き版についても説明する。
本論文では、機械学習の逆問題である機械教示の問題を考える。学習者をバッチ式のアルゴリズムとみなす従来の機械教示とは異なり、学習者は反復アルゴリズムを使用し、教師は学習者の現在のパフォーマンスに基づいて例を逐次的かつ知的に与えることができるという新しいパラダイムを研究する。反復学習の場合の教育の複雑さは、バッチ型の場合とは大きく異なることを示している。我々の反復型機械教授法は，学習者のために最小限の学習セットを構築する代わりに，学習者モデルの高速収束を達成することに焦点を当てている．教師が学習者モデルから得られる情報のレベルに応じて、教示例の数を減らし、教師なしの学習よりも高速に収束させることができる教示アルゴリズムを設計します。また、異なるデータ分布と実際の画像データセットを用いた広範な実験により、理論的な知見を検証する。
ソーシャルメディア上の個人は、様々な危機的状況（自殺、自傷行為、虐待、摂食障害など）にあることを明らかにすることがある。ソーシャルメディアのテキストから危機を自動的かつ正確に検出することは、重大な結果をもたらします。しかし、理由を説明せずに一般的な危機的状態を検出しても、その用途は限られています。ここでいう説明とは、危機の検出を合理化するための、テキストの一貫した簡潔なサブセットのことです。本研究では、ニューラル技術と非ニューラル技術を組み合わせて、危機を検出し説明するためのいくつかの方法を検討する。これらの手法を、様々なメッセージングアプリケーションを通じて利用可能な匿名の感情的サポートネットワークであるKokoから得られたユニークなデータセットで評価した。また、危機的状況とラベル付けされたサンプルの小さなサブセットに、対応する説明を付けた。我々の最良の手法は，検出と説明においてベースラインを大幅に上回った．
我々は，「ラベル付けされていない多数のビデオを見たり聞いたりすることで，何が学べるのか」という問題を考える．映像自体には、視覚と聴覚の対応関係という、これまで未利用だった貴重な情報源があります。制約のない生のビデオ以外には一切の監視を行わずに、視覚と聴覚のネットワークをゼロから学習することで、このタスクをうまく解決できることが示され、さらに興味深いことに、優れた視覚と聴覚の表現が得られる。これらの特徴は、2つの音の分類ベンチマークにおいて最先端を示し、ImageNetの分類においても最先端の自己教師付きアプローチと同等の性能を示した。また、このネットワークは、両方のモダリティでオブジェクトをローカライズし、細かい認識タスクを実行できることを示している。
標準的なリカレントニューラルネットワーク言語モデル（RNNLM）は、一度に1つの単語を生成し、明示的なグローバル文表現からは動作しません。本研究では、文全体の分散した潜在表現を組み込んだ、RNNベースの変分オートエンコーダー生成モデルを導入し、研究する。この因子化により、文のスタイル、トピック、高レベルの構文特徴など、文の全体的な特性を明示的にモデル化することができる。これらの文表現に対する事前処理からのサンプルは、単純な決定論的デコーディングによって、多様で整った文を顕著に生成する。この潜在空間を通過する経路を調べることで、既知の文の間を補う首尾一貫した新しい文を生成することができる。本論文では、このモデルが示す困難な学習問題を解決するための手法を提示し、欠落した単語の入力に有効であることを示し、このモデルの潜在文空間の多くの興味深い特性を探求し、言語モデリングにおけるこのモデルの使用に関する否定的な結果を提示する。
本論文では、芸術的スタイルのニューラルアルゴリズムの柔軟性と、高速スタイル転送ネットワークの速度を組み合わせ、あらゆるコンテンツ/スタイル画像ペアを使用してリアルタイムにスタイル化できる手法を紹介します。我々は、マルチスタイル転送ネットワークのための条件付きインスタンス正規化を活用した最近の研究を基に、スタイル画像から直接条件付きインスタンス正規化パラメータを予測するよう学習する。このモデルは、約80,000枚の絵画のコーパスで学習され、これまで観察されていなかった絵画にも一般化することができます。学習された埋め込み空間は滑らかで、豊かな構造を含んでおり、完全に教師なしの方法で絵画に関連する意味的情報を整理することを実証した。
疎な報酬の問題は、現代の強化学習において最も困難な課題の一つです。階層型強化学習（HRL）は、時間的に拡張された行動（オプション）のセットを使用してこの問題に取り組み、それぞれが独自のサブゴールを持っています。これらのサブゴールは通常、特定のタスクのために作られている。しかし、ここでは、視覚的な領域に広く適用できる一般的なサブゴールのクラスを紹介します。我々のアプローチの根底にあるのは、「環境の側面をコントロールする能力は、本質的に有用なスキルである」という仮説である（「補助タスク」を用いた研究と同様）。このようなサブゴールをエンド・ツー・エンドの階層型強化学習システムに組み込み、Atariシリーズのゲームの中から2種類のアルゴリズムをテストします。最も難しいゲームの1つであるMontezuma's revengeでは、疎な報酬を処理する能力が鍵となるため、我々のアプローチの優位性を強調している。このゲームでは，我々のエージェントは現在の最先端のHRLエージェントよりも数倍速く学習し，同程度の性能を達成しています．UPDATE 22/11/17: 我々は、単純な形状の報酬を持つ標準的なA3Cエージェント、すなわち外因性報酬＋特徴制御内因性報酬は、Montezuma Revengeにおいて我々のエージェントと同等の性能を持つことを発見した。実行された新しい実験に照らし合わせると、我々のHRLアプローチの優位性は、階層的なコンポーネントで抽象化されたスキルを探索し再利用する能力よりも、内在的な報酬から有用な特徴を学習する能力に起因すると考えられる。これにより、結果について新たな結論を得ることができました。
本論文では、現在の言語と視覚（LaVi）のモデルが、2つのモダリティ間の相互作用を真に把握しているかどうかを理解することを目的としています。この目的のために、MSCOCOデータセットの拡張版であるFOIL-COCOを提案する。このデータセットでは、画像に正しいキャプションと「フォイル」キャプション、つまり、元のキャプションと非常によく似ているが1つの誤り（「フォイルワード」）を含む画像の説明を関連付ける。現在のLaViモデルは、このデータの罠に陥り、次の3つのタスクで悪い結果となっていることを示しています。対照的に、人間はこれらのタスクでほぼ完璧なパフォーマンスを示します。FOIL-COCOのモデル化には、単に言語的な手がかりを利用するだけでは不十分であり、テキストと画像の関係を細かく理解する必要があるため、最先端の技術に挑戦していることを示した。
我々は、バッチ式正規化の利点をリカレントニューラルネットワークにもたらすLSTMの再パラメータ化を提案する。これまでの研究では、RNNの入力から隠蔽への変換に一括正規化を適用していたが、我々は、隠蔽から隠蔽への変換を一括正規化することが可能であり、有益であることを示す。我々の提案を、シーケンス分類、言語モデリング、質問応答などの様々な逐次問題で評価した。実証実験の結果、バッチ正規化LSTMは、収束の速さと汎化の向上を一貫して実現しています。
最近のモバイル機器は、モデルの学習に適した豊富なデータにアクセスでき、それによって機器上のユーザーエクスペリエンスを大幅に向上させることができます。例えば、言語モデルは音声認識やテキスト入力を向上させ、画像モデルは良い写真を自動的に選択することができます。しかし、このような豊富なデータは、プライバシーに配慮したものであったり、量が多かったり、あるいはその両方であったりすることが多く、従来の方法ではデータセンターにログインして学習することができませんでした。そこで、学習データをモバイル端末に分散させておき、ローカルで計算された更新情報を集約して共有モデルを学習する方法を提唱しています。この分散型アプローチを「Federated Learning」と呼んでいます。我々は、反復的なモデル平均化に基づいたディープネットワークの統合学習のための実用的な手法を提示し、5つの異なるモデルアーキテクチャと4つのデータセットを考慮した広範な実証的評価を行った。これらの実験により、この手法が、この設定の特徴である不均衡で非IIDのデータ分布に対してロバストであることが実証されました。通信コストは主要な制約であり、同期した確率的勾配降下法と比較して、必要な通信ラウンドを10～100倍削減できることを示しています。
多くの実世界のシナリオでは、エージェントにとって外在的な報酬は極めて希薄であり、あるいは全く存在しない。このような場合、好奇心はエージェントが環境を探索し、後に役立つ可能性のあるスキルを学ぶための内在的な報酬信号として機能します。我々は、好奇心を、自己教師付きインバース・ダイナミクス・モデルによって学習された視覚的特徴空間において、エージェントが自らの行動の結果を予測する能力の誤差として定式化する。我々の定式化は、画像のような高次元の連続状態空間に対応し、ピクセルを直接予測することの難しさを回避し、さらに重要なことに、エージェントに影響を与えない環境の側面を無視している。提案されたアプローチは、2つの環境で評価されています。VizDoomとSuper Mario Brosの2つの環境で評価を行った。1）外在的報酬が少ない場合、好奇心によって環境とのインタラクションをはるかに少なくしてゴールに到達する。2）外在的報酬がない場合、好奇心によってエージェントがより効率的に探索する。3）見たことのないシナリオ（例えば、同じゲームの新しいレベル）への一般化の場合、以前の経験から得られた知識によって、エージェントが新しい場所をゼロから始めるよりもはるかに速く探索する。デモ映像とコードはこちらのhttpsのURLからご覧いただけます。
畳み込みニューラルネットワークは、多くのコンピュータビジョンアプリケーションで驚くほどの性能を発揮する視覚的特徴を提供します。しかし、これらのネットワークの学習には膨大な量の監視が必要である。本論文では、ディープネットワークをエンド・ツー・エンドで監視なしに学習するための汎用フレームワークを紹介します。我々は、Noise As Targets (NAT)と呼ばれるターゲット表現のセットを固定し、それに合わせて深層特徴を制約することを提案する。この分野にとらわれないアプローチは、教師なし学習の標準的な問題である、些細な解決策や特徴の崩壊を回避します。また、確率的なバッチ再割り当て戦略と分離可能な二乗損失関数により、数百万枚の画像にも対応します。提案手法は、ImageNetやPascal VOCにおける最先端の教師なし手法と同等の性能を持つ表現を生成します。
抽象的な要約のためのRNNベースのエンコーダ・デコーダモデルは、短い入力・出力シーケンスでは良好な性能を達成している。しかし、長い文書や要約の場合、これらのモデルは反復的で支離滅裂なフレーズを含むことが多い。本研究では、入力と連続的に生成される出力を別々に注目する新しいイントラアテンションを持つニューラルネットワークモデルと、標準的な教師付き単語予測と強化学習（RL）を組み合わせた新しい学習方法を導入する。教師付き学習のみで学習されたモデルは、しばしば「暴露バイアス」を示します。これは、学習中の各ステップでグランドトゥルースが提供されることを前提としているからです。しかし、標準的な単語予測とRLのグローバルシーケンス予測トレーニングを組み合わせることで、結果としてサマリーがより読みやすくなります。このモデルを、CNN/Daily MailとNew York Timesのデータセットで評価しました。CNN/Daily Mailデータセットにおいて、我々のモデルは41.16 ROUGE-1スコアを獲得し、これまでの最新モデルよりも向上した。また，人間による評価でも，本モデルがより質の高い要約を生成することが示された．
情報検索のためのニューラルランキングモデルは、シャローニューラルネットワークやディープニューラルネットワークを用いて、クエリに対する検索結果の順位付けを行います。従来のランキング学習モデルは、手作業で作成された検索結果の特徴に対して機械学習技術を用いていました。一方、ニューラルモデルは、生のテキストから言語の表現を学習し、クエリとドキュメントの語彙のギャップを埋めることができます。従来のIRモデルとは異なり、これらの新しい機械学習ベースのアプローチはデータを必要とし、展開する前に大規模なトレーニングデータを必要とします。このチュートリアルでは、ニューラルIRモデルの背後にある基本的な概念と直観を紹介し、従来の検索モデルとの関係を整理します。まず、IRの基本概念と、テキストのベクトル表現を学習するための様々なニューラルおよび非ニューラルのアプローチを紹介します。次に、IRタスクを最後まで学習することなく、事前に学習されたニューラル用語埋め込みを採用するシャローニューラルIR手法について説明する。次に、深層ニューラルネットワークを紹介し、一般的な深層アーキテクチャについて説明する。最後に、情報検索のための現在のDNNモデルをレビューする。最後に、ニューラルIRの潜在的な将来の方向性についての議論で締めくくる。
シーケンス間学習の一般的なアプローチは、リカレントニューラルネットワークを用いて、入力シーケンスを可変長の出力シーケンスにマッピングするものである。本論文では、畳み込みニューラルネットワークのみを用いたアーキテクチャを紹介します。リカレントモデルと比較して、学習時にすべての要素の計算を完全に並列化することができ、非線形性の数が固定されていて入力長に依存しないため、最適化が容易です。ゲーテッド・リニア・ユニットを使用することで、勾配伝搬が容易になり、各デコーダ層に個別のアテンション・モジュールを装備しています。WMT'14英語-ドイツ語翻訳およびWMT'14英語-フランス語翻訳において、Wuら（2016）のディープLSTMセットアップの精度を、GPUおよびCPUの両方で1桁以上の高速化で上回りました。
ディープニューラルネットワークは、多くのコンピュータビジョン、音声、および言語処理タスクで最先端のパターン認識性能を達成する強力で一般的な学習モデルです。しかし、ディープ・ニューラル・ネットワークは、慎重に作られた敵対的な摂動の影響を受けやすく、入力の誤分類を余儀なくされることがわかっています。敵対的な事例は、敵が期待されるシステムの動作を覆すことを可能にし、望ましくない結果をもたらすため、これらのシステムが実世界に配備された場合、セキュリティ上のリスクとなる可能性があります。本研究では、深層畳み込みニューラルネットワークに焦点を当て、敵対者がターゲットとなるネットワークの内部情報を知らなくても、容易に敵対的な事例を作ることができることを実証しています。我々の攻撃は、ネットワークをオラクル（ブラックボックス）として扱い、プローブされた入力に対してネットワークの出力が観測できることのみを想定しています。最初の攻撃は、ランダムに選択された1つのピクセルまたは小さなピクセルのセットに摂動を加えるというシンプルなアイデアに基づいています。さらに、欲張りな局所探索の考え方を用いて、摂動を加えるピクセルの小さなセットを注意深く構築することで、この攻撃の有効性を向上させています。我々の提案する攻撃は、より強い誤分類の概念にも自然に拡張される。このような初歩的な攻撃であっても、ディープニューラルネットワークの脆弱性を明らかにすることができることを、我々の広範な実験結果は示しています。我々の提案したスキームの単純さと有効性は、堅牢なネットワークを設計するためのリトマス試験として役立つことを意味する。
ここでは、自然言語の記述を解析してPythonなどの汎用プログラミング言語で書かれたソースコードに変換する問題を考えます。既存のデータ駆動型の手法は、対象となるプログラミング言語の基本的な構文を考慮することなく、この問題を言語生成タスクとして扱っています。本論文では、セマンティック・パーシングの先行研究を参考に、文法モデルを用いた新しいニューラル・アーキテクチャを提案し、ターゲットとなる構文を事前知識として明示的に取り込む。実験の結果、この方法は自然言語記述から複雑なプログラムを生成するための効果的な方法であり、これまでのコード生成や意味解析のアプローチをはるかに凌駕する最先端の結果を得た。
本研究では、外観は全く異なるが知覚的に類似した意味構造を持つ画像間で、視覚的属性を伝達する新しい手法を提案する。視覚的属性の伝達とは、ある画像から別の画像への視覚的情報（色、トーン、テクスチャ、スタイルなど）の伝達を意味します。例えば、ある画像が絵画やスケッチであるのに対し、もう一つの画像は実際のシーンの写真であり、どちらも同じ種類のシーンを描いているとします。この技術は、2つの入力画像間の意味的に意味のある密な対応関係を見つける。これを実現するために、「画像の類似性」という概念を、マッチングのためのDeep Convolutional Neutral Networkから抽出された特徴に適応させています。この手法を「Deep Image Analogy」と呼んでいます。結果を生成するための最近接場の計算には、粗いものから細かいものへの戦略が用いられています。我々の提案した手法の有効性を、スタイル/テクスチャの移行、色/スタイルの交換、スケッチ/絵画から写真への移行、タイムラプスなど、様々なケースで検証した。
我々の目標は、自然言語の発話を実行可能なプログラムにマッピングするセマンティックパーサーを学習することである。これは間接的な監視しか利用できない場合に行われる。そのため、正しい結果を出力するプログラムを探す一方で、偶然にも正しい結果を出力する間違ったプログラム（spurious program）に惑わされないようにしなければなりません。本研究では、強化学習（RL）と最大限界尤度（MML）という2つの一般的な学習パラダイムを結びつけ、両者の長所を組み合わせた新しい学習アルゴリズムを提案する。新アルゴリズムは、MMLで伝統的に採用されている系統的な探索とRLのランダムな探索を組み合わせ、一貫性のあるプログラムに対して確率がより均等になるようにパラメータを更新することで、偽のプログラムを防止する。この学習アルゴリズムを新しいニューラルセマンティックパーサーに適用し、最近の文脈依存のセマンティックパーシングタスクにおいて、既存の最先端の結果を大きく上回る成果を示した。
近年、画像の説明文（キャプション）の自動生成、すなわち画像キャプションの作成が注目されている。本論文では、特に画像の日本語キャプションの生成について検討します。しかし，キャプションのデータセットは英語で作成されたものが多く，日本語のデータセットはほとんどありません。この問題を解決するために、MS-COCOの画像をもとに、大規模な日本語画像キャプションデータセットを構築しました。STAIR Captionsは、164,062枚の画像に対する820,310件の日本語キャプションから構成されています。実験では，STAIR Captionsを用いて学習したニューラルネットワークが，英語キャプションを生成した後に英日機械翻訳を用いて生成したキャプションと比較して，より自然で優れた日本語キャプションを生成できることを示した．
本論文では、計算効率の高い機械学習による自然言語対応の提案手法を紹介する。n-gram埋め込み機能を用いたフィードフォワードニューラルネットワークは、メッセージをベクトルにエンコードし、メッセージと応答のペアが高いドット積値を持つように最適化する。最適化された検索により、応答の提案を見つけることができる。この手法は，大規模な商用電子メールアプリケーションであるGmailのInboxで評価された．この手法は，大規模な商用電子メールアプリケーションである Inbox by Gmail で評価され，シーケンスからシーケンスへのアプローチと比較して，同じ品質をわずかな計算量と待ち時間で達成できることがわかった．
ほとんどの自然な動画には，多数のイベントが含まれています．例えば、「ピアノを弾いている人」のビデオには、「踊っている別の人」や「拍手している群衆」も含まれている可能性があります。本論文では、動画内のイベントの検出と記述の両方を行う、イベントの密なキャプション化というタスクを紹介する。このタスクでは、ビデオ内のイベントの検出と記述の両方を行います。このタスクでは、ビデオを1回通過するだけですべてのイベントを検出し、同時に検出されたイベントを自然言語で記述できる新しいモデルを提案します。このモデルでは、既存の提案モジュールの変形を導入し、数分にわたる長いイベントだけでなく、短いイベントも捉えることができるように設計されています。また、ビデオ内のイベント間の依存関係を把握するために、過去と未来のイベントから得られる文脈情報を利用して、すべてのイベントを共同で記述する新しいキャプションモジュールを導入しています。また、イベントを密にキャプションするための大規模なベンチマークであるActivityNet Captionsを紹介します。ActivityNet Captionsには、20kのビデオ（849ビデオ時間）と100kの総記述が含まれており、それぞれが固有の開始時刻と終了時刻を持っています。最後に、我々のモデルを用いて、イベントの高密度キャプション化、ビデオの検索、ローカリゼーションを行った結果を報告します。
本研究では、ニューラルネットワーク文エンコーダーの教師なしトレーニングのための新しい目的関数を提示します。この目的関数は、段落レベルの談話コヒーレンスからの信号を利用して、テキストを理解するモデルを訓練する。この目的関数は純粋な識別関数であり、従来の方法に比べて何倍もの速さでモデルを学習することができ、外部評価においても優れたモデルを得ることができる。
単語埋め込みは、有用な意味情報を含む単語の点表現を提供する。本論文では、複数の単語の意味、関連性、豊富な不確実性情報を含む、ガウス混合から形成されるマルチモーダルな単語分布を紹介する。これらの分布を学習するために、エネルギーベースの最大マージン目的を提案する。結果として、この手法はユニークで表現力のある意味情報を捉え、単語の類似性や関連性などのベンチマークデータにおいて、word2vecスキップグラムやガウス埋め込みなどの代替手法を凌駕することを示す。
深層ネットワークのトレーニングを成功させるには、何千ものアノテーションされたトレーニングサンプルが必要であるという大きな同意があります。本論文では、利用可能なアノテーション付きサンプルをより効率的に使用するために、データ増強の強力な利用に依存するネットワークと学習戦略を提示する。このネットワークは、文脈を把握するための収縮経路と、正確な位置特定を可能にする対称的な拡張経路から構成されている。このようなネットワークは、非常に少ない画像からエンド・ツー・エンドで学習することができ、ISBIの課題である電子顕微鏡スタック中の神経構造のセグメンテーションにおいて、先行する最良の手法（スライディングウィンドウ型畳み込みネットワーク）を上回る性能を示しました。また、透過型光学顕微鏡画像（位相差およびDIC）で学習した同じネットワークを用いて、ISBIのセルトラッキングチャレンジ2015のこれらのカテゴリーで大差をつけて優勝しました。さらに、このネットワークは高速です。512x512の画像のセグメンテーションは、最近のGPUでは1秒もかかりません。完全な実装（Caffeベース）と学習済みのネットワークは、このhttpのURL .
私たちの目標は、データの分析、テキストの操作、データベースへの問い合わせなど、よく指定された複雑な操作を行うための便利な自然言語インターフェースを作ることです。しかし、このようなタスクのための既存の自然言語インターフェースは、プログラミング言語で発揮される力に比べて非常に原始的です。このギャップを埋めるために、私たちはコアとなるプログラミング言語から始めて、ユーザーがコア言語を段階的に「自然化」できるようにしています。つまり、代替となるより自然な構文を定義したり、より複雑な概念を単純な概念の組み合わせで定義したりします。ボクセルの世界では、ユーザーのコミュニティが、共通のシステムに多様な言語を教え、それを使って何百もの複雑なボクセル構造を同時に構築できることを示しています。3日間で、ユーザーはコア言語のみを使用していたのが、直近の10Kの発話の85.9%で自然化された言語を使用するようになった。
本論文では、ニューラル機械翻訳（NMT）の新しい学習パラダイムを研究しています。これまでの研究のように人間の翻訳の可能性を最大化するのではなく、人間の翻訳とNMTモデルによって与えられた翻訳との違いを最小化する。この目標を達成するために、近年の生成的敵対ネットワーク（GAN）の成功にヒントを得て、敵対的な学習アーキテクチャを採用し、これをAdversarial-NMTと名付けました。Adversarial-NMTでは、NMTモデルの学習を、精巧に設計されたConvolutional Neural Network (CNN)である敵対者が支援します。敵対者の目的は、NMTモデルによって生成された翻訳結果と人間による翻訳結果を区別することです。NMTモデルの目標は、敵を欺くために高品質の翻訳を生成することです。政策勾配法を用いて、NMTモデルと敵対者の共同訓練を行います。Adversarial-NMTは、英仏および独英の翻訳タスクにおいて、いくつかの強力なベースラインよりも大幅に優れた翻訳品質を達成できることが示された。
シーンパーシング（画像中の物体やものを認識して分割すること）は、コンピュータビジョンの重要な問題の一つです。しかし、データ収集の努力にもかかわらず、シーン解析のための緻密で詳細なアノテーションを持つ、幅広いシーンとオブジェクトカテゴリをカバーする画像データセットはまだ少ない。本論文では、シーン、オブジェクト、オブジェクトのパーツ、さらにはパーツのパーツの多様なアノテーションを含むADE20Kデータセットを紹介し、分析します。シーン解析ベンチマークは、ADE20Kをベースに構築されており、150のオブジェクトクラスとスタッフクラスが含まれています。このベンチマークでは、いくつかのセグメンテーション・ベースライン・モデルが評価されています。カスケードセグメンテーションモジュールと呼ばれる新しいネットワークデザインは、カスケードの中でシーンを物、オブジェクト、オブジェクトパーツに解析し、ベースラインよりも改善することを提案する。さらに、学習されたシーン解析ネットワークは、画像コンテンツの除去やシーン合成などのアプリケーションにつながることを示しています。
リカレントニューラルネットワークは、言語モデリングなどのタスクにおいて、単語のシーケンスを予測することに大きな成功を収めている。しかし、このようなモデルはすべて、従来の分類フレームワークに基づいており、モデルはワンショットのターゲットに対して学習され、各単語は入力としても出力としても分離して表現される。これは、すべての情報を利用するという点でも、学習に必要なパラメータの数という点でも、学習に非効率性をもたらします。本論文では、言語モデリングの学習効率を向上させるための新しい理論的枠組みを紹介し、この枠組みが入力埋め込み行列と出力投影行列を結びつけることにつながり、学習可能な変数の数を大幅に減らすことができることを示す。このフレームワークは、様々なネットワークモデルを用いたPenn Treebankにおいて、最先端の性能を発揮します。
本研究では，非常にシンプルなゲーテッドリカレントニューラルネットワーク（RNN）を導入し，単語レベルの言語モデリングタスクにおいて，LSTMやGRUなどのよく知られたゲーテッドアーキテクチャと同等の性能を達成した．このモデルは、シンプルで予測可能な非カオス的なダイナミクスを持つことを証明しています。これは、基本的な動的システムがカオス的な挙動を示す、より標準的なゲーテッド・アーキテクチャとは全く対照的である。
深層人工ニューラルネットワークは、その巨大なサイズにもかかわらず、訓練時とテスト時の性能の差が驚くほど小さいことがあります。従来の常識では、一般化誤差が小さいのは、モデルファミリーの特性によるものか、学習時に用いられる正則化技術によるものかのどちらかであると考えられていた。 本研究では、大規模な系統的実験を通して、これらの伝統的なアプローチでは、大規模なニューラルネットワークが実際にうまく一般化する理由を説明できないことを示した。具体的には、確率的勾配法を用いて学習した画像分類用の最先端の畳み込みネットワークが、学習データのランダムなラベル付けに容易に適合することを実験で証明した。この現象は、明示的な正則化の影響を受けず、真の画像を全く構造化されていないランダムなノイズで置き換えても発生する。これらの実験結果を、単純な深さ2のニューラルネットワークは、パラメータの数がデータポイントの数を超えた時点で、完全な有限サンプル表現力を持つことを示す理論的な構築によって裏付けました。
近年、コンピュータビジョン、機械学習、自律走行車などのAI関連分野が大きく発展しています。急成長している分野では、最新の情報を得ることも、初心者としてその分野に参入することも難しくなっています。特定のサブ問題に関するいくつかのサーベイ論文は登場していますが、自律走行車用コンピュータビジョンの問題、データセット、手法に関する包括的なサーベイは出版されていません。本書は、このギャップを埋めるために、最新のデータセットと手法に関するサーベイを提供します。このサーベイには、自律走行のための認識、再構成、モーション推定、トラッキング、シーン理解、エンドツーエンドの学習など、いくつかの特定のトピックに関する歴史的に最も関連性の高い文献と、現在の技術状況の両方が含まれています。この目標に向けて、KITTI、MOT、Cityscapesなど、いくつかのチャレンジングなベンチマークデータセットを用いて、現状の技術のパフォーマンスを分析します。また、未解決の問題や現在の研究課題についても議論します。また，アクセスを容易にし，欠落している参考文献に対応するために，トピックや手法をナビゲートし，追加情報を提供するウェブサイトを提供しています。
深層フィードフォワードネットワークとリカレントネットワークは、多くの知覚や言語処理のアプリケーションで素晴らしい結果を達成しています。この成功は、部分的には、畳み込みネットワークや長短期記憶ネットワークのようなアーキテクチャの革新に起因しています。これらのアーキテクチャの革新の主な動機は、より優れたドメインナレッジを取り込み、重要なことに、より基本的なアーキテクチャよりも最適化が容易であることです。最近では、質問応答や一般的な計算を含むタスクのために、ニューラルチューリングマシンやメモリネットワークのようなより複雑なアーキテクチャが提案されており、新たな最適化の課題が生じている。本論文では、オーバーヘッドが少なく実装が容易な、勾配ノイズを追加する手法について議論します。この手法は、オーバーフィッティングの回避に役立つだけでなく、学習損失の低減にもつながります。この手法を用いるだけで、完全に接続された20層の深層ネットワークを、不十分な初期化から始めても、標準的な勾配降下法で学習することができます。例えば、難しい質問応答タスクにおいて、慎重に調整されたベースラインと比較してエラーレートが72%減少したことや、7,000回のランダムリスタートで学習された正確な2進法モデルの数が2倍になったことなど、多くの複雑なモデルで一貫した改善が見られました。この技術をさらに複雑な現代のアーキテクチャに適用することを期待しています」と述べています。
ディープニューラルネットワーク（DNN）による学習やその内部組織については、その大きな成功にもかかわらず、まだ包括的な理論的理解が得られていません。これまでの研究では、DNNを、各層が入力変数と出力変数に対して保持する相互情報量の平面である「情報平面」で分析することが提案されていた。彼らは、ネットワークの目的は、圧縮と予測の間の情報ボトルネック（IB）のトレードオフを各層ごとに逐次最適化することであると提案した。本研究では、このアイデアを踏襲し、DNNのInformation-Planeによる可視化の有効性を実証した。我々の主な結果は (i) 標準的なDLの学習エポックのほとんどは、入力の効率的な表現への圧縮に費やされ、学習ラベルの適合には費やされない。(表現の圧縮段階は、学習誤差が小さくなったときに始まり、Stochastic Gradient Decent (SGD)エポックは、学習誤差が小さくなると高速にドリフトしていたのが、学習誤差の値で制約された確率的な緩和、つまりランダムな拡散に変化する。(収束した層は、情報ボトルネック（IB）の理論的境界上にあるか、それに非常に近いところにあり、入力から任意の隠れ層へのマップ、およびこの隠れ層から出力へのマップは、IB自己矛盾方程式を満たしています。このノイズによる一般化のメカニズムは、1層ネットワークにはない、ディープニューラルネットワーク特有のものです。(iv) 隠れ層の数を増やすと、学習時間が劇的に短縮される。このように、隠れた層の主な利点は計算上のものです。これは、前の層からの情報圧縮によって超線形（単純な拡散では指数関数的）にスケールするため、緩和時間が短縮されることで説明できます。
私たちは、自然言語による指示でAtari社のゲームに勝つことを学習する、初の深層強化学習エージェントを紹介します。このエージェントは、環境観察と自然言語の間のマルチモーダルな埋め込みを用いて、英語の指示リストの進捗状況を自己監視し、ゲームのスコアを上げることに加えて、指示を完了することで報酬を得ることができる。我々のエージェントは、DQN（Deep Q-Networks）、A3C（Asynchronous Advantage Actor-Critic）エージェント、そしてOpenAI Gymに投稿された最高のエージェントを、Atari 2600で最も難しいとされる環境において、大幅に凌駕しました。Montezuma's Revenge」です。
畳み込みニューラルネットワークは近年、単一画像の超解像において高品質な再構成を実証している。本論文では、高解像度画像のサブバンド残差を段階的に再構成するLapSRN（Laplacian Pyramid Super-Resolution Network）を提案します。このモデルは、各ピラミッドレベルにおいて、粗い解像度の特徴マップを入力とし、高周波の残差を予測し、転置型の畳み込みを用いて、より細かいレベルへのアップサンプリングを行う。本手法では，前処理としてバイキュービック補間を必要としないため，計算量を大幅に削減することができる．提案されたLapSRNを、ロバストなシャルボニエ損失関数を用いたディープスーパービジョンで学習させ、高品質な再構成を実現した。さらに、我々のネットワークは、プログレッシブ再構成を介して1回のフィードフォワードパスでマルチスケール予測を生成し、リソースを考慮したアプリケーションを容易にしている。ベンチマークデータを用いた広範な定量的・定性的評価により，提案アルゴリズムは，速度と精度の点で最先端の手法に対して有利に働くことが示された．
非同期勾配降下法を用いて深層ニューラルネットワークコントローラを最適化する、概念的にシンプルで軽量な深層強化学習のフレームワークを提案する。本研究では、4つの標準的な強化学習アルゴリズムの非同期型を提案し、並列アクター学習器が学習を安定化させる効果があることを示すことで、4つの手法すべてがニューラルネットワークコントローラの学習に成功しました。最も優れた手法であるactor-criticの非同期型は、GPUではなくマルチコアCPU1台で半分の時間で学習を行いながら、Atariドメインでの現在の最先端技術を超えています。さらに、非同期actor-criticは、様々な連続運動制御問題や、視覚入力を用いてランダムな3D迷路をナビゲートするという新しいタスクにも成功することを示しています。
畳み込み自己回帰モデルは、近年、多くの生成タスクにおいて最先端の性能を示している。これらの成功には、高速で並列な学習方法が重要である一方、生成は一般的にナイーブな方法で実装されており、冗長な計算が不必要に繰り返されています。その結果、生成に時間がかかり、このようなモデルは実運用環境では実行できません。本研究では、畳み込み自己回帰モデルの生成を高速化する方法を提案します。鍵となるアイデアは、冗長な計算を避けるために隠れた状態をキャッシュすることである。我々の高速生成法をWavenetモデルとPixelCNN++モデルに適用し、それぞれ最大21倍、183倍の高速化を達成しました。
Softmax GANは、Generative Adversarial Network (GAN)の新しい改良型です。Softmax GANの主なアイデアは、オリジナルのGANにおける分類損失を、1つのバッチのサンプル空間におけるソフトマックスクロスエントロピー損失に置き換えることです。N個の実サンプルとM個の生成サンプルの敵対的学習において、識別器学習の目標は、それぞれが確率\frac{1}{M}である実サンプルにすべての確率質量を分配し、生成データにはゼロの確率を分配することです。生成器の学習段階では、バッチ内のすべてのデータポイントに、それぞれが確率\frac{1}{M+N}で、等しい確率を割り当てることが目標となります。オリジナルのGANはNoise Contrastive Estimation (NCE)と密接な関係がありますが、Softmax GANはGANのImportance Sampling版であることを示します。さらに、この単純な変更がGANの学習を安定させることを実験で示します。
皮肉の研究、皮肉検出システムのトレーニングと評価のための大規模コーパスであるSelf-Annotated Reddit Corpus (SARC)を紹介する。このコーパスには、これまでのデータセットの10倍にあたる130万の皮肉な発言と、その何倍もの非皮肉な発言のインスタンスが含まれており、バランスの取れたラベルと不均衡なラベルの両方での学習が可能である。さらに，各発言にはセルフアノテーションが施されており，皮肉は独立したアノテーターではなく著者によってラベル付けされ，ユーザー，トピック，会話のコンテキストが提供されている．このコーパスの精度を評価し、皮肉検出のベンチマークを作成し、ベースラインの手法を評価した。
Neural sequence-to-sequenceモデルは、抽象化されたテキストを要約するための新しいアプローチを提供してきた。しかし、これらのモデルには、事実の詳細を正確に再現できない、同じことを繰り返してしまうという2つの欠点がある。本研究では、標準的な「配列から配列へ」の注意モデルを、2つの方法で補強する新しいアーキテクチャを提案する。まず、ポインティングによって原文から単語をコピーすることができるハイブリッドなポインター・ジェネレータ・ネットワークを用いて、情報の正確な再現を助ける一方で、ジェネレータによって新しい単語を生成する能力を保持する。次に、カバレッジを用いて、何が要約されたかを追跡することで、繰り返しを抑制しています。我々のモデルをCNN / Daily Mailの要約タスクに適用したところ、現在の抽象的な最先端技術を少なくとも2 ROUGEポイント上回る結果が得られた。
これまでの研究では、意味の文字レベルのモデルを作成することで単語の構成性をモデル化し、希少な単語のスパース性の問題を軽減してきた。しかし、多くの文字システムでは、構成性は文字レベルでも効果があり、文字の意味はその部分の合計によって得られます。本論文では、文字の視覚的特徴に基づいて文字の埋め込みを作成することで、この効果をモデル化します。文字の画像を作成し、それを畳み込みニューラルネットワークに通すことで、視覚的な文字の埋め込みを作成します。テキスト分類タスクでの実験では、このモデルによって、中国語、日本語、韓国語などの言語で、珍しい文字を含むインスタンスをよりよく処理できることが示された。さらに，本研究で提案するモデルは，意味的な内容を持つ文字の部分に焦点を当てることを学習し，その結果，視覚的に一貫性のある埋込みが得られることを定性的な分析で示した．
本研究では，仮想敵対損失（Virtual Adversarial Loss）に基づく新しい正則化手法を提案した．仮想敵対損失は、各入力データポイントの周辺の条件付きラベル分布の、局所的な摂動に対する頑健性として定義される。敵対的学習とは異なり、本手法はラベル情報なしに敵対的方向を定義するため、半教師付き学習にも適用可能である。モデルを平滑化する方向は「仮想的に」敵対的であるに過ぎないため，我々の手法を仮想敵対的学習（VAT）と呼ぶ．VATの計算コストは比較的低く抑えられます。ニューラルネットワークの場合，仮想敵対損失の近似勾配は，フォワードプロパゲーションとバックプロパゲーションの2組だけで計算できます．実験では，複数のベンチマークデータセットを用いた教師付き学習および半教師付き学習タスクにVATを適用した．エントロピー最小化原理に基づいてアルゴリズムを簡単に改良することで，VATはSVHNおよびCIFAR-10の半教師付き学習タスクにおいて最先端の性能を達成した．
モバイルおよび組み込みビジョンアプリケーションのためのMobileNetsと呼ばれる効率的なモデルのクラスを紹介します。MobileNetsは、深さ方向に分離可能な畳み込みを用いて、軽量のディープニューラルネットワークを構築する効率的なアーキテクチャに基づいている。我々は、レイテンシーと精度を効率的にトレードオフする2つのシンプルなグローバルハイパーパラメータを導入しました。これらのハイパーパラメータにより、モデル構築者は、問題の制約に基づいて、アプリケーションに適したサイズのモデルを選択することができます。我々は、リソースと精度のトレードオフに関する広範な実験を行い、ImageNetの分類において、他の一般的なモデルと比較して高い性能を示した。さらに、物体検出、細粒度分類、顔の属性、大規模なジオローカリゼーションなど、幅広いアプリケーションやユースケースにおいて、MobileNetsの有効性を実証する。
本論文では、展示されている映画のポスターから、世界的な映画祭の優勝者を推定することを目的としています。この課題は、映画の評価や興行収入がなく、展示されている映画ポスターだけで推定を行わなければならないため、非常に困難です。この問題を解決するために、我々は、4大映画祭に出品された全ての映画ポスターを集めたデータベースを新たに作成しました。映画ポスターデータベース(MPDB)には、毎年の映画賞にノミネートされた80年以上の歴史的な映画が含まれています。我々は、映画ポスターから様々な情報を抽出するために、ハンドクラフト特徴、ミッドレベル特徴、ディープ特徴という2つの特徴タイプを適用した。実験の結果，色の特徴を用いることでアカデミー賞の受賞率が向上することや，顔の感情の特徴を用いることでMPDB上での受賞率が向上することなど，示唆に富む知見が得られた．この論文は、映画推薦のための人間の嗜好のモデル化の可能性を示唆しています。
近年、画像の自動記述は急速な進歩を遂げていますが、この分野での未解決の問題は何でしょうか？ほとんどの研究は、テキストベースの類似性メトリクスを用いて評価されていますが、これは何が改善されたのかを説明せずに、改善があったことを示すだけです。本論文では、最先端の注意力ベースのモデルによって生成された説明文の詳細なエラー分析を紹介します。この分析は2つのレベルで行われています。まず、説明文の正確さをチェックし、次に、不正確な説明文で観察されるエラーのタイプを分類します。その結果，誤りのない記述は全体の20％に過ぎず，驚くべきことに26％は画像に関係のない記述であることがわかりました．最後に、最も頻繁に発生するエラータイプ（例：性別の識別）を手動で修正し、これらのエラーに対処した場合のパフォーマンス報酬を推定したところ、タイプごとに0.2～1BLEUポイントの利益が得られることがわかった。
sketch-rnnは、一般的な物体のストロークベースの描画を行うことができるリカレントニューラルネットワーク（RNN）です。このモデルは、何百ものクラスを表す何千もの人間が描いた粗い画像で学習される。条件付きおよび無条件のスケッチ生成のためのフレームワークを説明し、ベクター形式の一貫したスケッチ画を生成するための新しいロバストな学習方法について述べる。
本論文では、教師なしモードで学習可能で、生成と推論の両方を維持し、条件付きおよび無条件のサンプルの品質を敵対的学習によって高めることができる、新しいオートエンコーダー型のアーキテクチャを提示する。これまでのオートエンコーダと敵対的ネットワークのハイブリッドとは異なり、本アプローチにおける敵対的ゲームは、エンコーダとジェネレータの間で直接設定され、学習の過程で外部マッピングは学習されない。ゲームの目的は、実データと生成データのそれぞれの分布と、潜在空間の事前分布との乖離を比較することである。生成器対符号化器の直接ゲームは、2つのコンポーネントの緊密な結合をもたらし、その結果、最近提案されたより複雑なアーキテクチャに匹敵する品質のサンプルと再構成が得られることを示している。
単純な潜在分布から任意の複雑なデータ分布にマッピングする生成モデルを学習するGAN（Generative Adversarial Networks）フレームワークの能力は、経験的に実証されており、そのような生成器の潜在空間がデータ分布の意味的な変化を捉えることを示す説得力のある結果が得られています。直感的には、データが与えられたときに、これらの意味的な潜在表現を予測するように訓練されたモデルは、意味論が関連する補助的な問題のための有用な特徴表現として役立つかもしれない。しかし、既存のGANでは、データを潜在空間に投影する逆マッピングを学習する手段がない。我々は、この逆マッピングを学習する手段として、双方向生成アドバーサリア・ネットワーク（BiGAN）を提案し、その結果、学習された特徴表現が、教師なしおよび教師あり特徴学習の現代的なアプローチに負けず、補助的な教師あり識別タスクに有用であることを実証する。
本報告書は、そのアプリケーションの専門家でありながら、ディープラーニングの初心者であるグループを対象としています。ディープニューラルネットワークの使用を、ディープラーニングにとって新しいアプリケーションで試してみたいと考えている方への実践的なアドバイスが含まれています。私たちは、プロジェクトをフェーズに分けて管理しやすくすることを提案します。このレポートには、各フェーズごとに、初心者の実務者を支援するための数多くの推奨事項や洞察が含まれています。
リカレントニューラルネットワーク（RNN）は、入力テキストを逐次処理し、単語トークン間の条件付き遷移をモデル化します。これに対して、再帰型ネットワークの利点は、自然言語の構成性と再帰的構造を明示的にモデル化できることです。しかし、現在の再帰的なアーキテクチャは、構文木に依存することで制限されています。本論文では、構文解析に依存しない強固な木構造モデルであるNeural Tree Indexers (NTI)を導入し、逐次RNNと構文木に基づく再帰的モデルの中間的な立場を提供する。NTIは、入力テキストをそのノード機能でボトムアップ的に処理することで、完全なn-aryツリーを構築します。アテンションメカニズムは、構造とノード機能の両方に適用することができます。我々は、NTIの二分木モデルを実装して評価した結果、このモデルが、自然言語推論、回答文選択、文分類という3つの異なるNLPタスクにおいて、最先端の再帰型ニューラルネットワークや再帰型ニューラルネットワークを凌駕する性能を達成したことを示した。
視覚における生成モデルは、アルゴリズムの改良と高品質な画像データセットの入手により、急速に進歩しています。本論文では，オーディオモデリングにおいても同様の進歩を実現するために，この2つの分野で貢献しています。まず，生のオーディオ波形から学習した時間コードを自己回帰デコーダの条件とする，強力な新しいWaveNetスタイルのオートエンコーダモデルについて説明します。NSynthは、音符の大規模かつ高品質なデータセットであり、公開されている類似のデータセットと比較して桁違いに大きい。NSynthを用いて、WaveNetオートエンコーダーが、十分に調整されたスペクトルオートエンコーダーのベースラインよりも質的・量的に向上したことを実証します。最後に、このモデルは、楽器間のモーフィングを可能にする埋め込みの多様性を学習し、リアルで表現力のある新しいタイプの音を作り出すために、音色を有意義に補間することを示します。
オートエンコーダーベースのGenerative Adversarial Networksを学習するために、Wasserstein距離から得られる損失とペアになった新しい平衡強化法を提案します。この方法は、学習中に生成器と識別器のバランスをとる。さらに、新しい近似収束指標、高速で安定した学習、高い視覚的品質を提供します。また、画像の多様性と視覚的品質の間のトレードオフを制御する方法を導き出しました。画像生成タスクに焦点を当て、高解像度においても視覚的品質の新たなマイルストーンを設定しました。これは、比較的シンプルなモデル構成と標準的な学習手順を用いて達成されています。
既存の音楽生成用ニューラルネットワークモデルの多くは、リカレントニューラルネットワークを使用しています。しかし、DeepMind社が最近提案したWaveNetモデルは、畳み込みニューラルネットワーク（CNN）がオーディオ領域においてもリアルな音楽波形を生成できることを示している。このような観点から、私たちはCNNを使って、記号領域で1小節ごとにメロディ（MIDIノートの連続）を生成することを検討しています。生成器に加えて、識別器を用いてメロディの分布を学習することで、生成的敵対的ネットワーク（GAN）としています。さらに、利用可能な事前知識を活用するために、新しい条件付きメカニズムを提案しています。これにより、モデルは、ゼロからメロディを生成したり、コード・シーケンスに従ってメロディを生成したり、前の小節のメロディ（例えば、プライミング・メロディ）を条件としてメロディを生成したりすることができます。MidiNetと名付けられたこのモデルは、複数のMIDIチャンネル（すなわちトラック）を持つ音楽を生成するように拡張することができます。我々は、MidiNetとGoogleのMelodyRNNモデルによって生成された8小節の長さのメロディを、同じプライミングメロディを使って比較するユーザー調査を行った。その結果、MidiNetはMelodyRNNモデルと比較して、リアルで聴きやすいという点で同等の性能を示したが、MidiNetのメロディの方がはるかに面白いと報告されている。
現在の音声強調技術は、スペクトル領域で動作したり、何らかの高レベルの特徴を利用したりしています。これらの技術の大半は、限られた数のノイズ条件に取り組み、一次統計に依存しています。これらの問題を回避するために，大規模なサンプルセットから複雑な関数を学習する能力を持つディープネットワークの利用が増加している．本研究では、生成的敵対的ネットワークを音声強調に用いることを提案する。現在の技術とは対照的に、我々は波形レベルで動作し、モデルをエンドツーエンドで学習し、28人の話者と40の異なる雑音条件を同じモデルに組み込み、モデルパラメータを共有する。また，28人の話者と40の異なる雑音条件を同じモデルに組み込み，モデルのパラメータを共通化しました．改良されたサンプルにより、提案モデルの実行可能性が確認され、客観的および主観的な評価により、その有効性が確認された。これにより、スピーチエンハンスメントのための生成アーキテクチャの研究が開始されます。生成アーキテクチャは、パフォーマンスを向上させるために、スピーチを中心とした設計上の選択を徐々に組み込むことができます。
本研究では、パラメータの数を減らし、大規模なLSTM（Long Short-Term Memory）ネットワークの学習を高速化する2つの簡単な方法を紹介します。1つ目は、LSTM行列を2つの小さな行列の積にする「設計による行列分解」であり、2つ目は、LSTM行列とその入力および状態を独立したグループに分割することです。この2つのアプローチにより、大規模なLSTMネットワークを、より少ないRNNパラメータで、ほぼ最新のパープレキシティまで高速に学習することができます。
画像から画像への変換は、画像ペアのトレーニングセットを用いて、入力画像と出力画像の間のマッピングを学習することを目的とした、視覚とグラフィックスの問題の一種です。しかし、多くの課題では、ペアとなる学習データは利用できない。我々は、ペアの例がない場合に、ソースドメインXからターゲットドメインYへの画像の翻訳を学習するためのアプローチを提示する。我々の目標は、G(X)からの画像の分布が、敵対的損失を用いてYの分布と区別できないようなマッピングG:X→Yを学習することである。このマッピングは非常に制約が少ないため、逆マッピングF:Y→Xと組み合わせ、F(G(X))≒X(およびその逆)を押すためのサイクル一貫性損失を導入する。コレクションスタイルの変換、オブジェクトの変換、季節の変換、写真の補正など、ペアとなるトレーニングデータが存在しないいくつかのタスクについて、定性的な結果を示す。また、いくつかの先行する手法との定量的な比較により、本手法の優位性が示されています。
我々は、散乱ネットワークを、教師付きハイブリッド・ディープ・ネットワークの最初の層の一般的かつ固定的な初期化として使用している。初期層は必ずしも学習する必要がないことを示し、事前に定義された表現を用いてこれまでで最高の結果を得るとともに、ディープCNNとの競争力を高めています。非常に小さいサイズの空間窓に対応する散乱係数を符号化する1×1畳み込みの浅いカスケードを使用することで、ILSVRC2012の画像データベースでAlexNetの精度を得ることができました。また、この局所的な符号化は、回転に対する不変性を明示的に学習することを示しています。散乱ネットワークと最新のResNetを組み合わせることで、わずか10層で、シングルクロップのトップ5エラーが11.4%と、Resnet-18アーキテクチャに匹敵する性能を達成しました。また、ハイブリッド・アーキテクチャーは、幾何学的プライアを組み込むことで、少量サンプル領域においてエンド・ツー・エンドのアーキテクチャーを上回る優れた性能を発揮することが分かりました。このことは，CIFAR-10データセットのサブセットとSTL-10データセットで実証した．
本論文では、最近提案された生成的敵対ネットワーク（GAN）を用いて、オートエンコーダーの隠れたコードベクトルの集約された事後を任意の事前分布とマッチングさせることで変分推論を行う確率的オートエンコーダーである「敵対的オートエンコーダー」（AAE）を提案している。この事前分布と集合事後のマッチングにより、事前空間のどの部分から生成しても意味のあるサンプルが得られるようになります。その結果、敵対的自動符号化器の復号器は、課せられた事前分布をデータ分布にマッピングする深い生成モデルを学習する。半教師付き分類、画像のスタイルとコンテンツの分離、教師なしクラスタリング、次元削減、データの可視化などのアプリケーションで、敵対的オートエンコーダーがどのように利用できるかを示している。我々は，MNIST，Street View House Numbers，Toronto Faceの各データセットを用いて実験を行い，敵対的オートエンコーダが生成モデリングや半教師付き分類タスクにおいて競争力のある結果を得ることを示した．
データは多くの異なる専門家によってラベル付けされますが、各専門家がラベル付けするのはデータのごく一部であり、各データポイントは複数の専門家によってラベル付けされます。これにより、個々の専門家の作業負荷が軽減され、観測されていないグランドトゥルースをより正確に推定することができます。専門家の意見が一致しない場合、多数意見を正しいラベルとして扱うか、正しいラベルを分布としてモデル化するのが標準的なアプローチである。しかし、これらのアプローチでは、どの専門家がどのラベルを作成したかという貴重な情報を利用することができない。この余分な情報を利用するために、我々は、専門家を個別にモデル化し、それらを組み合わせるための平均化された重みを、おそらくサンプル固有の方法で学習することを提案する。これにより、より信頼性の高い専門家に重みを与えたり、特定の種類のデータを分類する際に個々の専門家が持つ独自の強みを利用することができる。ここでは，我々のアプローチが，糖尿病性網膜症のコンピュータ支援診断の改善につながることを示す．また，Welinder and Perona (2010)やMnih and Hinton (2012)のアルゴリズムと比較しても，本手法が優れていることを示している．本研究は、専門家の意見を用いて学習用のラベルを定義する無数の実世界の設定に対処するための革新的なアプローチを提供します。
これは、完全に微分可能なニューラルネットワークに、「プランニングモジュール」を組み込んだものです。VINはプランニングを学習することができ、強化学習のポリシーなど、プランニングに基づく推論を伴う結果を予測するのに適しています。我々のアプローチの鍵となるのは、value-iterationアルゴリズムの新しい微分可能な近似であり、これは畳み込みニューラルネットワークとして表され、標準的なバックプロパゲーションを用いてエンドツーエンドで学習することができます。本研究では、離散的および連続的な経路計画の領域と、自然言語ベースの検索タスクにおいて、VINベースのポリシーを評価した。その結果、明示的な計画計算を学習することで、VIN政策は新しい未知の領域に対してよりよく一般化することを示した。
画像のマット化は、コンピュータビジョンの基本的な問題であり、多くのアプリケーションがあります。これまでのアルゴリズムでは、前景と背景の色が似ていたり、複雑なテクスチャを持つ画像の場合、性能が低下する。その主な理由は、1）低レベルの特徴しか利用していない、2）高レベルのコンテキストがない、というものである。本論文では、これらの問題に取り組むことができる新しい深層学習ベースのアルゴリズムを提案する。我々の深層学習モデルには2つの部分がある。第1の部分は、画像とそれに対応するトライマップを入力とし、画像のアルファマットを予測する深層畳み込みエンコーダー・デコーダーネットワークです。第2の部分は小さな畳み込みネットワークで、第1のネットワークのアルファマットの予測を改良し、より正確なアルファ値とシャープなエッジを持つようにします。さらに、49300枚のトレーニング画像と1000枚のテスト画像を含む大規模な画像マットデータセットも作成します。このアルゴリズムを，画像マットベンチマーク，テストセット，および多種多様な実写画像で評価した．実験結果は、我々のアルゴリズムが従来の手法よりも優れていることを明確に示している。
本論文では、写真のスタイルを転写するための深層学習アプローチを紹介します。このアプローチでは、多様な画像コンテンツを処理しながら、参照スタイルを忠実に転写することができます。我々のアプローチは、ニューラルネットワークの異なる層を考慮することで、スタイルを画像のコンテンツから分離する絵画的転写に関する最近の研究を基にしている。しかし、このアプローチはそのままでは、フォトリアリスティックなスタイルの転写には適していません。入力画像と参照画像の両方が写真であっても、出力には絵画を連想させるような歪みが見られます。我々の貢献は、入力から出力への変換が色空間において局所的にアフィンであることを制約し、この制約をカスタムの完全微分可能なエネルギー項で表現することである。このアプローチにより、時間帯、天候、季節、芸術的な編集など、さまざまなシナリオにおいて、歪みを抑制し、満足のいくフォトリアリスティックなスタイルの伝達が可能になることを示しています。
我々は、概念的にシンプルで柔軟性のある、オブジェクトインスタンスセグメンテーションのための一般的なフレームワークを提示する。本手法は、画像内のオブジェクトを効率的に検出すると同時に、各インスタンスに対して高品質なセグメンテーションマスクを生成します。この手法は、Mask R-CNNと呼ばれ、Faster R-CNNを拡張したもので、既存のバウンディングボックス認識のためのブランチと並行して、オブジェクトマスクを予測するためのブランチを追加しています。Mask R-CNNは学習が簡単で、Faster R-CNNにわずかなオーバーヘッドを加えるだけで、5fpsで動作します。さらに、Mask R-CNNは他のタスクへの応用が容易であり、例えば、同じフレームワークで人間の姿勢を推定することができます。また、COCOチャレンジの3つのトラック（インスタンス・セグメンテーション、バウンディングボックス・オブジェクト検出、人物キーポイント検出など）すべてにおいて、最高の結果を得ることができました。また、Mask R-CNNは、COCO 2016チャレンジの受賞者を含む、既存の単一モデルのエントリーをすべてのタスクで上回りました。私たちのシンプルで効果的なアプローチが、確固たるベースラインとして機能し、インスタンスレベル認識の将来の研究を容易にすることを期待しています。コードは以下で公開されています：このhttpsのURL
スタイル変換の急速な進歩にもかかわらず、マルチスタイルまたは任意のスタイル変換のためにフィードフォワード生成ネットワークを使用する既存のアプローチは、通常、画質とモデルの柔軟性が損なわれています。我々は、1次元のスタイル埋め込みを用いて包括的なスタイルモデリングを行うことは基本的に困難であると考えている。そこで我々は、2次の特徴統計量とターゲットスタイルのマッチングを学習するCoMatch Layerを導入する。このCoMatch Layerを用いてMulti-style Generative Network (MSG-Net)を構築し、リアルタイム性を実現しています。また、アップサンプル・コンボリューションという特殊な戦略を採用することで、フラクショナル・ストライド・コンボリューションに起因するチェッカーボード・アーティファクトを回避しています。本手法は，最新の手法と比較して優れた画質を実現している。提案されたMSG-Netは、リアルタイムスタイル変換のための一般的なアプローチとして、コンテンツスタイル補間、カラープリザベーション、空間制御、ブラシストロークサイズ制御など、ほとんどの既存技術と互換性があります。MSG-Netは、スタイル転送のために純粋にフィードフォワード方式でリアルタイムのブラシサイズ制御を実現した初めての手法です。Torch、PyTorch、MXNetフレームワーク用の実装と学習済みモデルは、一般に公開される予定です。
この論文では、最適化問題（ここでは、特に二次プログラムの形で）を、より大きなエンド・ツー・エンドの学習可能なディープネットワークの個々の層として統合するネットワークアーキテクチャであるOptNetを紹介します。これらの層は、従来の畳み込み層や完全連結層では捉えきれない制約や隠れた状態間の複雑な依存関係を符号化します。本論文では、このようなアーキテクチャの基礎を探ります。感度分析、バイレベル最適化、暗黙の微分などの手法を用いて、これらの層を正確に微分したり、層のパラメータを正確に微分したりする方法を示します。また、これらの層のための高効率ソルバーを開発します。このソルバーは、GPUを用いた高速なバッチソルブをプライマル・デュアル内点法で利用し、バックプロパゲーション勾配を実質的に追加のコストなしで提供します。また、これらのアプローチをいくつかの問題に適用し、注目すべき例として、この手法が、ゲームのルールに関する先験的な情報なしに、入力ゲームと出力ゲームだけを与えられて、ミニ数独（4x4）をプレイすることを学習できることを示す。これにより、我々のアーキテクチャが、他のニューラルアーキテクチャよりも硬い制約を学習する能力があることを強調する。
勾配ベースのオプティマイザーの収束率を向上させるための一般的な手法を紹介する。この手法は実装が容易で、実際によく機能する。本手法を確率的勾配降下法、ネステロフ運動量を用いた確率的勾配降下法、アダムに適用することで、様々な最適化問題における本手法の有効性を実証し、これらの一般的に使用されているアルゴリズムの初期学習率を手動で調整する必要性を大幅に削減できることを示した。この手法は、更新ルール自体の学習率に対する勾配を利用して、最適化の際に学習率を動的に更新するものである。この「超勾配」の計算には、追加の計算はほとんど必要なく、元の勾配のコピーを1つ余分にメモリに保存するだけでよく、逆モードの自動微分法で提供されるもの以上のものは必要ない。
人間は異なる領域のデータ間の関係を監視なしで容易に認識するが、自動的に関係を発見する学習は一般的に非常に困難であり、関係を示す多くのグランドトゥルースペアが必要となる。本論文では、ペアリングにかかるコストを回避するため、ペアリングされていないデータを用いてドメイン間の関係を発見するという課題に取り組む。我々は、異なるドメイン間の関係を発見することを学習する生成的敵対的ネットワークに基づく手法を提案する（DiscoGAN）。発見された関係を用いて、我々の提案するネットワークは、方位や顔の同一性などの重要な属性を保持しながら、あるドメインから別のドメインへスタイルを転送することに成功した。正式な実装のソースコードはhttps URLで公開されています。
深層学習のアーキテクチャは、その圧倒的なオーバーフィット能力にもかかわらず、見たことのないデータに対しても比較的よく一般化する傾向があり、実際に導入することができます。しかし、なぜそうなるのかを説明することは、まだ研究の余地があります。例えばHochreiter & Schmidhuber (1997); Keskar et al. (2017)のように、人気を博している1つの立脚した仮説は、確率的勾配に基づく手法によって見出される損失関数の最小値が平坦であることが、良好な一般化をもたらすというものである。本論文では、フラットネスのほとんどの概念はディープモデルにとって問題があり、汎化の説明に直接適用することはできないと主張する。具体的には、整流器ユニットを持つ深層ネットワークに注目すると、これらのアーキテクチャが示す固有の対称性によって引き起こされるパラメータ空間の特殊な形状を利用して、任意のシャープな最小値に対応する等価モデルを構築することができる。さらに、関数を再パラメトリック化することができれば、その一般化特性に影響を与えることなく、パラメータの形状を大幅に変更することができます。
多くの逐次処理タスクは、あるステップから次のステップへの複雑な非線形遷移関数を必要とする。しかし、「深い」遷移関数を持つリカレント・ニューラル・ネットワークの学習は、LSTM（Long Short-Term Memory）ネットワークを用いた場合でも、依然として困難である。本研究では、Gersgorinの円定理に基づいたリカレントネットワークの新しい理論的分析を紹介し、モデル化と最適化に関するいくつかの問題を明らかにし、LSTMセルの理解を深める。この解析に基づいて、LSTMアーキテクチャを拡張し、1以上のステップ間遷移の深さを許容するリカレント・ハイウェイ・ネットワークを提案する。いくつかの言語モデリング実験により、提案したアーキテクチャが強力で効率的なモデルになることを実証した。Penn Treebankコーパスでは，同じ数のパラメータを用いて，遷移深度を1から10に増やすだけで，単語レベルのパープレキシティが90.6から65.4に改善した．ウィキペディアの文字予測用の大規模データセット（text8とenwik8）では、RHNは以前のすべての結果を上回り、1文字あたり1.27ビットのエントロピーを達成した。
大規模なコーパスの統計的パターンを捉えることで、機械学習は、機械翻訳、質問応答、感情分析などの自然言語処理の大きな進歩を可能にしてきた。しかし、エージェントが人間と知的に対話するためには、単に統計的パターンを捉えるだけでは不十分である。本論文では、マルチエージェント集団において、目標を達成するための手段として、根拠のある構成的言語が出現するかどうか、またどのように出現するかを調査する。この目的のために、我々は、基本的な構成言語の出現をもたらすマルチエージェント学習環境と学習方法を提案する。この言語は、エージェントが時間の経過とともに発する抽象的な離散記号の流れとして表現されるが、それにもかかわらず、定義された語彙と構文を持つ首尾一貫した構造を持っている。また、言語によるコミュニケーションができない場合には、指差しや誘導などの非言語的なコミュニケーションが行われるようになります。
Q-learningやPolicy Gradientsなどの一般的なMDPベースのRL技術に代わるものとして、ブラックボックス最適化アルゴリズムの一種であるEvolution Strategies（ES）の使用を検討しています。MuJoCoとAtariでの実験により、ESは利用可能なCPUの数に応じて非常によくスケールする実行可能なソリューション戦略であることが示されました。共通の乱数に基づいた新しい通信戦略を用いることで、我々のES実装はスカラーの通信だけで済み、1000人以上の並列ワーカーにスケールアップすることが可能になりました。これにより、人型の3次元歩行を10分で解くことができ、1時間のトレーニングでほとんどのAtari社のゲームで競争力のある結果を得ることができました。さらに、ブラックボックス最適化手法としてのESの利点として、行動頻度や報酬の遅延に影響されず、非常に長い水平線にも耐性があり、時間的な割引や価値関数の近似を必要としないことを強調しています。
Naive Bayes(NB)やSupport Vector Machines(SVM)のモデルは、テキスト分類の基本的な手法としてよく用いられるが、その性能はモデルの種類や使用する特徴、タスクやデータセットによって大きく異なる。我々は以下のことを示す。(iii) NBの対数比を特徴量として用いたシンプルで新しいSVMの変形は、タスクやデータセットに関わらず一貫して良い性能を示す。これらの観察結果に基づいて、我々は、感情分析データセットにおいて、ほとんどの発表結果を上回る単純なNBおよびSVMの変種を特定し、時には最先端の性能レベルを提供する。
分子機械学習は、ここ数年で急速に成熟してきました。改良された手法と大規模なデータセットの存在により、機械学習アルゴリズムは分子の特性についてますます正確な予測を行うことができるようになりました。しかし、提案された手法の有効性を比較するための標準的なベンチマークがないため、アルゴリズムの進歩は限られたものになっています。ほとんどの新しいアルゴリズムは、異なるデータセットでベンチマークされるため、提案された手法の品質を評価することは困難です。本研究では、分子機械学習の大規模なベンチマークであるMoleculeNetを紹介します。MoleculeNetは、複数の公開データセットを収集し、評価基準を設定し、これまでに提案された複数の分子特徴化・学習アルゴリズムの高品質なオープンソース実装を提供します（DeepChemオープンソースライブラリの一部として公開されています）。MoleculeNetベンチマークは、学習可能な表現が分子機械学習の強力なツールであり、広く最高のパフォーマンスを提供することを示しています。しかし、この結果には注意点があります。学習可能な表現は、データの希少性や高度に不均衡な分類の下では、複雑なタスクへの対応にまだ苦戦しています。量子力学や生物物理学のデータセットでは、特定の学習アルゴリズムの選択よりも、物理学を意識した特徴付けの使用が重要になることがある。
コンピュータが理解可能な大規模な証明は、何百万もの中間的な論理ステップから構成されています。このようなステップの大部分は、人手によって選択され、人手によって導かれたヒューリスティックを中間目標に適用したものである。これまでのところ、機械学習は一般的にこれらのステップのフィルタリングや生成には使用されていない。本論文では、機械学習に基づく定理証明戦略の開発を目的として、高次論理（HOL）の証明に基づく新しいデータセットを紹介する。このデータセットは、BSDライセンスの下で公開されている。このデータセットで実行可能な様々な機械学習タスクを提案し、定理証明におけるそれらの意義を議論する。また、これらのタスクに適した単純なベースライン機械学習モデル（ロジスティック回帰、畳み込みニューラルネットワーク、リカレントニューラルネットワークなど）のベンチマークを行った。ベースラインモデルの結果は、HOLの定理証明に機械学習を適用することの有望性を示している。
深層強化学習法は、さまざまな環境で超人的な性能を発揮します。このような手法は非常に非効率的であり、妥当な性能を得るためには人間よりも何桁も多くのデータを必要とすることが多い。我々が提案する「Neural Episodic Control」は、新しい経験を素早く吸収し、それに基づいて行動することができる深層強化学習エージェントである。このエージェントは、価値関数の半表形式の表現を使用しています。これは、ゆっくりと変化する状態表現と迅速に更新される価値関数の推定値を含む、過去の経験のバッファです。我々は、幅広い環境において、我々のエージェントが他の最先端の汎用深層強化学習エージェントよりも大幅に速く学習することを示した。
GAN（Generative Adversarial Network）を用いた教師なし学習は、大きな成功を収めています。通常のGANは、シグモイドクロスエントロピー損失関数を持つ分類器として識別器を仮定しています。しかし、この損失関数は、学習過程で消失勾配問題を引き起こす可能性があることを発見しました。本論文では，この問題を解決するために，識別器に最小二乗の損失関数を採用した最小二乗生成アドバーサリアネットワーク（LSGAN）を提案する．LSGANの目的関数を最小化すると、Pearson \chi^2 divergenceを最小化できることを示す。LSGANが通常のGANよりも優れている点は2つあります。まず、LSGANは通常のGANよりも高品質な画像を生成することができます。第二に、LSGANは学習過程でより安定した性能を発揮します。LSGANを5つのシーンデータセットで評価したところ、LSGANで生成した画像は、通常のGANで生成した画像よりも高品質であることが実験結果からわかりました。また、LSGANsの安定性を示すために、LSGANsと通常のGANsの2つの比較実験を行います。
深層学習の成功は、タスクに適したアーキテクチャを見つけることにかかっています。深層学習がより困難なタスクにスケールアップしたことで、アーキテクチャを手作業で設計することが困難になっている。本論文では、進化によって深層学習アーキテクチャを最適化する自動化手法「CoDeepNEAT」を提案する。本手法は、既存のニューロエボリューション手法をトポロジー、コンポーネント、ハイパーパラメータに拡張することで、物体認識や言語モデリングなどの標準的なベンチマークにおいて、人間が設計した最良のアーキテクチャに匹敵する結果を達成している。また、雑誌のウェブサイトで画像のキャプションを自動化するという実世界のアプリケーションの構築もサポートしています。今後、計算機性能の向上が見込まれる中で、ディープネットワークの進化は、将来のディープラーニングアプリケーションを構築するための有望なアプローチである。
画像キャプション作成には、注意力に基づくニューラルエンコーダー・デコーダーのフレームワークが広く採用されている。ほとんどの方法では、生成されたすべての単語に対して視覚的な注意を働かせなければならない。しかし、デコーダは、"the "や "of "などの非視覚的な単語を予測するために、画像からの視覚情報をほとんど必要としない可能性が高い。例えば、"behind a red stop "の後の "sign "や、"talk on a cell "の後の "phone "など、視覚的に見える単語であっても、言語モデルだけで確実に予測できる場合があります。本論文では、視覚的センチネルを用いた新しい適応的注意モデルを提案します。このモデルは，各時間ステップにおいて，画像に注目するか（注目する場合はどの領域に注目するか），あるいは視覚的センチネルに注目するかを決定する．このモデルは、逐次的な単語生成のために意味のある情報を抽出するために、画像に注目するかどうか、どこに注目するかを決定する。COCO image captioning 2015 challenge datasetとFlickr30Kで我々の手法をテストした。我々の手法は、かなりのマージンで新しい最先端を設定している。
ニアレストネイバー（kNN）法は、ハードウェアの進歩とアルゴリズムの効率化の観点から、近年人気を集めています。現在、数多くの手法があり、それぞれに長所と短所があります。すべてのkNNベースの手法に共通する要件は、サンプル間の良好な表現と距離測定の必要性である。我々は、深いkNN表現の学習を可能にするdifferential boundary treeと呼ばれる新しい手法を紹介する。最近提案された境界木アルゴリズムを基にして、効率的な最近傍分類、回帰、検索を可能にします。ツリーのトラバースを確率的なイベントとしてモデル化することで、ツリーの予測に関連する微分可能なコスト関数を形成することができます。深層ニューラルネットワークを用いてデータを変換し、ツリーをバックプロパゲーションすることで、kNN法に適した表現を学習することができます。我々の手法は、適切な表現を学習することができ、明確に解釈可能な構造を持つ非常に効率的なツリーを実現できることを示している。
深層畳み込みネットワークは、多くの高次元問題において、最先端の分類と回帰の結果を提供します。本論文では、線形フィルタの重みと非線形性のカスケードでデータを散乱させる深層畳み込みネットワークのアーキテクチャを紹介します。また、その特性を分析するための数学的なフレームワークを紹介します。不変量の計算には、マルチスケールの縮退、階層的対称性の線形化、およびスパース分離が含まれる。また、応用例についても説明します。
現在の深層学習モデルは、ほとんどがニューラルネットワークに基づいて構築されています。すなわち、パラメータ化された微分可能な非線形モジュールの複数の層で、バックプロパゲーションによって学習することができます。この論文では、非微分可能なモジュールに基づいて深層学習モデルを構築する可能性を探ります。我々は、深層ニューラルネットワークの成功の背後にある謎は、3つの特性、すなわち、層ごとの処理、モデル内の特徴変換、十分なモデルの複雑さに負うところが大きいと推測する。そこで、これらの特徴を持つ深層ニューラルネットワークを生成する手法として、gcForestを提案しました。これは決定木アンサンブルアプローチで、ディープニューラルネットワークに比べてハイパーパラメータが非常に少なく、モデルの複雑さはデータに依存して自動的に決定することができます。実験によると、その性能はハイパーパラメータの設定に対して非常にロバストであり、ほとんどの場合、異なるドメインの異なるデータであっても、同じデフォルト設定を使用することで優れた性能を得ることができます。本研究は、非差分モジュールに基づく深層学習の扉を開き、バックプロパゲーションを用いずに深層モデルを構築する可能性を示しています。
教師なしの画像間翻訳は，異なる領域の画像の結合分布を，個々の領域の限界分布の画像を用いて学習することを目的としている．与えられた限界分布を到着させることができる共同分布の無限のセットが存在するので、追加の仮定なしに限界分布から共同分布について何も推論できない。この問題を解決するために、我々は共有latent spaceを仮定し、Coupled GANに基づいた教師なしの画像間翻訳フレームワークを提案する。提案したフレームワークを競合するアプローチと比較し、ストリートシーンの画像翻訳、動物の画像翻訳、顔の画像翻訳など、様々な困難な教師なし画像翻訳タスクにおいて高品質な画像翻訳結果を提示する。また、提案したフレームワークを領域適応に適用し、ベンチマークデータセットにおいて最先端の性能を達成しました。コードとその他の結果はこちらのhttps URLからご覧いただけます。
ニューラルネットワークを学習する際、合成勾配（Synthetic Gradients: SG）を使用すると、更新ロックをかけずに、つまり真の誤差勾配がバックプロパゲーションされるのを待たずに、層やモジュールを学習することができ、結果として非結合ニューラルインターフェース（Decoupled Neural Interfaces: DNI）を実現することができます。ニューラルネットワークの一部を非同期に、ローカルな情報のみで更新できるというこのアンロック機能は、Jaderberg et al (2016)で経験的に動作することが実証されました。しかし、DNIやSGが機能的、表象的、学習力学的にどのような変化をもたらすかについては、ほとんど実証されていない。本論文では、フィードフォワードネットワークに合成勾配を用いることでDNIを研究し、その挙動をよりよく理解し、最適化への影響を解明する。SGの組み込みが、ニューラルネットワークの学習システムの表現力に影響を与えないことを示し、線形モデルおよび深層線形モデルの学習システムの収束を証明する。実用的な問題では、合成勾配推定量が真の損失を近似するメカニズムを調査し、驚くべきことに、それがどのように劇的に異なるレイヤー単位の表現につながるかを明らかにする。最後に、合成勾配の使用と他の誤差近似技術との関係を明らかにし、議論と比較のための統一言語を見つけます。
暗黙的な確率モデルは、データをモデリングするための非常に柔軟なクラスです。これらのモデルは、観測値をシミュレートするプロセスを定義し、伝統的なモデルとは異なり、扱いやすい尤度関数を必要としません。本論文では、階層型暗黙モデルと深層型暗黙モデルという2つのモデル群を開発した。これらのモデルは、暗黙的な密度のアイデアと、階層的なベイズモデリングおよび深層ニューラルネットワークを組み合わせたものである。暗黙的モデルをベイズ解析に用いる場合、一般的には、正確でスケーラブルな推論を行う能力に制限がある。本研究では、暗黙的モデルのための変分推論アルゴリズムを開発しました。本手法の鍵となるのは、暗黙的でもある変分族を指定することです。これにより、モデルの柔軟性にマッチし、事後の正確な近似が可能となる。この手法は、暗黙的なモデルをこれまで不可能だったサイズにまで拡張し、新しいモデリングデザインへの扉を開きます。具体的には、生態学における捕食者-反捕食者間の大規模物理シミュレーション、離散データのためのベイジアン生成敵対ネットワーク、テキスト生成のための深層暗黙モデルなど、さまざまな応用例を紹介します。
米国では、人種、性別、教育、職業、失業率、その他の人口統計学的要因に関連する統計を測定するために、労働集約的な戸別訪問調査であるAmerican Community Survey（ACS）などの取り組みに、毎年10億ドル以上を費やしています。包括的なデータ源ではありますが、人口動態の変化がACSに反映されるまでには半世紀以上のタイムラグがあります。デジタル画像の普及とマシンビジョン技術の向上により、自動化されたデータ分析は、より安価で迅速な代替手段となる可能性があります。ここでは，Googleストリートビューによってアメリカの200都市で収集された5,000万枚のストリートシーンの画像から，社会経済的な傾向を判断する手法を紹介します。深層学習を用いたコンピュータビジョン技術を用いて、特定の地域で遭遇したすべての自動車のメーカー、モデル、年式を決定した。合計2,200万台の自動車（米国の全自動車の8％）が登録されたこの自動車センサスのデータを用いて、所得、人種、教育、投票パターンなどを1選挙区単位で正確に推定しました。(その結果、驚くほどシンプルで強力な関連付けが可能になりました。例えば、ある都市を15分間ドライブしたときに出会ったセダンの数がピックアップトラックの数よりも多ければ、その都市は次回の大統領選挙で民主党に投票する可能性が高く（88％の確率）、そうでなければ共和党に投票する可能性が高い（82％）という結果になりました。この結果は、人口統計学的傾向を監視する自動化システムが、労働集約的なアプローチを効果的に補完し、空間的な分解能でほぼリアルタイムに傾向を検出できる可能性を示唆している。
最近開発されたフィードバックアライメント（FA）とダイレクトフィードバックアライメント（DFA）の2つの手法は、従来のバックプロパゲーション更新をランダムなフィードバック更新に置き換えることで、視覚タスクにおいて驚くべき性能を得ることが示されている。しかし、どのようなメカニズムでこのようなランダムな更新で学習が行われるのかはまだ明らかになっていない。     本研究では、DFAが、我々がLinear Aligned Feedback Systems (LAFS)と呼ぶ層別学習法のノイズ的な変形と見なすことができると主張する。2つの手法の更新ルールを比較することで、この関係を理論的に裏付けます。 さらに、DFAで使用されるランダムな更新行列が読み出し行列として効果的に機能すること、DFAとLAFSの更新に使用されるエラーベクトルに強い相関関係があることを経験的に検証しました。このようにDFAとLAFSを結びつけることで、DFAで「整列」が起こる理由を説明できるようになりました。
人工ニューラルネットワークは、感覚処理、配列学習、強化学習などに非常に優れていますが、外部メモリを持たないため、変数やデータ構造を表現する能力や、長いタイムスケールでデータを保存する能力に限界があります。微分可能ニューラルコンピュータ（DNC）は、従来のコンピュータのランダムアクセスメモリのように、外部メモリマトリクスに読み書きできるニューラルネットワークで構成される機械学習モデルです。従来のコンピュータのように、メモリを使って複雑なデータ構造を表現したり操作したりすることができますが、ニューラルネットワークのように、データから学習することもできます。DNCは、教師付き学習で訓練された場合、自然言語による推論や推論問題を模して作られた合成問題に答えることができることを実証した。DNCは、指定された点の間の最短パスを見つけたり、ランダムに生成されたグラフのミッシングリンクを推論したりするタスクを学習し、これらのタスクを輸送ネットワークや家系図などの特定のグラフに一般化できることを示している。また、強化学習を用いて学習させたDNCは、シンボルの並びでゴールを変化させるムービングブロックパズルを完成させることができた。これらの結果から、DNCは、外部に読み書き可能なメモリを持たないニューラルネットワークではアクセスできない、複雑で構造化されたタスクを解決する能力を持っていることが明らかになった。
単語の埋め込みは、高度な意味情報を必要とする自然言語理解タスクでますます使用されている。しかし、新しい埋め込み手法の品質は、通常、単純な単語の類似性ベンチマークに基づいて評価されます。我々は、一般的な下流のタスク群で評価することにより、生体内での単語埋め込みを評価することを提案する。評価の使いやすさを確保するために、(1)多様なタスクで評価するという徹底した評価と、(2)調整されたハイパーパラメータの少ない単純なモデルを用いた簡単で迅速な評価の間のトレードオフ空間の良い点を見つけることに注意します。これにより、この評価を標準化されたスクリプトとオンライン評価として公開することができました。http://veceval.com/。
我々は、単語の類似性評価のための金標準データセットを作成し使用するための新しい方法を提案する。評価の信頼性を向上させることを目的とし、より高い評価者間合意を得るためにアノテーションタスクを再設計し、データセット内の各アノテーション決定の信頼性を考慮したパフォーマンス指標を定義することでこれを実現している。
推論や物理的なインタラクションなどの実世界のタスクの多くは、概念的なエンティティの識別と操作を必要とします。これらのタスクを解決するための最初のステップは、分散したシンボル状の表現を自動的に発見することです。本論文では、この問題を、各構成要素がニューラルネットワークでパラメータ化された空間混合モデルの推論として明示的に形式化する。そして、期待値最大化の枠組みに基づいて、個々のエンティティのグループ化と表現方法を同時に学習する微分可能なクラスタリング手法を導き出す。我々の手法を知覚的グルーピングタスクで評価したところ、構成されたオブジェクトを正確に復元できることがわかった。また、学習された表現が次のステップの予測に役立つことを示す。
本論文で紹介する手法は、オーバーフィット問題に直面しているコンピュータビジョンの実務者を支援することを目的としている。そのアイデアは、3枝のResNetにおいて、標準的な残差枝の合計を、確率的なアフィン結合に置き換えることである。テストされた最大のモデルは、CIFAR-10においてシングルショットで発表された最良の結果を改善し、テストエラーは2.86%に達しました。コードは https://github.com/xgastaldi/shake-shake で入手可能です。
Char2Wavは、音声合成のためのエンド・ツー・エンドモデルです。Char2Wavは、リーダーとニューラルボコーダの2つのコンポーネントで構成されています。リーダーは、注目を集めるエンコーダ・デコーダモデルである。エンコーダーは、テキストや音素を入力として受け取る双方向のリカレント・ニューラル・ネットワークで、デコーダーは、ボコーダーの音響特徴を生成するアテンション付きリカレント・ニューラル・ネットワーク（RNN）です。Neural vocoderは、中間表現から生の波形サンプルを生成するSampleRNNの条件付き拡張を指します。Char2Wavは、従来の音声合成モデルとは異なり、テキストから直接音声を生成することを学習します。
ビデオゲームをマスターするには、スキル、戦術、戦略が必要です。これらの特性は、人間のプレイヤーが自然に身につけることができても、コンピュータプログラムにそれを教えることは、はるかに難しい課題です。近年、強化学習の分野では、ゲームなどの人間の作業を学習することを目的とした、さまざまなアルゴリズムが開発されています。その結果、Arcade Learning Environment (ALE) (Bellemare et al., 2013)は、Atari 2600の様々なゲームでアルゴリズムを学習させるベンチマーク環境としてよく使われるようになりました。多くのゲームで、最先端のアルゴリズムは人間を凌駕している。本論文では、スーパーファミコンやセガ・ジェネシスなどのゲーム機のゲームを実行できる新しい学習環境「Retro Learning Environment --- RLE」を紹介します。この環境は拡張性があり、ALEと同じインターフェイスを維持しながら、より多くのビデオゲームやゲーム機を簡単に追加することができるようになっている。さらに、RLEはPythonとTorchに対応しています。SNESのゲームは、より高いレベルの複雑さと多様性のために、現在のアルゴリズムに大きな課題を与えています。
深層畳み込みニューラルネットワークを用いて、音声や音楽などの信号のサンプリングレートを向上させる新しいオーディオ処理技術を紹介します。我々のモデルは、低品質と高品質のオーディオ例のペアで学習され、テスト時には、画像の超解像に似た補間プロセスで低解像度信号内の欠落したサンプルを予測します。実験では、2倍、4倍、6倍のアップスケール率で、標準的な音声および音楽のベンチマークにおいて、ベースラインよりも優れた性能を示しました。この手法は、テレフォニー、圧縮、音声合成などの分野で実用化されており、音声生成タスクにおけるフィードフォワード型の畳み込みアーキテクチャの有効性を実証している。
本論文では、ノイズ除去や超解像などの画像復元のために、非常に深い完全畳み込み符号化・復号化フレームワークを提案する。このネットワークは、畳み込み演算子と非畳み込み演算子の複数の層で構成されており、破損した画像から元の画像へのエンド・ツー・エンドのマッピングを学習する。畳み込み層は特徴抽出器として機能し、ノイズや破損を除去しながら画像コンテンツの抽象化を行います。その後、脱畳み込み層を用いて画像の詳細を復元します。私たちは、畳み込み層と非畳み込み層をスキップ層で対称的に接続することを提案します。これにより、学習の収束が速くなり、より質の高い局所最適が得られます。スキップ層接続は、信号を直接下層に逆伝播させることができるため、勾配消失の問題に取り組み、深層ネットワークの学習を容易にし、結果として復元性能を向上させることができます。第二に、これらのスキップ接続は、画像の詳細を畳み込み層から非畳み込み層に渡すので、元の画像を復元するのに有効です。また、大容量化により、1つのモデルで様々なレベルのノイズに対応できるようになりました。実験結果は、我々のネットワークが、これまでに報告されたすべての最先端の手法よりも優れた性能を達成することを示している。
我々は、高精度の単一画像超解像（SR）法を発表する。本手法では，ImageNetの分類に用いられているVGG-netにヒントを得て，非常に深い畳み込みネットワークを用いている．ネットワークの深さを増やすことで、精度が大幅に向上することがわかりました。最終的なモデルでは、20のウェイト層を使用しています。深いネットワーク構造の中で、小さなフィルターを何度もカスケード接続することで、大きな画像領域の文脈情報を効率的に利用することができます。しかし、非常に深いネットワークでは、学習時に収束速度が重要な問題となります。我々は、シンプルかつ効果的な学習方法を提案する。残差のみを学習し，調整可能な勾配クリッピングによって極めて高い学習率(SRCNNの104倍)を実現する．提案手法は、既存の手法よりも精度が高く、視覚的にも改善された結果が容易に確認できる。
深層再帰的畳み込みネットワーク(DRCN)を用いた画像超解像法(SR)を提案する。このネットワークは、非常に深い再帰層（最大16の再帰層）を持っています。再帰層の深さを増やすことで、追加の畳み込みのために新たなパラメータを導入することなく、性能を向上させることができます。しかし、DRCNの学習は、標準的な勾配降下法では、勾配が爆発したり消失したりするため、非常に困難です。この学習の難しさを軽減するために、再帰的スーパービジョンとスキップコネクションという2つの拡張機能を提案する。我々の手法は、従来の手法を大差で凌駕する。
単一画像の超解像（SR）のための深層学習手法を提案する。本手法は、低解像度/高解像度画像間のエンドツーエンドのマッピングを直接学習する。このマッピングは、低解像度の画像を入力とし、高解像度の画像を出力する深層畳み込みニューラルネットワーク（CNN）として表現される。さらに、従来のスパースコーディングベースのSR手法も、深層畳み込みネットワークと見なすことができることを示している。しかし、各コンポーネントを個別に処理する従来の手法とは異なり、我々の手法はすべてのレイヤーを共同で最適化します。我々の深層CNNは、軽量な構造でありながら、最先端の復元品質を示し、実用的なオンライン使用のための高速性を実現しています。我々は、性能と速度の間のトレードオフを達成するために、様々なネットワーク構造とパラメータ設定を検討した。さらに，我々のネットワークを拡張して，3つのカラーチャンネルを同時に扱えるようにしたところ，全体的な復元品質が向上しました。
我々は、長距離依存性を持つ時間的データをモデル化するという一般的な問題を検討しています。十分に強力な時間モデルは、シーケンスの予測可能な要素と予測不可能な要素を分離し、それらの予測不可能な要素に関する不確実性を表現し、将来の予測に役立つ可能性のある新しい要素を迅速に特定する必要がある。このようなモデルを作成するために、私たちは外部記憶システムで補強された生成的時間モデルを導入しました。このモデルは、変分推論の枠組みの中で開発されており、実用的な学習方法とモデルの動作に関する洞察を得るための方法の両方を提供する。我々は、疎で長期的な時間依存性を持つ様々な問題について、これらのモデルがシーケンスの初期から情報を保存し、この保存された情報を効率的に再利用することを示した。これにより、LSTMのようなよく知られたリカレントニューラルネットワークに基づく既存のモデルよりも大幅に優れた性能を発揮することができます。
リカレントネットワークアーキテクチャの経験的探求
ニューラル言語モデルは、直前のトークン履歴の潜在的な表現を用いて次のトークンを予測します。近年、ニューラル言語モデルに微分可能なメモリ上の注目メカニズムを付加する手法が様々な形で提案されています。これらのモデルでは、次のトークンを予測するために、直近の履歴の記憶から情報を取得し、中・長距離の依存関係を学習することができます。しかし、従来のメモリ・アグメンテッド・ニューラル・ランゲージ・モデルの注意メカニズムは、時間ステップごとに1つの出力ベクトルを生成します。このベクトルは、次のトークンを予測するためにも、トークン履歴の微分可能な記憶のキーと値のためにも使われる。本論文では、微分可能な記憶のキーと値、および次の単語の分布を符号化するために別々の表現を出力する、キー・バリュー注目メカニズムを持つ神経言語モデルを提案する。このモデルは、2つのコーパスにおいて、既存のメモリ注目型ニューラル言語モデルを凌駕した。しかし、この手法では、主に最新の5つの出力表現のメモリを利用していることがわかりました。これにより、以前の時間ステップからの最近の出力表現の連結のみに基づいたより単純なモデルが、より洗練されたメモリオーグメンテーションされたニューラル言語モデルと同等であるという予想外の主旨の発見がなされました。
バッチ正規化は、ディープモデルの学習を高速化・改良するのに非常に有効です。しかし、学習ミニバッチが小さい場合や、独立したサンプルで構成されていない場合には、その効果は低下します。これは、モデル層の入力がミニバッチ内のすべてのサンプルに依存し、学習と推論の間で異なる活性化が生成されることが原因であると考えられます。そこで，学習モデルと推論モデルが，ミニバッチ全体ではなく個々の例に依存する同じ出力を生成することを保証する，簡単で効果的な拡張機能である「バッチ・リノーマライゼーション」を提案する．バッチ再正規化を用いて学習したモデルは、少量のミニバッチや非i.i.d.ミニバッチで学習した場合に、batchnormよりも大幅に優れた性能を発揮する。また、バッチ正規化は、初期化の影響を受けない、学習効率が高いなどのバッチノルムの利点を維持しています。
最近では、畳み込みニューラルネットワークを用いてテクスチャ合成やスタイル転送を行う手法が提案されています（Gatysら[2015,2016]など）。これらの手法は、場合によっては最先端の品質を持つ結果を生み出すことができるため、エキサイティングである。しかし、本論文では、これらの手法には、テクスチャ品質、安定性、必要なパラメータ調整、ユーザーコントロールの欠如などの限界もあることを示しています。本論文では，これらの問題を解決するために，畳み込みニューラルネットワークをベースとしたマルチスケール合成パイプラインを紹介する．まず、これまでの多くのアプローチにおける不安定性の原因を数学的に説明します。次に，ヒストグラム・ロスを利用して，模範画像と統計的によく一致するテクスチャを合成することで，これらの不安定性を改善する．また，局所的なスタイルロスをマルチスケールフレームワークに統合する方法も示している．これらの損失は、大きな特徴の品質を向上させ、コンテンツとスタイルの分離を改善し、paint by numbersのような芸術的なコントロールを提供することができる。我々のアプローチは，品質を向上させ，より少ない反復回数で収束させ，最適化の安定性を高めることができることを示している．
これまでの研究では、聴覚ベースのガボール特徴と深層学習アーキテクチャを組み合わせることで、ロバストな自動音声認識を実現するというアイデアが支持されていますが、このような組み合わせで得られる利益の原因はまだ分かっていません。我々は、これらの表現が深層学習デコーダに、より識別しやすい手掛かりを提供すると考えています。本論文の目的は、3つの異なる認識タスク（Aurora 4、CHiME 2、CHiME 3）で実験を行い、ガボール・フィルターバンク特徴によってエンコードされた情報の識別性を評価することで、この仮説を検証することです。さらに、低、中、高の時間変調周波数の寄与を識別するために、ガボールフィルターバンクのサブセットを特徴量として使用しました（それぞれ、LTM、MTM、HTMと名付けられました）。時間変調周波数が16Hzから25Hzの場合、HTMはすべての条件で一貫して残りの条件を上回り、チャンネルの歪み、低いS/N比、音響的に困難な現実のシナリオに対して、これらの表現のロバスト性が強調され、Mel-filterbank-DNNのベースラインに対して11から56%の相対的な改善が見られました。この結果を説明するために、DNNの活性化から音素クラス間の類似性を測定する方法を提案し、それらの音響特性と関連付ける。この指標は、観測されたエラー率と一致しており、音素レベルでの特定の違いを強調することで、提案された特徴の利点を正確に示すことができた。
近年、モバイルコンピューティングのためのニューラルネットワークに基づく機械学習技術がますます普及しています。古典的な多層ニューラルネットワークは、各ステージで行列の乗算を必要とします。乗算演算はエネルギー効率の良い演算ではないため、結果的にモバイル機器のバッテリーを消耗してしまう。本論文では、ルベーグ積分可能な関数の空間上で普遍的な近似特性を持つ、エネルギー効率の良い新しいニューラルネットワークを提案します。このニューラルネットワークは、Additive neural networkと呼ばれ、モバイルコンピューティングに非常に適しています。このニューラルネットワークの構造は、ef-operatorと呼ばれる新しいベクトル積の定義に基づいており、乗算器なしでの実装が可能です。ef-operatorでは、2つの実数の「積」は、それらの絶対値の和として定義され、その符号は実数の積の符号によって決定されます。この「積」を用いて、R^Nにおけるベクトル積を構成します。ベクトル積は，l_1ノルムを誘導する．提案された加法ニューラルネットワークは，XOR問題の解決に成功した．MNISTデータセットを用いた実験では，提案した加算型ニューラルネットワークの分類性能は，対応する多層パーセプトロンや畳み込みニューラルネットワーク（LeNet）と非常によく似ていることが示された．
単語のベクトル表現に対する標準的な外在的評価方法がないため、NLPコミュニティは、単語ベクトルの内在的評価の代理として、単語の類似性タスクに大きく依存してきた。ベクトル間の距離と人間が判断した意味的類似性を相関させる単語の類似性評価は、計算量が少なく高速であるため魅力的である。本論文では、単語類似性データセット上での単語ベクトルの評価に関連するいくつかの問題を提示し、既存の解決策をまとめる。我々の研究では、単語ベクトルの評価に単語の類似性タスクを使用することは持続可能ではないことを示唆しており、評価方法のさらなる研究を求めている。
単語表現の品質は、人間による単語の類似性の判断との相関を用いて評価されることが多い。ここでは、このような内在的な評価が、下流のタスクにおける表現の良し悪しを予測できるかどうかを検討する。我々は、18億語の未注釈コーパスから誘導された様々な単語ベクトルを用いて、10種類の単語の類似性ベンチマークの結果と、3つの標準的なシーケンスラベリングタスクにおけるタガーのパフォーマンスとの相関関係を研究し、ほとんどの内在的な評価が下流のパフォーマンスを予測するのに不十分であることを実証した。この問題は、内在的評価データセットにおいて、特定の類似性と関連性を区別できていないことが一因であると主張している。さらに研究を進めるために、評価ツールを公開している。
アテンションネットワークは、分類的な推論をディープニューラルネットワークに埋め込むための効果的なアプローチであることが証明されている。しかし、多くのタスクでは、エンド・ツー・エンドの学習を放棄することなく、より豊かな構造依存性をモデル化したい場合がある。本研究では、グラフィカルモデルを用いて符号化された、より豊かな構造的分布を深層ネットワークに組み込む実験を行った。この構造化された注意ネットワークは、基本的な注意手順の単純な拡張であり、部分的なセグメンテーションやサブツリーへの注意など、標準的なソフト選択アプローチを超えた注意の拡張が可能であることを示す。本研究では、2種類の構造化注意ネットワーク（線形鎖条件付きランダムフィールドとグラフベースの構文解析モデル）を用いて実験を行い、これらのモデルをニューラルネットワークのレイヤーとして実用的に実装する方法を説明した。実験によると、このアプローチは構造的バイアスを組み込むのに有効であり、構造化されたアテンションネットワークは、木の変換、ニューラル機械翻訳、質問応答、自然言語推論などの様々な合成タスクや実タスクにおいて、ベースラインのアテンションモデルよりも優れていることがわかった。さらに、この方法で学習したモデルは、単純な注意を一般化する興味深い教師なしの隠れた表現を学習することがわかった。
