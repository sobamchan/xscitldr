本論文では，物体検出のためのシンプルで汎用的なフレームワークである Pix2Seq を紹介する．タスクに関する事前知識を明示的に統合する既存のアプローチとは異なり、我々はオブジェクト検出を、観測されたピクセル入力を条件とする言語モデリングタスクとして単純にキャストする。オブジェクトの記述（バウンディングボックスやクラスラベルなど）は，離散的なトークンのシーケンスとして表現され，画像を認識して望ましいシーケンスを生成するようにニューラルネットを訓練する．これは、「ニューラルネットが、どこに何があるかを知っていれば、それを読み出す方法を教えればよい」という直感に基づいたアプローチです。タスクに特化したデータ補強を行うだけでなく、我々のアプローチはタスクに関する仮定を最小限に抑えていますが、難易度の高いCOCOデータセットにおいて、高度に専門化され最適化された検出アルゴリズムと比較して、競争力のある結果を得ることができました。
大は小を兼ねる」という言葉があるように、ディープニューラルネットワークのパラメータ数は爆発的に増加しており、計算機に制限のある環境で最先端のネットワークにアクセスできるようにすることはますます困難になっています。このギャップを埋める方法として、圧縮技術が再び重要視されています。しかし、一般的な圧縮技術で発生するトレードオフの評価は、ハイリソースのデータセットを中心に行われてきました。本研究では，代わりに，データが限られた環境における圧縮の影響を検討する．ここでは、データの制限と計算資源の制約が同時に発生することを「低資源ダブルバインド」と呼んでいます。これは、リソースの少ない言語のNLPでは一般的な設定ですが、パフォーマンスのトレードオフについてはあまり研究されていません。本研究では、機械翻訳というタスクにおける、データ制限のある領域での容量と一般化の関係について、驚くべき洞察を得ました。英語からヨルバ語、ハウサ語、イボ語、ドイツ語への翻訳を対象としたマグニチュード・プルーニングの実験では、リソースが少ない環境では、スパース性は頻度の高い文のパフォーマンスを維持するが、頻度の低い文には大きな影響を与えることがわかった。しかし，スパース性は，特に学習分布とは大きく異なるデータセットにおいて，分布外のシフトに対する頑健性を向上させる．今回の発見は、スパース性が低頻度属性の記憶を抑制する上で有益な役割を果たすことを示唆しており、低リソースのダブルバインドに対する有望な解決策を提供しています。
機械学習を拡張する上での大きな課題は、人間が評価することが非常に困難または時間のかかるタスクを実行するモデルをトレーニングすることです。本論文では、小説全体を抽象的に要約するタスクにおけるこの問題の進展を紹介する。我々の手法は、人間のフィードバックからの学習と、再帰的なタスク分解を組み合わせたもので、タスクのより小さな部分で訓練されたモデルを用いて、より広範なタスクに対する人間のフィードバックを支援します。人間のラベラーから大量のデモと比較を収集し、行動クローニングと報酬モデルを用いてGPT-3を微調整することで、再帰的に要約を行うことができます。推論時に、このモデルはまず本の小さなセクションを要約し、次にこれらの要約を再帰的に要約して本全体の要約を作成する。人間のラベラーは、本を全部読んでいないにもかかわらず、モデルの監督と評価を素早く行うことができる。その結果，本全体の良識ある要約を生成することができ，いくつかのケースでは人間が書いた要約の品質に匹敵することができた（sim5% of books）．本の長さを要約するための最近のデータセットであるBookSumにおいて、最先端の結果を得ることができた。また、これらの要約を用いたゼロショット質問応答モデルは、書籍や映画の脚本に関する質問に答えるチャレンジングなベンチマークであるNarrativeQAにおいて、最先端の結果を得ることができました。このモデルのサンプルのデータセットを公開します。
大規模なTransformerモデルは、近年の自然言語処理の進歩の中心となっています。しかし、これらのモデルの学習と推論のコストは急速に増加し、法外に高価になっています。ここでは、より効率的な変種を探索することで、Transformerのコストを削減することを目的としています。以前のアプローチと比較して、我々の検索は、Transformer TensorFlowプログラムを定義するプリミティブに対して、より低いレベルで実行されます。その結果、自動回帰型言語モデリングのためのオリジナルのTransformerやその他の変形よりも学習コストが小さいPrimerと名付けられたアーキテクチャを特定した。Primerの改善は、ReLU活性化の二乗化と、自己注意におけるQ、K、Vの各投影の後に深さ方向の畳み込み層を追加するという、2つの単純な修正に起因するものである。
実験によると、PrimerがTransformerよりも優れている点は、計算規模が大きくなるにつれて増加し、最適なモデルサイズでは品質に関してべき乗則に従うことがわかった。また、Primerを様々なコードベースに落とし込むことで、追加のチューニングなしにトレーニングを大幅に高速化できることを経験的に検証した。例えば、500Mのパラメータサイズでは、Primerは、C4自動回帰言語モデリングにおけるオリジナルのT5アーキテクチャを改善し、学習コストを4倍に削減しました。さらに、学習コストが削減されたことで、目標とするワンショット性能を得るために必要な計算量が大幅に減少しました。例えば、GPT-3 XLと同様の1.9Bのパラメータ設定では、PrimerはTransformerと同じワンショット性能を得るために必要な学習計算量が1/3になります。再現性を高めるために、T5ではモデルといくつかの比較結果をオープンソース化しています。
大規模な言語モデル（LM）は、非常に流暢なテキストを生成し、NLPタスクに効率的に適応することができます。生成されたテキストの品質を安全性の観点から測定・保証することは、LMを実世界に展開する上で必須である。この目的のために、先行研究ではしばしばLMの毒性の自動評価に依存している。本研究では、このアプローチを批判的に検討し、いくつかの毒性緩和戦略を自動評価と人間による評価の両方で評価し、モデルバイアスとLM品質の観点から毒性緩和の結果を分析した。その結果、RealToxicityPromptsデータセットにおいて、基本的な介入戦略は、これまでに確立された自動評価基準を効果的に最適化することができるが、その代償として、疎外されたグループに関するテキストとその方言の両方に対するLMカバレッジが減少することがわかった。さらに、人間の評価者は、毒性低減のための介入を行った後に、自動評価による高い毒性スコアに同意しないことが多いことがわかり、LMの毒性を慎重に評価する上でのニュアンスの違いが浮き彫りになりました。
科学研究の基本的な目的は、因果関係を解明することです。しかし，生命科学や社会科学では因果関係が重要な役割を果たしているにもかかわらず，予測タスクを重視してきた自然言語処理（NLP）では，因果関係はそれほど重要ではありませんでした．しかし、因果関係推論と言語処理を融合した学際的な研究分野が登場するなど、この違いは解消されつつある。しかし、NLPにおける因果関係の研究は、統一された定義やベンチマークデータ、残された課題の明確な説明がないまま、各分野に散在しています。この調査では、学術的な分野の研究をまとめ、NLPの全体像の中に位置づけています。因果関係を推定するという統計学的な課題を紹介し、テキストが結果や治療法として、あるいは交絡に対処する手段として使用される設定を網羅します。さらに、NLPモデルのパフォーマンス、ロバスト性、公平性、解釈可能性を向上させるための因果関係推論の潜在的な利用法を探ります。このようにして、計算言語学のコミュニティに因果推論の統一的な概要を提供します。
複雑なシステムでは、個々のエージェントが全体像を知らずに局所的に入手可能な情報のみに基づいて行動し、環境内で相互に作用するエージェントの集合体から複雑なグローバルな行動が生じることがよくあります。このようなシステムは、群最適化やセルラーオートマトンなどの分野における人工知能アルゴリズムの開発にインスピレーションを与えてきた。本研究では、複雑な細胞システムから集団行動が生じることに着想を得て、環境からの各感覚入力を、互いに固定された関係のない、異なるが同一のニューラルネットワークに供給するシステムを構築する。これらの感覚ネットワークは、局所的に受け取った情報を統合するように訓練され、注意メカニズムを介したコミュニケーションによって、全体的に一貫した方針を生み出すことができることを示す。さらに、1つのエピソードの中で、入力の順序がランダムに何度も入れ替わっても、システムはそのタスクを実行することができます。このような順列不変のシステムは、広く適用可能なロバスト性と一般化の特性も示しています。インタラクティブなデモとビデオによる成果の紹介：このhttpsのURL
テキストやレイアウトの事前学習は、その効果的なモデル構成と、大規模な非ラベルのスキャン/デジタル生文書の利点から、様々な視覚的に豊かな文書理解タスクにおいて有効であることが証明されています。本論文では、マルチモーダルなフレームワークを用いて、テキスト、レイアウト、画像の事前学習を行うことで、新しいモデルアーキテクチャと事前学習タスクを活用した、\textbf{LayoutLMv2}を発表します。具体的には、LayoutLMv2は、既存のマスクされた視覚言語モデリングタスクだけでなく、新しいテキスト-画像間のアライメントタスクとテキスト-画像間のマッチングタスクを事前学習段階で使用し、クロスモダリティの相互作用をよりよく学習しています。また、Transformerアーキテクチャに空間認識型の自己注意メカニズムを統合することで、モデルが異なるテキストブロック間の相対的な位置関係を完全に理解できるようにしています。実験の結果、LayoutLMv2は強力なベースラインを上回り、FUNSD (0. 7895 -> 0.8420) など、下流のさまざまな視覚的に豊かな文書理解タスクにおいて、最先端の結果を達成しました。 7895 -> 0.8420), CORD (0.9493 -> 0.9601), SROIE (0.9524 -> 0.9781), Kleister-NDA (0.834 -> 0.852), RVL-CDIP (0.9443 -> 0.9564), DocVQA (0.7295 -> 0.8672). なお、学習済みのLayoutLMv2モデルは、こちらのhttpsのURLで公開されています。
AIは、広範なデータで大規模に学習され、下流の幅広いタスクに適応可能なモデル（BERT、DALL-E、GPT-3など）の台頭により、パラダイムシフトを迎えています。私たちは、これらのモデルを基礎モデルと呼び、その決定的に重要でありながら不完全な性格を強調しています。本報告書では、基礎モデルの能力（言語、視覚、ロボット、推論、ヒューマンインタラクションなど）や技術的原則（モデルのアーキテクチャ、学習手順、データ、システム、セキュリティ、評価、理論など）から、応用分野（法律、医療、教育など）や社会的影響（不公平感、誤用、経済・環境への影響、法的・倫理的配慮など）に至るまで、基礎モデルの可能性とリスクについて徹底的に説明しています。基盤モデルは標準的な深層学習や転移学習をベースにしていますが、その規模は新たな創発能力をもたらし、多くのタスクに有効であることから、均質化を促します。均質化は強力なレバレッジをもたらしますが、基礎モデルの欠陥が下流のすべての適合モデルに継承されるため、注意が必要です。基礎モデルの普及が間近に迫っているにもかかわらず、我々は現在、基礎モデルがどのように機能するのか、どのような場合に失敗するのか、また、その創発的な特性によって何ができるのかについて、明確な理解ができていません。これらの問題に取り組むためには、基礎モデルに関する重要な研究の多くが、その基本的な社会工学的性質に見合った、深い学際的な協力を必要とすると考えています。
最先端の抽象的な要約モデルに共通して見られる問題は、生成された要約が入力文書と事実上一致しないことがあることである。自動要約は、もっともらしく聞こえるが不正確な要約を生成する可能性があるという事実は、自動要約の幅広い応用を制限する大きな懸念である。本論文では、要約における事実の一貫性に対処するためのアプローチを紹介する。まず、事実の一貫性を測定するための効率的な自動評価指標を提案し、次に、モデルの学習中に提案した指標を最大化する新しい学習アルゴリズムを提案する。大規模な実験により，我々の手法が事実の一貫性，さらには要約の全体的な品質を向上させるのに有効であることを，自動評価指標と人間の評価の両方で確認した．
本論文は、自然言語処理における新しいパラダイムである「プロンプトベースの学習」の研究成果を調査し、整理したものである。従来の教師付き学習では、入力xを受け取り、出力yをP(y|x)として予測するモデルを学習していたが、プロンプトベース学習では、テキストの確率を直接モデル化する言語モデルに基づいている。これらのモデルを使って予測タスクを実行するには、テンプレートを使って元の入力xを、いくつかの未記入のスロットを持つテキスト文字列プロンプトx'に修正し、次に言語モデルを使って未記入の情報を確率的に埋めて最終的な文字列xを得て、そこから最終的な出力yを導き出すことができる。このフレームワークが強力で魅力的な理由は、大量の生のテキストに対して言語モデルを事前に学習させることができること、新しいプロンプト関数を定義することで、モデルが数ショット、あるいはゼロショット学習を行うことができ、ラベル付きデータがほとんど、あるいは全くない新しいシナリオに適応することができることである。本論文では、この有望なパラダイムの基本を紹介し、既存の研究を幅広くカバーできる統一された数学的表記法を説明するとともに、既存の研究をいくつかの次元で整理した。この分野に興味を持つ初心者がよりアクセスしやすくなるように、既存の研究を系統的にレビューし、プロンプトベースの概念を高度に構造化したタイポロジーを作成するだけでなく、例えば、常に更新されたサーベイや論文リストを含むこのhttpのURLのウェブサイトなどのリソースを公開しています。
少数精鋭のNLP研究は非常に活発ですが、評価スイートは、挑戦的でありながら現実的なテスト設定がなく、慎重な実験デザインを採用していないため、バラバラの研究スレッドで行われています。そのため、どの技術が最も優れているのか、あるいは単純なベースラインよりも優れているのかどうかさえ、コミュニティは分かっていません。私たちは、理想的な数撃ちゃ当たるNLPベンチマークの要件を策定し、数撃ちゃ当たるNLPテクニックの統一的かつ包括的な測定を提供する初のベンチマーク、パブリックリーダーボード、およびフレームワークであるFLEXを発表します。FLEXは、4つの転送設定の測定、ゼロショット評価のためのテキストラベル、統計的な精度を最適化しつつ、大規模な計算リソースを持たない研究者でも評価コストを抑えられるベンチマーク設計の原則的なアプローチなど、数ショット評価のための新しいベストプラクティスを取り入れ、紹介しています。さらに、UniFewは、シンプルで強力なプロンプトベースの少数ショット学習モデルです。このモデルは、言語モデルの事前学習の目的に合わせて下流のタスクフォーマットを適応させる最近のプロンプトベースのアプローチの複雑な仕組みを排除し、事前学習と微調整のプロンプトフォーマットを統一しています。UniFewは、シンプルであるにもかかわらず、一般的なメタ学習やプロンプトベースのアプローチに負けない結果を得ることができることを示している。
建築物は人間居住地の社会的・環境的持続可能性の中心であるため、その管理と計画をサポートするためには高品質の地理空間データが必要です。世界中の当局がこのようなデータを収集し、公開することが増えていますが、これらはほとんどが独立した取り組みであり、ユーザーが都市の持続可能性のためにその可能性を十分に活用することが困難になっています。本研究では，各国政府が無料で公開している建築物の2次元地理空間データを，個別の都市から国全体に至るまで，グローバルに調査しました．28カ国で公開されている1億棟以上の建築物を含む140件以上のデータを、アクセスのしやすさ、豊富さ、データの質、整合性、他のアクターとの関係の5つの観点から評価し、ベンチマークを行いました。その結果，各国政府が公開している多くの建築物データは，空間分析に有用であるものの，データの質には大きな格差があり，すべての事例が高品質で調和がとれており，記述的情報が豊富であるとは限らないことがわかりました．本研究では、権威あるデータと、クラウドソースであるOpenStreetMapとの比較も行っており、相互に有益で補完的な関係を示唆しています。
事前に学習された言語モデル（LM）と知識グラフ（KG）から得られる知識を用いて質問に答えるという問題は、2つの課題を提示している。すなわち、QAコンテキスト（質問と回答の選択肢）が与えられた場合、（i）大規模なKGから関連する知識を特定すること、（ii）QAコンテキストとKGに対する共同推論を実行すること、が必要である。本研究では、QA-GNNという新しいモデルを提案し、2つの重要な技術革新によって上記の課題に取り組みます。(i)関連性スコアリング（LMを用いて、与えられたQAコンテキストに対するKGノードの重要性を推定する）、(ii)共同推論（QAコンテキストとKGを接続して共同グラフを形成し、グラフニューラルネットワークを用いて両者の表現を相互に更新する）。QA-GNNをCommonsenseQAおよびOpenBookQAデータセットで評価した結果、既存のLMモデルやLM+KGモデルよりも優れていること、また、質問中の否定を正しく処理するなど、解釈可能で構造化された推論を行う能力があることを示した。
現在、地球が経験している温暖化の少なくとも4分の1は、人為的なメタンの排出によるものです。しかし、メタンガスの排出を地上の排出源に帰属させるためには、世界中の排出源の位置と特徴を示す包括的なデータベースが不可欠です。本研究では、自由に利用できる高解像度航空写真を活用して、世界のメタン排出量の最大の原因の1つである石油・ガスのインフラを自動的に検出する深層学習アルゴリズムを開発します。OGNetは、石油・ガスインフラの標準的な4つの公開データセットには存在しない多くの施設を検出することを示しています。検出された施設はすべて、インフラの種類や貯蔵タンクの数など、メタン排出に寄与することが知られている特徴と関連しています。本研究で作成されたデータは、このhttpのURLから自由に入手することができます。
情報の氾濫は、価値の高い多くの分野で共通の課題です。その代表例が，COVID-19に関する生物医学文献の爆発的な増加であり，数ヶ月のうちに数十万の論文にまで膨れ上がった．一般的に、生物医学文献は毎分2本のペースで増加し、毎年100万本以上の新しい論文が発表されています。生物医学分野をはじめとする多くの垂直領域における検索は，クリックログからの直接的な監視が少ないため，困難を極めます．自己教師付き学習は、アノテーションのボトルネックを克服するための有望な方向性として浮上している。我々は、ドメイン固有の事前学習に基づく垂直検索のための一般的なアプローチを提案し、生物医学ドメインのケーススタディを紹介する。本手法は、訓練や開発に関連性ラベルを使用せず、大幅に単純化されているにもかかわらず、COVID関連の生物医学検索コンペティションであるTREC-COVIDの公式評価において、最良のシステムと同等以上の性能を示した。最新のクラウドインフラの分散コンピューティングを使用して，我々のシステムはPubMedの数千万の記事に拡張することができ，生物医学文献の新しい検索体験であるMicrosoft Biomedical Searchとして展開されている：このhttpsのURL。
人間は対照的な説明をすることが知られています。対照的な説明とは、観察された出来事が他の反事実的な出来事（対照ケース）よりも起こった理由を説明することです。人間の説明方法において対比性が果たす役割は非常に大きいにもかかわらず、現在のNLPモデルの説明方法ではこの特性がほとんど見られません。本研究では、モデルの出力を対照的なケースに変更する入力の編集という形で、モデルの予測を対照的に説明する手法であるMinimal Contrastive Editing (MiCE)を発表する。2値センチメント分類、トピック分類、多肢選択式質問応答の3つのタスクで実験を行った結果、MiCEは対比的であるだけでなく、人間の対比的な編集と同じように、最小限で流暢な編集を行うことができることがわかった。本論文では，NLPシステム開発における2つのユースケース，すなわち，誤ったモデル出力のデバッグとデータセットのアーティファクトの発見にMiCEの編集がどのように利用できるかを示し，対照的な説明を作成することがモデルの解釈可能性のための有望な研究方向であることを示した．
人間は対照的な説明をすることが知られています。これは、ある観測された事象が、他の反事実的な事象（対照ケース）ではなく、なぜ起こったのかを説明するものです。人間の説明方法には対照的な性質が重要な役割を果たしているにもかかわらず、現在のNLPモデルを説明する方法にはこの性質がほとんどありません。本研究では、モデルの出力を対照的なケースに変更する入力の編集という形で、モデルの予測を対照的に説明する手法であるMinimal Contrastive Editing (MiCE)を発表する。2値センチメント分類、トピック分類、多肢選択式質問応答の3つのタスクで実験を行った結果、MiCEは対比的であるだけでなく、人間の対比的な編集と同じように、最小限で流暢な編集を行うことができることがわかった。また，NLPシステム開発における2つのユースケース，すなわち，誤ったモデル出力のデバッグとデータセットのアーティファクトの発見にMiCEの編集がどのように利用できるかを示し，対照的な説明の生成がモデルの解釈可能性のための有望な研究方向であることを示した．
これは、入力の品質を評価する批評家（例えば、コンパイラ）が与えられた場合、悪い例（例えば、構文エラーのあるコード）を良い例（例えば、構文エラーのないコード）に変換する修正器を訓練することを目的としています。既存の研究では、ヒューリスティックな手法（トークンの削除など）を用いて良い例を汚し、（悪い、良い）ペアからなる学習データを作成している。しかし、このように合成されたデータで訓練されたフィクサーは、実際の悪い入力の分布にうまく外挿することができない。このギャップを埋めるために、我々はBreak-It-Fix-It (BIFI)という新しい学習手法を提案する。(i) 批評家を使って、実際の悪い入力に対する修正者の出力をチェックし、訓練データに良い（固定）出力を追加する、(ii) ブレーカーを訓練して、良いコードから現実的な悪いコードを生成する。これらのアイデアに基づき、BreakerとFixerを反復的に更新しながら、それらを併用してより多くのペアデータを生成します。BIFIを2つのコード修復データセットで評価します。GitHub-Pythonは、PythonコードのAST解析エラーを修復することを目的とした新しいデータセットであり、DeepFixは、Cコードのコンパイラエラーを修復することを目的としています。BIFIは既存の手法よりも優れており、GitHub-Pythonでは90.5%(+28.5%)、DeepFixでは71.7%(+5.6%)の修復精度を得ることができました。注目すべきは、BIFIがラベル付きデータを必要としないことであり、様々な修復タスクを教師なしで学習するための強力な出発点となることを期待しています。
タグ付けや機械読解などの多くのNLPタスクは、ネガティブな例がポジティブな例を大幅に上回り、膨大な数の背景例（または簡単なネガティブな例）が学習を圧倒するという、深刻なデータ不均衡問題に直面しています。最も一般的に使用されているクロスエントロピー（CE）基準は、実際には精度指向の目的であるため、トレーニングとテストの間に矛盾が生じる。トレーニング時には、各トレーニングインスタンスは目的関数に等しく貢献するが、テスト時には、F1スコアは正例に関心がある。本論文では、データに偏りのあるNLPタスクにおいて、標準的なクロスエントロピー目的の代わりにダイスロスを使用することを提案する。Dice lossはSorensen-Dice係数またはTversky指数に基づいており、偽陽性と偽陰性に同じような重要性を持ち、データ不均衡の問題に影響されません。理論的には，評価時のF1スコアと訓練時のdice lossとの差を縮めることができる．提案された学習目的では、データの不均衡なNLPタスクの広い範囲で、大幅なパフォーマンスの向上が見られた。特に、品詞タグ付けタスクにおいて、CTB5、CTB6、UD1.4でSOTA結果を達成し、名前付きエンティティ認識タスクにおいて、CoNLL03、OntoNotes5.0、MSRA、OntoNotes4.0でSOTA結果を達成し、さらに、機械読解や言い換え識別のタスクでも競争力のある結果を得ることができました。
刑事法における機械学習の応用の多くは、人に関する予測を行い、その予測を使って判断を導くことに焦点を当てています。例えば、裁判官は、誰を公判前に勾留するかを決定する際に、リスク評価ツールを使って、将来の暴力の可能性を予測します。このような予測技術が意思決定の対象となる人を分析するのに対し、私たちは意思決定そのものを精査する機械学習の新たな方向性を提案します。私たちの目的は、行動を予測することではなく、人間の裁量判断の公正さと一貫性を向上させるための機会をデータに基づいて一般市民に提供することです。偵察」と「再考」という2つの機能を備えていることから、私たちはこのアプローチを「Reconアプローチ」と呼んでいます。偵察」では、自然言語処理を用いて何千もの公聴会記録を精査し、公聴会での判断に影響を与えたと思われる要因を明らかにします。Reconsiderationでは、モデリング技術を用いて、これらの決定を詳細に検討する必要があるような異常なケースを特定します。偵察」では、一連の判決に共通する問題を示すパターンを明らかにし、「再考」では、個々の事件における潜在的な誤りや不正を指摘します。コンピュータ科学者と法学者のチームが、カリフォルニア州の仮釈放の決定に「リコン・アプローチ」を適用した初期の研究について説明します。この研究を基に、リコン・アプローチの課題と、刑罰や刑法以外の裁量的な意思決定に適用できる可能性について議論する。
コンピュータビジョンでは、ミニバッチ内の各画像に対して、データ補強手順から1つのサンプルを抽出することが標準的な方法ですが、この選択が一般化のために最適であるかどうかは明らかではありません。本研究では、ユニークな画像ごとの補強サンプルの数が、ホールドアウトされたデータのパフォーマンスにどのように影響するかを詳細に実証的に評価しました。驚くべきことに，画像ごとに複数のサンプルを抽出することで，各ミニバッチにおけるユニークな学習例の数が減少するにもかかわらず，小バッチおよび大バッチの学習において達成されるテスト精度が一貫して向上することがわかった．この効果は，異なる増倍数で同じ数のパラメータ更新と勾配評価を行った場合にも生じる．この結果は、データセットのサブサンプリングによって生じる勾配推定値の分散には暗黙の正則化効果があるものの、データの増強プロセスによって生じる分散はテストの精度を低下させることを示唆している。最近提案されたNFNetモデルファミリーに補強多項式を適用することで、追加データなしで86.8% top-1というImageNetの新しい技術水準を達成しました。
表形式のデータは、不正行為の検出からゲノミクスやヘルスケアに至るまで、機械学習の多くの重要なアプリケーションを支えています。勾配ブースティングやランダムフォレストなど、表形式の問題を解決する古典的なアプローチは、実務者に広く利用されています。しかし、最近の深層学習手法は、一般的な手法に負けない程度の性能を達成している。我々は、表形式のデータ問題を解決するためのハイブリッドな深層学習アプローチを考案した。我々の手法であるSAINTは、行と列の両方で注目を行い、強化された埋め込み手法を含んでいる。また、ラベルが不足している場合に使用するための新しいコントラスト自己教師付き事前学習法を研究します。SAINTは、これまでの深層学習手法よりも一貫して性能を向上させており、様々なベンチマークタスクにおいて、XGBoost、CatBoost、LightGBMなどの勾配ブースティング手法を平均して凌駕しています。
特別な目的の学習システムは、設計時に許容されるタスクの知識を前提としています。このようなシステムを不測のタスクに適応させるには，新しいタスクやデータセットごとに出力ヘッドを追加するなど，アーキテクチャの操作が必要になる．本研究では、画像と自然言語によるタスク記述を受け取り、バウンディングボックス、コンフィデンス、テキストを出力する、タスクに依存しない視覚言語システムを提案する。このシステムは、分類、ローカライズ、質問応答、キャプション作成など、幅広い視覚タスクをサポートする。本システムは、複数のスキルを同時に学習する能力、新規のスキルとコンセプトの組み合わせでタスクを実行する能力、新しいスキルを忘れずに効率的に学習する能力を評価する。
広く使われている学習済みの言語モデルの多くは、単語やサブワードの単位に対応するトークンのシーケンスで動作します。トークンのシーケンスとしてテキストをエンコードするには、トークン化が必要ですが、これは通常、モデルとは独立したアーティファクトとして作成されます。トークンフリーのモデルは、生のテキスト（バイトや文字）を直接処理するため、あらゆる言語のテキストをすぐに処理できる、ノイズに強い、複雑でエラーが発生しやすいテキストの前処理パイプラインを排除して技術的負債を最小限に抑えるなど、多くのメリットがあります。しかし、バイト列や文字列はトークン列よりも長いため、トークンフリーモデルの開発では、生のテキストを直接処理するためのコストを軽減するために、新しいモデルアーキテクチャを導入することが多くありました。本論文では、標準的なTransformerアーキテクチャを最小限の変更でバイト列の処理に使用できることを示します。また、パラメータ数、学習FLOPs、推論速度のトレードオフを明確にし、バイトレベルのモデルがトークンレベルのモデルと競合することを示しました。また，バイトレベルのモデルは，ノイズに対するロバスト性が非常に高く，スペルや発音に敏感なタスクで優れた性能を発揮することを示した．今回の貢献の一環として、T5アーキテクチャに基づいて事前に学習されたバイトレベルのTransformerモデルの新しいセットと、実験に使用したすべてのコードとデータを公開します。
強化学習（RL）をシーケンスモデリング問題として抽象化したフレームワークを導入しました。これにより、Transformerアーキテクチャのシンプルさとスケーラビリティ、およびGPT-xやBERTなどの言語モデリングにおける関連する進歩を利用することができます。特に、Decision Transformerは、RLの問題を条件付きシーケンスモデリングとして扱うアーキテクチャです。価値関数を適合させたり、政策勾配を計算したりするRLの先行的なアプローチとは異なり、Decision Transformerは、因果的にマスクされたTransformerを活用して、最適なアクションを単純に出力します。Decision Transformerのモデルは、望ましいリターン（報酬）、過去の状態、および行動に自己回帰モデルを条件付けすることで、望ましいリターンを達成する未来の行動を生成することができます。Decision Transformerは、そのシンプルさにもかかわらず、Atariタスク、OpenAI Gymタスク、Key-to-Doorタスクにおいて、最先端のモデルフリーオフラインRLベースラインと同等以上の性能を発揮する。
物理的世界における知的行動は、複数の空間的・時間的スケールで構造を示します。動作は、最終的には瞬間的な筋肉の緊張や関節のトルクのレベルで実行されますが、より長いタイムスケールで定義された目標を達成するために選択されなければなりませんし、身体自体をはるかに超えた関係、最終的には他のエージェントとの協調を含むものです。近年の人工知能の研究では、複雑な動作、長期的な計画、マルチエージェントの協調といったそれぞれの問題に対して、学習ベースのアプローチが期待されている。しかし、それらを統合するための研究は限られています。本研究では、物理的にシミュレートされたヒューマノイド・アバターのチームが、リアルな仮想環境でサッカーをするトレーニングを行うことで、この問題を研究します。本研究では、模倣学習、シングルエージェントおよびマルチエージェントの強化学習、および集団ベースのトレーニングを組み合わせた手法を開発し、さまざまな抽象度の意思決定のために行動の伝達可能な表現を利用します。一連のステージでは、プレイヤーはまず、完全に関節のある身体を制御して、走る、曲がるなどのリアルな人間のような動きをすることを学び、次に、ドリブルやシュートなどの中レベルのサッカースキルを習得し、最後に、他者を意識してチームとしてプレーすることで、ミリ秒のタイムスケールでの低レベルの運動制御と、数十秒のタイムスケールでのチームとしての協調したゴール指向の行動との間のギャップを埋める。私たちは、さまざまな抽象度の行動の出現と、これらの行動の基礎となる表現を、実世界のスポーツ分析の統計を含むいくつかの分析技術を用いて調査しました。私たちの研究は、物理的に具現化されたマルチエージェントの設定において、複数のスケールで統合された意思決定を完全に実証するものです。プロジェクトのビデオはこちらのhttpsのURLからご覧いただけます。
トランスフォーマーは、深層学習における最も重要なアーキテクチャ・イノベーションの一つとなっており、過去数年間で多くのブレイクスルーを可能にしてきました。ここでは、ゲーティングを用いたMLPに基づくシンプルなネットワークアーキテクチャgMLPを提案し、主要な言語および視覚アプリケーションにおいてTransformerと同等の性能を発揮できることを示します。この比較から、gMLPが同じ精度を達成できることから、Vision Transformersでは自己注意が重要ではないことがわかりました。BERTでは、我々のモデルは、事前学習perplexityでTransformerと同等の性能を達成し、いくつかの下流のNLPタスクでも優れています。gMLPの性能が悪い微調整タスクでは、gMLPモデルを大幅に大きくすることで、Transformersとの差を縮めることができます。一般的に、我々の実験では、gMLPはデータや計算量が増えてもTransformersと同等のスケーリングが可能であることを示しています。
コンピュータビジョン用の最新の機械学習モデルは、特にImageNetのようなデータセットにおいて、特定の視覚認識タスクの精度が人間を上回っています。しかし、高精度を達成するには様々な方法があります。機械学習システムが発見する特定の決定関数は、システムがさらされるデータだけでなく、モデルの帰納的バイアスによっても決定されます。本研究では、ニューラルネットワークモデルの詳細な行動分析という最近のトレンドに沿って、評価指標としての精度にとどまらず、エラーのパターンに注目しています。本研究では、標準的な畳み込みニューラルネットワーク（CNN）と、最近提案されたアテンションベースのネットワークであるVision Transformer（ViT）の比較に焦点を当てている。注意ベースのネットワークは、視覚タスクにおいてCNNよりも高い精度を達成することが示されているが、我々は、エラーの一貫性をより詳細に調べるための新しい指標を用いて、そのエラーが人間のエラーとより一貫していることを実証した。これらの結果は、より人間に近い視覚モデルを構築するためにも、人間の視覚物体認識を理解するためにも意味がある。
GPT-3のような大規模な事前学習を行うことで、与えられたプロンプトから一見すると高品質なテキストを生成することができるようになりました。しかし、このような生成システムは、事実を幻視してしまうという問題を抱えていることが多く、有用な外部情報を取り込むようには本来設計されていません。このような問題を解決するために、グラウンディング型の生成モデルが提案されているが、これらのモデルの学習は、対応する情報関連文書が文脈として提供されている、ほとんど利用できないパラレルデータに依存している。本研究では、言語モデルの信号に基づいて、基底生成器と文書検索器を共同で学習することで、データの制約を緩和するフレームワークを提案する。このモデルは、生成時に最も高い有用性を持つ文書を検索するように学習し、Mixture-of-Experts (MoE) アンサンブルを用いてそれらの文書を注意深く組み合わせ、フォローオンテキストを生成する。生成器と検索器の両方がこの共同学習を活用し、相乗的に働くことで、散文や対話の生成において、より情報的で関連性の高いテキストを生成できることを実証しています。
事前に学習された言語モデルの時代において、Transformerはモデルアーキテクチャの事実上の選択肢となっています。最近の研究では、完全な畳み込み（CNN）アーキテクチャが有望視されていますが、事前学習-微調整のパラダイムでは検討されていません。言語モデルの文脈では、畳み込みモデルは、事前学習されたTransformerに対抗できるのか？本論文では、この研究課題について調査し、いくつかの興味深い結果を示します。8つのデータセット/タスクを対象とした広範な実験の結果、CNNベースの事前学習済みモデルは、注意点はあるものの、特定のシナリオにおいてTransformer対応モデルと競合し、それを上回ることがわかりました。全体として、本稿で得られた知見は、事前学習とアーキテクチャの進歩を混同して考えるのは誤りであり、両者の進歩は独立して考えるべきであることを示唆している。我々の研究は，代替アーキテクチャに対する健全な楽観主義への道を開くものであると信じている．
本研究では，コンピュータビジョン，自然言語，オーディオのデータセットのうち，最も一般的に使用されている10個のテストセットにおけるラベルエラーをアルゴリズムで特定し，これらのラベルエラーがベンチマーク結果に与える影響を調査しました．10個のデータセットの平均誤差は3.4%と推定され、例えばImageNetの検証セットでは2916個のラベルエラーが6%を占めていました。推定されるラベルエラーは、自信を持って学習することで発見され、クラウドソーシングで人間が検証します（アルゴリズムでフラグを付けた候補の54％が実際に誤ってラベル付けされています）。意外なことに、誤ってラベル付けされたデータの割合が高い現実のデータセットでは、容量の小さいモデルの方が、容量の大きいモデルよりも実質的に有用であることがわかった。例えば、ラベルを修正したImageNetでは、ResNet-18がResNetを上回りました。例えば、ラベルを修正したImageNetでは、元々誤ったラベルを付けたテスト例の割合がわずか6％増加しただけで、ResNet-18はResNet-50を上回ります。CIFAR-10のラベルを修正した場合。また、CIFAR-10のラベルを修正した場合、VGG-11はVGG-19よりも優れていますが、これは元々のラベルが間違っていたテスト例の割合が5％増加した場合です。従来、MLの実務者はテストの精度に基づいてどのモデルを導入するかを選択していたが、我々の発見はここで注意を促すものであり、特にノイズの多い実世界のデータセットにおいては、正しくラベル付けされたテストセットでモデルを判断する方が有用であることを提案している。
本研究では，コンピュータビジョン，自然言語，オーディオのデータセットのうち，最も一般的に使用されている10個のテストセットのラベルエラーをアルゴリズムで特定し，これらのラベルエラーがベンチマーク結果に影響を与える可能性を調査した．10個のデータセットの平均誤差は3.4%と推定され、例えばImageNetの検証セットでは2916個のラベルエラーが6%を占めていました。推定されるラベルエラーは、自信を持って学習することで発見され、クラウドソーシングで人間が検証します（アルゴリズムでフラグを付けた候補の54％が実際に誤ってラベル付けされています）。意外なことに、誤ってラベル付けされたデータの割合が高い現実のデータセットでは、容量の小さいモデルの方が、容量の大きいモデルよりも実質的に有用であることがわかった。例えば、ラベルを修正したImageNetでは、ResNet-18がResNetを上回りました。例えば、ラベルを修正したImageNetでは、元々誤ったラベルを付けたテスト例の割合がわずか6％増加しただけで、ResNet-18はResNet-50を上回ります。CIFAR-10のラベルを修正した場合。また、CIFAR-10のラベルを修正した場合、VGG-11はVGG-19よりも優れていますが、これは元々のラベルが間違っていたテスト例の割合が5％増加した場合です。従来、MLの実務者は、テストの精度に基づいてどのモデルを導入するかを選択していましたが、今回の結果は、特にノイズの多い実世界のデータセットでは、正しくラベル付けされたテストセットでモデルを判断する方が有用であることを示唆しており、注意が必要です。
NLPシステムでは、テキストに含まれる数字を特別に考慮することはほとんどありません。これは、脳内で数字は単語とは異なる形で表現されているという神経科学のコンセンサスとは全く対照的です。数字に関する最近のNLPの研究を、タスクとメソッドの包括的な分類法にまとめました。主観的な数字の概念を、粒度（正確なものとおおよそのもの）と単位（抽象的なものと地に足のついたもの）の2つの次元に沿って配置された7つのサブタスクに分解します。これまでに発表された18種類の数字のエンコーダーとデコーダーが行った無数の表現上の選択を分析します。さらに、テキストで数字を表現するためのベストプラクティスをまとめ、デザインのトレードオフと統一的な評価からなる、NLPにおける全体的な数値表現のビジョンを明確にしました。
多言語事前学習表現と言語間転移学習の組み合わせは、リソースの少ない言語のための機能的なNLPシステムを構築するための最も効果的な方法の一つです。しかし、事前学習のための大規模な対訳コーパスや、微調整のための十分な注釈付きデータがない、極めてリソースの少ない言語の場合、伝達学習はまだ十分に研究されておらず、困難な課題となっています。さらに、最近の研究では、多言語表現は言語間で驚くほど分離されていることが明らかになっており、リソースの少ない言語への転移にはさらなる課題がある。本論文では、メタ学習に基づいたフレームワークであるMetaXLを提案する。MetaXLは、補助言語からターゲット言語への表現の適切な変換を学習し、効果的な伝達のためにそれらの表現空間を近づける。大規模なモノリンガルコーパスや大量のラベル付きデータを持たない実世界のローリソース言語で、クロスリンガル感情分析や名前付きエンティティ認識などのタスクを対象とした大規模な実験を行い、我々のアプローチの有効性を示した。MetaXLのコードは、このhttpのURLで公開されています。
これは、フローズン言語モデルに特定のタスクを実行させるための「ソフトプロンプト」を学習するための、シンプルかつ効果的なメカニズムです。GPT-3で使用されている離散的なテキストプロンプトとは異なり、ソフトプロンプトはバックプロパゲーションによって学習され、任意の数のラベル付き例からの信号を取り込むように調整することができます。エンド・ツー・エンドで学習するアプローチは、GPT-3の「数回の学習」よりも大きな差で上回っています。さらに、T5を用いたモデルサイズの削減により、プロンプトチューニングがスケールに応じて競争力を増すことを示しました。モデルのパラメータ数が数十億を超えると、我々の手法は「ギャップを縮め」、モデルチューニング（すべてのモデルの重みを調整する）の強力なパフォーマンスに匹敵します。この発見は、大規模なモデルの共有や提供にはコストがかかりますが、1つの凍結されたモデルを複数の下流のタスクに再利用することができれば、この負担を軽減することができるという点で、特に重要です。我々の手法は、最近提案されたLi and Liang (2021)の「prefix tuning」を単純化したものと見ることができ、この手法や他の同様のアプローチとの比較を行う。最後に、ソフトプロンプトを用いて凍結したモデルを調整することで、完全なモデルチューニングと比較して、ドメイン移行に対するロバスト性にメリットがあることを示す。
最近の高品質な機械翻訳システムを人間が評価することは難しい問題であり、不適切な評価手順が誤った結論を導く可能性があるという証拠が増えています。人間評価に関する研究は数多く行われていますが、この分野では一般的に受け入れられる標準的な手順がまだありません。そこで本研究では，MQM（Multidimensional Quality Metrics）と呼ばれるフレームワークを用いて，明示的なエラー分析に基づく評価手法を提案する。本研究では，これまでで最大規模のMQM研究を実施し，2つの言語ペアで行われたWMT 2020共有タスクのトップシステムの出力を，完全な文書コンテキストにアクセスできるプロの翻訳者が提供したアノテーションを用いてスコアリングした．得られたデータを徹底的に分析した結果、評価されたシステムのランキングはWMTのクラウドワーカーによって確立されたものとは大きく異なり、機械の出力よりも人間の出力が明らかに好まれていることがわかった。驚くべきことに、事前に訓練されたエンベッディングに基づく自動評価基準が、人間のクラウドワーカーよりも優れていることもわかりました。今後の研究のために、我々のコーパスを公開します。
最新の学習済み言語モデルにおいて、入力と出力の埋め込みの間で重みを共有するという標準的な手法を再評価した。その結果、非結合型の埋め込みによってモデリングの柔軟性が高まり、多言語モデルの入力埋め込みにおけるパラメータ割り当ての効率を大幅に改善できることを示しました。入力エンベッディングのパラメータをTransformer層で再配分することで、微調整時に同じ数のパラメータで標準的な自然言語理解タスクの性能を劇的に向上させることができる。また、出力エンベッディングに追加の容量を割り当てることで、出力エンベッディングが事前学習後に破棄されたとしても、微調整の段階でモデルに持続的な利益をもたらすことを示す。これは、出力エンベッディングを大きくすることで、モデルの最後の層が訓練前のタスクに過度に特化することを防ぎ、Transformerの表現をより一般的なものにして、他のタスクや言語への移植性を高めることができるという分析結果です。これらの知見を活用することで、微調整の段階でパラメータ数を増やすことなく、XTREMEベンチマークで強力な性能を達成するモデルを学習することができます。
近年、機械学習モデルの頑健性を評価するために、敵対的な攻撃手法が開発されています。しかし、主流の評価基準では限界があり、設定が異なると結果が食い違うこともあります。我々は、勾配ベースの攻撃やクエリベースの攻撃など、様々な攻撃アルゴリズムを検討することで、偏りのない性能評価のための統一的な基準についてのコンセンサスが得られていないことに気づく。そこで我々は、Piece-wise Sampling Curving (PSC) ツールキットを提案し、与えられた範囲の敵対者間の包括的な比較を生成することで、前述の不一致に効果的に対処する。さらに、PSCツールキットは、計算コストと評価効果のバランスをとるためのオプションを提供します。実験の結果、PSCツールキットは攻撃アルゴリズムの包括的な比較を提示し、実際には不一致を大幅に減らすことができました。
自己教師付き学習は自然言語処理において急速な進歩を遂げていますが、研究者がどのような場合に資源を大量に消費するドメイン固有の事前トレーニング（domain pretraining）を行うべきかは依然として不明です。法律は、不可解なことに、法律用語はユニークであると広く見られているにもかかわらず、ドメイン・プレトレーニングによって実質的な利益が得られた例はほとんど記録されていません。私たちは、これらの既存の結果は、既存の法律NLPタスクが簡単すぎて、ドメイン事前トレーニングが役立つ場合の条件を満たしていないことに起因すると仮定しています。これは、53,000以上の多肢選択式の質問からなる新しいデータセットで、引用されたケースの関連する判例を特定するものです。このデータセットは、弁護士にとって基本的なタスクであり、法律的に意味があると同時に、NLPの観点からも難しいものです（BiLSTMベースラインでF1は0.4）。次に、CaseHOLDおよび既存の法的NLPデータセットでの性能向上を評価します。一般的なコーパス（Google Books と Wikipedia）で事前学習したトランスフォーマーアーキテクチャ（BERT）は性能を向上させますが、カスタム法的語彙を用いたドメイン事前学習（BERT よりも大きな米国の全裁判所にわたる約 350 万件の判決のコーパスを使用）は、CaseHOLD で最も大幅な性能向上を示し（F1 で 7.2% の向上、BERT に比べて 12% の向上）、他の 2 つの法的タスクでも一貫して性能を向上させました。3 つの法的タスクにおけるパフォーマンスの向上レベルは、タスクのドメイン特異性に直接関連していました。また、Transformerベースのアーキテクチャも、異なる法律用語を示唆する埋め込みを学習することが分かりました。
Clarkら[2020]は、ELECTRAのアプローチは、計算バジェットに対するNLPパフォーマンスにおいて非常に効率的であると主張しています。そのため、この再現性研究では、この主張に焦点を当て、以下の質問でまとめています。低リソース環境でのNLPにおいて，ELECTRAを用いて，計算コストの観点からSOTAに近い性能を実現できるか？
観察データを用いて言語特性の因果効果を推定するという問題を考えます。例えば、苦情を丁寧に書くと、対応が早くなるのか？肯定的な製品レビューは、どのくらい売り上げを伸ばすのか？本論文では、実用的な手法を開発する前に、この問題に関連する2つの技術的課題に取り組んでいます。第一に、関心のある因果量を書き手の意図の効果として形式化し、観察データからこれを特定するために必要な仮定を確立します。第二に、実際には、関心のある言語的特性のためのノイズの多い代用手段（例えば、分類器や辞書からの予測）にしかアクセスできない。我々は、このような状況に対応する推定量を提案し、そのバイアスがテキストの調整を行ったときに制限されることを証明する。これらの結果に基づいて、言語的特性の因果効果を推定するアルゴリズムであるTextCauseを紹介する。本手法は、(1)ノイズの多いプロキシの品質を向上させるために遠隔監視を活用し、(2)テキストの調整を行うために事前に訓練された言語モデル(BERT)を活用する。提案手法は、Amazonレビューのセンチメントが半仮想的な売上高に与える影響を推定する際に、関連するアプローチよりも優れていることを示す。最後に、苦情の丁寧さが官僚の応答時間に与える影響を調査する応用ケーススタディを紹介します。
複雑で雑然としたシーンのコンテキストを理解することは、セマンティックセグメンテーションにとって難しい問題です。しかし、これらのシーンでは、オブジェクトのスケール、形状、外観などのシーンの要因が大きく変化するため、事前に追加の監督なしにコンテキストをモデル化することは困難である。この問題を解決するために，我々はオブジェクトの構造とオブジェクト間の階層を学習することを提案する．本研究では、入力画像から特性を捉えるために、階層的、文脈的、かつマルチスケールの新しいピラミッド型表現を設計する。本研究では、あらかじめ定義された数の領域に基づいて、異なる階層領域に再帰的にセグメンテーションを行い、これらの領域におけるコンテキストを集約することが重要なアイデアである。集約されたコンテクストは、リージョン間のコンテクストの関係を予測し、次の階層レベルでリージョンを分割するために使用されます。最後に，再帰的に集約されたコンテクストからピラミッド表現を構築することで，マルチスケール性と階層性が達成される．実験では、提案手法がPASCAL Contextにおいて最先端の性能を達成することを確認した。
人工知能の分野では、データの大規模化と教師なし学習によるモデルの大容量化が相まって、表現学習や統計的生成が大きく進展しています。生命科学の分野では、今後予想されるシークエンスの増加により、天然配列の多様性に関する前例のないデータが期待されています。進化のスケールでのタンパク質言語モデリングは、生物学のための予測的かつ生成的な人工知能への論理的なステップです。この目的のために、私たちは教師なし学習を用いて、進化の多様性にまたがる2億5000万個のタンパク質配列の860億個のアミノ酸を対象に、深い文脈の言語モデルを学習しました。結果として得られたモデルは、その表現の中に生物学的特性に関する情報を含んでいる。この表現は、配列データのみから学習されます。学習された表現空間は、アミノ酸の生化学的性質のレベルから、タンパク質の遠隔地の相同性までの構造を反映したマルチスケールの組織を持っています。二次構造や三次構造に関する情報は表現に符号化されており、直線的な投影によって識別することができる。表現学習は、様々な用途に一般化する特徴を生み出し、変異効果や二次構造の最先端の教師付き予測を可能にし、長距離接触予測の最先端の特徴を改善します。
ディープニューラルネットワークや巨大な言語モデルは、自然言語のアプリケーションで広く使われるようになっています。これらのモデルは大量の学習データを必要とすることで知られているため、低リソース環境でのパフォーマンスを向上させるための研究が活発化しています。最近のニューラルモデルへの基本的な変化と、人気のあるpre-train and fine-tuneパラダイムに触発され、低リソースの自然言語処理のための有望なアプローチを調査します。データの利用可能性の異なる次元について議論した後、学習データが疎な場合に学習を可能にする手法の概要を構造化して説明する。これには、データ増強や遠隔監視のような追加のラベル付きデータを作成するメカニズムや、ターゲット監視の必要性を低減する伝達学習の設定が含まれる。この調査の目的は、これらの手法がどのように異なるかを説明することです。なぜなら、これらの手法を理解することは、特定の低リソース環境に適した手法を選択するために不可欠だからです。さらに、未解決の課題を明らかにし、将来の研究の方向性を示すことも重要な課題です。
Mixupは，入力例とそれに対応するラベルを線形に補間する最新のデータ補強技術である．Mixupは、ピクセルレベルで画像を補間することで、画像分類に強い効果を示している。この研究に触発され、本稿では、i) テキストデータは生のフォーマットではほとんど混合できないため、mixupを自然言語処理タスクにどのように適用するか、ii) BERTなどの変換器ベースの学習モデルにおいてmixupが依然として有効であるかどうかを調査する。この目的を達成するために、我々は、エンド・ツー・エンドの学習システムを維持しつつ、広範囲のNLPタスクのために、「mixup-transformer」と名付けた変換器ベースの事前学習アーキテクチャにmixupを組み込む。本研究では，GLUEベンチマークを用いた大規模な実験を行い，提案するフレームワークを評価する．さらに、学習データを一定の比率で削減することで、低リソースのシナリオにおけるmixup-transformerの性能を検証することも行った。我々の研究では、mixupは事前学習された言語モデルに対してドメインに依存しないデータ補強技術であり、結果としてトランスフォーマーベースのモデルの大幅な性能向上につながることが示された。
BERTのような言語モデルに基づく事前学習モデルは、様々なNLPタスクにおいて大きな利益をもたらしています。本論文では、条件付きデータ増強のために、自動回帰モデル（GPT-2）、自動エンコーダーモデル（BERT）、seq2seqモデル（BART）など、さまざまなタイプの変換器ベースの事前学習モデルを研究しています。我々は、クラスラベルをテキストシーケンスに前置することで、事前に学習されたモデルを条件付きでデータ拡張するための簡単かつ効果的な方法を提供することを示す。さらに、3つの分類ベンチマークにおいて、事前学習されたSeq2Seqモデルは、低リソース環境において他のデータ補強手法よりも優れた性能を示した。さらに、データの多様性の観点から、学習済みモデルに基づくデータ補強の違いや、クラス・ラベル情報をどの程度保持できるかについても検討する。
自然言語処理（NLP）は、臨床テキストに含まれる膨大な非構造化データを解き明かし、医療研究を改善するのに役立ちます。しかし、この分野の発展を妨げる大きな障壁は、患者の守秘義務によりデータの共有が禁止されていることであり、その結果、公開されているデータセットは小さく、断片的で、隔離されたものになっています。NLPモデルの開発には大量のデータが必要であるため、我々は自然言語生成を利用してデータセットを増強し、下流の臨床関連タスクのNLPモデル開発に利用できるようにすることで、この障害を回避することを目的としています。本研究では、構造化された患者情報を連続的に生成する方法を提案します。最先端のTransformerモデルを用いて実験を行い、この拡張データセットが下流の分類タスクにおいてベースラインを上回る能力を持つことを実証した。最後に、この分野の研究を促進するために、ユーザーインターフェースを作成し、生成モデルを訓練するためのスクリプトを公開します。
標準的なマルコフ決定プロセスの形式では、ユーザーは報酬関数を記述することでタスクを指定します。しかし、多くの場合、ユーザーは言葉や数字でタスクを説明することはできませんが、タスクが解決された場合に世界がどのように見えるかという例を容易に提供することができます。本研究では、このような状況に着目し、成功した状態の例が与えられたときに、成功する確率の高い状態を訪れることを目的とした制御アルゴリズムを第一原理から導き出す。先行研究では、同様の問題設定に対して、まず補助的な報酬関数を学習し、次に別の強化学習アルゴリズムを用いてこの報酬関数を最適化するという2段階のプロセスで取り組んでいる。これに対し、我々は再帰的分類に基づいた手法を導き出し、補助的な報酬関数を使わず、代わりに遷移と成功した結果から価値関数を直接学習する。この方法では、調整するハイパーパラメータやデバッグするコードの行数が少なくて済みます。本手法は、典型的な報酬関数の項の代わりに例題を用いることで、データ駆動型の新しいベルマン方程式を満たすことを示している。実験によると、我々の手法は、明示的な報酬関数を学習する従来の手法よりも優れている。
変形器モデルは、多くの自然言語処理（NLP）タスクにおいて、その技術水準を向上させてきた。本論文では、標準的なTransformerアーキテクチャの2つの重要な課題、すなわち、入力長のスケーリングと構造化された入力の符号化に対応する、新しいTransformerアーキテクチャであるExtended Transformer Construction（ETC）を紹介します。長い入力に対応するために、グローバルトークンと通常の入力トークンの間に、新しいグローバル-ローカルアテンションメカニズムを導入した。また、グローバル・ローカルアテンションを相対的な位置の符号化とContrastive Predictive Coding (CPC)の事前学習目的と組み合わせることで、ETCが構造化された入力を符号化できることを示している。長い入力や構造化された入力を必要とする4つの自然言語データセットにおいて、最先端の結果を得ることができた。
信頼性の高い正確な3Dトラッキングフレームワークは、自律走行などの多くのアプリケーションにおいて、周囲の物体の将来の位置を予測し、観察者の行動を計画するために不可欠である。本研究では、移動するプラットフォーム上で撮影された一連の2D画像から、移動する物体を効果的に関連付け、その3Dバウンディングボックス情報を推定するフレームワークを提案する。本研究では、準密な類似性学習を利用して、様々な姿勢や視点にある物体を外観の手がかりのみで識別する。最初の2次元の関連付けの後、3次元バウンディングボックスの深さ順のヒューリスティックを利用して、ロバストなインスタンスの関連付けを行い、モーションベースの3次元軌道予測を利用して、隠蔽された車両の再識別を行います。最後に、LSTMベースの物体速度学習モジュールが、より正確な動きの推定のために、長期的な軌道情報を集約します。提案したシミュレーションデータと，KITTI，nuScenes，Waymoデータセットなどの実世界のベンチマークを用いた実験により，本トラッキングフレームワークが都市部での運転シナリオにおいてロバストなオブジェクトの関連付けとトラッキングを実現することが示された．また、Waymo Openベンチマークでは、3Dトラッキングと3Dディテクションの課題において、カメラのみのベースラインを初めて確立しました。擬似高密度3Dトラッキングパイプラインは、nuScenes 3Dトラッキングベンチマークにおいて、公開されているすべての手法の中で最も優れたビジョンのみの提出物と比較して、5倍近いトラッキング精度を達成し、素晴らしい改善をもたらしました。当社のコード、データ、学習済みモデルは、このhttpsのURLから入手できます。
マスクド・ランゲージ・モデルは、テキストを処理する際のデファクト・スタンダードになりつつあります。最近では、ナレッジグラフなどの外部知識ソースを用いて単語表現をさらに豊かにするアプローチがいくつか提案されています。しかし、これらのモデルは、単言語の設定でのみ考案され、評価されています。本研究では、言語に依存しないエンティティ予測タスクを中間的な学習手順として提案し、エンティティのセマンティクスに基づいて単語表現を基づかせ、エンティティの共有語彙を用いて異なる言語間のギャップを埋める。我々のアプローチは、新しい語彙意味知識を神経モデルに効果的に注入し、ゼロショットの異言語設定での様々な意味タスクのパフォーマンスを向上させることを示す。さらに、中間的な学習を行うことで、補助的な入力を必要としないため、新しいデータセットにすぐにモデルを適用することができます。実験では、最大100言語のWikipedia記事を使用し、英語版Wikipediaのみを使用してエンティティを予測した場合、強力なベースラインと比較して一貫した利益を得ることができました。さらに言語を追加すると、ある時点まではほとんどのタスクで改善が見られましたが、全体的には、増え続けるWikipediaの言語でトレーニングを行うことで、モデルの伝達性を向上させることは自明ではないことがわかりました。
BERT のような大規模な言語モデルは、幅広い NLP タスクにおいて最先端の性能を達成しています。しかし、最近の研究では、このようなBERTベースのモデルは、テキストの敵対的攻撃の脅威に直面して脆弱であることが示されています。我々は、情報理論的な観点からこの問題に対処することを目的とし、事前に学習された言語モデルをロバストに微調整するための新しい学習フレームワークであるInfoBERTを提案します。InfoBERTには、モデル学習のための2つの相互情報ベースの正則化が含まれています。(InfoBERTには、モデル学習のための2つの相互情報ベースの正則化が含まれています。（i）入力と特徴表現の間のノイズの多い相互情報を抑制する情報ボトルネック正則化、および（ii）局所的なロバスト特徴とグローバル特徴の間の相互情報を増加させるロバスト特徴正則化です。我々は、標準的な学習と敵対的な学習の両方において、言語モデルの表現学習のロバスト性を理論的に分析し、改善するための原理的な方法を提供します。広範な実験により、InfoBERTは、自然言語推論（NLI）および質問応答（QA）タスクにおいて、いくつかの敵対的なデータセットに対して、最先端のロバストな精度を達成することが実証されています。InfoBERTのコードはこちらのhttpsのURLから入手できます。
新しいコンピュータビジョンのアーキテクチャは注目を集めていますが、モデルアーキテクチャの影響は、学習方法やスケーリング戦略の変更と同時に混同されることがよくあります。我々の研究では、定型的なResNet（He et al. その結果、驚くべきことに、学習方法とスケーリング戦略は、アーキテクチャの変更よりも重要であることがわかりました。我々は、最適なスケーリング戦略が学習レジームに依存することを示し、2つの新しいスケーリング戦略を提案する。(1）オーバーフィッティングが発生する可能性がある領域ではモデルの深さをスケーリングする（そうでない場合は幅のスケーリングが望ましい）、（2）画像の解像度をこれまでの推奨値よりもゆっくりと上げる（Tan & Le, 2019）。改良された学習戦略とスケーリング戦略を用いて、TPU上でEfficientNetsよりも1.7倍～2.7倍高速なResNetアーキテクチャファミリ、ResNet-RSを設計し、ImageNetで同等の精度を達成します。大規模な半教師付き学習の設定では、ResNet-RSはEfficientNet NoisyStudentよりも4.7倍高速でありながら、86.2%のトップ1 ImageNet精度を達成しました。この学習手法は、一連のダウンストリームタスクにおける転送性能を向上させ（最先端の自己教師付きアルゴリズムに匹敵する）、Kinetics-400のビデオ分類にも拡張されています。我々は、実務家がこれらのシンプルな改訂版ResNetsを今後の研究のベースラインとして使用することを推奨する。
畳み込みは、現代のニューラルネットワークの中核的な要素であり、視覚における深層学習の急増の引き金となった。本研究では、視覚タスクのための標準的な畳み込みの本質的な原理を再考し、特に空間にとらわれない、チャンネルに依存しないという点に注目しました。その代わりに、前述の畳み込みの設計原理を反転させることで、深層ニューラルネットワークのための新しい原子演算を提示します（インボリューションと呼ばれます）。さらに、最近よく使われている自己注目演算子を解明し、複雑すぎるインスタンス化として我々のinvolutionファミリーに組み込む。提案されたインボリューション演算子は、新世代の視覚認識用ニューラルネットワークを構築するための基本的な要素として活用でき、ImageNetの分類、COCOの検出とセグメンテーション、Cityscapesのセグメンテーションなど、いくつかの一般的なベンチマークにおいて、さまざまな深層学習モデルを強化することができる。今回開発したインボリューションベースのモデルは、ResNet-50を用いたコンボリューショナルベースラインの性能を、トップ1精度で最大1.6％、バウンディングボックスAPで2.5％と2.4％、平均IoUで4.7％向上させるとともに、上記のベンチマークにおいて計算コストをそれぞれ66％、65％、72％、57％に圧縮しました。すべてのタスクに対するコードと事前学習済みモデルは、このhttpsのURLから入手できます。
パイプライン化されたNLPシステムは、エンドツーエンドのニューラルモデリングに取って代わられましたが、一般的に使用されているモデルのほとんどは、いまだに明示的なトークン化のステップを必要としています。データ由来のサブワード辞書に基づく最近のトークン化アプローチは、手動で作られたトークン化器よりも脆弱ではないが、これらの技術はすべての言語に同じように適しているわけではなく、固定された語彙を使用することでモデルの適応能力が制限される可能性がある。本論文では、CANINEを紹介する。CANINEは、明示的なトークン化や語彙を使用せずに、文字列を直接操作するニューラルエンコーダであり、文字を直接操作するか、あるいはオプションとしてソフトな帰納的バイアスとしてサブワードを使用する事前学習戦略を備えている。CANINEは、より細かい入力を効果的かつ効率的に利用するために、入力配列の長さを短縮するダウンサンプリングと、文脈をエンコードするディープトランスフォーマースタックを組み合わせている。CANINEは、難易度の高い多言語ベンチマークであるTyDi QAにおいて、モデルパラメータが28%少ないにもかかわらず、同等のmBERTモデルを2.8F1上回った。
教師なしの事前学習は、近年の自然言語理解の発展に大きく貢献している。本論文では、半教師付き学習によってラベルのないデータを活用するもう一つの方法として、自己学習を研究する。特定のタスクのための追加データを得るために、ラベル付きデータからタスク固有のクエリエンベッディングを計算し、ウェブからクロールされた数十億のラベルなし文のバンクから文を検索するデータ補強法SentAugmentを紹介する。これまでの半教師付き手法とは異なり、本手法はドメイン内のラベル無しデータを必要としないため、より一般的に適用できる。実験によると、自己学習は様々なタスクにおいて強力なRoBERTaベースラインを補完するものであることが示されています。我々の補強アプローチは、標準的なテキスト分類ベンチマークにおいて最大2.6%の改善をもたらし、スケーラブルで効果的な自己学習を可能にします。最後に、知識蒸留法と少数ショット学習でも大きな成果を上げています。
深層学習では、単層的な隠れた状態で例を表現することから、豊かな構造を持つ状態へと向かう動きが見られます。例えば、Transformerは位置によってセグメント化し、オブジェクト中心のアーキテクチャは画像をエンティティに分解します。これらのアーキテクチャでは、異なる要素間のインタラクションはペアワイズインタラクションによってモデル化されています。トランスフォーマーは自己注意を利用して他の位置からの情報を取り込み、オブジェクトセントリック・アーキテクチャーはグラフニューラルネットワークを利用してエンティティ間の相互作用をモデル化しています。しかし、一対の相互作用だけでは、全体的な協調や、下流のタスクに利用できる一貫した統合された表現を実現できない場合があります。認知科学の分野では、機能的に特化したコンポーネントが、帯域制限のある共通の通信チャネルを介して情報を共有するグローバル・ワークスペース・アーキテクチャが提案されています。我々は、複雑な環境の構造をモデル化するための深層学習の文脈において、このような通信チャネルの使用を検討する。提案手法には、異なる専門モジュール間のコミュニケーションが行われる共有ワークスペースが含まれるが、通信帯域に制限があるため、専門モジュールはアクセスを競わなければならない。しかし、通信帯域に制限があるために、専門モジュールはアクセスを競わなければならない。我々は、容量制限が、(1)専門化と構成化を促進する、(2)独立した専門モジュールの同期を促進する、という合理的な根拠を持つことを示す。
畳み込みニューラルネットワーク（CNN）をバックボーンに用いることは、コンピュータビジョンでは大きな成功を収めているが、本研究では、畳み込みを用いずに多くの高密度予測タスクに有用な単純なバックボーンネットワークを調査する。最近提案された画像分類に特化したTransformerモデル(ViTなど)とは異なり、様々な高密度予測タスクへのTransformerの移植の難しさを克服したPyramid Vision Transformer～(PVT)を提案する。PVTは、従来の技術と比較していくつかの利点があります。(1) 一般的に低解像度の出力を持ち、計算コストやメモリコストが高いViTとは異なり、PVTは画像の密なパーティションで学習することで、密な予測に重要な高解像度の出力を実現するだけでなく、プログレッシブ・シュリンキング・ピラミッドを使用して、大きな特徴マップの計算を削減することができます。(2) PVTは、CNNとTransformerの両方の長所を受け継いでおり、CNNのバックボーンを置き換えるだけで、畳み込みを伴わない様々な視覚タスクにおいて統一的なバックボーンとなります。(3) PVTを大規模な実験で検証し、物体検出、セマンティック、インスタンス・セグメンテーションなど、多くの下流タスクの性能を高めることを示した。例えば、COCOデータセットにおいて、同程度のパラメータ数で、RetinaNet+PVTは40.4APを達成し、RetinNet+ResNet50（36.3AP）を4.1AP上回ることができました。PVTがピクセルレベルの予測のための有用なバックボーンとなり、今後の研究が促進されることを期待しています。コードはこちらのhttpsのURLから入手できます。
最近では、MoCo、SimCLR、BYOL、SwAVなどの自己教師付き学習法が、教師付き学習法との差を縮めています。これらの結果は、高度に精査されたImageNetデータセットという対照的な環境で達成されています。しかし、自己教師付き学習の前提は、任意のランダムな画像や、任意の制限のないデータセットから学習できることです。本研究では、教師なしのランダムな画像で大規模なモデルを学習することにより、自己教師付き学習がその期待に応えられるかどうかを探ります。最終的に得られたSElf-supERvised (SEER)モデルは、512GPUを用いて1B枚のランダム画像で学習した13億個のパラメータを持つRegNetYで、84.2%のトップ1精度を達成し、自己教師付きの前学習モデルを1%上回り、自己教師付き学習が実世界で機能することを確認した。また，興味深いことに，自己教師付きモデルは，ImageNetの10%しか利用できない場合でも，77.9%のトップ1を達成するなど，優れた少数ショット学習者であることが分かりました．Code: this https URL
本論文では、E(n)-Equivariant Graph Neural Networks (EGNNs)と呼ばれる、回転、並進、反射、順列に対して等変量なグラフニューラルネットワークを学習する新しいモデルを紹介します。既存の手法とは異なり、本研究では、中間層に計算量の多い高次の表現を必要とせず、なおかつ競争力のある、あるいはそれ以上の性能を達成しています。また、既存の手法が3次元空間上での等変量に限定されているのに対し、我々のモデルは高次元空間に容易に拡張することができます。本研究では、力学系モデリング、グラフオートエンコーダーにおける表現学習、分子特性の予測において、本手法の有効性を実証する。
この論文では、実際のシステムを説明していません。その代わりに、表現に関する一つのアイデアを提示し、複数の異なるグループによる進歩をGLOMという架空のシステムに統合することを可能にしています。これらの進歩には、トランスフォーマー、ニューラルフィールド、対照的な表現学習、蒸留、カプセルなどがあります。GLOMは次のような疑問に答えます。固定されたアーキテクチャを持つニューラルネットワークは、どのようにして画像を解析し、画像ごとに異なる構造を持つ部分-全体の階層を作ることができるのか？それは、同じベクトルの島を使って解析木のノードを表現するという単純なものです。GLOMがうまく機能すれば、変換器のようなシステムが生成する表現を視覚や言語に適用したときの解釈性が大幅に改善されるはずです。
私たちは、物体検出から言語理解、マルチモーダル推論に至るまで、異なるドメインにまたがる最も著名なタスクを同時に学習するための統一されたトランスフォーマーモデル「UniT」を提案します。UniTモデルは、トランスフォーマーのエンコーダ-デコーダアーキテクチャに基づいて、各入力モダリティをエンコーダでエンコードし、エンコードされた入力表現に対して共有デコーダで各タスクの予測を行い、その後にタスク固有の出力ヘッドを配置します。モデル全体の学習は、各タスクからの損失を利用してエンド・ツー・エンドで行われます。変換器を用いたマルチタスク学習に関するこれまでの取り組みと比較すると、タスク固有のモデルを個別に微調整する代わりに、すべてのタスクに対して同じモデルパラメータを共有することで、異なるドメインにまたがるより多様なタスクを扱うことができる。実験では、8つのデータセットで7つのタスクを共同で学習し、コンパクトなモデル・パラメータのセットを用いて、同じ監督下で各ドメインの確立された先行研究と同等の性能を達成しました。コードはMMFでこのhttpsのURLで公開されます。
我々は、入力と構造化された文脈情報（例えば、他のピクセルに囲まれたピクセル）との間の長距離の相互作用を捉えるための、自己注意に代わるフレームワークであるラムダレイヤーを発表します。ラムダ層は、利用可能な文脈をラムダと呼ばれる線形関数に変換し、これらの線形関数を各入力に個別に適用することで、このような相互作用を捉える。線形アテンションと同様に、ラムダ層は高価なアテンションマップをバイパスしますが、対照的に、コンテンツと位置に基づく相互作用の両方をモデル化するため、画像のような大きな構造を持つ入力に適用することができます。結果として得られたニューラルネットワークアーキテクチャであるLambdaNetworksは、ImageNet分類、COCOオブジェクト検出、インスタンスセグメンテーションにおいて、畳み込み型やアテンション型を大幅に凌駕し、計算効率も向上しています。さらに、様々なスケールのハイブリッド・アーキテクチャであるLambdaResNetsを設計し、画像分類モデルの速度と精度のトレードオフを大幅に改善します。LambdaResNetsは、ImageNetにおいて優れた精度を達成する一方で、最新の機械学習アクセラレータにおいて、一般的なEfficientNetsよりも3.2～4.4倍高速である。130Mの疑似ラベル付き画像を追加した大規模な半教師付き学習では、LambdaResNetsはImageNetで最大86.7%の精度を達成する一方で、EfficientNet NoisyStudentよりも9.5倍、Vision Transformerよりも9倍高速で、同等の精度を実現しています。
Middleburyオプティカルフローベンチマークの結果からもわかるように、オプティカルフロー推定アルゴリズムの精度は着実に向上しています。しかし、その典型的な定式化は、HornとSchunckの研究からほとんど変わっていません。我々は、目的関数、最適化手法、および最新の実装方法が精度にどのように影響するかを徹底的に分析することで、最近の進歩を可能にした要因を明らかにしようとしています。その結果、「古典的」なフロー式が、最新の最適化技術や実装技術と組み合わされることで、驚くほどの性能を発揮することがわかりました。さらに、最適化の際に中間の流れ場を中央値でフィルタリングすることは、近年の性能向上の鍵であると同時に、より高エネルギーのソリューションをもたらすこともわかりました。この現象の背後にある原理を理解するために、中央値フィルタリングのヒューリスティックな手法を公式化した新しい目的を導き出しました。この目的語には、広い空間的な近傍領域のフロー推定値をロバストに統合する非局所的な項が含まれています。この新しい用語を、フローと画像の境界に関する情報を含むように修正することで、Middleburyベンチマークの上位に位置する手法を開発しました。
大規模な生成言語モデルを教師付きタスクにマッピングする一般的な方法では、モデルの新しい能力を十分に調査できない可能性があります。GPT-3を例に、0ショットのプロンプトが数ショットのプロンプトを大幅に上回ることを示します。このような場合の数ショットの例題の機能は、メタ学習というよりも、既に学習したタスクの位置を特定するという表現が適していることを示唆している。この分析は、強力な言語モデルを制御・評価する際のプロンプトの役割を再考する動機となる。本研究では、自然言語のレンズを通してプロンプトを検討することの有用性を強調しながら、プロンプトプログラミングの方法を議論します。また、物語や文化的アンカーの能力を利用して、微妙な意図を符号化する手法や、評決を出す前に問題を構成要素に分解することを促す手法についても検討します。また、プロンプトプログラミングのより包括的な理論に基づいて、さまざまなタスクのための独自の自然言語プロンプトを生成するモデルの種となるメタプロンプトのアイデアを紹介します。最後に、言語モデルと対話するためのこれらのより一般的な方法を、既存および将来のベンチマークや実用的なアプリケーションにどのように組み込むことができるかについて議論します。
バッチ正規化は、ほとんどの画像分類モデルの重要なコンポーネントですが、バッチサイズと例間の相互作用に依存することに起因する多くの望ましくない特性を持っています。最近の研究では、正規化層を持たない深層ResNetsの学習に成功しているが、これらのモデルは、バッチ正規化されたネットワークのテスト精度には及ばず、大きな学習率や強力なデータ増強に対して不安定であることが多い。本研究では、これらの不安定性を克服する適応的な勾配クリッピング技術を開発し、大幅に改善されたクラスのノーマライザフリーResNetsを設計した。小型のモデルは、ImageNetにおけるEfficientNet-B7のテスト精度に匹敵する一方で、学習速度は最大8.7倍となり、大型のモデルは86.5%という最先端のトップ1精度を達成しました。また，3億枚のラベル付き画像からなるデータセットで大規模な事前学習を行った後にImageNetで微調整を行った場合，Normalizer-Freeモデルはバッチで正規化されたモデルよりも大幅に優れた性能を発揮し，最高のモデルでは89.2%の精度を達成しました．私たちのコードは、以下のhttps URLで公開されています。 deepmind-research/tree/master/nfnets
このチュートリアル記事では、オフライン強化学習アルゴリズムの研究を始めるために必要な概念的なツールを読者に提供することを目的としています。オフライン強化学習アルゴリズムとは、オンラインでデータを収集することなく、過去に収集したデータを利用する強化学習アルゴリズムのことです。オフライン強化学習アルゴリズムは、大規模なデータセットを強力な意思決定エンジンに変えることを可能にする、非常に有望な手法です。効果的なオフライン強化学習法は、利用可能なデータから最大限の効用を持つ政策を抽出することができるため、医療や教育、ロボット工学などの幅広い意思決定領域の自動化を可能にします。しかし、現在のアルゴリズムの限界がこれを困難にしています。本講演では、特に最新の深層強化学習法の文脈において、これらの課題を読者に理解してもらうことを目的としています。また、これらの課題を軽減するために最近の研究で検討されたいくつかの潜在的な解決策を、最近のアプリケーションとともに説明し、この分野における未解決の問題についての展望についても議論します。
深層学習のエネルギーコストと性能コストが増大していることから、コンポーネントを選択的に刈り込むことでニューラルネットワークのサイズを小さくすることが求められています。疎なネットワークは、生物学的なものと同様に、元の密なネットワークと同じように、あるいはそれ以上に一般化することができます。疎なネットワークは、通常のネットワークのメモリ使用量をモバイル機器に合わせて削減できるだけでなく、成長し続けるネットワークの学習時間を短縮することができます。本論文では、深層学習におけるスパース性に関する先行研究を調査し、推論と学習の両方におけるスパース化の広範なチュートリアルを提供します。ニューラルネットワークの要素を削除したり追加したりするアプローチ、モデルのスパース性を達成するための様々なトレーニング戦略、そして実際にスパース性を利用するメカニズムについて説明します。300以上の研究論文からアイデアを抽出し、現在スパース性を利用したいと考えている実務家や、フロンティアを前進させることを目標としている研究者にガイダンスを提供します。本論文では、スパース化の数学的手法に必要な背景を含め、早期構造適応などの現象や、スパース性と学習プロセスの複雑な関係を説明し、実際のハードウェアでの高速化を実現するテクニックを示しています。また、様々なスパースネットワークを比較する際の基準となる、刈り込みパラメータ効率の指標を定義します。最後に、スパース性が将来の作業負荷をどのように改善できるかを推測し、この分野における主要な未解決問題を概説します。
分散した複数のエンティティが、プライバシーを守りながら、共有されたディープネットを共同で学習するにはどうすればよいか？本論文では、既存の分散型深層学習パイプラインにプラグインできる、トレーニング画像のシンプルな暗号化であるInstaHideを紹介します。この暗号化は効率的で、トレーニング中に適用してもテストの精度にはほとんど影響しません。InstaHideは、ランダムに選ばれたいくつかの画像を混合し、ランダムなピクセル単位のマスクを適用することで構成される「ワンタイムシークレットキー」で各トレーニング画像を暗号化します。この論文のその他の貢献は以下の通りです。(a) 大規模な公開データセット（ImageNetなど）を暗号化の際の混合に使用することで、セキュリティを向上させている。(b) 既知の攻撃に対して、精度にわずかな影響を与えるだけで、プライバシーを保護する効果があることを示す実験結果。(c) プライバシーをうまく攻撃するには、攻撃者が難しい計算問題を解く必要があることを示す理論的分析。(d) Mixupだけでは、いくつかの効率的な攻撃に対して安全ではないことが示されているため、ピクセル単位のマスクの使用がセキュリティ上重要であることを示している。(e) チャレンジデータセットの公開 このhttpsのURL 私たちのコードはこのhttpsのURLで入手可能です。
深層学習のエネルギーコストと性能コストの増大に伴い、コンポーネントを選択的に刈り込むことでニューラルネットワークのサイズを縮小することが求められています。疎（スパース）ネットワークは、生物学的にも同じように、元の密なネットワークと同じように、あるいはそれ以上に一般化します。疎なネットワークは、通常のネットワークのメモリ使用量をモバイル機器に合わせて削減できるだけでなく、成長し続けるネットワークの学習時間を短縮することができます。本論文では、深層学習におけるスパース性に関する先行研究を調査し、推論と学習の両方におけるスパース化の広範なチュートリアルを提供します。ニューラルネットワークの要素を削除したり追加したりするアプローチ、モデルのスパース性を達成するための様々なトレーニング戦略、そして実際にスパース性を利用するメカニズムについて説明します。300以上の研究論文からアイデアを抽出し、現在スパース性を利用したいと考えている実務家や、フロンティアを前進させることを目標としている研究者にガイダンスを提供します。本論文では、スパース化の数学的手法に必要な背景を含め、早期構造適応などの現象や、スパース性と学習プロセスの複雑な関係を説明し、実際のハードウェアでの高速化を実現するテクニックを示しています。また、様々なスパースネットワークを比較する際の基準となる、刈り込みパラメータ効率の指標を定義します。最後に、スパース性が将来の作業負荷をどのように改善できるかを推測し、この分野における主要な未解決問題を概説して終わります。
視覚・言語学習のための既存の手法では、一般的に、タスクごとに特定のアーキテクチャと目的を設計する必要があります。例えば、視覚的な質問に答えるためのマルチラベル回答分類器、参照表現理解のための領域スコアラー、画像キャプション作成のための言語デコーダなどです。このような煩わしさを解消するために、本研究では、異なるタスクを単一のアーキテクチャで学習する統一的なフレームワークを提案する。すなわち、マルチモーダル条件付きテキスト生成であり、我々のモデルは視覚的およびテキスト的な入力に基づいてテキストにラベルを生成することを学習する。視覚的質問応答、参照表現理解、視覚的コモンセンス推論など、これまで識別タスクとしてモデル化されてきた7つの一般的な視覚・言語ベンチマークにおいて、我々の生成的アプローチ（単一の統一アーキテクチャ）は、最近のタスク固有の最先端視覚・言語モデルと同等の性能を達成した。さらに、我々の生成的アプローチは、稀な答えを持つ質問に対して、より優れた一般化能力を示す。また、我々のフレームワークは、単一のアーキテクチャと単一のパラメータセットでマルチタスク学習を可能にし、個別に最適化されたシングルタスクモデルと同等の性能を達成することを示している。我々のコードは以下のサイトで公開されています：このhttps URL
本論文では、生徒・教師ベースの自己教師学習のための新しいアプローチ、Momentum^2 Teacherを紹介します。このアプローチは、ネットワークの重みとバッチ正規化(BN)統計の両方に対してモメンタム更新を行う。教師の重みは、生徒のモメンタムアップデートであり、教師のBN統計は、履歴のもののモメンタムアップデートである。Momentum^2 Teacherはシンプルで効率的です。また、TPUなどの特殊なハードウェアを用いた大規模な学習や、GPUを用いた非効率な操作（シャッフルBN、同期BN）を必要とせず、ImageNetの線形評価プロトコルにおいて、小バッチサイズ（128）で最先端の結果（74.5%)を達成することができます。なお、実装と学習済みモデルはGitHubで公開しています。
実世界の多くのアプリケーションでは、電力消費量の計画など、長周期の時系列を予測する必要があります。長周期時系列予測（LSTF）では、出力と入力の間の正確な長距離依存関係の結合を効率的に捉えることができる、高い予測能力がモデルに求められます。最近の研究では、Transformerによる予測能力の向上の可能性が示されています。しかし、Transformerには、2次の時間的複雑さ、高いメモリ使用量、エンコーダ・デコーダアーキテクチャの固有の制限など、LSTFに直接適用することを妨げるいくつかの深刻な問題があります。これらの問題を解決するために、我々は、3つの特徴的な特性を持つInformerと名付けられたLSTFのための効率的なトランスフォーマーベースのモデルを設計する。(i) $ProbSparse$の自己注目メカニズムにより、時間計算量とメモリ使用量が$O(L ˶L ˶L)$となり、配列の依存関係の整列についても同等の性能を得ることができる。(ii) 自己注意の蒸留は、カスケード接続された層の入力を半分にすることで、支配的な注意を強調し、極端に長い入力シーケンスを効率的に処理します。(iii) 生成スタイルデコーダは、概念的には単純であるが、長い時系列を段階的に予測するのではなく、一度の前進操作で予測するため、長い時系列の予測の推論速度が飛躍的に向上する。4つの大規模データセットを用いた広範な実験により、Informerは既存の手法を大幅に凌駕し、LSTF問題に新たな解決策を提供することが実証されました。
無限小の学習率の場合、確率的勾配降下法（SGD）は、フルバッチ損失関数上の勾配フローの経路をたどります。しかし、適度に大きな学習率では、より高いテスト精度が得られる。テスト精度を最大化する学習率は、学習損失を最小化する学習率よりも大きいことが多いため、この一般化の利点は収束限界では説明できない。この現象を解釈するために、ランダムシャッフルを用いたSGDでは、学習率が小さく有限であれば、平均的なSGD反復子も、修正された損失の上で、勾配流の経路に近いところに留まることを証明する。この修正損失は、元の損失関数と、ミニバッチ勾配のノルムにペナルティを課す暗黙の正則化とで構成される。穏やかな仮定の下では、バッチサイズが小さい場合、暗黙の正則化項の規模は、学習率とバッチサイズの比に比例する。我々は、学習率が小さいときに、暗黙の正則化項を損失に明示的に含めることでテスト精度が向上することを経験的に検証した。
機械学習（ML）の急速な普及に伴い、現在では多くの領域で、大規模なデータコーパスで事前に学習したモデルを微調整するアプローチが用いられています。しかし、我々の実験によると、GPUを使用した場合、BERTのようなモデルの微調整でさえ何時間もかかることが分かりました。先行研究では、微調整を行う層の数を制限することが提案されていますが、例えば、最後の層を除くすべての層を凍結するなど、そのような静的なアプローチでは精度の低下につながることがわかりました。そこで、学習する層を適応的に選択するシステム「AutoFreeze」を提案し、精度を維持しながらモデルの微調整を高速化できることを示す。また、中間活性化の効率的なキャッシングを可能にするメカニズムを開発することで、微調整を行う際の前方計算時間を短縮することができる。4つのNLPタスクで評価した結果、キャッシングを有効にしたAutoFreezeは、ファインチューニングのパフォーマンスを最大で2.55倍向上させることができます。
BoTNetは、概念的にシンプルでありながら、画像分類、オブジェクト検出、インスタンスセグメンテーションなどの複数のコンピュータビジョンタスクに自己注意を組み込む強力なバックボーンアーキテクチャです。ResNetの最後の3つのボトルネックブロックで、空間的な畳み込みをグローバルな自己注意に置き換えるだけで、我々のアプローチは、レイテンシーのオーバーヘッドを最小限に抑えながら、パラメータを削減し、インスタンスセグメンテーションとオブジェクト検出においてベースラインを大幅に改善します。また、BoTNetの設計を通じて、ResNetのボトルネックブロックに自己注意を払うことで、いかにTransformerブロックとして見ることができるかを指摘しています。BoTNetは、マスクR-CNNフレームワークを用いたCOCOインスタンス分割ベンチマークにおいて、マスクAP44.4%、ボックスAP49.7%を達成しました。最後に、BoTNetの設計を画像分類に簡単に適用した結果、ImageNetベンチマークで84.7%のトップ-1精度という強力な性能を達成し、TPU-v3ハードウェア上で一般的なEfficientNetモデルよりも最大2.33倍の計算時間を実現しました。私たちのシンプルで効果的なアプローチが、視覚のための自己注意モデルの将来の研究のための強力なベースラインとなることを期待しています。
言語モデリングで人気のトランスフォーマーは、最近、画像分類のためのVision Transformers (ViT)など、視覚タスクを解決するために探求されています。ViTモデルは、各画像を一定の長さのトークンのシーケンスに分割し、複数のTransformer層を適用して、それらの大域的な関係をモデル化して分類します。しかし、ViTは、中規模データセット（例：ImageNet）でゼロから学習させた場合、CNNと比較して劣った性能を達成しました。その理由は以下の通りである。1) 入力画像の単純なトークン化では，隣接するピクセル間の重要な局所構造（エッジや線など）をモデル化できず，学習サンプルの効率が低い． 2) ViTの冗長な注目バックボーンの設計では，固定の計算予算と限られた学習サンプルでは，特徴の豊かさが制限される．このような限界を克服するために、我々は新しいToken-to-Token Vision Transformers (T2T-ViT)を提案する。これは、1) 隣接するトークンを再帰的に1つのトークンに集約することで、画像をトークンに漸進的に構造化する層状のToken-to-Token (T2T)変換を導入することで、周囲のトークンが示す局所的な構造をモデル化し、トークンの長さを短縮することができる。2) ビジョン変換のための効率的なバックボーンは、広範な研究の結果、CNNのアーキテクチャ設計に基づいて考案された深い細長い構造になっている。T2T-ViTは、ViTのパラメータ数とMAC数を200%削減し、ImageNetでゼロから学習した場合には2.5%以上の改善を達成しました。また、ImageNet上で直接学習した場合には、ResNetsを上回り、MobileNetsと同等の性能を達成しています。例えば、T2T-ViTはResNet50と同等のサイズで、ImageNet上で80.7%のトップ1精度を達成しています。(コード：このhttpsのURL)
大規模なラベルなしテキストデータで学習された言語モデル(LM)であり、豊富な文脈表現を生成できるBERTを微調整することで、自動音声認識(ASR)のためのシンプルな手法を提案します。BERTは、大規模なラベルなしテキストデータで学習された言語モデル（LM）であり、豊富な文脈表現を生成することができます。したがって、強力な音響モデル（AM）をゼロからトレーニングする従来のASRシステムと比較して、BERTモデルを微調整するだけで音声認識が可能であると考えています。最初の研究として、我々はAISHELLデータセットで提案されたアイデアの有効性を実証し、BERTの上に非常に単純なAMを積み重ねることで合理的な性能が得られることを示す。
データセットは、正確で展開可能なシステムをトレーニングするためのリソースであるだけでなく、新しいモデリングアプローチを開発するためのベンチマークでもあります。大規模で自然なデータセットは、正確なシステムを訓練するために必要ですが、モデリングの革新を推進するためにも必要なのでしょうか。例えば、人気の高いSQuAD質問応答ベンチマークは、新しいモデリング・アプローチの開発を推進してきましたが、合成ベンチマークやより小さなベンチマークも同様のイノベーションをもたらしたのでしょうか？この反実例的な質問に答えることは不可能ですが、必要な条件、つまりSQuADで得られた知見をベンチマークが再現できるかどうかを研究することはできます。20のSQuADモデル化アプローチのレトロスペクティブな研究を行い、32の既存および合成ベンチマークがどの程度SQuADと一致しているのか、つまりアプローチを同じようにランク付けしているのかを調べました。私たちは、自然言語に似ていない小さな合成ベンチマークを慎重に作成しましたが、SQuADとの高い一致率を示しました。この結果は、小さくて慎重に設計された合成ベンチマークが、新しいモデリング・アプローチの開発を促進するのに役立つかもしれないという興味深い可能性を提起しています。
本論文では、画像の異常検知とセグメンテーションの問題を取り上げます。異常検出では、入力画像に異常があるかどうかを二値的に判断し、異常セグメンテーションでは、ピクセルレベルで異常の位置を特定することを目的としています。サポートベクトルデータ記述（SVDD）は、古くから異常検出に用いられているアルゴリズムですが、その深層学習版を、自己教師付き学習を用いたパッチベースの手法に拡張します。この拡張により、異常のセグメンテーションが可能となり、検出性能が向上します。その結果、MVTec ADデータセットのAUROCで測定した異常検出性能とセグメンテーション性能は、従来の最新手法と比較して、それぞれ9.8%と7.0%向上しました。この結果は，提案手法の有効性と産業応用の可能性を示すものである．提案手法の詳細な解析により、その動作に関する洞察が得られ、コードはオンラインで公開されています。
ディープニューラルネットワーク（DNN）は、医療から社会、さらには司法に至るまで、無数の重要なアプリケーションの意思決定に広く利用されています。このような意思決定の重要性を考えると、これらのモデルを解釈できることは非常に重要です。本研究では、モデルの性能を低下させることなくノイズを適用できる領域を学習することで、画像分割モデルを解釈する新しい手法を紹介する。この手法をCTスキャンにおける膵臓のセグメンテーションに適用し、Grad-CAMやオクルージョン感度などの既存の説明可能性技術と定性的に比較した。さらに、他の手法とは異なり、我々の説明可能性モデルは、不明瞭な画像に対する下流のパフォーマンスに基づいて定量的に評価できることを示す。
ディープネットワークのエンド・ツー・エンド（E2E）トレーニングでは、バックプロパゲーションのために中間活性化を保存する必要があるため、GPUのメモリフットプリントが大きくなってしまいます。本論文では、この問題を解決するために、ネットワークを勾配で分離されたモジュールに分割し、局所的に監視しながら学習する局所監視学習を再検討する。我々は、E2E損失を用いて局所モジュールを単純に学習すると、タスクに関連する情報が初期層で崩壊してしまい、フルモデルの性能が低下することを実験的に示した。この問題を回避するために、我々は情報伝播(InfoPro)損失を提案する。これは、ローカルモジュールが、タスクに無関係な情報を徐々に廃棄しながら、できるだけ多くの有用な情報を保持するよう促すものである。InfoPro損失は本来の形では計算することが難しいため、実現可能な上界を代理の最適化目的として導出し、シンプルかつ効果的なアルゴリズムを得ることができる。実際、提案手法は、再構成損失と通常のクロスエントロピー/コントラスト項の組み合わせを最小化することに帰着することを示している。5つのデータセット（CIFAR、SVHN、STL-10、ImageNet、Cityscapes）を対象とした大規模な実証実験の結果、InfoProは、E2Eトレーニングと比較して40％以下のメモリフットプリントで競争力のある性能を達成できることが確認されました。また、この手法では、ローカルモジュールを非同期で学習することができるため、学習の高速化が期待できます。コードは、このhttpsのURLから入手できます。
人間の学習にヒントを得て、研究者たちは、学習中の例題をその難易度に基づいて順序付けることを提案しています。標準的なi.i.d.トレーニングの改善策として、トレーニングの初期段階でネットワークに簡単な例を見せるカリキュラム学習と、最も難しい例を最初に見せるアンチカリキュラム学習の両方が提案されている。本研究では、順序付けられた学習の相対的な利点を調査することを目的としている。まず、アーキテクチャと最適化バイアスに起因する暗黙のカリキュラムを調査し、サンプルが非常に一貫した順序で学習されることを発見しました。次に，明示的なカリキュラムの利点を定量化するために，カリキュラム，アンチカリキュラム，ランダムカリキュラム（学習データセットのサイズを時間とともに動的に増加させるが，例はランダムに並べる）の3種類の学習について，何千もの順序で大規模な実験を行った．その結果，標準的なベンチマークデータセットにおいて，カリキュラムにはわずかな利点しかなく，ランダムに並べられたサンプルはカリキュラムやアンチカリキュラムと同等以上の性能を発揮することがわかった．我々は、カリキュラム学習の実際の使用例にヒントを得て、限られたトレーニング時間の予算とノイズの多いデータがカリキュラム学習の成功に果たす役割を調査した。我々の実験では、限られた訓練時間やノイズの多いデータがある場合でも、カリキュラムは、反カリキュラムやランダムな順序付けではなく、実際にパフォーマンスを向上させることができることを示した。
機械による読解に関する最近の研究は、テキストレベルの理解に焦点を当てているが、実世界の文書の視覚的なレイアウトやコンテンツに対する人間の理解のレベルにはまだ達していない。本研究では、VisualMRCと名付けられた新しい視覚的機械読解データセットを紹介する。このデータセットでは、質問と文書画像が与えられると、機械が画像内のテキストを読んで理解し、自然言語で質問に答える。VisualMRCは、画像中のテキストを含む既存の視覚的質問応答（VQA）データセットと比較して、自然言語の理解と生成能力の開発に重点を置いています。VisualMRCは、複数のドメインのウェブページから抽出した10,000以上の文書画像に対して、30,000以上の質問と抽象的な回答のペアを含んでいる。また、大規模なテキストコーパスで事前に学習された既存のsequence-to-sequenceモデルを拡張し、文書の視覚的なレイアウトやコンテンツを考慮した新しいモデルを導入しています。VisualMRCを用いた実験によると、このモデルは、基本的なsequence-to-sequenceモデルや最新のVQAモデルを上回る性能を示した。しかし、ほとんどの自動評価指標において、その性能は人間のそれを下回っています。このデータセットは、視覚と言語理解を結びつけることを目的とした研究を促進します。
ソフトウェア開発の大部分は、プログラムで表現する必要のある基本的な手順や論理を概念化したり、伝達したりすることである。特に、見慣れないライブラリのAPIを扱う際には、概念をコード化することがプログラミングの大きな難関となります。近年、機械学習を利用して自然言語のクエリからコードを生成・検索する手法が普及していますが、これらは主に検索精度や生成されたコードと開発者が書いたコードとの重なりなどを基準に評価されており、実際に開発者のワークフローにどのような影響を与えているかは意外と知られていません。私たちは、"現在の技術では、開発者の生産性や精度を向上させることができるのか、開発者の経験にどのような影響を与えるのか、そして残されたギャップや課題は何か？"という疑問を持ち、このような技術をIDE内で使用することの期待と課題を初めて包括的に調査しました。まず、コード生成機能とコード検索機能をハイブリッドで実装したIDE用プラグインを開発し、仮想環境をオーケストレーションすることで、多くのユーザーイベントを収集できるようにしました。そして、様々なバックグラウンドを持つ開発者に、基本的なファイル操作から機械学習やデータの可視化まで、14種類のPythonプログラミングタスクを、プラグインを使用した場合と使用しなかった場合の両方で実行してもらいました。開発者の経験に関する定性的な調査では概ね肯定的な結果が得られましたが、生産性の向上、コード品質、プログラムの正確性に関する定量的な結果は結論が出ていません。分析の結果、将来の機械学習ベースのコード生成/検索開発者アシスタントの効果を向上させることができるいくつかのペインポイントを特定し、開発者がコード生成をコード検索よりも好む場合やその逆の場合を実証しました。今後の実証研究やより良いモデルの開発のための道を開くために、すべてのデータとソフトウェアを公開します。
グラフ構造を持ったデータは、科学や工学の分野で広く使われています。グラフニューラルネットワーク（GNN）は、グラフに見られる関係性の誘導バイアスを利用するように設計されており、構造情報がノードの特徴を補うシナリオにおいて、他の形式のニューラルネットワークよりも優れた性能を発揮することが示されています。最も一般的なGNNアーキテクチャは、メッセージパッシングに基づいて近隣からの情報を集約します。その汎用性の高さから、広く応用されています。本論文では、特殊なグラフでありながら広く使われているDAGに着目し、より強い帰納的バイアスである部分的順序付けをニューラルネットワークの設計に導入します。DAGNNは、部分順序によって定義されたフローに従って情報を処理するアーキテクチャです。DAGNNは、先行研究を特別なケースとして包含するフレームワークと考えられるが（例えば、木のモデルやノード表現を再帰的に更新するモデル）、先行研究のアーキテクチャに欠けているいくつかの重要な要素を明らかにする。代表的なDAGデータセット（ソースコード、ニューラルアーキテクチャ、確率的グラフモデル）を用いて、アブレーション研究を含む包括的な実験を行い、DAGNNが、より単純なDAGアーキテクチャや一般的なグラフアーキテクチャよりも優れていることを実証した。
コンピュータビジョンにおける畳み込みニューラルネットワーク（CNN）の成功は、主にその強い帰納的バイアスによるもので、CNNが学習なしに、つまりランダムな重みでビジョン関連のタスクを解決できるほどの強さを持っています。同様に、LSTM（Long Short-Term Memory）も、時間をかけて情報を保存するという強い帰納的バイアスを持っている。しかし、多くの実世界のシステムは保存法則に支配されており、物理的なシステムや経済的なシステムのように、特定の量を再分配する必要があります。私たちの新しい質量保存型LSTM（MC-LSTM）は、LSTMの帰納的バイアスを拡張して、これらの保存量の再分配をモデル化することで、これらの保存法則に従っています。MC-LSTMは、足し算などの算術演算を学習する際に、その和が時間的に一定であるという強い保存則を持つ、神経演算ユニットの新たな最先端を切り開きました。さらに、MC-LSTMは、交通量予測、振り子のモデル化、水文学の大規模なベンチマークデータセットに適用され、ピーク流量の予測において最先端の技術を確立しました。水文学の例では、MC-LSTMの状態が実世界のプロセスと相関しており、したがって解釈可能であることを示しています。
予測タスクのインスタンス単位の不確実性を伝達するために、将来のテストポイントにおける期待損失をユーザが指定したレベルで制御するブラックボックス予測器のために、セット値の予測を生成する方法を示します。本手法は、ホールドアウトセットを用いて予測セットのサイズを校正することにより、あらゆるデータセットに対して明示的な有限サンプル保証を提供する。このフレームワークは、多くのタスクにおいて、単純で、分布に依存しない、厳密なエラー制御を可能にし、5つの大規模な機械学習問題で実証する。(1)いくつかの間違いが他の間違いよりもコストが高い分類問題、(2)各観測値が複数の関連するラベルを持つマルチラベル分類、(3)ラベルが階層構造を持つ分類問題、(4)関心のあるオブジェクトを含むピクセルのセットを予測したい画像セグメンテーション、(5)タンパク質構造予測。最後に、不確実性定量化の拡張として、ランキング、メトリック学習、分布ロバスト学習について説明する。
時系列データを探索的に分析することで、複雑な力学系の理解を深めることができる。グランジャー因果は、時系列データの相互作用を分析するための実用的なフレームワークであり、様々な分野で応用されている。本論文では、自己説明型ニューラルネットワークの拡張に基づいて、非線形力学下での多変量グランジャー因果関係を推論する新しいフレームワークを提案する。このフレームワークは、関係性の推論に加えて、グランジャー因果関係の効果の兆候を検出し、その時間的変動を検査することができるため、他のニューラルネットワークに基づくグランジャー因果関係の推論手法よりも解釈が容易である。シミュレーションデータを用いた包括的な実験において、我々のフレームワークは、Granger因果関係の推論において、いくつかの強力なベースライン手法と同等の性能を示し、相互作用の兆候の推論においては、より優れた性能を達成することを示した。この結果は、我々のフレームワークが、グランジャー因果関係を推論するための、入力の少ないニューラルネットワークに代わる実行可能な、より解釈可能な手法であることを示唆している。
本論文では、音楽を条件とした3Dダンス生成のための変換器ベースの学習フレームワークを紹介する。本論文では、音楽を条件とした3Dダンス生成のための変換器ベースの学習フレームワークを紹介する。本研究では、音楽とダンス動作の相関関係を学習するクロスモーダル変換器と、長時間の凍結しない動作を生成するために必要なFull-attention with future-N監視機構が重要な要素である。さらに、AISTのマルチビュー・ダンスビデオから再構成した、3Dモーションと音楽のペアの新しいデータセット「AIST++」を提案している。このデータセットには、10ジャンルのダンスの振り付けを網羅した1408シーケンスの110万フレームの3Dダンスモーションが含まれており、マルチビューカメラのパラメータも付いている。我々の知る限りでは、この種のデータセットとしては最大のものです。AIST++での豊富な実験により、我々の手法が質的にも量的にも最先端の手法よりもはるかに優れた結果を出すことが実証されました。
微調整は、事前に学習された大規模な言語モデルを活用して下流のタスクを実行するための事実上の方法です。しかし、微調整はすべての言語モデルのパラメータを変更するため、タスクごとに完全なコピーを保存する必要があります。本論文では、自然言語生成タスクにおける微調整に代わる軽量な手法として、プレフィックス調整を提案する。これは、言語モデルのパラメータを凍結したまま、タスク固有の小さな連続したベクトル（プレフィックスと呼ばれる）を最適化するものである。プレフィックスチューニングはプロンプトからヒントを得て、後続のトークンがあたかも「仮想トークン」のようにこのプレフィックスにアテンションできるようにする。本研究では、GPT-2を用いた表計算とBARTを用いた要約処理にプレフィックスチューニングを適用した。その結果、パラメータの0.1%を学習するだけで、前置チューニングはフルデータ環境で同等の性能を得ることができ、低データ環境では微調整よりも優れた性能を発揮し、学習時に見られなかったトピックを持つ例への外挿性も高いことがわかった。
エンティティは、私たちが知識を表現したり集約したりする際の中心となるものです。例えば、Wikipediaのような百科事典は、エンティティによって構成されています（例えば、Wikipediaの記事ごとに1つ）。このようなエンティティを検索する能力は、エンティティのリンクやオープンドメインの質問応答など、知識集約型のタスクには欠かせません。現在のアプローチは、各エンティティに対して1つの原子ラベルを持つ分類器として理解することができます。その重みベクトルは、説明文などのエンティティのメタ情報をエンコードすることで生成される高密度のエンティティ表現です。このアプローチには、いくつかの欠点があります。(i)コンテキストとエンティティの親和性は主にベクトルのドット積で表され、細かい相互作用を見逃す可能性がある。(ii)大きなエンティティセットを考慮する場合、密な表現を保存するために大きなメモリフットプリントが必要となる。本研究では、自己回帰的に左から右へ、トークンごとに固有の名前を生成してエンティティを検索する初めてのシステムであるGENREを提案します。このシステムでは、(i)自己回帰形式が文脈と固有名の関係を直接捉え、両者を効果的に相互符号化すること、(ii)我々のエンコーダ・デコーダアーキテクチャのパラメータは、固有数ではなく語彙数に応じて変化するため、メモリフットプリントが大幅に削減されること、(iii)ソフトマックス損失が負のデータをサブサンプリングすることなく計算されること、などにより、前述の技術的問題を軽減することができる。エンティティ曖昧性解消、エンドツーエンドのエンティティリンク、文書検索のタスクについて、20以上のデータセットを用いて実験を行ったところ、競合システムに比べてメモリフットプリントをごくわずかに抑えながら、最先端の結果、あるいは非常に競争力のある結果を得ることができた。最後に、エンティティの名前を指定するだけで、新しいエンティティを追加できることを実証しました。コードと学習済みモデルはこのhttpsのURLにあります。
同じデータセットで同じニューラルネットワークアーキテクチャを複数回学習させた場合、学習内容に関わらず同じような言語的一般化を行うことができるのでしょうか？この疑問を検討するために、多ジャンル自然言語推論（MNLI）データセットでBERTの100インスタンスを微調整し、自然言語推論における構文の一般化を評価するHANSデータセットで評価しました。MNLI データセットでは、すべてのインスタンスの動作は非常に一貫しており、精度は 83.6%～84.8% でした。一方，同じモデルでも，一般化の性能には大きなばらつきがありました．例えば，主語と目的語の入れ替えという単純なケース（"the doctor visited the lawyer "は "the lawyer visited the doctor "を含まないと判断するなど）では，精度は0.00%から66.2%の範囲であった。このようなばらつきは，ニューラルネットワークのようなバイアスの低い学習者にとっても同様に魅力的な多くのローカルミニマムが存在するためであると考えられる．
ニューラルネットワークによってパラメータ化された、暗黙的に定義された連続的で微分可能な信号表現は、従来の表現に比べて多くの利点をもたらす可能性のある強力なパラダイムとして浮上している。しかし、このような暗黙的な神経表現のための現在のネットワークアーキテクチャは、信号を詳細にモデル化することができず、信号の空間的および時間的な微分を表現することができませんでした。我々は、暗黙的な神経表現に周期的な活性化関数を利用することを提案し、正弦波表現ネットワーク（Sirens）と呼ばれるこのネットワークが、複雑な自然信号とその微分を表現するのに理想的であることを示した。サイレンの活性化統計を分析して原理的な初期化スキームを提案し、画像、波動場、ビデオ、音声、およびそれらの派生物の表現を実証します。さらに、Sirensを活用して、特定のEikonal方程式（符号付き距離関数が得られる）、ポアソン方程式、ヘルムホルツ方程式や波動方程式などの難しい境界値問題を解く方法を紹介します。最後に、Sirensとハイパーネットワークを組み合わせて、Siren関数の空間上のプライアを学習します。
我々は、認識されるオブジェクトのデザインに影響を与えることができる現実的なコンピュータビジョンの設定のクラスを研究しています。この能力を利用して、ビジョンモデルの性能とロバスト性を大幅に向上させるフレームワークを開発しました。このフレームワークは、最新の機械学習アルゴリズムの入力摂動に対する感度を利用して、「ロバストなオブジェクト」、すなわち、自信を持って検出または分類できるように明示的に最適化されたオブジェクトを設計します。このフレームワークの有効性を、標準的なベンチマークから（インシミュレーションの）ロボット工学、実世界の実験に至るまで、さまざまな視覚ベースのタスクで実証します。我々のコードは、このhttpsのURLにあります。
ゼネラリストロボットは、環境内で様々なタスクをこなすことができなければなりません。各タスクを指定する魅力的な方法の1つは、ゴール観測の観点からです。しかし、強化学習を用いてゴールに到達するための方針を学習することは、難しい問題です。学習された力学モデルは、報酬やタスク指示データなしに環境を学習するための有望なアプローチであるが、このようなモデルを用いてゴールに到達するための計画を立てるには、観測値とゴールの状態の間の機能的類似性の概念が必要である。本研究では、モデルベースの視覚的ゴール到達のための自己教師付き手法を提案する。この手法では、モデルフリー強化学習を用いて学習した動的距離関数と、視覚的ダイナミクスモデルの両方を用いる。この手法は、オフラインのラベルのないデータを用いて学習するため、大規模かつ多様なデータセットへの適用が可能である。実験では、本手法が、テスト時に様々なタスクを実行するモデルをうまく学習できることがわかった。シミュレーションされたロボットアームを使って、気の散るものの中で物体を動かしたり、現実のロボットを使って引き出しの開閉を学習したりすることができた。比較の結果、このアプローチは、モデルフリーおよびモデルベースの先行手法を大幅に上回ることがわかりました。動画や映像は、こちらのURLからご覧いただけます。
私たちは、ハイレベルな概念を使って対話できるモデルを求めています。例えば、モデルがレントゲン写真に骨棘があると考えなかったとしても、重度の関節炎を予測できるでしょうか？現在の最新モデルは、生の入力（例：ピクセル）から出力（例：関節炎の重症度）に直接つながるようにエンド・ツー・エンドで訓練されているため、「骨棘の有無」のような概念の操作には通常対応していません。私たちは、学習時に提供される概念をまず予測し、次にこれらの概念を使ってラベルを予測するという古典的なアイデアを再検討しました。構造上、予測された概念値を編集し、これらの変更を最終的な予測に伝搬させることで、これらの概念ボトルネックモデルに介入することができます。X線写真の等級付けや鳥の識別において、概念ボトルネックモデルは、標準的なエンドツーエンドモデルに匹敵する精度を達成するとともに、高レベルの臨床概念（「骨棘」）や鳥の属性（「翼の色」）を用いた解釈を可能にする。また、これらのモデルは、人間とモデルのより豊かな相互作用を可能にします。テスト時にコンセプトに関するモデルの間違いを修正できれば、精度は大幅に向上します。
本論文では、互換性があり、再利用可能なネットワークコンポーネントへの第一歩を踏み出すことを提案する。異なるタスクのために個別にネットワークを学習するのではなく、タスク間で互換性のあるネットワークコンポーネントを生成するように学習プロセスを適応させる。具体的には、ネットワークを特徴抽出器とタスクヘッドの2つのコンポーネントに分割し、それらの間の互換性を達成するための様々なアプローチを提案する。これらのアプローチを、標準的なデータセットを用いた画像分類のタスクで体系的に分析した。その結果、微調整や元のタスクでの精度を損なうことなく、直接互換性のあるコンポーネントを生成できることを実証した。その後、3つのアプリケーションで互換性のあるコンポーネントの使用を実証する。教師なしのドメイン適応、アーキテクチャの異なる特徴抽出器間での分類器の移行、伝達学習の計算効率の向上。
NLPコミュニティでは、continuous bag-of-words (CBOW) の単語埋め込みはskip-gram (SG) 埋め込みよりも性能が劣る傾向にあるというのが一般的な見解です。この通説は、両者の学習目的の理論的な違いよりも、公式の実装であるword2vec.cやGensimのような標準的なソフトウェアライブラリにおける誤ったCBOWの実装に起因するものであることがわかりました。我々は、CBOWの正しい実装により、様々な内在的・外在的タスクにおいてSGと完全に競合する単語埋め込みが得られる一方で、学習速度は3倍以上であることを示します。我々の実装であるkōanは、このhttpsのURLで公開しています。
影響関数は、テスト予測のための訓練データポイントの「影響」を近似するもので、幅広い用途があります。人気があるにもかかわらず、その計算コストはモデルやトレーニングデータのサイズに対してうまくスケールしません。我々は、FastIFを発表します。FastIFは、影響力関数に簡単な修正を加え、実行時間を大幅に改善するものです。本手法では、k-Nearest Neighbors（kNN）を用いて探索空間を良好なデータ候補のサブセットに絞り込み、逆ヘシアンベクトル積の推定において速度と品質のトレードオフのバランスが最も良い構成を特定し、高速な並列版を導入する。提案した手法は、元の影響値との高い相関性を保ちながら、約80倍の高速化を達成しました。このようにして得られた高速な影響関数の有用性を、4つのアプリケーションで実証する。まず、影響力のあるデータポイントがテスト時間の挙動を「説明」できるかどうかを、シミュレーショ ン可能性の枠組みを用いて検証します。第二に、トレーニングデータポイントとテストデータポイントの間の影響の相互作用を視覚化します。第3に、特定の影響力のあるデータポイントに対して微調整を加えることでモデルのエラーを修正することができ、HANSデータセットにおいて訓練されたMultiNLIモデルの精度を2.5%向上させることができることを示す。最後に、同様の設定で、学習時に見られなかったデータポイントを微調整する実験を行ったところ、HANSデータセットで2.8%、ANLIデータセットで1.7%、モデルの精度が向上しました。全体として、我々の高速影響関数は、大規模なモデルやデータセットに効率的に適用することができ、我々の実験は、モデルの解釈やモデルのエラーを修正する際に影響関数の可能性を示している。コードはこのhttpsのURLから入手できます。
生成的敵対ネットワーク（GAN）の性能は、限られた量の訓練データがあると大きく劣化します。これは主に、識別器が正確な訓練セットを記憶しているためである。この問題に対処するために、我々はDifferentiable Augmentation (DiffAugment)を提案する。これは、実サンプルと偽サンプルの両方に様々なタイプの微分可能な補強を課すことで、GANのデータ効率を改善するシンプルな手法である。学習データを直接増強する従来の試みでは、実画像の分布を操作するため、ほとんど効果がありませんでした。DiffAugmentでは、生成されたサンプルに微分可能な増強を採用することができ、効果的に学習を安定させ、より良い収束をもたらします。実験では、様々なGANアーキテクチャや損失関数に対して、無条件生成とクラス条件生成の両方で、本手法が一貫して利益を得られることを実証した。DiffAugmentを用いることで、ImageNet 128x128において、最先端のFID 6.80、IS 100.8を達成し、FFHQとLSUNにおいては、1,000枚の画像を与えたときのFIDを2-4倍に削減することができました。さらに，わずか20%の学習データで，CIFAR-10およびCIFAR-100の最高性能に匹敵する結果を得ることができました．最後に、我々の手法は、既存の伝達学習アルゴリズムと同等でありながら、事前学習なしに、わずか100枚の画像を用いて、高忠実度の画像を生成することができます。コードはこちらのhttpsのURLから入手できます。
近年、密な表現に基づく検索システムは、オープンドメインの質問応答やそれに関連するタスクにおいて重要な改善をもたらしました。このアプローチは非常に効果的であるが、知識源全体の密なベクトルをメモリに保持する必要があるため、メモリを大量に消費する。本論文では、高密度のレトリバー・リーダーシステムのメモリフットプリントをどのように削減できるかを研究する。インデックスサイズを削減するために、次元削減、ベクトル量子化、通過フィルタリングの3つの戦略を検討する。我々のアプローチを、2つの質問応答ベンチマークで評価する。TriviaQAとNaturalQuestionsの2つの質問応答ベンチマークで我々のアプローチを評価し、6Gb以下のメモリで競争力のあるシステムを得ることが可能であることを示した。
本研究では、複数の物体の追跡問題を解決するためのシンプルかつ効率的なスキームであるTransTrackを提案する。TransTrackは、注目ベースのクエリ・キー・メカニズムであるトランスフォーマ・アーキテクチャを利用しています。TransTrackは、前のフレームからのオブジェクト特徴を現在のフレームのクエリとして適用し、新たにやってくるオブジェクトを検出できるように、学習されたオブジェクトクエリのセットを導入します。また、オブジェクトの検出と関連づけをワンショットで行うことで、オブジェクトの検出と追跡を同時に行う新しいパラダイムを構築し、検出による追跡手法の複雑な多段階設定を簡略化しています。MOT17およびMOT20ベンチマークにおいて、TransTrackはそれぞれ74.5%および64.5%のMOTAを達成し、最先端の手法と競合する結果となりました。TransTrackは、複数物体の追跡に新しい視点を提供することができると期待しています。コードは以下のサイトで公開されています。\コードは以下のサイトで公開されています。
近年，学習済みのニューラル言語モデルの進歩により，多くの自然言語処理（NLP）タスクの性能が大幅に向上している．本論文では、2つの新しい技術を用いてBERTモデルとRoBERTaモデルを改良した、新しいモデルアーキテクチャDeBERTa（Decoding-enhanced BERT with disentangled attention）を提案する。1つ目はdisentangled attentionメカニズムで、各単語はその内容と位置をそれぞれ符号化する2つのベクトルを用いて表現され、単語間の注意の重みは、それぞれの内容と相対的な位置に関するdisentangled行列を用いて計算される。次に、モデルの事前学習において、マスクされたトークンを予測するために、復号層に絶対的な位置を組み込む強化されたマスクデコーダを使用します。さらに、新しい仮想敵対的学習法を用いて、モデルの一般化を向上させるための微調整を行う。これらの技術により、モデルの事前学習の効率と、自然言語理解（NLU）および自然言語生成（NLG）の下流タスクのパフォーマンスが大幅に向上することを示しています。RoBERTa-Large と比較して、訓練データの半分で訓練された DeBERTa モデルは、広範囲の NLP タスクにおいて一貫して優れた性能を示し、MNLI では +0.9%（90.2% 対 91.1%）、SQuAD v2.0 では +2.3%（88.4% 対 90.7%）、RACE では +3.6%（83.2% 対 86.8%）の向上を達成した。注目すべきは、15億個のパラメータを持つ48のトランスフォーム層で構成されるより大きなバージョンをトレーニングすることで、DeBERTaをスケールアップしたことです。この大幅な性能向上により、単一のDeBERTaモデルはSuperGLUEベンチマーク（Wang et al., 2019a）のマクロ平均スコアで初めて人間の性能を上回り（89.9対89.8）、アンサンブルのDeBERTaモデルは2021年1月6日時点でSuperGLUEのリーダーボードのトップに座り、人間のベースラインをかなりの差で上回っている（90.3対89.8）。
本論文では、大規模なラベルなしコーパス上で文の表現を効率的に学習するための新しい学習方法であるConditional Masked Language Modeling（CMLM）を紹介します。CMLMは，隣接する文の符号化されたベクトルを条件として，文表現の学習をMLMの学習に統合するものである．我々が開発した英語のCMLMモデルは、SentEvalにおいて最先端の性能を達成し、教師付き信号を用いて学習したモデルよりも優れています。完全に教師なしの学習方法であるCMLMは、広範囲の言語やドメインに拡張することができます。本研究では、ビットテキスト検索（BR）および自然言語推論（NLI）タスクを用いて共同学習した多言語CMLMモデルが、従来の最先端の多言語モデルを大幅に上回ることを発見しました。本研究では、学習された表現の言語バイアスを調査し、文の意味を保持したまま表現から言語識別情報を取り除くための、学習後のモデルに依存しないシンプルなアプローチを提案する。
一般に、深層学習モデルの性能向上と一般化のためには、十分なデータが不可欠です。しかし、データ収集には多くの制限（コスト、リソースなど）があるため、ほとんどの分野で十分なデータが不足しています。また、データソースやライセンスの領域も様々であるため、十分なデータを収集することが困難です。このような状況では、事前に学習されたモデルだけでなく、外部の知識も活用することが難しくなります。そのため，小さなデータセットを効果的に活用することが重要となる。私たちは、データ、損失関数、予測の3つの側面からいくつかの技術を適用し、少ないデータでゼロからの学習を可能にしました。これらの手法により、1クラスあたり50枚の画像からなるImageNetデータを活用して、高い精度を得ることができました。さらに、我々のモデルは、Visual Inductive Printers for Data-Effective Computer Vision Challengeにおいて4位にランクインしています。
データミキシングによる補強は、ディープモデルの学習に有効であることがわかっています。最近の手法では、主に画像ピクセルの混合比率に基づいてラベルを混合します。繊細な画像の主な識別情報は通常、微妙な領域に存在するため、このラインに沿った手法は、繊細な認識において重いラベルノイズが発生しやすい。本論文では、Semantically Proportional Mixing (SnapMix)と呼ばれる新しい方式を提案する。これは、クラス活性化マップ(CAM)を利用して、細粒度データを増強する際のラベルノイズを軽減するものである。SnapMixは、混合画像の固有の意味的構成を推定することで、その画像のターゲットラベルを生成します。また、非対称な混合操作を可能にし、合成画像とターゲットラベルの間の意味的な対応関係を保証します。実験によると、我々の手法は、様々なデータセットや異なるネットワーク深度の下で、既存の混合ベースのアプローチを一貫して凌駕している。さらに，中間レベルの特徴を取り入れることで，提案するSnapMixはトップレベルの性能を達成し，細かい認識のための強固なベースラインとしての可能性を示している．当社のコードは、このhttpsのURLから入手できます。
問題の構造を分析し、それを相互に関連する下位問題に分解する能力であるプランニングは、人間の知能の特徴である。深層強化学習（RL）は、比較的単純な制御タスクの解決に大きな期待が寄せられているが、複雑化する環境に対応するために、既存の深層強化学習パラダイムにどのようにプランニングを組み込むかは、依然として未解決の問題である。モデルベースRLは、世界モデルを学習し、ステップバイステップの仮想ロールアウトを用いてプランニングを行うものである。しかし、この種の世界モデルは、計画の地平線が長くなると現実との乖離が大きくなり、長期計画には苦戦します。時間的に拡張された推論能力をエージェントに与えるためには、どのようにして世界モデルを学習すればよいのだろうか？本研究では、疎な多段階の遷移で構成されるグラフ構造の世界モデルを学習することを提案する。我々は、ゴール空間に散在する（到達可能性の観点から）潜在的なランドマークを、グラフ上のノードとして学習する新しいアルゴリズムを考案した。この同じグラフにおいて、エッジはQ関数から抽出された到達可能性の推定値である。ロボット操作からナビゲーションまで、さまざまな高次元連続制御タスクにおいて、L3Pと名付けられた我々の手法は、先行研究を大幅に凌駕し、モデルフリーRLのロバスト性とグラフ探索アルゴリズムの一般化の両方を活用できる唯一の手法であることが多いことを実証した。今回の研究は、強化学習におけるスケーラブルなプランニングに向けた重要な一歩であると考えています。
最近、純粋に注意力に基づいたニューラルネットワークが、画像分類などの画像理解タスクに対応することが示された。しかし、これらの視覚変換器は、高価なインフラを使用して何億もの画像で事前に学習されているため、その採用は制限されています。本研究では、Imagenetのみで学習することにより、競争力のある畳み込みなしの変換器を作成します。また、1台のコンピュータで3日以内に学習させることができます。我々の参照ビジョン変換器（86Mパラメータ）は、外部データなしでImageNet上で83.1%のトップ-1精度（シングルクロップ評価）を達成しました。さらに重要なのは、変換器に特化した教師-生徒間の戦略を導入することです。これは、生徒が注意によって教師から学ぶことを保証する蒸留トークンに依存しています。このトークンベースの蒸留の面白さを、特にConvnetを教師として使用した場合に示します。これにより、Imagenet（最大85.2%の精度を得た）と他のタスクに移行した場合の両方で、コンボネットに負けない結果を報告することができる。我々はコードとモデルを共有しています。
自然言語テキストの意味は、共参照関係、述語-引数構造、ブリッジングアナフォア関係など、様々な種類のエンティティ間の結束によって支えられています。しかし、名詞述語の述語-引数構造やブリッジングアナフォラ関係はあまり研究されておらず、その解析は非常に困難でした。近年のニューラルネットワーク、特にBERT（Devlin et al.2019）を含む自己学習ベースの言語モデルの進歩により、多くの自然言語処理タスクが大幅に改善され、テキスト全体の結束力の分析に関する研究に飛び込むことが可能になった。本研究では、日本語テキストにおけるまとまりの統合的な分析に取り組みました。その結果、各タスクにおいて既存の研究を大幅に上回り、特にアナフォラのゼロ化と共参照の解決では10～20ポイント程度の改善が見られた。さらに、共参照の解決は他のタスクとは性質が異なるため、特別に扱うべきであることを示しました。
強化学習は、エージェントが未知の環境で困難な課題を解決することを可能にします。しかし、報酬関数を手動で作成することは、時間とコストがかかり、人為的なエラーが発生しやすい。エージェントが外部からの監視を受けずに学習するために、競争的な目標が提案されてきたが、それらがタスクの報酬や人間の行動をどの程度反映しているかは不明であった。本質的な目的の開発を促進するために、我々は、オンラインで最適化するのではなく、事前に収集したエージェントの行動のデータセットに対して、潜在的な目的をレトロスペクティブに計算し、その相関関係を分析することで比較する。本研究では、7つのエージェント、3つのAtariゲーム、3Dゲーム「Minecraft」を対象に、入力エントロピー、情報利得、エンパワーメントを研究した。その結果、3つの本質的な目的は、タスク報酬よりも人間の行動の類似性の指標との相関が強いことがわかった。さらに、入力エントロピーと情報利得は、タスク報酬よりも人間の類似性と強く相関しており、人間のプレイヤーと似たような行動をするエージェントを設計するために、本質的な目的を使用することが示唆された。
中国ではここ数十年で急速に都市化が進んでおり，特に新世紀に入ってからは，住宅問題が最も重要な課題の一つとなっている．住宅空室率（HVR）の推定と分析は、このパズルを解決するための意思決定に役立ちます。特に政府部門にとっては重要な意味を持つ。本論文では、NPP-VIIRSの夜間光合成データ、地理的国家条件監視データ（GNCMD）、居住者人口分布データを用いて、青島市のHVRを推定する実用的なモデルを提案した。主な手順は以下の通りです。第一に、データを前処理し、最終的に500*500グリッドを基本単位とする一連のデータセットを形成する。第二に、SVM学習用のサンプルグリッドとして市内の異なるタイプの400グリッドを選択し、合理的なHVRモデルを確立する。第三に、モデルを用いて青島市のHVRを推定し、空間統計分析法を用いて同市におけるHVRの空間的差異パターンを明らかにする。その結果、青島市南東部沿岸地域のHVRは相対的に低く、低低のクラスターがパッチ状に分布していると結論づけられた。同時に、他の地域では、都心部に低値が集積し、郊外に向かって増加する傾向を示しています。一方、海や山に面した郊外や景観の良い地域は、都市の中で最も空いている部分であると考えられる。
本論文では、多言語の生の音声波形から単一のモデルを事前学習することで、多言語の音声表現を学習するXLSRを紹介する。このモデルは、マスクされた潜在的な音声表現に対する対比課題を解くことで学習され、言語間で共有される潜在的な部分の量子化を共同で学習するwav2vec 2.0をベースにしている。結果として得られたモデルは、ラベル付きデータ上で微調整され、実験では、言語間の事前学習が単言語の事前学習を大幅に上回ることが示されました。CommonVoiceベンチマークにおいて、XLSRは既知の結果と比較して、相対的な音素エラーレートを72%削減しました。BABELでは、XLSRは同等のシステムと比較して、単語誤り率を16%改善しました。我々のアプローチは、強力な個別モデルに負けない単一の多言語音声認識モデルを可能にする。分析の結果、潜在的な離散音声表現は言語間で共有されており、関連する言語では共有率が高まることがわかった。私たちは、53の言語で事前学習された大規模なモデルであるXLSR-53をリリースすることで、低リソースの音声理解の研究を活性化したいと考えています。
逐次データの長距離相互作用を学習するために設計されたトランスフォーマは、さまざまなタスクで最先端の結果を示し続けています。CNNとは対照的に、トランスフォーマーには局所的な相互作用を優先する帰納的なバイアスがありません。これにより、表現力が豊かになる一方で、高解像度画像のような長いシーケンスでは計算が不可能になる。本研究では、CNNの帰納的バイアスの有効性と変換器の表現力を組み合わせることで、高解像度画像をモデル化し、合成することができることを示す。我々は、(i)CNNを使って画像構成要素の豊富な語彙を学習し、(ii)トランスフォーマを使って高解像度画像内の構成要素を効率的にモデル化する方法を示す。我々のアプローチは、オブジェクトクラスのような非空間的な情報と、セグメンテーションのような空間的な情報の両方が、生成された画像を制御することができる条件付き合成タスクに容易に適用できる。特に、変換器を用いたメガピクセル画像の意味的に誘導された合成に関する最初の結果を提示し、クラス条件付きのImageNetにおける自己回帰モデルの間の技術的な状態を取得します。コードとプレトレーニングされたモデルは、このhttpsのURLにあります。
学習済みのネットワークをタスクに応じて微調整することは、NLPにおいて経験的に大きな進歩をもたらしましたが、ネットワークのサイズが大きいため、マルチタスクでメモリに制約のある環境では微調整を行うことが困難です。本研究では、事前学習-微調整の枠組みの中で、パラメータ効率の良い伝達学習を可能にするシンプルなアプローチとして、diff pruningを提案する。このアプローチでは、事前学習されたパラメータベクトルの上に適用されるタスク固有の差分ベクトルを学習することで、微調整を行います。diffベクトルは、L0ノルムペナルティの微分可能な近似を用いて、学習中に適応的に刈り込まれ、スパース性を促進する。Diff プルーニングは、タスクの数が増えるとパラメータ効率が良くなります。これは、各タスクの diff ベクトルのゼロではない位置と重みのみを保存する必要があり、共有された事前学習モデルを保存するコストは一定だからです。さらに、学習中にすべてのタスクにアクセスする必要がないため、タスクが次々と到着する場合や、タスクのセットが不明な場合にも魅力的です。diffプルーニングによって微調整されたモデルは、タスクごとに事前学習されたモデルのパラメータを0.5%変更するだけで、GLUEベンチマークにおいて完全に微調整されたベースラインと同等の性能を発揮することがわかりました。
また、Supermasks in Superposition（SupSup）モデルは、壊滅的な忘却なしに数千のタスクを連続的に学習することができる。我々のアプローチは、ランダムに初期化された固定のベースネットワークを使用し、各タスクに対して、良好な性能を達成するサブネットワーク（スーパーマスク）を見つける。タスクの識別情報がテスト時に与えられていれば、正しいサブネットワークを最小のメモリ使用量で検索することができる。与えられていない場合、SupSupは勾配ベースの最適化を用いてタスクを推定し、出力エントロピーを最小にする学習済みスーパーマスクの線形重ね合わせを見つけます。実際には、2500個のタスクの中でも、1回の勾配ステップで正しいマスクを特定できることが多いことがわかった。また、2つの有望な拡張機能を紹介する。まず、SupSupモデルは、タスクの識別情報がなくても完全に学習することができる。これは、新しいデータが不確実であることを検出し、新しい学習分布のために追加のスーパーマスクを割り当てることができるからである。最後に、スーパーマスクの成長するセット全体を、固定サイズのホップフィールドネットワークのアトラクタとして暗黙的に保存することで、一定サイズのリザーバに保存することができる。
我々は、物体検出を直接的なセット予測問題として捉える新しい手法を提案します。本手法は、検出パイプラインを合理化し、非最大値抑制手順やアンカー生成など、タスクに関する事前知識を明示的に符号化する多くの手作業によるコンポーネントを効果的に取り除く。DEtection TRansformer（DETR）」と呼ばれる新しいフレームワークの主な構成要素は、二者択一のマッチングによってユニークな予測を強制するセットベースのグローバルロスと、トランスフォーマ・エンコーダ・デコーダ・アーキテクチャです。DETRは、学習されたオブジェクトクエリの固定された小さなセットが与えられると、オブジェクトの関係とグローバルな画像コンテキストを推論して、最終的な予測のセットを並列に直接出力します。この新しいモデルは、他の多くの最新検出器とは異なり、概念的にシンプルで、専用のライブラリを必要としません。DETRは、難易度の高いCOCOオブジェクト検出データセットにおいて、定評のある高度に最適化されたFaster RCNNベースラインと同等の精度とランタイム性能を示した。さらに、DETRは統一された方法でパンオプティック・セグメンテーションを生成するために容易に一般化することができます。DETRは、競合するベースラインを大幅に凌駕することを示しています。トレーニングコードとプレトレーニングモデルはこちらのhttpsのURLから入手可能です。
中国では人口の増加に伴い、作物栽培地（CA）保護の重要性が高まっています。正確で最新のCAマップを取得するための強力なツールとして、高空間分解能のリモートセンシング（RS）画像から抽出した情報を用いた自動マッピングがある。RS画像の情報抽出には、特徴の分類が含まれており、これはRSコミュニティにおける長年の研究課題である。深層セマンティック・セグメンテーション・ネットワーク技術などの新しい深層学習技術は、関連する文脈上の特徴を自動的に発見し、より良い画像分類結果を得るための効果的な手法です。本研究では、深層セマンティック・セグメンテーション・ネットワークを利用して、高解像度のRS画像からCAを分類・抽出しました。赤-緑-青（RGB）バンドのみのWorldView-2（WV-2）画像を用いて、情報抽出とCAマッピングタスクに対する提案されたセマンティック分類フレームワークの有効性を確認した。具体的には、深層学習フレームワークのTensorFlowを用いて、DeepLabv3+をベースにCAの抽出とマッピングを行うためのサンプリング、トレーニング、テスト、分類のプラットフォームを構築した。画素単位の精度評価法とランダムサンプルポイントの精度評価法を活用することで、提案手法は調査対象地域のCA分類の許容精度（総合精度＝95％、Kappa＝0.90）を効率的に得ることができ、他の深層セマンティックセグメンテーションネットワーク（U-Net/PspNet/SegNet/DeepLabv2）や、最尤（ML）、サポートベクターマシン（SVM）、RF（Random Forest）などの従来の機械学習手法よりも優れた性能を発揮すると結論づけた。さらに、提案されたアプローチは、作物エリア内の様々な種類の作物に対応できる高い拡張性を備えています。全体として、提案されたアプローチは、零細農家の小規模で不規則な畑を適切に記述し、RGB高空間分解能画像の非常に高いレベルの詳細を扱うことができる、精密で効果的なモデルを訓練することができる。
SFの世界では、ロボットがいつの日か私たちの物理的な空間に生息し、私たちと同じように世界を感じ取り、私たちの肉体労働を助け、自然言語で私たちとコミュニケーションをとるようになるというビジョンが一般的です。ここでは、仮想環境を用いて人間と自然に対話できる人工的なエージェントを設計する方法を研究しています。この環境では、複雑な視覚認識と目標指向の身体制御、根拠のある言語の理解と生成、マルチエージェントによる社会的相互作用など、人工知能（AI）研究の中心的な課題が統合されています。人間と協調して行動できるエージェントを作るには、人間と協調しながら訓練するのが理想的です。しかし、これは現状では現実的ではありません。そこで、人間の役割を別の学習したエージェントで近似させ、逆強化学習のアイデアを用いて、人間と人間、エージェントとエージェントの対話行動の間の格差を減らすことにしました。我々のエージェントを厳密に評価することは非常に困難であるため、エージェントのビデオを見た人間による評価や、エージェントと直接対話することによる評価など、様々な行動テストを開発しました。これらの評価は、対話的なトレーニングと補助的な損失が、行動の教師付き学習だけで達成される以上にエージェントの行動を改善することを説得的に示している。さらに、エージェントの能力は、データセットに含まれる文字通りの経験を超えて一般化することを実証した。最後に、エージェントに対する評価が人間の判断とよく一致する評価モデルを育成し、新たなエージェントモデルを追加の努力なしに評価できるようにした。この仮想環境における我々の結果は、大規模な人間の行動の模倣が、知的で対話的なエージェントを作成するための有望なツールであり、そのようなエージェントを確実に評価するという課題を克服することが可能であることを示している。
ドメイン横断型の名前付き実体認識（NER）モデルは、対象ドメインにおけるNERサンプルの希少性の問題に対処することができる。しかし、既存のNERベンチマークの多くは、ドメインに特化したエンティティタイプを欠いていたり、特定のドメインに焦点を当てていなかったりするため、クロスドメイン評価の効果が低くなってしまう。これらの障害を解決するために、我々はクロスドメインNERデータセット（CrossNER）を導入する。これは、5つの多様なドメインにまたがる完全にラベル付けされたNERデータのコレクションであり、異なるドメインに特化したエンティティカテゴリを持つ。さらに、言語モデルの事前学習（ドメイン適応型事前学習）を継続するために、ドメインに関連するコーパスを使用することは、ドメイン適応に効果的であるため、ドメインに関連するコーパスも提供します。そして、異なるレベルのドメインコーパスと事前学習戦略を活用して、クロスドメインタスクのドメイン適応型事前学習を行うことの有効性を探るために、包括的な実験を行った。その結果、ドメインに特化したエンティティを含む小数のコーパスに着目し、ドメイン適応型事前学習ではより困難な事前学習戦略を利用することが、NERのドメイン適応に有益であり、我々の提案する手法は既存のクロスドメインNERのベースラインを一貫して上回ることができた。それにもかかわらず、実験はこのクロスドメインNERタスクの難しさを示している。我々のデータセットとベースラインが、NERドメイン適応分野の研究を促進することを期待している。コードとデータはこのhttpsのURLから入手できます。
スプリアスな特徴の存在は、母集団内の多くのグループで良好な性能を発揮するロバストなモデルを得るという目標を妨げる。自然な解決策は、モデルからスプリアスな特徴を取り除くことである。しかし、本研究では、スプリアスな特徴を除去すると、オーバーパラメータ化されたモデルの帰納的バイアスのために、精度が低下することを示している。本研究では，ノイズレスなオーバーパラメータ化線形回帰において，スプリアス特徴の除去が異なるグループ（より一般的にはテスト分布）の精度にどのように影響するかを完全に特徴付ける．さらに、スプリアス特徴の除去は、バランスの取れたデータセット（各ターゲットが各スプリアス特徴と同じように共起する）においても精度を低下させる可能性があり、また、モデルが他のスプリアス特徴の影響を不用意に受けやすくなる可能性があることを示す。最後に，ロバストな自己訓練によって，全体の精度に影響を与えることなくスプリアス特徴を除去できることを示す．Toxic-Comment-DetectoinデータセットおよびCelebAデータセットを用いた実験により、我々の結果が非線形モデルにおいても有効であることが示された。
現在の深層学習の成功の大部分は、データの有効性、より正確にはラベル付けされたデータの有効性にあります。しかし、データセットに人間のアノテーション（注釈）を付けることは、特に動画の場合、高いコストがかかります。画像領域では、最近の手法により、ラベル付けされていないデータセットに意味のある（擬似）ラベルを監督なしで生成することができるようになったが、特徴表現の学習が現在の焦点となっている動画領域では、このような開発は行われていない。本研究では、a) 強力な特徴エンコーダーがあれば、教師なしでビデオデータセットのラベル付けができるわけではないことを示し、b) 音声モダリティと視覚モダリティの間の自然な対応関係を利用して、人間によるアノテーションなしでビデオデータセットの疑似ラベル付けを可能にする新しいクラスタリング手法を提案する。広範な分析により、結果として得られたクラスタは、グランドトゥルースの人間のラベルと高いセマンティックオーバーラップを持つことが示された。さらに、一般的なビデオデータセットであるKinetics、Kinetics-Sound、VGG-Sound、AVEの教師なしラベル付けに関する最初のベンチマーク結果を紹介します。
シャムネットワークは、最近の教師なし視覚表現学習の様々なモデルで共通の構造となっている。これらのモデルは、崩壊解を避けるための一定の条件の下で、1つの画像の2つの拡張子の間の類似性を最大化する。本論文では、単純なシャムネットワークが、以下のいずれの条件を用いても意味のある表現を学習できるという驚くべき実証結果を報告する。(i)負のサンプルペア、(ii)大きなバッチ、(iii)モメンタムエンコーダー。我々の実験では、損失と構造について崩壊する解が存在するが、停止勾配操作が崩壊を防ぐのに不可欠な役割を果たしていることを示している。我々はstop-gradientの意味についての仮説を提示し、さらにそれを検証する概念実証実験を示す。私たちの「SimSiam」手法は、ImageNetや下流のタスクで競争力のある結果を達成しました。このシンプルなベースラインが、教師なし表現学習におけるシャムアーキテクチャの役割を再考する動機となることを期待しています。コードは公開される予定です。
忠実度の高い画像を対象としたGAN（Generative Adversarial Networks）の学習には、通常、大規模なGPUクラスターと膨大な数の学習画像が必要です。本論文では、最小限の計算コストでGANのための数ショットの画像合成タスクを研究します。我々は、1024^2の解像度で優れた品質を得る軽量のGAN構造を提案する。特筆すべきは、RTX-2080 GPU1台で数時間の学習を行うだけでモデルがゼロから収束し、100以下の学習サンプルでも一貫した性能を発揮することです。本研究では、スキップレイヤーのチャンネルごとの励起モジュールと、特徴エンコーダーとして学習された自己教師付き識別器という2つの手法を採用しています。様々な画像領域をカバーする13のデータセット（データセットとコードはhttps://github.com/odegeasslbc/FastGAN-pytorch）を用いて、データと計算予算が限られている場合に、我々のモデルが最先端のStyleGAN2と比較して優れた性能を発揮することを示した。
強化学習（RL）の問題には、ロバスト性、伝達学習、教師なしRL、創発的複雑性など、さまざまなものがありますが、これらの問題では、ポリシーを学習するタスクや環境の分布を指定する必要があります。しかし、有用な環境の分布を作成するには、エラーが発生しやすく、開発者の時間と労力が大幅にかかります。そこで、開発者が未知のパラメータを持つ環境を提供し、そのパラメータを用いて、有効で解決可能な環境の分布を自動的に生成する、Unsupervised Environment Design (UED)を提案する。環境を自動的に生成する既存のアプローチは、共通の失敗モードに悩まされている。ドメインランダム化では、構造を生成することができず、環境の難易度をエージェントの学習進捗に合わせることもできない。主人公のエージェントのために構造化された解決可能な環境を生成するために、環境を生成する敵対者と同盟を組む第二の敵対者エージェントを導入します。敵対エージェントは、主人公エージェントと敵対エージェントのリターンの差として定義される後悔を最大化する環境を生成するように動機づけられる。この手法をPAIRED（Protagonist Antagonist Induced Regret Environment Design）と呼んでいる。我々の実験によると、PAIREDは複雑化する環境の自然なカリキュラムを作成し、PAIREDエージェントは新規性の高い環境でテストされたときに、より高いゼロショット転送性能を達成する。
物質を組み合わせて新しい価値を生み出すことは、私たちの社会にとって重要な活動です。日々の料理から工業製品の製造まで、手順書にはその方法が書かれており、読者はその手順を再現することができます。自然言語理解に関するいくつかの先行研究で指摘されているように、手続きテキストの重要な特性の1つは、材料の結合操作である文脈依存性であり、これはグラフや木構造で表現できる。本論文では、このような構造を明示的に導入することが、画像シーケンスから手続き型テキストを生成するという視覚と言語のタスクに与える影響を調べることを目的とする。この目的のために，(1)木構造結合木の定義を視覚・言語版に拡張した新しいデータセットと，(2)文脈依存性を効率的に学習する新しい構造考慮型手続きテキスト生成モデルを提案する．実験結果は、提案手法が従来の汎用的な手法の性能を向上させることを示している。
深層ニューラルネットワークにおけるオーバーフィッティングを緩和するための新しい正則化手法を提案する。これは、ランダムに変換された学習サンプルを利用して、元のネットワークの幅をサンプリングして生成されたサブネットワークのセットを学習プロセスで正則化するというものである。提案手法は、ネットワークの生の勾配に自己誘導型の外乱を導入するため、Gradient Augmentation (GradAug)と呼ばれています。我々は、GradAugが、ネットワークが十分に一般化された、より多様な表現を学習するのに役立つことを実証する。さらに、GradAugは実装が簡単で、様々な構造やアプリケーションに適用することができる。GradAugは、ImageNetの分類において、ResNet-50を78.79%まで向上させ、これは新しい最先端の精度となります。CutMixと組み合わせることで、さらに79.67%まで向上させ、高度な学習トリックのアンサンブルを凌駕しています。汎化能力は、COCOオブジェクト検出とインスタンスセグメンテーションで評価され、GradAugは他の最先端の手法を大きく上回っています。また、GradAugは画像の歪みやFGSM攻撃にも強く、低データ領域でも高い効果を発揮する。コードはこちらのhttpsのURLから入手できます。
近年、機械学習は、学術的な研究分野としても、現実のビジネス問題の解決策としても、関心が高まっています。しかし、機械学習モデルを実運用システムに導入する際には、様々な問題や懸念があります。本調査では、様々なユースケース、産業、アプリケーションにおける機械学習ソリューションの展開について、公表されているレポートをレビューし、機械学習の展開ワークフローの段階に対応する実用的な検討事項を抽出しました。今回の調査では、実践者が展開の各段階で課題に直面していることがわかった。この論文の目的は、これらの課題に対処するアプローチを探るための研究アジェンダをレイアウトすることです。
DQNが登場して以来、強化学習研究の大部分は、関数近似器としての深層ニューラルネットワークを用いた強化学習に焦点を当ててきた。新しい手法の評価には、Atari 2600のゲームなど、今やスタンダードとなった環境が用いられます。このようなベンチマークは評価の標準化に役立つ一方で、計算コストがかかるため、計算資源に余裕のある人とそうでない人の間の格差を広げるという残念な副作用があります。本研究では、大規模な環境が重視されているにもかかわらず、従来の小規模な環境でも科学的に貴重な知見を得ることができ、恵まれないコミュニティの参入障壁を下げることができると主張します。我々の主張を立証するために、Rainbowアルゴリズムを紹介した論文[Hessel et al., 2018]を実証的に再検討し、Rainbowが使用するアルゴリズムに関する新しい洞察を提示します。
大規模な事前トレーニングとタスク固有の微調整は、現在、コンピュータビジョンや自然言語処理の多くのタスクで標準的な方法論となっています。最近では、AIのこれら2つの重要な分野の交差点にある課題に取り組むために、視覚と言語のBERTを事前訓練するための多数の方法が提案されています。これらのモデルは、シングルストリーム・エンコーダとデュアルストリーム・エンコーダのいずれかに分類されます。本研究では、これらの2つのカテゴリーの違いを研究し、どのようにしてこれらを1つの理論的枠組みに統合できるかを示します。次に、5つのV&L BERTsの経験上の違いを識別するために対照実験を行いました。この実験により、報告されている結果の違いのほとんどは、学習データとハイパーパラメータが原因であることが示されましたが、これらの大規模モデルでは埋め込み層が重要な役割を果たしていることも明らかになりました。
wav2vec 2.0は、潜在空間内の音声入力をマスクし、共同で学習された潜在表現の量子化に基づいて定義されたコントラストタスクを解決します。Librispeechのすべてのラベル付きデータを使用した実験では、クリーン/その他のテストセットで1.8/3.3のWERを達成した。ラベル付きデータの量を1時間に減らした場合、wav2vec 2.0は100時間のサブセットにおいて、100倍少ないラベル付きデータを使用しながら、従来の技術を上回っています。また、わずか10分のラベル付きデータと53k時間の非ラベル付きデータを用いた事前学習でも、4.8/8.2のWERを達成しています。この結果は、限られた量のラベル付きデータでも音声認識が可能であることを示しています。
Universal Dependenciesは、依存関係に基づく語彙主義の枠組みの中で、多くの言語に対して言語間で一貫性のあるツリーバンク注釈を作成するための、オープンコミュニティの取り組みです。このアノテーションは、言語的に動機づけられた単語のセグメンテーション、リーマ、ユニバーサル品詞タグ、標準化された形態素からなる形態素層、および述語、引数、修飾語の間の構文関係に焦点を当てた構文層から構成されている。本稿では、ガイドラインのバージョン2（UD v2）について、UD v1からUD v2への主な変更点を説明し、現在利用可能な90言語のツリーバンクの概要を紹介する。
リモートセンシングの重要性を考えると、表現学習のコミュニティでは驚くほどほとんど注目されていない。この問題に対処し、この分野におけるベースラインと共通の評価プロトコルを確立するために、我々は5つの多様なリモートセンシングデータセットを標準化された形で簡単に利用できるようにした。具体的には、一般的なリモートセンシング表現を開発するためのドメイン内表現学習を調査し、リモートセンシング表現学習に適したデータセットにはどのような特性が重要であるかを探る。確立されたベースラインは、これらのデータセットで最先端の性能を達成している。
ワンショット半教師付き学習の最近の進歩は、新しいアプリケーションの深層学習の障壁を下げました。しかし、最先端の半教師付き学習は、学習に時間がかかり、性能はラベル付きデータやハイパーパラメータ値の選択に敏感である。本論文では、ワンショット半教師付き学習法を紹介します。この方法は、最先端の方法よりも最大で1桁速く学習し、より頑健です。具体的には、半教師付き学習と自己学習の1段階、単一ネットワーク版を組み合わせることで、FROST手法はより高速に学習し、ラベル付きサンプルの選択やハイパーパラメータの変更に対してより頑健であることを示します。また、ラベルなしデータの構成が不明な場合、つまりラベルなしデータに各クラスの数が不均等に含まれている場合や、どの学習クラスにも属さない分布外の例が含まれている場合にも、FROSTが優れた性能を発揮することを実験で実証しています。FROSTは、高性能で学習速度が速く、ハイパーパラメータの影響を受けにくいため、ワンショットの半教師付き学習に最も適した手法です。我々のコードはこちらのhttpsのURLから入手可能です。
階層化されたVAEは、全ての自然画像ベンチマークにおいて、対数尤度でPixelCNNを上回りながら、サンプルを高速に生成することに初めて成功しました。まず、理論的には、VAEは自己回帰モデルを表現することができ、また、より高速で優れたモデルが存在する場合には、それを十分に深くすることができます。これにもかかわらず、自己回帰モデルは歴史的に対数尤度でVAEを上回ってきました。我々は、VAEを従来よりも大きな確率的深さにスケーリングし、CIFAR-10、ImageNet、およびFFHQで評価することで、深さが不十分であることがその理由を説明できるかどうかを検証します。PixelCNNと比較して、これらの非常に深いVAEは、より高い尤度を達成し、より少ないパラメータを使用し、数千倍の速さでサンプルを生成し、高解像度の画像に適用することができる。これは、VAEが効率的な階層的視覚表現を学習しているためであると定性的に考えられています。ソースコードとモデルはこちらのhttpsのURLで公開しています。
言語のニューラルジェネレーティブモデルでは、見たことのないシーケンスの長さに外挿することが課題となっています。本研究では、しばしば見落とされがちなモデリング上の決定、すなわち、特別なEOS（End-of-Sequence）語彙項目を用いて生成プロセスの終了を予測することが、長さの外挿に与える影響を特徴付ける。我々は、テスト時に正しい長さのシーケンスを生成するようにモデルを強制するというオラクル設定を研究し、EOSを予測するように訓練されたネットワーク(+EOS)と訓練されていないネットワーク(-EOS)の長さ外挿性を比較した。その結果、-EOSは+EOSを大幅に上回り、例えば、ブラケットクロージングタスクではトレーニング時の10倍の長さまで外挿することができ、また、難易度の高いSCANデータセットの長さ一般化タスクでは+EOSを40%上回ることができました。EOSモデルと+EOSモデルの隠れた状態とダイナミクスを比較することで、+EOSモデルが一般化に失敗する理由は、(1)隠れた状態を不必要に配列の直線的な位置で階層化している（長さ多様体と呼ぶ構造）、(2)EOSトークンが最も高い確率で予測されると、クラスタ（長さアトラクタと呼ぶ）にはまり込んでしまう、などであることがわかった。
文章の埋め込みは、知識を下流のタスクに移すことができるため、自然言語処理（NLP）における重要な研究テーマである。一方、BERTと呼ばれる文脈に基づいた単語表現は、かなりの数のNLPタスクにおいて最先端の性能を達成しています。しかし、BERTに基づく単語モデルから高品質の文表現を生成することは、未解決の問題です。以前の研究では、BERTの異なる層が異なる言語特性を捉えることが示されました。これにより、より良い文表現を見つけるために、層間で情報を融合することができる。本研究では、深層文脈モデルの単語表現の層ごとのパターンを研究する。そして、単語表現が占める空間の幾何学的分析を通じて、BERTベースの単語モデルを分解することで、新しい文の埋め込み方法を提案します。これは「SBERT-WK法」と呼ばれています。SBERT-WKでは、さらなる学習は必要ありません。我々は、意味的なテキストの類似性と下流の教師付きタスクで SBERT-WK を評価する。さらに、詳細な言語分析のために、10の文レベルのプロービング課題が提示されている。実験では、SBERT-WKが最先端の性能を達成していることが示されている。本コードは公開されています。
SLAM（Simultaneous Localization and Mapping）システムに表現学習アプローチを融合させることは、SLAMが高度にモジュール化された複雑な性質を持つことから、未解決の問題である。SLAMは、生のセンサー入力を、ロボットと環境の状態に関する分布に変換する操作です。もし、この変換（SLAM）が微分可能な関数として表現できるならば、タスクベースのエラー信号を利用して、タスクパフォーマンスを最適化する表現を学習することができる。しかし、典型的な高密度SLAMシステムのいくつかのコンポーネントは、微分不可能である。本研究では、SLAMシステムを微分可能な計算グラフとして提起し、勾配ベースの学習とSLAMを統合する方法論であるgradSLAMを提案する。微分可能な信頼領域オプティマイザ、表面測定と融合スキーム、レイキャスティングを、精度を犠牲にすることなく提案する。密なSLAMと計算グラフの融合により、3Dマップから2Dピクセルへのバックプロップが可能となり、SLAMのための勾配ベースの学習に新たな可能性をもたらします。TL;DR: 自動微分フレームワークの力を利用して、密なSLAMを微分可能にします。
我々は、敵対的模倣における重大な脆弱性は、識別器ネットワークが視覚的特徴と専門家のラベルとの間の偽の関連性を学習する傾向にあることを示す。識別器がタスクに無関係な特徴に焦点を当てると、有益な報酬信号が得られず、タスクパフォーマンスの低下につながる。我々は、この問題を詳細に分析し、標準的なGenerative Adversarial Imitation Learning (GAIL)を凌駕する解決策を提案する。提案手法であるTRAIL（Task-Relevant Adversarial Imitation Learning）は、制約付き識別器最適化を用いて、情報量の多い報酬を学習する。また、行動クローンや従来のGAILを含むベースライン模倣エージェントよりも明らかに優れた性能を示した。
大規模なオーディオビジュアルの翻訳とダビングのためのシステムについて説明します。ソース言語の音声内容は、テキストに転写され、翻訳され、元の話者の声を使ってターゲット言語の音声に自動合成される。また、映像コンテンツは、翻訳された音声に合わせて話者の唇の動きを合成して翻訳され、ターゲット言語でのシームレスな視聴体験を実現します。音声翻訳と映像翻訳のサブシステムには、それぞれの領域で何千時間ものデータをもとに学習された大規模な汎用合成モデルが搭載されています。これらの汎用モデルは、翻訳前に特定の話者に合わせて微調整されます。この微調整には、対象となる話者のデータを集めた補助的なコーパスを使用するか、翻訳対象のビデオ自体を微調整プロセスの入力として使用します。本レポートでは、システム全体のアーキテクチャの概要と、ビデオダビングコンポーネントの詳細について説明します。システム全体に関連するオーディオコンポーネントとテキストコンポーネントの役割については概説しますが、その設計については詳細には触れません。このシステムを使って作成された翻訳およびダビングされたデモビデオは、この https URL で見ることができます。
英語のコミュニティ質問応答フォーラムからの140のソースドメインで自己教師付きトレーニングを行うことにより、テキストマッチングモデルのゼロショット転送能力を大規模に研究しています。その結果、140個のモデルすべてが驚くほどよく転送され、大多数のモデルが一般的なIRベースラインを大幅に上回ることがわかった。また、最高のゼロショット転送性能を得るためには、ソースドメインの幅広い選択を考慮することが重要であることを示し、最大かつ最も類似したドメインに依存するだけの標準的な手順とは対照的である。さらに、複数のソースドメインを最適に組み合わせる方法についても幅広く研究しています。我々は、利用可能なすべてのソース・ドメインに対して、自己教師付き、教師付きマルチタスク学習を組み込むことを提案する。我々の最良のゼロショット転送モデルは、6つのベンチマークにおいて、インドメインBERTおよび従来の技術を大幅に上回りました。インドメインデータを用いてモデルを微調整することで、さらに大きな利益が得られ、9つのベンチマークすべてで新しい技術水準を達成しました。
我々は、診断フィードバック（例：コンパイラのエラーメッセージ）からプログラムを修復することを学習する問題を考えます。プログラムの修復には2つの理由があります。第一に、ソースコードと診断フィードバックの間でシンボルを推論し、追跡することが必要である。第二に、プログラム修復に利用できるラベル付きデータセットは比較的少ない。本研究では、これら2つの課題に対する新しい解決策を提案する。第一に、ソースコードと診断フィードバックに含まれるプログラム修復に関連するシンボルを結びつけるプログラムフィードバックグラフを導入し、その上にグラフニューラルネットワークを適用して推論プロセスをモデル化する。次に、プログラム修復のための自己教師付き学習パラダイムを提示する。これは、オンラインで入手可能なラベルのないプログラムを活用して、大量のプログラム修復例を作成し、モデルの事前学習に使用するものである。我々の提案するアプローチを、プログラミング入門の課題の修正（DeepFixデータセット）と、プログラム合成の出力の修正（SPoCデータセット）という2つのアプリケーションで評価する。最終的なシステムであるDrRepairは、DeepFixで68.2%の完全修復率（過去のベストと比較して22.9%増）、SPoCで48.4%の合成成功率（過去のベストと比較して3.7%増）を達成し、先行研究を大幅に上回る結果となった。
トランスフォーマーは、自己注意の二次的な複雑さが原因で、長い配列にはあまり対応できません。ここ数ヶ月の間に、この問題に対処するために、効率的で高速なTransformerが幅広く提案されており、多くの場合、vanilla Transformerモデルよりも優れた、または同等のモデル品質を主張しています。今日まで、このクラスのモデルをどのように評価するかについて、確立されたコンセンサスはありません。さらに、様々なタスクやデータセットで一貫性のないベンチマークが行われているため、多くのモデルの中から相対的なモデル品質を評価することが困難になっています。本論文では、長文シナリオ下でのモデルの品質評価に特化した、体系的で統一されたベンチマーク「LRA」を提案します。本ベンチマークは、1Kから16Kのトークンを含む一連のタスクであり、テキスト、自然画像、合成画像、類似性、構造、視覚的・空間的推論を必要とする数学的表現など、幅広いデータタイプとモダリティを網羅している。我々は、新たに提案したベンチマーク群において、10種類の確立された長距離トランスフォーマーモデル（Reformers、Linformers、Linear Transformers、Sinkhorn Transformers、Performers、Synthesizer、Sparse Transformers、Longformers）を系統的に評価した。LRAは、このクラスの効率的なトランスフォーマーモデルをよりよく理解するための道を開き、この方向での研究を促進し、取り組むべき新たな課題を提示しています。ベンチマークコードは、このhttpsのURLで公開されます。
自然な画像の理解を助けるために、自然な画像なしで事前に訓練された畳み込みニューラルネットワークを使用することは可能でしょうか？この論文では、数式駆動型の教師付き学習という新しいコンセプトを提案しています。実世界の背景知識に存在する自然法則に基づいたフラクタルを割り当てることで、画像パターンとそのカテゴリラベルを自動的に生成します。理論的には、事前学習に自然の画像ではなく自動生成された画像を用いることで、ラベル付き画像の無限規模のデータセットを生成することができます。自然画像を含まないデータベースであるFractal DataBase (FractalDB)を用いて事前学習したモデルは、すべての設定において人間がアノテーションしたデータセットを用いて事前学習したモデルを必ずしも上回るわけではないが、ImageNet/Placesを用いて事前学習したモデルの精度を部分的に上回ることができた。提案するFractalDBを用いた画像表現は、畳み込み層の可視化と注目点というユニークな特徴を捉えています。
MLモデルは、実世界のドメインに展開すると、予想外の悪い挙動を示すことが多い。私たちは、これらの失敗の主な理由として、アンダースペックを挙げています。MLパイプラインは、学習領域において同等の強力なホールドアウト性能を持つ多くの予測子を返すことができる場合、アンダースペックとなります。Underspecificationは、深層学習をベースにしたものなど、最新のMLパイプラインでは一般的です。アンダースペックのパイプラインによって返された予測子は、トレーニングドメインのパフォーマンスに基づいて同等のものとして扱われることが多いですが、ここではそのような予測子がデプロイメントドメインでは非常に異なった振る舞いをする可能性があることを示しています。この曖昧さは、実際には不安定さやモデルの挙動不良につながる可能性があり、以前に確認されたトレーニングドメインとデプロイメントドメインの構造的不一致から生じる問題とは異なる故障モードです。この問題は、コンピュータビジョン、医療用画像、自然言語処理、電子カルテに基づく臨床リスク予測、医療ゲノミクスなどの例を用いて、実用的なMLパイプラインの幅広い分野で現れることを示します。この結果は、あらゆる分野での実運用を目的としたモデリングパイプラインにおいて、不完全性を明示的に考慮する必要があることを示している。
ニューラル言語モデルにおける文法構造のエンコーディングを分析する方法として、伝達学習を提案する。非言語データでLSTMを学習し、自然言語でのパフォーマンスを評価することで、どのような種類のデータがLSTMが自然言語に使用できる一般化可能な構造的特徴を誘発するかを評価する。その結果、潜在的な構造を持つ非言語データ（MIDI音楽やJavaコード）で学習すると、表面的な形式や語彙には重なりがないにもかかわらず、自然言語に対するテストのパフォーマンスが向上することがわかった。このような改善をもたらすモデルがどのような抽象的構造を符号化しているかを特定するために、2つの人工的な括弧言語で同様の実験を行った。1つは階層的な再帰構造を持つ言語、もう1つは対になるトークンを持つが再帰を持たない言語である。驚くべきことに、どちらの人工言語でモデルをトレーニングしても、自然言語でテストした場合と同じように大幅な改善が見られた。さらに、語彙の重複を考慮して自然言語間の移行を実験したところ、テスト言語でのゼロショット性能は、訓練言語との類型的な構文の類似性と高い相関があることがわかった。これは、事前訓練によって誘導された表現が、言語間の構文特性に対応していることを示唆している。この結果は、神経モデルが抽象的な構文構造をどのように表現しているのか、また、自然言語の習得を可能にする構造的な帰納的バイアスの種類についての洞察を与えるものである。
ゼロアナフォラ解決（ZAR）の重要な問題の一つは、ラベル付きデータが少ないことです。本研究では、データ増強によってこの問題をどれだけ効果的に軽減できるかを検討します。本研究では、事前に学習した言語モデルを用いて、ラベル付きの学習インスタンスを生成するCDA(Contextual Data Augmentation)と呼ばれる最新のデータ補強手法を採用しました。CDAは、テキスト分類や機械翻訳など、他のいくつかの自然言語処理タスクにおいても有効であることが報告されている。本研究では，CDAにおける2つの課題，すなわち，データ増強のための計算コストをいかに削減するか，また，生成されたデータの品質をいかに確保するか，について検討する．また、CDAをZARに適応させるために、[MASK]ベースのオーグメンテーションと言語制御マスキングという2つの手法を提案しました。その結果，日本語のZARを対象とした実験では，提案手法が精度向上と計算コスト削減の両方に貢献していることがわかった．また，提案手法は，従来のCDAと比較して，増強された学習データの品質を向上させることができることが明らかになった。
強化学習（RL）アルゴリズムの進歩は、現在の手法の限界を試すような困難な環境の開発と密接に関係しています。既存のRL環境は、十分に複雑であるか、高速なシミュレーションに基づいているかのいずれかですが、その両方であることはほとんどありません。NetHack Learning Environment (NLE)は、RL研究のためのスケーラブルで、手続き的に生成され、確率的で、リッチで、チャレンジングな環境であり、人気のあるシングルプレイヤーのターミナルベースのローグライクゲームであるNetHackに基づいています。NetHackは、探索、計画、スキル獲得、言語条件付きRLなどの問題の長期的な研究を推進するのに十分な複雑さを持ちながら、大量の経験を集めるのに必要な計算資源を劇的に削減することができると主張しています。NLEとそのタスク群を既存のものと比較し、RLエージェントのロバスト性と体系的な一般化をテストするための理想的な媒体である理由を論じている。我々は、分散型ディープRLベースラインとRandom Network Distillation探索を用いて、ゲームの初期段階における経験的な成功を、環境で訓練された様々なエージェントの質的な分析とともに実証する。NLEはこのhttpsのURLでオープンソースになっています。
深層アンサンブルと呼ばれる、異なるランダムな初期化から訓練されたニューラルネットワークの重みを超えるアンサンブルは、最先端の精度とキャリブレーションを達成します。最近導入されたバッチ・アンサンブルは、よりパラメータ効率の高いドロップイン・リプレースメントを提供する。本論文では、重みだけでなく、ハイパーパラメータも含めたアンサンブルを設計することで、両方の設定において最先端の技術を向上させます。予算に依存しない最高の性能を得るために、我々はハイパーディープアンサンブルを提案する。これは、複数のランダムな初期化にまたがって層化された、異なるハイパーパラメータに対するランダムな探索を含む単純な手順である。このアンサンブルの高い性能は、重みとハイパーパラメータの両方に多様性のあるモデルを組み合わせることの利点を強調している。さらに、パラメータ効率の良いバージョンとして、バッチアンサンブルと自己調整ネットワークの層構造を利用したハイパーバッチアンサンブルを提案します。本手法の計算コストとメモリコストは、一般的なアンサンブルに比べて著しく低い。画像分類タスクにおいて、MLP、LeNet、ResNet 20、Wide ResNet 28-10の各アーキテクチャを用いて、ディープアンサンブルとバッチアンサンブルの両方を改善しました。
深層学習の計算効率を向上させることは、モデルの再学習を頻繁に行う必要があるタスクや、多数のモデルを学習する必要があるワークロードにとって重要です。今回紹介するSliceOutは、GPUのメモリレイアウトを利用して、最終テストの精度に影響を与えずに深層学習モデルを高速に学習するために設計された、ドロップアウトにヒントを得たスキームです。本手法は、連続したユニットのセットをランダムにドロップすることで、(1)小さいテンソルの高速なメモリアクセスと行列の乗算、(2)ウェイトグラデーションとアクティベーションのゼロユニットへのメモリ割り当てを回避することによるメモリの節約により、学習の高速化を実現します。テスト時には，SliceOutをオフにすることで，テストの精度を維持したまま，線形数のアーキテクチャで暗黙のアンサンブルを実行します．その結果，Wide ResNets，EfficientNets，Transformerの各モデルにおいて，精度の低下を最小限に抑えつつ，10～40％の速度向上とメモリの削減を実現しました．これにより、大規模な計算ワークロードの処理が全体的に高速化され、それに伴うエネルギー消費やCO2排出量も大幅に削減されます。
大規模なテキストコーパスは、様々な自然言語処理（NLP）タスクにおいてますます重要になってきており、自動言語識別（LangID）は、多言語コンテキストでそのようなデータセットを収集するために必要なコア技術です。LangIDは、1,366もの言語で90%以上の平均F1を達成したモデルが報告されており、文献ではほとんど解決済みとして扱われています。しかし、これらのモデルを用いて作成されたウェブクローリングテキストコーパスの人間が判断したLangID精度は、多くの低リソース言語で5%程度にとどまっており、よりロバストな評価が必要であることがわかった。さらに分析を進めると、ドメインの不一致、クラスの不均衡、言語の類似性、十分な表現力を持たないモデルなど、様々なエラーモードがあることがわかった。これらのエラーを軽減するために，2つのクラスの技術を提案する．すなわち，単語リストに基づく調整可能な精度のフィルタ（約500言語の精選されたリストを公開している）と，変換器に基づく半教師付きLangIDモデルで，データセット精度の中央値を5.5%から71.2%に向上させることができる．これらの技術により、500以上の言語でそれぞれ10万以上の比較的きれいな文章をカバーする初期データセットを作成することができ、1,000言語のウェブテキストコーパスへの道が開かれました。
強化学習（RL）は、エージェントが環境に遷移と報酬を求める能力が実質的に無制限であるような、さまざまなオンライン設定で素晴らしい性能を達成しています。しかし、多くの実用的なアプリケーションでは、状況は逆になります。エージェントは、大量の無方向のオフライン経験データにアクセスできるかもしれませんが、オンライン環境へのアクセスは非常に限られています。本研究では、このオフライン環境に焦点を当てます。我々の主な洞察は、様々な行動で構成されたオフラインデータが提示された場合、このデータを活用する効果的な方法は、反復的かつ時間的に拡張されたプリミティブな行動の連続空間を抽出し、これらのプリミティブを下流のタスク学習に使用することである。このようにして抽出されたプリミティブには2つの目的があります。1つは、データでサポートされている行動とそうでない行動を区別することで、オフラインRLでの分布のずれを回避するのに役立つこと、もう1つは、時間的な抽象度を提供することで、有効な水平線を減らし、理論的にはより良い学習をもたらし、実際にはオフラインRLを改善することです。オフラインでのポリシー最適化に加えて、この方法でオフラインでの原始的な学習を行うことは、様々なベンチマークドメインでのオンラインRLにおける数ショットの模倣学習や探索・伝達の改善にも活用できることを示しています。ビジュアルはこちらのURLからご覧いただけます。
放射線科のテキストレポートからラベルを抽出することで、医療画像モデルの大規模なトレーニングが可能になります。レポートのラベル付けに対する既存のアプローチは、通常、医療分野の知識に基づいた高度な特徴工学か、専門家による手動のアノテーションに依存している。本研究では、利用可能なルールベースシステムの規模と専門家のアノテーションの質の両方を活用する、BERTベースの医用画像レポートラベリングアプローチを紹介します。生物学的に事前学習されたBERTモデルは、最初にルールベースのラベラーのアノテーションで学習され、その後、自動逆翻訳で補強された専門家のアノテーションの小セットで微調整され、優れた性能を発揮することを実証しました。最終モデルであるCheXbertは、ルールベースのラベラーを統計的に有意に上回ることができ、胸部X線の最大級のデータセットにおけるレポートラベリングに新たなSOTAを設定することができました。
本論文では、LMU MunichがWMT 2020の教師なし共有タスクに、ドイツ語<->上ソルブ語の2つの言語方向で提出したことを説明します。我々のコアとなる教師なしニューラル機械翻訳(UNMT)システムはChronopoulouら(2020)の戦略に従っており、オンラインバックトランスレーションで訓練されたUNMTモデルを初期化する前に、(ドイツ語で)単言語の事前訓練された言語生成モデルを使用し、ドイツ語と上ソルブ語の両方でそれを微調整します。UNMTモデルの微調整には、教師なし統計的機械翻訳（USMT）システムから得られた疑似並列データを使用します。また、BPE-Dropoutを低リソース（上ソルブ語）のデータに適用し、よりロバストなシステムを得た。さらに、残差アダプタを用いた実験を行い、Upper Sorbian->Germanの方向で有用であることがわかった。また、SMT翻訳をより原則的な方法で使用するために、バックトランスレーション中のサンプリングとカリキュラム学習を検討しました。最後に、最も性能の高いシステムをアンサンブルし、BLEUスコアをドイツ語→上ソルビアン語で32.4、上ソルビアン語→ドイツ語で35.2としました。
Transformerモデルは、多くのシーケンスモデリングタスクにおいて、最先端の性能を達成しています。しかし、深さが大きかったり、変化したりするモデルの能力をどのように活用するかは、まだ未解決の課題である。我々は、レイヤー選択の事後分布を学習することで、どのレイヤーを使用するかを自動的に学習する確率的なフレームワークを提示する。このフレームワークの拡張として、多言語機械翻訳のために1つの共有Transformerネットワークを言語ペアごとに異なる層選択の事後分布で学習する新しい方法を提案する。提案手法は、消失勾配の問題を緩和し、100層などの深いTransformerの安定した学習を可能にする。WMT英独機械翻訳とマスクド言語モデリングタスクで評価したところ、提案手法はより深いTransformerを学習するための既存のアプローチよりも優れていた。また、多言語機械翻訳の実験では、本手法がモデル容量の増加を効果的に活用し、多様な言語ペアを持つ多対多の翻訳に普遍的な改善をもたらすことを実証した。
自動音声認識のための半教師付き学習における最近の開発成果を採用し、Libri-Lightデータセットのラベルのない音声を利用したLibriSpeechで最先端の結果を得た。具体的には、wav2vec 2.0を用いて事前学習した巨大なConformerモデルを用いて、SpecAugmentでノイズの多い学生の学習を行う。これにより、LibriSpeech test/test-otherセットにおいて、現在の最先端のWERが1.7%/3.3%であるのに対し、1.4%/2.6%のWERを達成することができた。
自己教師付き学習は，ラベルのないデータのみを用いて表現を事前学習することで，コストのかかる教師付き信号への依存度を低減する戦略として登場した．これらの手法は、ヒューリスティックな代理分類タスクとデータ増強を組み合わせたもので、大きな成功を収めているが、この成功の理論的理解はまだ限られている。本論文では、因果関係の枠組みを用いて、自己教師付き表現学習を分析する。本論文では、自己教師付き表現学習を因果関係のあるフレームワークを用いて分析し、前学習の際に用いられる代理分類器に明示的な不変性制約を与えることで、データ増強をより効果的に利用できることを示す。これに基づき、我々は、不変性正則化を用いて、増強されたデータ間でのプロキシターゲットの不変的な予測を強制する新しい自己教師付き目的、不変性因果メカニズムによる表現学習(ReLIC)を提案する。さらに、因果関係を利用することで、自己保存法の一種である対照学習を一般化し、これらの手法の成功のための別の理論的説明を提供する。実証的には、ImageNetにおいて、RELICは頑健性と分布外の一般化の点で競合手法を大きく上回り、また、Atariにおいても57ゲーム中51ゲームで人間レベル以上の性能を達成しました。
Performersは、正規の（ソフトマックス）フルランクアテンショントランスフォーマーを証明可能な精度で推定できるトランスフォーマーアーキテクチャであり、スパース性や低ランク性などの前提条件に頼ることなく、（2次関数ではなく）線形の空間と時間の複雑さのみで推定できるものです。ソフトマックスアテンションカーネルを近似するために、Performersは新しいFast Attention Via positive Orthogonal Random featuresアプローチ(FAVOR+)を使用しており、これはスケーラブルなカーネル法として独立した興味を持つかもしれません。FAVOR+は、ソフトマックス以外のカーネル化可能な注意メカニズムを効率的にモデル化するためにも使用できます。この表現力は、通常のTransformerでは対応できない大規模なタスクにおいて、初めてsoftmaxと他のカーネルを正確に比較し、最適な注意カーネルを調査するために非常に重要です。Performersは、通常のTransformerと完全に互換性のある線形アーキテクチャであり、注目行列の不偏またはほぼ不偏な推定、均一な収束、低い推定分散などの強力な理論的保証を備えています。Performersは、ピクセル予測、テキストモデル、タンパク質配列モデルなど、さまざまなタスクでテストされました。Performersは、ピクセル予測、テキストモデル、タンパク質配列モデリングなど、さまざまなタスクでテストを行い、効率的なスパースアテンションやデンシーアテンションの手法と競合する結果を示し、Performersが活用する新しいアテンション学習パラダイムの有効性を示しました。
一般的に、構造化されていないラベルのないテキストで学習される文脈的な単語表現は、実世界の実体に対する明示的な根拠を含んでおらず、それらの実体に関する事実を記憶することができないことが多い。本研究では、複数の知識ベース(KB)を大規模モデルに埋め込み、それによって構造化された人間が編集した知識で表現を強化する一般的な手法を提案する。各KBに対して、まず、統合されたエンティティリンカーを用いて、関連するエンティティの埋め込みを検索し、次に、単語からエンティティへの注目という形で、文脈上の単語表現を更新する。これまでのアプローチとは異なり、少量のエンティティリンク監視と大量の生テキストを組み合わせたマルチタスク設定で、エンティティリンカーと自己教師付き言語モデリング目的をエンドツーエンドで共同学習します。WordNet および Wikipedia のサブセットを BERT に統合した後、知識強化 BERT（KnowBert）は、perplexity の改善、プロービングタスクで測定された事実の想起能力、および関係抽出、エンティ ティタイピング、語義曖昧性解消に関する下流の性能を実証した。KnowBert の実行時間は BERT と同程度であり、大規模な KB にも対応しています。
処方薬の識別は、患者や医療関係者にとって頻繁に行われる作業ですが、多くの錠剤が似たような外見（例：白い丸い錠剤）をしているため、投薬ミスのリスクが高まるという問題があります。本論文では，錠剤画像認識に関する最大規模のパブリックベンチマークであるePillIDを紹介します．ePillIDは，9804種類の外観クラス（4902種類の錠剤の両面）を表す13k枚の画像から構成されています．ePillIDは、9804種類の外観クラス（4902種類の錠剤の両面）を表す13k枚の画像から構成されています。本研究では、実験設定と、このベンチマークにおける様々なベースラインモデルの評価結果を示します。最良のベースラインは、双線形特徴を用いたマルチヘッド・メトリック学習アプローチを用いたもので、非常に優れた性能を示しましたが、誤差分析によると、特に混乱したクラスを区別することができないことが分かりました。コードとデータはこのhttpsのURLで公開されています。
神経抽象的要約モデルは柔軟性があり、首尾一貫した要約を生成することができますが、時々不貞腐れてしまい、制御が難しい場合があります。先行研究では、出力を制御して忠実度を高めるために様々なタイプのガイダンスを提供することが試みられているが、これらの戦略がどのように比較対照されるかは明らかではない。本論文では、異なる種類の外部ガイダンスを効果的に入力とすることができる、一般的で拡張可能なガイド付き要約フレームワーク(GSum)を提案し、いくつかの異なる種類の実験を行った。実験の結果，このモデルが有効であることを示し，4つの一般的な要約データセットにおいて，ハイライトされた文をガイダンスとして使用した場合に，ROUGEによる最先端の性能を達成した．さらに、我々のガイド付きモデルは、より忠実な要約を生成することができることを示し、異なる種類のガイダンスがどのように質的に異なる要約を生成するかを示すことで、学習されたモデルにある程度の制御性を与える。
Mischiefは、言語モデルのために、人間が読める現実的な敵対例のクラスを生成するための、シンプルで軽量な手法です。Mischiefは、4つの変換器ベースのアーキテクチャを用いて、様々なダウンストリームタスクと、様々な濃度の例文を用いて、アルゴリズムの徹底的な実験を行いました。その結果，Mischiefが生成した敵対的なサンプルがテストセットに含まれていると，報告されているベースラインと比較して，これらのモデルの性能が大幅に（最大で20％）低下することがわかりました．しかし、類似したサンプルをトレーニングセットに含めることで、敵対的なテストセットでベースラインのスコアを回復させることが可能であることも実証した。さらに、特定のタスクにおいて、Mischiefセットを用いて学習されたモデルは、元の非敵対的なベースラインと比較して、パフォーマンスをわずかに向上させることができた。
Mischiefは、言語モデルのために、人間が読める現実的な敵対的な例のクラスを作成するための、シンプルで軽量な手法である。Mischiefのアルゴリズムは、4つの変換器ベースのアーキテクチャを用いて、さまざまな下流のタスクや、さまざまな濃度の例文を用いて、徹底的に実験を行いました。その結果，Mischiefが生成した敵対的なサンプルがテストセットに含まれていると，報告されているベースラインと比較して，これらのモデルの性能が大幅に（最大で20％）低下することがわかりました．しかし、類似したサンプルをトレーニングセットに含めることで、敵対的なテストセットでベースラインのスコアを回復させることができることも実証しました。さらに、特定のタスクにおいて、Mischiefセットを用いて学習したモデルは、元の非逆問題のベースラインと比較して、わずかながら性能が向上しています。
ニューラル・アーキテクチャ・サーチ（NAS）は、2012年に畳み込みニューラルネットワークがもたらしたのと同様に、ゲームチェンジャーとなることが期待されるエキサイティングな新分野です。様々なタスクで大幅な改善をもたらした多くの優れた研究にもかかわらず、異なる手法間の比較はまだ非常に未解決な問題です。ほとんどのアルゴリズムは同じデータセットでテストされていますが、すべてのアルゴリズムに共通する実験プロトコルはありません。そのため、アブレーション研究が十分に活用されていないこともあり、特定の手法が他の手法よりも効果的である理由が明確になっていません。我々の最初の貢献は、5つのデータセットで8つのNAS法をベンチマークすることです。異なる探索空間を持つ手法を比較するというハードルを克服するために，我々は，ランダムにサンプリングされた平均的なアーキテクチャに対する手法の相対的な改善度を用いることを提案する．驚くべきことに、多くのNAS技術が平均アーキテクチャのベースラインを大きく上回ることができないことがわかりました。さらに、NASパイプラインの各コンポーネントの貢献度を理解するために、一般的に使用されているDARTS探索空間を用いた実験を行いました。これらの実験により、以下のことが明らかになりました。(セルベースの探索空間は精度の範囲が非常に狭く，シードがアーキテクチャの順位に大きな影響を与えること，手作業で設計されたマクロ構造（セル）が探索されたミクロ構造（演算）よりも重要であること，そしてセル数が8個のアーキテクチャと20個のアーキテクチャの間で順位が変化することから分かるように，デプスギャップが実際に存在することです．最後に，ベストプラクティスを提案します．これらは，コミュニティにとって有用であり，現在のNASの落とし穴を軽減するのに役立つことを期待しています．使用したコードはこちらのhttpsのURLから入手できます。
深層学習用の一般的なオプティマイザーは、適応型手法（Adamなど）と加速型スキーム（Stochastic Gradient Descent (SGD) with Momentumなど）に大別されます。畳み込みニューラルネットワーク(CNN)のような多くのモデルでは、適応型手法はSGDに比べて収束は速いが汎化は悪い。Generative Adversarial Network(GAN)のような複雑な設定では、その安定性から適応型手法が一般的にデフォルトとなっている。我々は、適応型手法のような速い収束、SGDのような良好な汎化、そして学習の安定性という3つの目標を同時に達成するためにAdaBeliefを提案する。AdaBeliefの直感は、現在の勾配方向に対する「信念」に応じてステップサイズを適応させることである。ノイズの多い勾配の指数移動平均（EMA）を次の時間ステップでの勾配の予測と見なし、観測された勾配が予測から大きく外れている場合は、現在の観測を信用せず、小さなステップを踏み、観測された勾配が予測に近い場合は、それを信用して大きなステップを踏みます。AdaBeliefを大規模な実験で検証し、画像分類や言語モデリングにおいて、高速な収束と高い精度で他の手法を上回ることを示した。具体的には、ImageNetにおいて、AdaBeliefはSGDと同等の精度を達成している。さらに、Cifar10上のGANの学習において、AdaBeliefは高い安定性を示し、よく調整されたAdamオプティマイザと比較して、生成されたサンプルの品質を向上させた。コードはこちらのhttpsのURLから入手可能です。
局所特徴量フレームワークは、疎なキーポイントの選択とマッチングに固有の離散性があるため、エンド・ツー・エンドで学習することが難しい。DISK(DIScrete Keypoints)は、強化学習(RL)の原理を利用してこれらの障害を克服する新しい手法であり、多くの正しい特徴のマッチをエンド・ツー・エンドで最適化します。シンプルで表現力豊かな確率モデルにより、学習と推論の領域を近づけることができ、ゼロからの学習でも十分な収束性を維持することができます。図1に示すように、我々の特徴は、識別性を維持しながら非常に高密度に抽出することができ、良いキーポイントを構成するものについて一般的に考えられている仮定に挑戦し、3つのパブリックベンチマークで最先端の結果を得ることができました。
大規模なデータセットは、NLP研究において当たり前のものとなっています。しかし、データの量を重視するあまり、データの質を評価することが難しくなっています。本研究では、データセットを特徴づけ、診断するためのモデルベースのツールである「データマップ」を紹介します。データマップを構築するために、ほとんど無視されてきた情報源である、学習中の個々のインスタンスに対するモデルの振る舞い（トレーニングダイナミクス）を活用します。これにより、各事例について、真のクラスに対するモデルの信頼度と、この信頼度のエポック間の変動という2つの直観的な尺度が得られる（1回の学習で得られる）。4つのデータセットで実験を行った結果、モデルに依存するこれらの指標は、データマップ内の3つの異なる領域を明らかにし、それぞれが顕著な特徴を持つことがわかった。まず、データマップには、モデルに対して「曖昧」な領域が存在し、分布外の汎化に最も寄与していることがわかった。次に、データの中で最も人口の多い地域は、モデルにとって「学習しやすい」地域であり、モデルの最適化において重要な役割を果たします。最後に、データマップでは、モデルが「学習困難」と判断したインスタンスのある領域が明らかになりますが、これは多くの場合、ラベリングエラーに対応します。今回の結果は、データの量から質へと焦点を移すことで、ロバストなモデルや分布外の一般化の改善につながることを示しています。
教師付き深層学習は、過去10年間で大きな成功を収めてきました。しかし、手動のラベルに依存し、攻撃を受けやすいという欠点があるため、人々はより良い解決策を模索しています。これに代わるものとして、自己教師付き学習は、ここ数年の表現学習における飛躍的な成果により、多くの研究者を魅了している。自己教師付き表現学習は、入力データそのものを教師として活用し、ほとんどすべての種類の下流タスクに恩恵をもたらす。本調査では、コンピュータビジョン、自然言語処理、グラフ学習における表現のための新しい自己教師付き学習法を紹介する。既存の実証的な手法を包括的にレビューし、それらを目的に応じて、生成的、対照的、生成的-対照的（敵対的）の3つの主要なカテゴリにまとめます。さらに、自己教師付き学習がどのように機能するかについての深い考えを提供するために、関連する理論的分析作業を調査する。最後に、自己教師付き学習の未解決問題と将来の方向性について簡単に議論する。調査のためのアウトラインスライドを提供する。
オプティマイザーの選択は、深層学習において最も重要な設計上の決定の一つと考えられていますが、それは簡単なことではありません。増え続ける文献には、何百もの最適化手法が掲載されています。明確な理論的指針や決定的な経験的証拠がないため、逸話に基づいて決定されることが多いのです。本研究では、このような逸話を、決定的なランキングとまではいかなくても、少なくとも証拠に裏付けられたヒューリスティックに置き換えることを目的としています。そのために、特に人気のある15種類の深層学習用オプティマイザーを対象とした大規模で標準的なベンチマークを実施し、幅広い選択肢の中から簡潔な概要を示す。50,000以上の個別の実行を分析して、以下の3つのポイントを貢献します。(i) オプティマイザーの性能はタスクによって大きく異なる。(ii）複数のオプティマイザーをデフォルトのパラメータで評価することは，1つの固定されたオプティマイザーのハイパーパラメータを調整するのとほぼ同じ効果があることを確認した．(テストしたすべてのタスクにおいて、ある最適化手法が明らかに優勢であるとは言えませんが、我々の実験では、一般的に競争力のある結果をもたらす特定のオプティマイザとパラメータの選択を大幅に削減することができました。Adamは依然として強力な競争相手であり、新しい手法はAdamを大幅かつ一貫して上回ることができませんでした。このオープンソースの結果は、新たな最適化手法をより意味のある形で評価するための、挑戦的でよく調整されたベースラインとして、さらなる計算努力を必要とせずに利用できます。
医用画像の視覚的表現を学習することは、医用画像理解の中核をなすものですが、手でラベルを付けたデータセットのサイズが小さいことが、その進歩を妨げています。既存の研究では、ImageNetの事前学習から重みを移す方法が一般的ですが、画像の特性が大きく異なるため、最適ではありません。また、医用画像とペアになっているテキストレポートデータからルールベースのラベル抽出を行う方法もありますが、これは不正確で一般化するのが困難です。我々は、画像とテキストデータの自然な組み合わせから直接医療用視覚表現を学習する、教師なしの代替戦略を提案する。2つのモダリティの間の双方向の対照的な目的を介して、ペアのテキストデータで医療画像エンコーダを事前にトレーニングする我々の方法は、ドメインにとらわれず、専門家の追加入力を必要としない。事前学習した重みを4つの医用画像分類タスクと2つのゼロショット検索タスクに転送して本手法を検証し、本手法がほとんどの設定において強力なベースラインを大幅に上回る画像表現をもたらすことを示した。注目すべきは、4つの分類タスクにおいて、本手法は、ImageNetで初期化されたものと比較して、10%のラベル付きトレーニングデータしか必要とせず、優れたデータ効率を示すことである。
k-nearest-neighbor機械翻訳（kNN-MT）は、類似性検索のためにニューラル翻訳モデルからの表現を使用して、キャッシュされた例の大規模なデータストア上の最近傍分類器でトークンを予測します。このアプローチは，追加の学習を必要とせず，デコーダがテスト時に何十億もの例に直接アクセスできるように拡張することができ，その結果，多くの設定で一貫して性能が向上する，非常に表現力の高いモデルが得られます．kNN-MTは、ドメイン固有のデータストアを使用することで、1つのモデルを様々なドメインに適応させることができ、ゼロショット転送と比較して平均9.2BLEUの結果を向上させ、これらのドメインでトレーニングを行わなくても、新たに最先端の結果を得ることができます。大規模な多言語モデルは、特定の言語ペアに特化することもでき、英語からドイツ語と中国語への翻訳では3BLEUの向上が見られました。kNN-MTは、ソースとターゲットのコンテキストを組み合わせて関連性の高い例を抽出するため、定性的には解釈が容易です。
多くのNLPタスクは主観的な性質を持っているにもかかわらず、ほとんどのNLU評価では、高い一致率を持つと思われる多数派のラベルをグランドトゥルースとして使用することに重点が置かれてきました。しかし、人間の意見の分布についてはあまり注目されていない。我々は、よく使われるNLI評価セットにおけるCollective HumAn OpinionSを研究するために、合計464,500のアノテーションを持つデータセット、ChaosNLIを収集した。このデータセットは，SNLIとMNLIの3,113例とAbductive-NLIの1,532例について，1例あたり100個のアノテーションを集めて作成したものである．分析の結果、以下のことが明らかになった。(3)モデルは，人間の合意度が高いデータのサブセットではほぼ完璧な精度を達成するが，人間の合意度が低いデータではランダムな推測にほとんど勝てない．このことから、評価データセットの一致度の低い部分について、古い測定基準でモデルの性能を向上させることの妥当性が疑問視されています。そのため，今後のデータ収集においては，人間の意見の一致度を詳細に調査し，人間の意見の集合的な分布に対してモデルの出力を評価することが必要であると主張する。ChaosNLIデータセットと実験スクリプトはこちらのhttps URLから入手可能です。
事前に学習された言語モデル、特にマスクド言語モデル（MLM）は、多くのNLPタスクで成功を収めてきました。しかし，これらのモデルは，学習したコーパスに間違いなく存在する文化的バイアスを利用し，暗黙のうちに偏った表現による弊害を生み出しているという十分な証拠がある。米国の保護された人口グループに対する言語モデルの社会的バイアスを測定するために、Crowdsourced Stereotype Pairs benchmark (CrowS-Pairs)を紹介します。CrowS-Pairsには、人種、宗教、年齢などの9種類のバイアスを扱ったステレオタイプをカバーする1508の例題があります。CrowS-Pairsでは、ステレオタイプが多い文と少ない文の2つの文がモデルに提示されます。このデータは、歴史的に不利な立場にあるグループに関するステレオタイプに焦点を当て、有利な立場にあるグループと対比させています。今回評価した3つのMLMは、CrowS-Pairsの全てのカテゴリにおいて、ステレオタイプを表現する文章を大幅に好むことが分かりました。より偏りの少ないモデルの構築に向けて、このデータセットは進歩を評価するためのベンチマークとして使用することができます。
Transformerアーキテクチャは、自然言語処理タスクのデファクトスタンダードとなっていますが、コンピュータビジョンへの応用はまだ限られています。視覚分野では、注意は畳み込みネットワークと一緒に適用されるか、全体的な構造を維持したまま畳み込みネットワークの特定のコンポーネントを置き換えるために使用されます。我々は、このようなCNNへの依存は必要なく、純粋な変換器を画像パッチのシーケンスに直接適用することで、画像分類タスクにおいて非常に優れた性能を発揮できることを示す。Vision Transformer (ViT)は、大量のデータで事前学習を行い、複数の中規模・小規模の画像認識ベンチマーク（ImageNet、CIFAR-100、VTABなど）に転送したところ、最先端の畳み込みネットワークと比較して、学習に必要な計算資源が大幅に少ないにもかかわらず、優れた結果を得ることができました。
帰属法では、モデルの予測に対する入力の寄与度を評価します。予測に影響を与えずに入力を削除できる場合、入力のサブセットは無関係であるとみなされます。概念的には簡単ですが、消去の目的は難しく、最新のディープNLPモデルでは近似探索にコストがかかります。また、消去法は後知恵のバイアスの影響を受けやすく、入力を削除できるという事実は、モデルがその入力を削除できることを「知っている」ことを意味しません。結果として生じる刈り込みは過度に攻撃的で、モデルがどのようにして予測に至ったかを反映していません。これらの課題に対処するために、Differentiable Maskingを導入しました。DiffMaskは、微分可能性を維持しながら、入力のサブセットをマスクアウトすることを学習します。入力トークンを含むか無視するかの判断は、分析モデルの中間隠れ層に基づく単純なモデルで行われます。第一に、検索ではなく予測を行うため、このアプローチは効率的です。第二に、分類器のプロービングと同様に、ネットワークが対応する層で「知っている」ことを明らかにします。これにより、アトリビューション・ヒートマップを描くだけでなく、ネットワークの各層でどのように意思決定が行われているかを分析することができます。DiffMaskを使用して、感情分類と質問応答に関するBERTモデルを研究しています。
複雑なオープンドメインの質問に答えるために、シンプルで効率的なマルチホップ高密度検索アプローチを提案し、HotpotQAとマルチエビデンスFEVERという2つのマルチホップデータセットで最先端の性能を達成した。従来の手法とは異なり、本手法は文書間のハイパーリンクや人間が注釈を付けたエンティティマーカーなどのコーパス固有の情報へのアクセスを必要とせず、どのような非構造化テキストコーパスにも適用できる。また、効率と精度のトレードオフも改善され、HotpotQAで公表されている最高の精度に匹敵する一方で、推論時間は10倍高速化されています。
ニューラルネットワークの学習能力を向上させるための取り組みは、重みの初期化ではなく、最適化手法の役割に焦点を当ててきた。しかし、最近の研究では、ニューラルネットワークは、「宝くじ」と呼ばれるサブネットワークのランダムな初期重みに依存しており、解に素早く収束することが示唆されています。重みの初期化がどのように性能に影響するかを調べるために、2次元セルラーオートマトン「Conway's Game of Life」のnステップを予測するように学習した小さな畳み込みネットワークを調べた。このタスクで学習したこのアーキテクチャのネットワークは、ほとんど収束しないことがわかりました。むしろ、安定して収束させるためには、より多くのパラメータを必要とします。さらに、最小値に近いアーキテクチャは、パラメータのわずかな変化にも敏感で、1つの重みの符号を変えるだけで、ネットワークが学習できなくなることがある。最後に、d_0の確率で細胞が生きている例で最小ネットワークを学習すると、解に収束する可能性が劇的に高まるという臨界値d_0が観測された。つまり、この関数を学習するために必要なネットワークのサイズは、関数を実装するために必要な最小のネットワークよりも大幅に大きくなることが多いということです。
オープンドメインの質問応答は、コンテクスト候補を選択するための効率的な通路検索に依存しており、TF-IDFやBM25などの従来の疎なベクトル空間モデルが事実上の手法となっている。本研究では、密度の高い表現のみで検索を実用化できることを示す。ここでは、シンプルなデュアルエンコーダーフレームワークにより、少数の質問と文章から埋め込みを学習する。広範なオープンドメインQAデータセットで評価したところ、我々の密な検索器は、トップ20のパッセージ検索精度の点で、強力なLucene-BM25システムを9%-19%絶対的に大きく上回り、我々のエンド・ツー・エンドQAシステムが複数のオープンドメインQAベンチマークで新しい最先端を確立するのに役立った。
多話者音声合成を含む多くの実世界の問題は、少数のタスク固有のコンポーネントのみで大規模なモデルをメタ学習する能力から大きな恩恵を受けることができます。これらのタスク固有のモジュールのみを更新することで，オーバーフィットのリスクを冒すことなく，必要なステップ数だけ低データのタスクにモデルを適応させることができる．残念ながら、既存のメタ学習手法は、長時間の適応には対応できないか、あるいは手作業で作られたタスク固有のアーキテクチャに依存している。本論文では、このような最適ではない選択の必要性を排除するメタ学習手法を提案する。具体的には、タスクに特化したモジュールと一般的な再利用可能なモジュールの両方を自動的に発見・学習するために、ベイジアンシュリンケージに基づいた一般的な手法を開発した。経験的に、我々の手法は、意味のあるタスク固有のモジュールの小さなセットを発見し、タスクデータが少なく、適応期間が長い、数ショットの音声合成のようなドメインにおいて、既存のメタ学習アプローチよりも優れていることを実証した。また、MAML、iMAML、Reptileなどの既存のメタ学習手法が、我々の手法の特別なケースとして現れることも示している。
勾配降下法は、オーバーフィッティングや明示的な正則化を行わずに、ディープニューラルネットワークを最適化するのに驚くほど優れています。我々は、勾配降下法の離散的なステップが、大きな損失勾配を持つ勾配降下法の軌道にペナルティを与えることで、モデルを暗黙的に正則化することを発見した。我々はこれを暗黙の勾配正則化（implicit gradient regularization: IGR）と呼び、バックワードエラー分析を用いてこの正則化の大きさを計算した。その結果、暗黙の勾配正則化は勾配降下法をフラットミニマムに導くことを経験的に確認しました。さらに、暗黙的な勾配正則化項は明示的な正則化として使用することができ、この勾配正則化を直接制御することができることを実証した。より広い意味で、我々の研究は、バックワードエラー分析が、学習率、モデルサイズ、パラメータ正則化がどのように相互作用して、勾配降下法で最適化されたオーバーパラメータモデルの特性を決定するかという長年の疑問に対する有用な理論的アプローチであることを示している。
タスクの類似性という概念は、ドメイン適応やメタ学習など、さまざまな機械学習パラダイムの中核をなすものです。タスクの類似性を定量化する現在の手法は、ヒューリスティックであったり、タスク間のラベルセットを強く仮定していたり、タスク固有の最適なパラメータに依存するアーキテクチャ依存のものが多い（例えば、各データセットでモデルを学習する必要がある）などの問題がある。本研究では、(i)モデルに依存せず、(ii)学習を必要とせず、(iii)ラベルセットが完全に分離していてもデータセットを比較でき、(iv)しっかりとした理論的根拠を持つ、データセット間の距離の代替概念を提案する。この距離は、最適な輸送に依存しており、これにより、豊富な幾何学的認識、解釈可能な対応関係、およびよく理解された特性が得られます。我々の結果は、この新しい距離がデータセットの有意義な比較を提供し、様々な実験設定とデータセットにおいて、伝達学習の硬さとよく相関することを示している。
我々は、下流のタスクを解決するために使用するデータの表現を評価する問題を考える。我々は、表現の品質を、興味のあるタスクで低損失を達成する表現の上に予測子を学習する際の複雑さで測定することを提案し、余剰記述長(SDL)と\varepsilon sample complexity(SC)という2つの手法を導入する。従来の手法は，特定のデータ量に存在する最適予測子の情報量を測定するものであったが，我々の手法は，指定された許容範囲内で最適予測子の近似値を復元するためにデータから必要な情報量を測定するものである．我々は，検証損失と評価データセットのサイズをプロットすることで，これらの手法を比較するフレームワークを提示している（「損失-データ」曲線）．相互情報量や最小記述長プローブなどの既存の尺度は、損失-データ曲線のデータ軸に沿ったスライスと積分に対応するが、我々の尺度は損失軸に沿ったスライスと積分に対応する。我々は、様々なサイズのデータセットにおけるこれらの手法の動作を比較するための実データを用いた実験と、表現評価のための高性能なオープンソースライブラリをこのhttps URLで提供している。
参考訳を必要としない、シンプルで効果的な機械翻訳評価手法を提案する。本手法は、(1)大規模な多言語知識ベースを用いて、原文と訳文候補のそれぞれに見出されるエンティティの言及を接地し、(2)訳文候補に見出されたエンティティと原文に見出されたエンティティのリコールを測定することに基づいている。我々の手法は，WMT19ベンチマークの参照なし評価の18言語ペアのうち9言語ペアで人間の判断との最高の相関を達成し，このタスクにおける単一の評価手法としては最大の勝利数となった．また、4つの言語ペアにおいて、BLEUよりも人間の判断との相関が高い結果となりました。さらなる研究の発展のために、WMT19のメトリクストラックデータから18言語ペアの180万件の実体言及を含むデータセットを公開しました。
手作業で設計された特徴量を学習された関数に置き換えることで、知覚的なタスクを解決する方法に革命をもたらしたように、学習されたアルゴリズムはモデルを訓練する方法を変えると信じています。本研究では、ユーザーがハイパーパラメータを指定しなくても、様々な問題を学習できる汎用的な学習済みオプティマイザーに注目しています。本研究では、ニューラルネットワークをパラメータとした階層型オプティマイザーを導入し、検証損失などの追加機能を利用することで、自動的に正則化を行うことができる。学習されたオプティマイザの多くは、単一のタスクまたは少数のタスクでしか学習されていません。しかし、我々のオプティマイザーは、何千ものタスクでトレーニングを行い、桁違いの計算量を利用して、未知のタスクに対してより一般化したオプティマイザーを実現しています。学習されたオプティマイザは、性能が高いだけでなく、既存の一次オプティマイザとは異なる動作を学習します。例えば、暗黙の正則化を持つ更新ステップを生成し、問題のハイパーパラメータ（バッチサイズなど）やアーキテクチャ（ニューラルネットワークの幅など）の変化に適応します。さらに、これらの学習されたオプティマイザーは、自分自身をゼロからトレーニングするような、分布外のタスクにも有用であるという証拠を示しています。
機械学習（ML）モデルは、さまざまな分野の判断にますます信頼されるようになっていますが、このようなモデルを使用したシステムの安全性がますます懸念されています。特にMLモデルは、潜在的に信頼できないソースからのデータを用いて学習されることが多く、敵は慎重に作成したサンプルを学習セットに挿入することで、モデルを操作する機会を与えられています。最近の研究では、ポイズニング攻撃と呼ばれるこの種の攻撃は、敵対者がモデルにバックドアやトロイの木馬を挿入することを可能にし、推論時に簡単な外部のバックドアトリガーで悪意のある動作を可能にし、モデル自体はブラックボックスの視点でしか見られないことが示されています。この種の攻撃を検知することは困難です。なぜなら、敵対者だけが知っているバックドア・トリガーが存在する場合にのみ、予期しない動作が発生するからです。モデルのユーザは，学習データの直接のユーザであれ，カタログから事前に学習されたモデルのユーザであれ，自分のMLベースのシステムの安全な動作を保証することはできない．本論文では、ニューラルネットワークのバックドアを検出・除去するための新しいアプローチを提案します。広範な実験結果により、テキストや画像を分類するニューラルネットワークに有効であることを実証します。我々の知る限り、これはバックドアを挿入するために作られた毒のあるデータを検出し、検証済みの信頼できるデータセットを必要とせずにモデルを修復することができる初めての方法論です。
あるテキストデータに潜在する質問とは？本研究では、質問生成モデルを用いて文書のコレクションを探索することを検討している。corpus2questionと名付けられた我々の手法は、事前に訓練された質問生成モデルをコーパス上に適用し、結果として得られた質問を頻度と時間によって集約することからなる。この手法は、大量のテキストデータを要約するための、トピックモデリングやワードクラウドなどの手法に代わるものです。結果は、COVID-19に関連する科学論文のコーパスにcorpus2questionを適用すると、トピックに関する関連する質問が得られることを示している。最も頻度の高い質問は、"What is covid 19 "と "What is the treatment for covid "です。また、1000件の中で最も頻度の高い質問は、「What is the threshold for herd immunity」と「What is the role of ace2 in viral entry」です。提案手法は，CovidQA質問応答データセットから得られた27の専門家が作った質問のうち，13の質問に対して類似した質問を生成したことを示す．実験を再現するためのコードと生成された質問は，以下のサイトで公開されている：このhttps URL
大規模な言語モデル（LM）は，自然言語の分布を十分に模倣して現実的なテキストを生成することができるが，分布のどの領域を生成するかを制御することは困難である．これは、大規模なLMの学習に使用されるデータセットには、通常、重大な毒性、憎悪、バイアス、ネガティブな要素が含まれているため、特に問題となります。GeDiは、小さなLMを生成識別器として利用し、大きなLMからの生成を導くことで、より安全で制御可能なものにするための効率的な手法として提案するものである。GeDiは、望ましい属性（制御コード）を条件としたクラス条件付き分布と、望ましくない属性（反制御コード）を条件としたクラス条件付き分布の2つのクラス条件付き分布を正規化することにより、ベイズ則を用いて可能な全ての次のトークンの分類確率を計算し、各ステップで生成を導く。その結果、GeDiは、従来の手法よりも強い制御性を持ちながら、30倍以上の生成速度を達成しました。さらに、GeDiは4つのトピックだけを学習することで、キーワードだけで新しいトピックをゼロショットで制御可能に生成することができ、従来の制御可能な生成方法にはない新しい能力を発揮する。最後に、GeDiはGPT-2(1.5Bパラメータ)の毒性を、言語的な品質を犠牲にすることなく大幅に低減できることを示しています。
学習領域で良好な性能を発揮するモデルは、しばしば領域外（OOD）の例に一般化できないことがあります。オーバーフィッティングを防ぎ、OODの一般化を向上させるためには、データの増強が一般的な手法として用いられます。しかし、自然言語処理では、基礎となるデータ多様性に留まる新しい例を生成することは困難である。本研究では、データ多様体上をランダムに移動する破壊関数と再構成関数のペアを用いて、合成学習例を生成するデータ補強法であるSSMBAを紹介する。本研究では、自然言語領域におけるSSMBAの利用について検討し、多様体の仮定を利用して、マスクされた言語モデルを用いて破損したテキストを再構成する。3つのタスクと9つのデータセットを対象としたロバスト性ベンチマークの実験において、SSMBAは、インドメインデータとOODデータの両方において、既存のデータ補強手法やベースラインモデルを一貫して上回り、OOD Amazonレビューで0.8%の精度、OOD MNLIで1.8%の精度、インドメインIWSLT14ドイツ語-英語で1.4BLEUの向上を達成しました。
近年、携帯電話やスマートウォッチ、IoTなどのデバイス上で全て動作する小型で高精度なニューラルネットワークの開発が注目されています。これにより、ユーザーのプライバシー、一貫したユーザーエクスペリエンス、低レイテンシーを実現することができます。ウェイクワードの検出から短いテキストの分類まで、幅広いアプリケーションが対象となっていますが、まだ長いテキストの分類のためのオンデバイスネットワークはありません。我々は、学習可能な投影と注目と畳み込みを組み合わせた新しい投影注目ニューラルネットワークPRADOを提案する。我々は、複数の大規模文書のテキスト分類タスクで我々のアプローチを評価する。その結果、学習可能な投影モデルが、意味的に類似したフレーズを見つけ出し、コンパクトなサイズを維持しながら高い性能に到達することに有効であることを示した。このアプローチを用いて、200キロバイトの小さなニューラルネットワークを学習すると、従来のCNNやLSTMモデルよりも性能が向上し、複数の長文ドキュメントの分類タスクで最先端に近い性能を得ることができました。また、このモデルを転移学習に適用し、その頑健性と、限られたデータのシナリオで性能をさらに向上させる能力を示しました。
我々は、Question-Answer driven Semantic Role Labeling (QA-SRL) アノテーションの新しい大規模コーパスと、初めての高品質QA-SRLパーサーを発表する。我々のコーパスQA-SRL Bank 2.0は、3つのドメインの64,000以上の文章に対する250,000以上の質問と回答のペアから構成されており、新しいクラウドソーシング方式で収集されたもので、適度なコストで高い精度と良好なリコールを実現している。また、QA-SRLの2つのサブタスク、すなわち、述語の引数スパンの検出と、意味的関係を示す質問の生成に関するニューラルモデルを紹介する。最良のモデルは、パイプライン化されたQA-SRL予測タスクにおいて、質問の精度が82.6%、スパンレベルの精度が77.6%(人間の評価による)を達成した。また、これらのモデルは、低コストで追加のアノテーションを収集するために使用することができます。
これまで、文法的誤り訂正（GEC）システムのエラータイプ性能は、システム出力にアノテーションがないため、リコールの観点からしか測定できませんでした。この問題を解決するために、我々はERRANTを導入した。ERRANTは、文法的誤り訂正ツールキットであり、原文と訂正文の並列から自動的に編集を抽出し、データセットに依存しない新しいルールベースのフレームワークに基づいて分類するように設計されている。これにより、さまざまな粒度でのエラータイプ評価が可能になるだけでなく、アノテーターの作業負荷の軽減や、既存のGECデータセットの標準化にも利用できる。人間の専門家は、少なくとも95%のケースで、自動編集を「良好」または「許容範囲」と評価したので、我々はERRANTをCoNLL-2014共有タスクのシステム出力に適用し、初めて詳細なエラータイプ分析を行った。
本研究では、言語の事前訓練(BERTなど)に用いられる位置符号化法を調査し、既存の定式化にいくつかの問題があることを明らかにした。まず、絶対位置エンコーディングにおいて、位置エンベッディングと単語エンベッディングに適用される加算演算は、2つの異種の情報資源の間に混合した相関をもたらすことを示す。これは、注目に不必要なランダム性をもたらし、モデルの表現力をさらに制限する可能性がある。第二に、記号\texttt{[CLS]}の位置を他の単語と同じように扱うことは、下流のタスクにおける特別な役割（文全体の表現）を考慮すると、合理的な設計であるかどうか疑問である。このような観点から、私たちは、TUPE (Transformer with ˶‾᷄ -̫ ‾᷅˵) と呼ばれる新しい位置符号化方式を提案します。TUPEは、自己言及モジュールにおいて、単語の文脈相関と位置相関を別々のパラメータ化で計算し、それらを加算します。この設計により、異種の埋込みに対する相関の混在やノイズを除去し、異なる投影行列を使用することで、より高い表現力を提供します。さらに、TUPEは、\texttt{[CLS]}シンボルを他の位置から解き放ち、すべての位置からの情報を容易に取り込むことができます。GLUEベンチマークを用いた大規模な実験とアブレーション研究により、提案手法の有効性が実証されました。コードとモデルはこのhttpsのURLで公開されています。
トランスフォーマー・モデル・アーキテクチャは、言語、視覚、強化学習などの様々な分野でその有効性が認められており、近年、非常に大きな関心を集めています。例えば、自然言語処理の分野では、Transformerは最新の深層学習スタックに欠かせない定番モデルとなっています。最近では、Transformerのアーキテクチャを改良した「X-former」と呼ばれるモデルが数多く提案されており、その多くは計算効率やメモリ効率を向上させています。この論文では、熱心な研究者がこのような状況を把握するのを助けることを目的として、効率性を重視した最近の「X-former」モデルの大規模かつ思慮深い選択を特徴付け、複数のドメインにわたる既存の研究およびモデルの組織的かつ包括的な概要を提供します。
注意はTransformerの重要な構成要素であり、最近では自然言語処理で大きな成功を収めている。したがって、注意はTransformerの様々な言語能力を調査するために広範囲に研究されており、注意の重みと特定の言語現象との間の類似性を分析することに焦点を当てている。本論文では、注意の重みだけでは、注意の出力を決定する2つの要因のうちの1つに過ぎないことを示し、2つ目の要因である変換された入力ベクトルのノルムを取り入れたノルムベースの分析を提案する。BERTとTransformerベースのニューラル機械翻訳システムのノルムベース分析の結果、以下のような知見が得られました。(i)先行研究とは異なり、BERTは特殊なトークンにあまり注意を払っていない。これらの発見は、Transformerの内部構造に関する洞察を提供するものである。
画像からの深層強化学習（RL）における報酬駆動型の特徴学習の限界を克服するために、我々は表現学習を政策学習から切り離すことを提案する。このタスクでは、畳み込みエンコーダーを学習して、短い時間差で区切られた観測値のペアを、画像の補強とコントラスト損失を用いて関連付ける。オンラインRLの実験では、ATCのみを用いてエンコーダを学習することで、ほとんどの環境でエンドツーエンドのRLと同等かそれ以上の性能が得られることが示された。さらに、いくつかの主要なULアルゴリズムを、専門家のデモンストレーションでエンコーダを事前に学習し、重みを固定してRLエージェントで使用することでベンチマークしたところ、ATCで学習したエンコーダを使用したエージェントは他のすべてのアルゴリズムよりも優れていることがわかった。また、複数の環境から得られたデータを用いてマルチタスクエンコーダを学習し、下流の様々なRLタスクへの一般化を示した。最後に、ATCの構成要素を削除し、RLが拡張を必要とする場合に、事前に学習したエンコーダーからの（圧縮された）潜在的な画像の再生を可能にする新しいデータ拡張を導入した。我々の実験は、DeepMind Control、DeepMind Lab、Atariにおける視覚的に多様なRLベンチマークを対象としており、我々の完全なコードはこのhttps URLで入手可能である。
非自動回帰機械翻訳のための効率的な推論手順を提案する。これは、連続空間において純粋に翻訳を反復的に改良するものである。機械翻訳のための連続潜在変数モデル(Shu et al., 2020)が与えられたとき、潜在変数のみを入力として、ターゲット文の限界対数確率の勾配を近似する推論ネットワークを訓練する。これにより、勾配ベースの最適化を用いて、推論時にその限界確率をほぼ最大化するターゲット文を見つけることができる。各改良ステップでは、低次元の潜在空間（実験では8を使用）での計算しか行わないため、トークン空間で改良を行うことが多い既存の非自動回帰推論手順で発生する計算オーバーヘッドを回避することができる。我々のアプローチを、離散変数と連続変数の両方からなるハイブリッド空間で最適化する、最近提案されたEMのような推論手順(Shu et al., 2020)と比較する。WMT'14 En-De、WMT'16 Ro-En、IWSLT'16 De-Enにおいて我々の手法を評価し、EM-likeな推論に比べて2つの利点があることを確認した。(1)計算効率が良い、すなわち、各改良ステップが2倍の速さであること、(2)より効果的であり、同じ数の改良ステップでより高い限界確率とBLEUスコアが得られること。例えば、WMT'14 En-Deにおいて、我々のアプローチは、自己回帰モデルよりも6.2倍高速にデコードすることができ、翻訳品質の劣化は最小限（0.9 BLEU）でした。
自己教師付き画像表現学習の新しいアプローチであるBootstrap Your Own Latent（BYOL）を紹介します。BYOLは、オンラインネットワークとターゲットネットワークと呼ばれる2つのニューラルネットワークに依存しており、これらのニューラルネットワークは相互に作用し、互いに学習する。画像の拡張ビューから、オンラインネットワークを訓練し、異なる拡張ビューの下で同じ画像のターゲットネットワーク表現を予測します。同時に、オンラインネットワークのゆっくりとした動きの平均値でターゲットネットワークを更新します。最先端の手法は負のペアに依存していますが、BYOLは負のペアなしで新たな状態を達成しました。BYOLは、ImageNetにおいて、ResNet-50アーキテクチャを用いた線形評価で74.3%のトップ1分類精度を達成し、より大きなResNetでは79.6%を達成した。BYOLは、転送型および半教師型のベンチマークにおいて、現在の技術水準と同等以上の性能を発揮することを示している。BYOLの実装と事前学習済みモデルはGitHubに掲載されています。
画像の異常検出（Anomaly Detection: AD）は、コンピュータビジョンの基本的な問題であり、通常の状態から大きく逸脱した画像や画像の部分構造を識別することを指します。一般的なADアルゴリズムは、タスクに特化したデータセットを用いて正常性のモデルをゼロから学習しようとしますが、異常が大規模にアクセスできないことや、異常の出現が曖昧であることから、ほとんどが正常なデータを用いた半教師付きのアプローチに限られています。本研究では、別のアプローチで、大規模な自然画像データを用いた識別モデルによって学習された深い特徴表現が、正常性を記述し、伝達学習の設定で微妙な異常を検出するのに適していることを示します。正規性のモデルは、ImageNet上で正規データのみを用いて学習した分類ネットワークの深層特徴表現に、多変量ガウス（MVG）を当てはめることで確立されます。続いて、異常スコアとしてマハラノビス距離を適用することで、MVTec ADデータセットにおいて、15のクラスすべてでAUROC値95.8\1.2(mean ˶˙º̬˙º̬˙º)を達成し、現在の技術水準を上回る結果を得ました。さらに、主成分分析を用いて、学習した表現がなぜADタスクに対して識別性があるのかを調べた。その結果、正常なデータに含まれる分散の少ない主成分が、正常な事例と異常な事例を識別するのに重要な成分であることがわかりました。このことは、正常なデータのみを用いてゼロから学習したADアプローチの性能が低いことの説明になります。これらの最も関連性の高い成分のみにMVGを選択的にフィットさせることで、ADの性能を維持しつつ、モデルの複雑さをさらに軽減することができます。また、MVGの仮定に基づいて、許容可能な偽陽性率のしきい値を選択することで、作業ポイントを設定することを検討します。コードはこのhttpsのURLから入手可能
文書内の任意の位置にあるテキストの欠落部分を予測するタスクであるテキスト・インフィリングのためのシンプルなアプローチを紹介します。インフィリングは、特に文章作成支援ツールにおいて豊富な機能を実現できる可能性があるが、言語モデリング（インフィリングの特別なケースである、文書の最後にテキストを予測する）に多くの注目が集まっている。本論文では、言語モデル（LM）の能力を、より一般的なタスクであるインフィリングに拡張することを目的としている。この目的のために、人為的にマスクされたテキストとマスクされたテキストを結合したシーケンスに対して、市販のLMを訓練（または微調整）した。この手法を「言語モデリングによる埋め合わせ」と呼び、短編小説、科学論文、歌詞の3つの異なるドメインにおいて、LMが文章全体を効果的に埋め合わせることができることを示す。さらに、短編小説の領域では、我々のアプローチによって埋められた文章を機械的に生成されたものと人間が識別することは困難であることを示す。
また、変換器ベースの言語モデルを定理証明の自動化に応用することを検討しています。この研究は、人間と比較した自動定理証明器の主な限界である、オリジナルの数学用語の生成が、言語モデルからの生成によって対処可能になる可能性があることに動機づけられている。本研究では、形式化言語Metamathのための自動証明器および証明アシスタントGPT-fを開発し、その性能を分析した。GPT-fは、Metamathライブラリに採用された新しい短い証明を発見しました。これは、我々の知る限り、深層学習ベースのシステムが、形式数学コミュニティに採用された証明を提供した初めての例です。
BERTのような大規模なニューラル言語モデルを事前に訓練することで、多くの自然言語処理（NLP）タスクにおいて目覚ましい成果を上げています。しかし、ほとんどの事前学習の取り組みは、ニュースワイヤーやウェブなどの一般的なドメインコーパスに焦点を当てています。一般的な前提として、ドメインに特化した事前トレーニングであっても、一般的なドメインの言語モデルから始めることで利益を得ることができると考えられています。本稿では、生物医学のようにラベルのないテキストが豊富にあるドメインでは、言語モデルをゼロから事前学習することで、一般ドメインの言語モデルを継続的に事前学習するよりも大きな利益が得られることを示すことで、この仮定に挑戦します。この研究を促進するために，我々は一般に公開されているデータセットから包括的な生物医学NLPベンチマークを作成した．実験の結果，ドメイン固有の事前学習は，幅広い生物医学NLPタスクのための強固な基盤となり，全体的に最先端の結果をもたらすことがわかった．さらに、事前学習とタスク固有の微調整の両方におけるモデリングの選択を徹底的に評価した結果、名前付きエンティティ認識（NER）で複雑なタグ付けスキームを使用するなど、BERTモデルでは不要な一般的な手法があることを発見しました。生物医学NLPの研究を促進するために、私たちは最先端の事前学習済みモデルとタスク固有のモデルをコミュニティに公開し、BLURBベンチマーク（Biomedical Language Understanding & Reasoning Benchmarkの略）をフィーチャーしたリーダーボードをこのhttpsのURLに作成しました。
私たちは、新しいフローベースのビデオ補完アルゴリズムを発表します。これまでのフロー補完法では、動きの境界の鋭さを維持できないことが多い。本手法では，まずモーションエッジを抽出して補完し，それを用いてシャープなエッジを持つ断片的で滑らかなフロー補完を導く．既存の手法では、隣接するフレーム間の局所的なフローのつながりに色を伝搬させる。しかし、この方法では、動画内のすべての欠落領域に到達することはできません。なぜなら、動きの境界線が不可解な障壁を形成しているからです。我々の手法は、時間的に離れたフレームに非局所的なフロー接続を導入することでこの問題を軽減し、動きの境界を越えてビデオコンテンツを伝播することを可能にする。この手法をDAVISデータセットで検証しました。視覚的、定量的な結果から、我々の手法は最先端のアルゴリズムと比較して良好な結果が得られた。
本論文では、TAL（Temporal Action Localization）のための中間的な監督形式、すなわち、シングルフレーム監督について研究する。シングルフレーム監督を得るためには、アノテーターはアクションの時間的ウィンドウ内の単一フレームのみを識別するように求められる。これにより、アクションの境界をアノテーションする必要のある完全なスーパーバイズメントを得るための労力を大幅に削減することができる。ビデオレベルのラベルをアノテーションするだけの弱いスーパーバイズと比較して、シングルフレームスーパーバイズは、アノテーションのオーバーヘッドを低く抑えながら、時間的なアクション信号を追加で導入する。このようなシングルフレーム監視を最大限に利用するために、我々はSF-Netと呼ばれる統合システムを提案する。まず、我々は各ビデオフレームのアクションネススコアを予測することを提案する。アクションネス・スコアは、典型的なカテゴリ・スコアとともに、潜在的なアクションの発生に関する包括的な情報を提供し、推論中の時間的境界の精密化を助けることができる。次に、単一フレームのアノテーションに基づいて、疑似アクションフレームと背景フレームをマイニングする。疑似アクションフレームは、アノテーションされた各シングルフレームを、その近くにある文脈上のフレームに適応的に展開することで特定し、背景フレームは、複数の動画に含まれるアノテーションされていないすべてのフレームから、疑似背景フレームを抽出する。これらの疑似ラベル付けされたフレームは、グランドトゥルースのラベル付けされたフレームと合わせて、分類器の学習に使用されます。THUMOS14、GTEA、BEOIDを用いた大規模な実験において、SF-Netは、セグメント・ローカライゼーションとシングル・フレーム・ローカライゼーションの両方において、最新の弱い教師付き手法を大幅に改善しました。特に、SF-Netは、より多くのリソースを必要とするアノテーションを必要とする完全教師付きの手法と同等の結果を達成しています。コードはこの https URL で公開されています。
本論文では，動画間の視覚的対応関係を抽出するタスクに注目する．アクションクラスのクエリビデオクリップが与えられたとき、それをトレーニングビデオと空間的、時間的に一致させることを目的としている。このような細かいアライメントタスクのためのトレーニングデータを得ることは困難であり、しばしば曖昧である。そこで我々は、クロスビデオサイクルコンシステンシーを用いて、空間と時間の対応関係を学習する新しいアライメント手順を提案する。学習の際、2つのビデオが与えられると、第1のビデオの所定のフレーム内のパッチを、第2のビデオのフレームを介してマッチングすることで接続するサイクルを計算する。重なっているパッチを繋ぐサイクルは、重なっていないパッチを繋ぐサイクルよりも高いスコアが得られるようになっている。Penn ActionとPouringのデータセットを用いた実験では、提案手法がビデオ間で意味的に類似したパッチを対応させることをうまく学習でき、物体やアクションの状態に敏感な表現を学習できることが示された。
Generative Adversarial Network（GAN）は、様々なコンピュータビジョンアプリケーションで人気を博しており、最近ではリソースに制約のあるモバイル機器にも導入され始めています。他の深層モデルと同様に、最先端のGANは高いパラメータの複雑さに悩まされています。そのため、最近ではGAN（通常は生成器）を圧縮することが検討されています。深層分類器の圧縮に関する膨大な文献と一般的な成功に比べて、GANの圧縮に関する研究はまだ初期段階にあり、より洗練された組み合わせではなく、個々の圧縮技術を活用しています。我々は、GANの学習は不安定であることが知られているため、異なる圧縮技術を直感的に積み重ねても満足のいく結果は得られないと考えています。そこで我々は、GAN圧縮のために複数の圧縮手段を組み合わせた初の統一的な最適化フレームワークを提案し、GANスリミング（GS）と名付けました。GSは、モデル蒸留、チャネル・プルーニング、量子化という3つの主流の圧縮技術を、GANミニマックス目的とともに、1つの統一された最適化形式にシームレスに統合し、最後から最後まで効率的に最適化することができる。その結果、GSは画像間変換GANの圧縮において、既存の手法を大幅に上回る結果を得ることができました。具体的には、GSを用いて、最先端のスタイル変換ネットワークであるCartoonGANを、画質の劣化を最小限に抑えながら、最大47倍に圧縮しました。コードと事前に学習されたモデルは、このhttpsのURLで見ることができます。
適切な誘導バイアスを持つことは、データやコンピューティングリソースが制限要因となる場合や、トレーニングデータがテスト時の条件を完全には代表していない場合など、多くのタスクやシナリオにおいて重要となります。しかし，帰納的バイアスを定義し，設計し，効率的に適応させることは，必ずしも容易ではありません．本論文では、帰納的バイアスの効果をあるモデルから別のモデルに移すための、知識の蒸留の力を探ります。適切な誘導バイアスを持つことが重要となるタスクやシナリオの文脈で、LSTMとTransform、CNNとMLPという異なる誘導バイアスを持つモデル群を検討します。モデルが収束する解に対する帰納的バイアスの効果を調べ、帰納的バイアスの効果が知識の蒸留を通じてどのように、またどの程度まで伝達されるかを、性能だけでなく収束した解の様々な側面から調査します。
自己教師付き表現学習では、ラベル付きデータを必要としない補助的な予測タスク（プレテキストタスクと呼ばれる）を解決して、意味的表現を学習する。これらのプレテキストタスクは、画像パッチの欠落の予測、文脈からの画像のカラーチャンネルの復元、単語の欠落の予測など、入力特徴のみを用いて作成されるが、この既知の情報を予測することで、下流の予測タスクに有効な表現の学習に役立つ。本論文では、条件付き独立性に基づくメカニズムを仮定し、ある種のプレテクストタスクを解くことで、下流の教師付きタスクのサンプルの複雑さを証明的に減少させる表現を学習する方法を公式化する。形式的には、口実タスクの構成要素間の近似独立性（ラベルと潜在変数の条件付き）により、学習した表現の上に線形層を学習するだけで、サンプルの複雑さを大幅に減少させて下流のタスクを解くことができる表現を学習できることを定量化する。
深層学習、変分推論、その他多くの分野の成功は、メガ次元の目的の勾配を計算するための逆モード自動微分（AD）の特殊な実装によって支えられています。これらのツールの基盤となっているAD技術は、数値精度で正確な勾配を計算するように設計されていますが、現代の機械学習モデルはほとんどの場合、確率的勾配降下法で学習されています。確率的最適化のためだけに、厳密な（ミニバッチ）勾配に計算とメモリを費やす必要があるのでしょうか？私たちは、ランダム化自動微分法（RAD）の一般的なフレームワークとアプローチを開発しました。RADは、分散と引き換えに、メモリを減らして不偏の勾配推定値を計算することができます。一般的なアプローチの限界を検討し、利点を実現するためには問題特有の構造を活用する必要があることを主張する。本論文では、様々な単純なニューラルネットワークアーキテクチャに対するRAD技術を開発し、固定のメモリバジェットに対して、フィードフォワードネットワークでは小さなバッチサイズを使用するよりも少ない反復回数で収束し、リカレントネットワークでも同程度の回数で収束することを示す。また、RADは科学計算にも応用できることを示し、核分裂炉を表す線形反応拡散PDEの制御パラメータを最適化するための低メモリ確率的勾配法の開発にも使用しています。
言語モデルがより強力になるにつれ、学習と評価は、特定のタスクに使用されるデータとメトリックによってますますボトルネックになっています。例えば、要約モデルは、人間の参考文献の要約を予測するように学習され、ROUGEを用いて評価されることが多いが、これらの指標はどちらも我々が本当に気にしている要約の品質に対する大まかな代用である。本研究では、人間の好みを最適化するようにモデルを訓練することで、要約の質を大幅に向上させることが可能であることを示す。我々は、人間が要約を比較した大規模で高品質なデータセットを収集し、人間が好む要約を予測するモデルを訓練し、そのモデルを報酬関数として使用し、強化学習を用いて要約ポリシーを微調整する。我々の手法をRedditのTL;DRデータセットに適用したところ、我々のモデルは、人間が参照する要約や、教師付き学習のみで微調整された大規模なモデルを大幅に上回ることがわかった。また、我々のモデルはCNN/DMのニュース記事にも適用され、ニュースに特化した微調整を行わなくても、人間のリファレンスとほぼ同等の要約を作成することができました。我々は、人間のフィードバックデータセットと微調整されたモデルを理解するために広範な分析を行い、我々の報酬モデルが新しいデータセットに一般化すること、そして我々の報酬モデルを最適化することで、人間に合わせてROUGEを最適化するよりも優れた要約が得られることを立証しました。この論文から得られた証拠によって、機械学習の研究者が、学習損失が実際に望むモデルの動作にどのように影響するかに、より注意を払うようになることを期待しています。
本論文では、データ密度の勾配を推定する波形生成の条件付きモデルであるWaveGradを紹介します。このモデルは、スコアマッチングと拡散確率モデルに関する先行研究に基づいて構築されている。このモデルは、ガウスホワイトノイズ信号から始まり、メルスペクトログラムを条件とした勾配ベースのサンプラーを介して、信号を反復的に改良する。WaveGradは、洗練されたステップの数を調整することで、推論速度とサンプル品質を自然に交換する方法を提供し、オーディオ品質の点で、非自動回帰モデルと自動回帰モデルの間のギャップを埋めます。わずか6回のイテレーションで、忠実度の高いオーディオサンプルを生成できることがわかりました。実験の結果、WaveGradは、少ない逐次処理で、敵対的な非自動回帰モデルのベースラインを上回り、強力な尤度ベースの自動回帰モデルのベースラインにマッチする、忠実度の高いオーディオを生成できることがわかりました。オーディオのサンプルはこちらのhttpsのURLでご覧いただけます。
本作品では、新しいネットワーク設計のパラダイムを提示しています。本研究の目的は、ネットワーク設計の理解を深め、様々な環境で一般化する設計原理を発見することです。個々のネットワークインスタンスの設計に焦点を当てるのではなく、ネットワークの集団をパラメトリックに表現するネットワーク設計空間を設計する。全体的なプロセスは、古典的な手作業によるネットワークの設計に類似していますが、設計空間レベルにまで高めています。我々の方法論を用いて、ネットワーク設計の構造的側面を探り、RegNetと呼ぶ単純で規則的なネットワークからなる低次元の設計空間に到達した。 RegNetのパラメトリック化の中核となる洞察は驚くほど単純なもので、良いネットワークの幅と深さは量子化された線形関数で説明することができる。RegNetの設計空間を分析したところ、現在のネットワーク設計の慣行とは一致しない興味深い発見がありました。RegNetのデザインスペースは、幅広いフロップレジームでうまく機能するシンプルで高速なネットワークを提供します。RegNetモデルは、同程度の学習設定とフロップの下では、一般的なEfficientNetモデルを上回り、GPUでは最大5倍の速度を実現します。
本論文では、X3Dを紹介します。これは、小さな2D画像分類アーキテクチャを、空間、時間、幅、深さといった複数のネットワーク軸に沿って段階的に拡張する、効率的なビデオネットワークのファミリーです。機械学習における特徴選択法にヒントを得て、シンプルなステップ式ネットワーク拡張アプローチを採用し、各ステップで1つの軸を拡張することで、精度と複雑さの良好なトレードオフを実現している。X3Dを特定の目標の複雑さに拡張するために、プログレッシブフォワードエキスパンションとバックワードコントラクションを行います。X3Dは、最先端の性能を達成する一方で、以前の研究と同様の精度を得るために必要な乗算加算とパラメーターは、4.8倍と5.5倍少なくなっています。最も驚くべき発見は、高い時空間分解能を持つネットワークが、ネットワークの幅やパラメーターを非常に軽くしながら、優れた性能を発揮できることです。ビデオの分類と検出のベンチマークにおいて、これまでにない効率で競争力のある精度を報告する。コードは以下のURLで公開されます：このhttpsのURL
注意メカニズムは、ディープニューラルネットワークの一般的なコンポーネントとなっていますが、異なる影響因子や、これらの因子から注意を計算する方法がどのように性能に影響するかについては、ほとんど検討されていません。本研究では、注目メカニズムの一般的な理解を深めるために、一般化された注目方式の中で、様々な空間的な注目要素を消去する実証研究を行いました。この研究では、様々なアプリケーションを用いて、ディープネットワークにおける空間的注意について、従来の理解とは異なる重要な知見を得ました。例えば、Transformerの注意におけるクエリとキーコンテンツの比較は、自己注意では無視できますが、エンコーダとデコーダの注意では不可欠であることがわかりました。また、変形可能な畳み込みとキーコンテンツのみの強調表示を適切に組み合わせることで、自己注意における精度と効率のトレードオフを最良のものにすることができる。この結果は、注意メカニズムの設計には改善の余地があることを示唆しています。
ゲームの難易度を動的に調整する方法は、特定のプレイヤーに合わせてゲームを調整し、プレイヤーの興味を最大限に引き出すことができます。しかし、現在の手法では、対戦相手の難易度や資源の有無など、限られたゲームの特徴しか変更できないことが多い。一方、経験に基づくプロシージャルコンテンツ生成（Procedural Content Generation: PCG）は、難しすぎず簡単すぎないレベルなど、望ましい特性を持つ完全なレベルを生成することができるが、多くの反復作業が必要となる。本論文では、特定の目標難易度を持つ完全なレベルをわずか数回の試行で生成・検索できる手法を紹介する。これを可能にするのは、もともとロボットが素早く適応するために開発された「知的試行錯誤アルゴリズム」である。このアルゴリズムでは、まず、リニエンシーやマップカバレッジなど、あらかじめ定義された次元で変化するさまざまなレベルを作成します。この情報を用いて、ベイズ最適化手順を展開し、事前のマップの難易度をエージェントの能力を反映して更新します。この手法は、様々なプランニングエージェントのスキルランドスケープを理解しながら、わずか数回の試行で特定の目標難易度を持つレベルを確実に見つけることができる。
深層生成モデルのための既存の離接手法は、手で選んだプライヤーと複雑なエンコーダベースのアーキテクチャに依存している。本論文では、生成モデルの入力に対するヘシアンが対角線になるように促す単純な正則化項である「ヘシアン・ペナルティ」を提案する。この正則化項は、入力に対する生成モデルのヘシアンが対角線になるように促す単純な正則化項であり、学習時に効率的に計算するために、Hutchinsonの推定量に基づいた、モデルに依存しない不偏の確率的近似を導入する。我々の手法は、わずか数行のコードで、様々なディープジェネレーターに適用することができる。我々は、いくつかのデータセットでProGANに適用したところ、Hessian Penaltyを用いた学習により、潜在空間に軸合わせの離接がしばしば現れることを示した。さらに、我々の正則化項を用いて、教師なしでBigGANの潜在空間に解釈可能な方向を特定する。最後に、過度にパラメータ化された潜在空間に適用した場合、ヘシアン・ペナルティが実質的な縮小を促すという経験的な証拠を提供する。
因果モデルは、すべての介入の下でのデータ生成プロセスをコンパクトかつ効率的にエンコードすることができ、したがって、分布の変化の下でよりよく一般化することができる。これらのモデルはベイジアンネットワークとして表現されることが多く、変数の数に応じた学習効果は期待できない。さらに、これらのアプローチでは、過去に学習した知識を新しい因果モデルの学習に役立てることができない。これらの課題に取り組むために、我々は、因果関係モデルを学習するための ˶˙º̬˙˶ (CRN)という新しいアルゴリズムを提案する。(CRN)と呼ばれる、ニューラルネットワークを用いた因果関係モデルの学習アルゴリズムを提案する。CRNは、連続的な表現を用いて因果モデルを表現するため、変数の数が増えても十分に対応できる。また、これらのモデルは、新しい因果モデルの学習を促進するために、過去に学習した情報を取り込むことができる。最後に、連続的な表現を用いた因果モデルを評価するために、デコーディングに基づく指標を提案する。本研究では、合成データを用いて本手法を検証し、高い精度と、以前に見たことのない因果モデルへの迅速な適応を達成した。
超解像は、与えられた低解像度の画像に対して複数の予測が可能であるため、課題の多い問題である。この基本的な事実は、最新の深層学習に基づくアプローチではほとんど無視されています。これらの手法は、代わりに再構成と敵対的損失の組み合わせを使用して決定論的マッピングを訓練する。そこで本研究では、SRFlowを提案する。これは、低解像度の入力が与えられたときの出力の条件付き分布を学習できる、正規化フローに基づく超解像法である。我々のモデルは、単一の損失、すなわち負の対数尤度を用いて原理的に学習される。そのため、SRFlowは、問題の非重畳的な性質を直接考慮し、多様なフォトリアリスティックな高解像度画像の予測を学習します。さらに、SRFlowが学習した強力な画像の後処理を利用して、他の画像からコンテンツを転送するなどして超解像画像を強化することができる柔軟な画像操作技術を設計します。SRFlowは、顔を対象とした大規模な実験を行いました。また、一般的な超解像についても実験を行いました。SRFlowは、超解像の空間を探索することで多様性を持たせつつ、PSNRと知覚品質の両方の指標において、最先端のGANベースのアプローチを凌駕する。
最近の研究では、自己注意が画像認識モデルの基本的な構成要素として役立つことが示されています。本研究では、自己注視のバリエーションを探り、画像認識におけるその有効性を評価する。自己注意には2つの形式があります。1つはペアワイズ自己注意で、これは標準的なドットプロダクト注意を一般化したもので、基本的には集合演算子です。もう1つはパッチワイズ自己注意で、これは厳密にはコンボリューションよりも強力です。我々のペアワイズ自己注意ネットワークは、畳み込みモデルと同等かそれ以上の性能を示し、パッチワイズモデルは、畳み込みベースラインを大幅に上回る。また、学習した表現の頑健性を調べる実験を行い、自己注意ネットワークは、頑健性と一般性の点で大きな利点があると結論付けた。
本研究では、大規模なラベルなしのビデオデータからビデオ表現を学習する新しい手法を提案する。理想的には、この表現は、一般的で移植可能であり、行動認識やゼロショットまたは数ショットの学習などの新しいタスクに直接使用することができる。本研究では、教師なし表現学習をマルチモーダル・マルチタスク学習問題として定式化し、表現を蒸留によって異なるモーダル間で共有する。さらに、進化的探索アルゴリズムを用いて損失関数の進化の概念を導入し、多くの（自己教師付き）タスクとモダリティを取り込む損失関数の最適な組み合わせを自動的に見つける。第三に、Zipfの法則に基づき、事前制約として大規模なラベルなしデータセットへの分布マッチングを用いた、教師なし表現評価指標を提案する。この教師なしの制約は、ラベル付けによって導かれるものではなく、弱い教師付きのタスクに特化したものと同様の結果を得ることができる。提案された教師なし表現学習は、単一のRGBネットワークで結果を出し、以前の手法よりも優れている。注目すべきは、大規模で完全にラベル付けされたビデオデータセットを除いて、いくつかのラベルベースの手法（ImageNetなど）よりも効果的であることだ。
畳み込みは局所性を利用して効率化を図るが、その代償として長距離の文脈が欠落する。セルフアテンションは、CNNに非局所的なインタラクションを追加するために採用されている。最近の研究では、注意を局所領域に制限することで、自己注意層を重ねて完全な注意ネットワークを得ることが可能であることが証明されている。この論文では、2次元の自己注意を2つの1次元の自己注意に因数分解することで、この制約を取り除くことを試みています。これにより、計算の複雑さを軽減し、より大きな、あるいはグローバルな領域で注意を実行することができる。併せて、位置に敏感な自己注意のデザインも提案しています。両者を組み合わせることで、位置に敏感な軸方向の注意層が得られる。これは、画像分類や高密度予測のための軸方向の注意モデルを形成するために積み重ねることができる新しいビルディングブロックである。本研究では、4つの大規模データセットを用いて、本モデルの有効性を実証した。特に、ImageNetにおいて、我々のモデルは、既存のスタンドアローンの自己注意モデルよりも優れている。また、COCO test-devにおいて、我々のAxial-DeepLabは、ボトムアップ型の最先端モデルよりもPQを2.8%向上させました。この最先端は、パラメータ効率が3.8倍、計算効率が27倍の小型モデルによって達成されています。Axial-DeepLabは、「Mapillary Vistas」と「Cityscapes」でも最先端の結果を出しています。
BERTのような事前に学習された言語モデルは、自然言語理解（NLU）における多くのタスクで顕著な性能を発揮しています。このモデルのトークンは、英語などの言語では単語またはサブワード、中国語などの言語では文字という意味で、通常は細かく設定されています。例えば、英語では、自然な語彙単位を形成する複数の単語表現があるため、粗い粒度のトークン化を使用することも合理的であると考えられます。実際、細粒度トークン化も粗粒度トークン化も、事前に学習した言語モデルの学習にはメリットとデメリットがあります。本論文では、細粒度トークン化と粗粒度トークン化の両方に基づいて、AMBERT（A Multi-grained BERT）と呼ばれる新しい事前学習済み言語モデルを提案しています。AMBERTは、英語の場合、トークン化後の単語の列（細粒度トークン）とフレーズの列（粗粒度トークン）の両方を入力とし、単語の列の処理には1つのエンコーダを、フレーズの列の処理にはもう1つのエンコーダを使用し、2つのエンコーダ間で共有されるパラメータを利用して、最終的に単語の文脈表現の列とフレーズの文脈表現の列を作成します。実験は、CLUE、GLUE、SQuAD、RACEなど、中国語と英語のベンチマークデータセットで行われました。その結果、AMBERTはすべてのケースでBERTを上回ることができ、特に中国語ではその改善が顕著であることがわかりました。また、推論におけるAMBERTの効率を向上させる手法を開発し、BERTと同じ計算コストで依然としてBERTよりも優れた性能を発揮しています。
データベースへの自然言語インターフェース（NLIDB）は、リレーショナルデータへのエンドユーザーのアクセスを民主化します。自然言語によるコミュニケーションとプログラミングの基本的な違いにより、エンドユーザがシステムにとって曖昧な質問をしたり、基礎となる問い合わせ言語の意味的範囲外の質問をしたりすることはよくあることです。Photonは、自然言語入力に対してSQLマッピングを即座に決定できないようなフラグを立てることができる、堅牢でモジュール式のクロスドメインNLIDBです。Photonは、強力なニューラル・セマンティック・パーサ（Spider devベンチマークで63.2%の構造精度）、ヒューマン・イン・ザ・ループの質問補正器、SQL実行器、応答生成器から構成されています。質問補正器は、入力された質問に含まれる混乱の範囲を検出し、ユーザーが翻訳可能な入力を与えるか、または最大数の反復を行うまで、言い換えを提案する識別的なニューラルシーケンスエディターです。模擬データを用いた実験により、提案手法が翻訳不可能なユーザー入力に対するtext-to-SQLシステムの堅牢性を効果的に向上させることが示された。我々のシステムのライブデモは、このhttpのURLで見ることができます。
既存のゼロショット学習法の多くは、この問題を視覚的な意味の埋め込みとみなしています。本研究では、Generative Adversarial Networks(GAN)が画像を生成できることが実証されていることから、GANを活用してテキストの説明から見たことのないカテゴリを想像し、例を見たことのない新しいクラスを認識する。具体的には、未知のクラスに関するノイズの多いテキスト記述（例：Wikipediaの記事）を入力とし、このクラスのための合成された視覚的特徴を生成する、シンプルかつ効果的な生成モデルを提案する。疑似データを追加することで、ゼロショット学習は伝統的な分類問題に自然に変換されます。さらに，生成された特徴量のクラス間の識別性を維持するために，視覚的ピボット正則化を明示的な監督として提案する．複雑に設計された正則化を用いる従来の手法とは異なり、我々のアプローチは、追加の正則化なしにノイズをうまく抑制することができる。経験的には、テキストベースのゼロショット学習に関する最大規模のベンチマークにおいて、本手法が一貫して最新の技術を上回ることを示している。
既存の半教師付き学習（SSL）アルゴリズムは、ラベル付きの例とラベルなしの例の損失のバランスをとるために、単一の重みを使用しています。しかし、すべてのラベルなしデータが等しいわけではない。この論文では、ラベルのない例ごとに異なる重みを使用する方法を研究しています。先行研究で行われていた、すべての重みを手動で調整することは、もはや不可能です。その代わりに、モデルの訓練例への依存度を示す影響関数に基づいたアルゴリズムによって重みを調整する。このアプローチを効率化するために，影響関数の高速かつ効果的な近似法を提案する．この手法は、半教師付きの画像および言語分類タスクにおいて、最先端の手法よりも優れていることを実証した。
データ補強は、分類器の精度とロバスト性を向上させるために広く研究されている。しかし、画像合成のためのGANモデルの改良における画像補強の可能性については、これまでの研究では十分に検討されていない。本研究では、様々な設定でGANトレーニングのための様々な既存の補強技術の有効性を体系的に研究します。バニラGANと正則化を用いたGANの両方について、画像を補強する方法についての洞察とガイドラインを提供し、生成された画像の忠実度を大幅に向上させます。驚くべきことに、実画像と生成画像の両方に正則化を用いれば、バニラGANでも最近の最先端の結果と同等の生成品質が得られることがわかりました。このGAN学習を、コントラスト損失や一貫性正則化など、他の補強に基づく正則化技術と組み合わせると、補強によって生成画像の品質がさらに向上します。一貫性損失とコントラスト損失の両方を追加正則化として用いたCIFAR-10の条件付き生成について、新たに最先端の結果を提供します。
近年の深層学習は、囲碁で人間に勝利したり、画像認識や音声認識、翻訳などのタスクで世界をリードする性能を発揮したりと、成果を挙げてきました。しかし、このような進歩には、膨大な計算能力を必要とします。この記事では、5つの著名なアプリケーション分野におけるDeep Learningアプリケーションの計算需要について報告し、5つの分野の進歩がすべてコンピューティングパワーの増加に強く依存していることを示します。この依存度を外挿すると、現在の路線での進歩は、経済的にも技術的にも環境的にも急速に維持できなくなることがわかります。したがって、これらのアプリケーションを継続的に発展させていくためには、飛躍的に計算効率の高い手法が必要となります。そのためには、深層学習に変更を加えるか、他の機械学習手法に移行する必要があります。
ビジュアルダイアログに関する先行研究では、VisDial上でディープニューラルモデルを単独でトレーニングすることに焦点が当てられています。その代わりに、ビジュアル・ダイアログに移行する前に、関連する視覚言語データセットでの事前学習を活用するアプローチを提示しています。我々は、最近提案されたViLBERT（Lu et al., 2019）モデルをマルチターンの視覚的に接地された会話に適応させる。我々のモデルは、Conceptual CaptionsとVisual Question Answeringのデータセットでプレトレーニングされ、VisDialで微調整される。我々の最良の単一モデルは、先行研究（モデルアンサンブルを含む）よりもNDCGとMRRで1%以上の絶対値で上回った。次に、VisDialで「高密度」のアノテーションを用いて微調整を行うと、NDCGはベースモデルよりも10%以上高くなるが、MRRはベースモデルよりも17%以上低くなることがわかりました。これは、NDCGとMRRという2つの主要な指標の間にトレードオフがあることを示しています。これは、密なアノテーションが質問に対する元のグランドトゥルースの回答とうまく相関していないことが原因であると考えられます。
クエリ拡張は、画像検索で広く使われている手法で、元のクエリから高いランクの画像を組み合わせて拡張クエリを作成し、それを再発行することで、一般的にリコールと精度を向上させることができます。クエリ拡張の重要な側面は、画像を新しいクエリに結合する適切な方法を選択することです。興味深いことに、クエリ展開が経験的に成功していることは否定できませんが、様々な注意点を持つアドホックな手法が主流であり、クエリ展開の方法を学ぶための研究はあまり行われていませんでした。本論文では、より原理的なクエリ拡張のフレームワークを提案する。ここでは、拡張されたクエリを形成するためにどのように画像を集約すべきかを学習するモデルを、識別的な方法で学習する。このフレームワークでは、自己注意メカニズムを利用して、異なる画像間の情報伝達方法を効果的に学習するモデルを提案している。我々のアプローチは、標準的なベンチマークにおいて、既存のアプローチよりも高い精度を得ることができる。さらに重要なことに、我々のアプローチは、既存の手法の注意点を克服し、異なる体制下で一貫して高い精度を示す唯一の手法である。
教師付きディープネットワークは、ステレオ画像ペアの対応関係を見つけるための最良の手法の一つです。他の教師付きアプローチと同様に、これらのネットワークは学習時にグランドトゥルースデータを必要とします。しかし、正確で高密度な対応関係のデータを大量に収集することは非常に困難です。我々は、グランドトゥルースの深さや、対応するステレオペアにこれほどまでに依存する必要はないことを提案する。最近の単眼深さ推定の進歩にヒントを得て，我々は単一の画像からもっともらしい視差マップを生成する．さらに、それらの欠陥のある視差マップを、慎重に設計されたパイプラインで使用して、ステレオトレーニングペアを生成します。このようにしてトレーニングを行うことで、RGBの単一画像の集合体をステレオトレーニングデータに変換することができます。これにより、実際の深度を収集したり、手作業で合成データを作成したりする必要がなく、人手を大幅に削減することができます。その結果，COCOのような，これまでステレオでの利用が難しかったデータセットにおいて，ステレオマッチングネットワークをゼロからトレーニングすることができます．広範な実験を通して、我々のアプローチは、KITTI、ETH3D、Middleburyで評価した場合、標準的な合成データセットで訓練されたステレオネットワークよりも優れていることを示している。
グラフ内の分散ノード表現を学習するためのスケーラブルで高性能なアルゴリズムであるFastRPを紹介します。FastRPは、DeepWalkやnode2vecなどの最先端の手法に比べて4,000倍以上高速であるが、実世界のネットワークを用いて様々なダウンストリームタスクで評価した結果、同等またはそれ以上の性能を達成している。ほとんどのネットワーク埋め込み手法は、ノードの類似性行列を構築し、この行列に次元削減技術を適用するという2つの要素で構成されていることがわかった。これらの手法の成功は、採用されている次元削減手法ではなく、この類似性行列の適切な構築に起因するものであることを示している。ネットワーク埋め込みのためのスケーラブルなアルゴリズムとしてFastRPを提案する。FastRPの主な特徴は次の2点である。1) グラフ内の推移関係を把握するためのノード類似性行列を明示的に構築し、ノードの度数に基づいて行列のエントリを正規化する。この2つの設計方法を組み合わせることで、ノードの埋め込みを繰り返し計算することができ、類似性行列を明示的に構築する必要がないため、FastRPをさらに高速化することができます。また、FastRPは、実装、並列化、ハイパーパラメータの調整が容易であるという利点もあります。ソースコードはこちらのhttps URLで公開されています。
機械学習は一般化という概念を前提としています。つまり、十分に大きな学習セットで低いエラーを達成したモデルは、同じ分布からの新しいサンプルでもうまく機能するはずです。我々は、データのホワイトニングと2次最適化の両方が、一般化を妨げる可能性があることを示した。一般に，モデルの学習は，データセットのサンプル-サンプル2次モーメント行列に含まれる情報を利用する．一般的なクラスのモデル、すなわち完全連結の第1層を持つモデルでは、この行列に含まれる情報が一般化に利用できる唯一の情報であることを証明する。ホワイトニングされたデータを用いて学習されたモデルや、ある種の二次最適化スキームを用いて学習されたモデルでは、この情報へのアクセスが少なくなり、その結果、一般化能力が低下したり、存在しなくなったりする。これらの予測をいくつかのアーキテクチャで実験的に検証したところ、理論的な要件を緩和しても汎化能力が損なわれないことをさらに実証しました。しかし、正則化された二次最適化を行うことで、実用的なトレードオフが得られることを実験的に示しました。この場合、学習は加速されますが、失われる情報は少なくなり、状況によっては汎化能力が向上することもあります。
本研究では、連続的な状態を持つ最新のホップフィールドネットワークと、それに対応する更新規則を紹介します。この新しいホップフィールドネットワークは、指数関数的に（連想空間の次元に応じて）多くのパターンを記憶することができ、1回の更新でパターンを取り出すことができ、取り出し誤差も指数関数的に小さくなります。また、3種類のエネルギーミニマム（更新の固定点）を持っています。(1)すべてのパターンを平均化したグローバル固定点、(2)パターンのサブセットを平均化した準安定状態、(3)1つのパターンを保存する固定点。この新しい更新ルールは、トランスフォーマーで使われているアテンションメカニズムと等価です。この等価性により、トランスフォーマーモデルのヘッドの特徴を明らかにすることができます。これらのヘッドは、最初の層では好ましくは全体的な平均化を行い、より高い層では準安定状態による部分的な平均化を行います。最新のホップフィールドネットワークは、生の入力データ、中間結果、学習したプロトタイプの保存とアクセスを可能にする層として、深層学習のアーキテクチャに統合することができます。これらのホップフィールド層は、完全連結ネットワーク、畳み込みネットワーク、リカレントネットワークを超える新しい深層学習の方法を可能にし、プーリング、メモリ、アソシエーション、アテンションメカニズムを提供します。私たちは、ホップフィールド層が様々な領域に幅広く適用できることを実証しました。ホップフィールド層は、4つの複数インスタンス学習問題のうち3つの問題、および数十万インスタンスの免疫レパートリー分類で最先端の成果を上げた。また、UCIベンチマークでは、深層学習が苦手とする小規模な分類問題を対象としていますが、ホップフィールド層は、さまざまな機械学習手法と比較して、新たに最先端の結果をもたらしました。最後に，ホップフィールド層は，2つの創薬データセットで最先端の成果を上げました．ホップフィールド層の実装は、以下のURLでご覧いただけます。
子どもたちは、生まれてから数ヶ月以内に、自分を取り巻く世界について意味のある期待を抱くようになります。このような初期の知識は、感覚データに適用される一般的な学習メカニズムでどれくらい説明できるのでしょうか。また、より本質的な生得的バイアスを必要とするものはどれくらいあるのでしょうか。しかし、データ収集技術の向上と最近の深層学習の進展により、高レベルの視覚カテゴリーの開発など、より狭い範囲での進展が期待されています。本論文では、最新の自己教師付き深層学習手法と、3人の幼児の視点から記録された最近の縦断的な自己中心的ビデオデータセット（Sullivan et al.2020）を利用して、まさにそのような進歩を達成することを目的としている。我々の結果は、一般的な自己教師付き学習の目的を用いて、発達段階に応じて現実的な自然のビデオから強力で高レベルの視覚的表現を出現させることを示している。
シングルイメージディレーニングでは、入力画像を、背景画像、透過マップ、雨筋、大気光の融合とみなします。画像の復元（背景画像の生成）のための高度なモデルが提案されているが、それらは透過媒体ではなく、同じ性質を持つ雨筋を背景とみなしている。ベール効果をモデル化するために、蒸気（すなわち、雨筋の蓄積や霧状の雨）が透過マップで伝達されるため、雨筋と蒸気の融合は雨の画像形成を自然に反映しない。本研究では，雨筋を蒸気とともに伝送媒体として再構成し，雨のイメージングをモデル化する．また、雨筋の透過マップを学習するために、SNetと名付けられたエンコーダ・デコーダCNNを提案する。雨筋は様々な形や方向で現れるため、SNet内のShuffleNetユニットを使用して、雨筋の異方性を表現します。蒸気は雨筋によって運ばれてくるので、空間ピラミッドプーリング（SSP）を含むVNetを提案し、雨筋の伝搬マップに基づいて蒸気の伝搬マップを多次元的に予測します。また、ANetと呼ばれるエンコーダCNNを用いて大気光を推定します。SNet、VNet、およびANetは、雨の画像を復元するための透過マップと大気光を予測するために共同で学習されます。ベンチマークデータを用いた広範な実験により，雨の筋や蒸気を予測するための提案された視覚モデルの有効性が実証された．また、提案したディレーニング手法は、最新のディレーニング手法と比較しても良好な結果が得られた。
トランスフォーマーは、様々なタスクで大きな成功を収めており、NLPの新たな主力となっています。LSTMとは異なり、トランスフォーマーは自己注意によって入力配列を処理する。これまでの研究では、階層構造を処理するための自己注意の計算能力には限界があることが示唆されていました。本研究では、形式言語をモデル化するための自己注意の計算能力を数学的に調査した。ソフトアテンションとハードアテンションの両方において、自己注意の計算能力には強い理論的限界があることを示し、入力の長さに応じて層や頭の数が増えない限り、周期的な有限状態の言語や階層構造をモデル化することはできないことがわかった。自己注意の実用的な成功や、言語学において階層構造が重要な役割を果たしていることを考えると、このような限界は驚くべきことであり、理論言語学で一般的に想定されている形式言語には弱すぎるモデルでも、自然言語をうまく近似できることを示唆している。
転移学習は、画像認識タスクで事前に訓練されたディープニューラルネットワークを新しいドメインに適応させるための強力な方法論として登場した。このプロセスは、大規模な特徴が豊富なソースデータセットで事前に訓練されたニューラルネットワークを使用して、本質的な一般的な画像プロパティをエンコードする初期層を凍結し、その後、ターゲットの状況に関連する特定の情報をキャプチャするために最後の数層を微調整することで構成されています。このアプローチは、限られた、あるいは弱いラベル付きのデータしか利用できない場合に特に有効である。本研究では、限られたデータしか利用できない場合に、逆に学習されたモデルは、逆に学習されていないモデルよりも転送効率が良いことを実証した。さらに、敵対的な学習を行うと、学習した表現がテクスチャではなく形状を保持するようになり、ソースモデルの転送性に影響を与えることがわかった。最後に、影響関数のレンズを通して、転送された敵対的なトレーニングを受けたモデルには、人間が識別できる意味情報がより多く含まれていることを発見し、敵対的なトレーニングを受けたモデルがより良く転送される理由を少なくとも部分的に説明することができました。
より多くのデータを使って学習することは、深層学習の時代において、パフォーマンスを向上させる最も安定した効果的な方法です。これまでで最大の物体検出データセットであるOpen Imagesは、一般的かつ高度なシナリオでの物体検出に大きなチャンスと課題をもたらします。しかし、巨大なデータ規模に対応するために半自動の収集とラベリングのパイプラインを採用しているため、Open Imagesデータセットは、オブジェクトが明示的または暗黙的に複数のラベルを持つ可能性があり、ラベル分布が極端に不均衡であるというラベル関連の問題に悩まされています。本研究では、これらのラベル問題を定量的に分析し、シンプルかつ効果的な解決策を提供します。オブジェクト検出におけるマルチラベル問題を処理するために、コンカレントソフトマックスを設計し、ラベルの不均衡に対処するために、ハイブリッドトレーニングスケジューラを用いたソフトサンプリング法を提案する。Open Imagesで公開されている物体検出テストセットにおいて、我々の手法は3.34ポイントの劇的な改善をもたらし、60.90mAPの最高の単一モデルを導き出した。また、アンサンブル結果は67.17mAPを達成し、Open Imagesの公開テスト2018の最良結果を4.29ポイント上回った。
我々は、テニスの試合のアノテーションされた放送映像を、プロのテニスプレーヤーのように振る舞い、登場するインタラクティブに制御可能なビデオスプライトに変換するシステムを発表します。我々のアプローチは、制御可能なビデオテクスチャに基づいており、テニスのラリーの周期的な構造のドメイン知識を利用して、ポイントプレイの重要な意思決定の瞬間にクリップトランジションを配置し、制御入力を受け入れる。最も重要なのは、ビデオコレクションのポイントを利用して、ポイント中のプレーヤーのコート上の位置やショット選択の判断をモデル化することです。これらの行動モデルを用いて、現実のプレイヤーが試合中に取るであろう行動を反映したビデオクリップを選択することで、個々のテニスの動きだけでなく、フルポイントというマクロなレベルでリアルな動作をするスプライトを生成しています。本システムでは、ウィンブルドン中継のようなプロテニスプレイヤー同士の斬新なポイントを生成することができ、現実には対戦していない選手同士の対戦を実現したり、ウィンブルドンの決勝戦で選手をインタラクティブに操作したりといった新しい体験が可能になります。テニスのエキスパートによると、今回の手法で生成されたラリーは、映像合成時のモーション・トランジションの品質のみを考慮したビデオ・スプライト手法に比べて、選手の動作が格段にリアルであるとのことです。
深層強化学習は、ロボットやその環境の正確なモデルを必要とせずに、実世界で複雑なタスクを実行するロボットを訓練できる可能性を秘めています。現実的なアプローチは、シミュレーションでエージェントを訓練し、それを現実世界に移すことです。この方法では、シミュレーションされた環境のさまざまな側面をランダムに変化させることで、訓練されたエージェントを現実とのギャップに強くすることができます。しかし、現実世界に配備されているこのようなエージェントを、タスクパフォーマンス以外の面から理解することはあまり行われていない。本研究では、視覚領域のランダム化を行った場合と行わなかった場合のエージェントの質的・量的な比較を通して、そのようなエージェントを検討する。また、FetchおよびJacoロボット用のエージェントを視覚運動制御タスクで訓練し、異なるテスト条件でどの程度一般化できるかを評価する。最後に、一連の解釈可能な技術を用いて、訓練されたエージェントの内部を調査した。その結果、ドメインランダム化の主な成果は、より強固で絡み合った表現であり、より大きな空間構造を持つ大きな重みを伴うことがわかった。さらに、領域ランダム化エージェントは、より複雑なサンプルを必要とし、オーバーフィットする可能性があり、リカレント処理への依存度が高いことを実証しました。さらに、本研究で導入した改善されたサリエンシー法を用いても、定性的な研究と定量的な測定は必ずしも一致しないことを示し、訓練されたエージェントの行動について十分な洞察を得るためには、検査ツールを組み合わせる必要があることを示しています。
センチメント分析、感情分類、皮肉検出などの感情タスクは、豊富なユーザー生成データ、正確な計算言語モデル、様々なドメインでの幅広い関連アプリケーションのため、近年人気があります。その一方で、自然言語処理の予測モデルや下流のタスクに不可欠なステップとして、テキストの前処理の重要性が多くの研究で強調されています。情動システムにおける前処理はよく研究されていますが、情動システムに適用される単語ベクトルベースのモデルにおける前処理は研究されていません。この限界を解決するために、我々は、単語ベクトルモデルに基づく感情分析における前処理技術の役割について包括的な分析を行います。この分析はこの種のものとしては初めてのものであり、各前処理技術の重要性について、前処理された単語ベクトルモデルでは一般的に無視される学習段階や、下流のタスク段階で適用した場合の有益な洞察を提供する。
人間の注意力にヒントを得て、ニューラルネットワークが入力データの特定の部分に焦点を合わせることができるように、計算機上の注意メカニズムが設計されました。注意メカニズムは解釈可能性を達成すると主張されているが、機械と人間の注意の実際の関係についてはほとんど知られていない。本研究では、テキスト分類タスクにおいて、人間と計算機の注意メカニズムを初めて定量的に評価した。そのために、大規模なクラウドソーシング調査を実施し、テキスト分類を行う際に人間が注目する部分をコード化した人間の注目マップを収集した。公開されているYELPデータセットを用いて収集したテキスト分類用の人間注目度データセット「YELP-HAT」を基に、深層学習モデルによって作成された機械注目度マップと人間注目度マップの定量的な比較分析を行います。この分析により、人間と機械のアテンションマップの関係を、「単語選択の重複」「語彙カテゴリ上の分布」「センチメント極性の文脈依存性」の3つの側面から洞察することができます。この結果は、監督下の注意から、人間中心の注意に基づく説明の設計に至るまで、将来の有望な研究機会を開くものである。
ユーザーの過去の深層学習の経験は、精度にどのような影響を与えるのでしょうか？我々は、異なるレベルの経験を持つ31人の参加者に基づく最初の研究を発表します。彼らのタスクは、与えられた深層学習アーキテクチャのハイパーパラメータ最適化を実行することです。その結果、参加者の経験と最終的なパフォーマンスの間に強い正の相関があることがわかりました。さらに、経験豊富な参加者は、平均して少ないリソースでより良いソリューションを見つけることができることが示されました。さらに、経験のない参加者は、最適なハイパーパラメータを追求する際にランダムな戦略をとることが示唆されました。本研究では、深層学習における最先端の結果と科学的な再現性の比較において、主観的な人的要因を調査しています。
構造化されていないテキスト文書のタイトルを生成する新しい手法を提案します。我々は、問題を逐次的な質問と回答のタスクとして再構成する。深層ニューラルネットワークは、分解可能なタイトルを持つ文書とタイトルのペアで学習されます。これは、タイトルの語彙が文書の語彙のサブセットであることを意味します。モデルの学習には、一般に公開されている数百万の文書-タイトルペア（ニュース記事とヘッドライン）のコーパスを使用します。このモデルを用いて，無作為化二重盲検試験を行ったところ，被験者はどちらのタイトルが人間によって生成されたものか，あるいは機械によって生成されたものかを知ることができなかった．約150万件のニュース記事を対象に学習させたところ、このモデルは、大半の場合、人間が書いたオリジナルの見出しと同等かそれ以上だと人間が判断する見出しを生成した。
実世界のデータは，各クラスの頻度が異なるため，ロングテール分布になることが多い．例えば、データセットには、代表性の低いクラスが多数存在したり、十分すぎるほどのデータを持つクラスが少数存在したりする。しかし、データセットを表現するモデルは、通常、クラス間で合理的に均質な性能を持つことが期待されます。クラスバランスのとれた損失の導入や、データの再サンプリングや増強に関する高度な手法は、データの不均衡問題を軽減するための最良の方法の一つです。しかし、代表性の低いクラスについての問題の他の部分は、失われた情報を回復するために追加の知識に頼らなければならない。本研究では、十分なサンプルを持つクラスから学習した特徴量を用いて、特徴空間内の代表性の低いクラスを補強することで、ロングテール問題に対処する新しいアプローチを提示する。具体的には、クラスの活性化マップを用いて、各クラスの特徴をクラス共通の成分とクラス固有の成分に分解する。そして，十分なサンプル数を持たないクラスから得られたクラス固有の特徴と，混乱したクラスから得られたクラスジェネリックな特徴を融合することで，学習段階において，十分なサンプル数を持たないクラスの新しいサンプルを即座に生成する．iNaturalist、ImageNet-LT、Places-LT、CIFARのロングテール版など、さまざまなデータセットでの我々の結果は、最先端の性能を示している。
画像が鏡に映っているかどうかは、どのようにして判断するのでしょうか？鏡面反射の幾何学的性質はよく理解されていますが、コンピュータビジョンのデータ増強に広く利用されているにもかかわらず、鏡面反射がスケールの大きい画像の分布にどのような影響を与えるかについてはあまり語られていません。本論文では、反射によって視覚データの統計がどのように変化するかを調べます。このような変化を、鏡像とは異なる物体の概念である幾何学的キラリティにちなんで、「視覚的キラリティ」と呼ぶことにする。視覚的キラリティーの解析では、カメラの画像処理に起因する画像中の低レベルのキラリティー信号や、人物や顔の画像から視覚的キラリティーを発見することができるなど、驚くべき結果が得られました。この研究は、データ増強、自己教師付き学習、および画像フォレンジックに影響を与えます。
本研究では、ラベルのないビデオから時空間的な視覚表現を学習する、自己教師付きコントラストビデオ表現学習（CVRL）手法を紹介します。我々の表現は対比損失を用いて学習され、同じ短いビデオからの2つの補強されたクリップは埋め込み空間で一緒に引き寄せられ、異なるビデオからのクリップは押しのけられます。我々は、ビデオの自己教師付き学習のための優れたデータ補強を研究し、空間的および時間的な情報が重要であることを発見した。我々は、空間的および時間的な手がかりを含むデータ補強を注意深く設計する。具体的には、フレーム間の時間的整合性を維持しつつ、ビデオの各フレームに強力な空間補強を施す、時間的整合性のある空間補強法を提案する。また、時間的に離れたクリップに対して不変性を過度に強要することを避けるために、サンプリングベースの時間的補強法を提案する。Kinetics-600において，CVRLによって学習された表現に基づいて学習された線形分類器は，3D-ResNet-50 (R3D-50)をバックボーンとして70.4%のトップ1精度を達成し，ImageNetの教師付き事前学習を15.7%，SimCLRの教師なし事前学習を18.8%，同じように拡張されたR3D-50を用いて上回った．CVRLの性能は、より大きなR3D-152（2xフィルター）バックボーンを用いることで、72.9%までさらに向上し、教師なしと教師ありの映像表現学習の差を大幅に縮めることができます。我々のコードとモデルは，この https URL で公開されます．
一般的な画像間翻訳フレームワークであるpixel2style2pixel（pSp）を紹介します。我々のpSpフレームワークは、一連のスタイルベクトルを直接生成する新しいエンコーダネットワークに基づいており、これは事前に学習されたStyleGANジェネレータに供給され、拡張されたW+潜在空間を形成する。まず最初に、我々のエンコーダが、追加の最適化なしに実画像をW+に直接埋め込むことができることを示す。次に、我々のエンコーダを利用して、画像から画像への変換タスクを直接解決することを提案する。これは、ある入力領域から潜在領域へのエンコード問題と定義する。以前のStyleGANエンコーダで使用されていた標準的なinvert first, edit laterの方法論を逸脱することで、我々のアプローチは、入力画像がStyleGANドメインで表現されていない場合でも、様々なタスクを処理することができる。また、翻訳タスクをStyleGANで解決することで、敵対者を必要としないため、学習プロセスが大幅に簡素化されること、ピクセル間の対応関係がないタスクを解決するためのサポートが充実していること、スタイルの再サンプリングによってマルチモーダル合成を本質的にサポートしていることを示します。最後に、我々のフレームワークは、様々な顔画像から画像への翻訳タスクにおいて、単一のタスクに特化して設計された最先端のソリューションと比較しても、その可能性を実証し、さらに人間の顔の領域を超えて拡張できることを示します。
タグ付けや機械読解などの多くのNLPタスクは、ネガティブな例がポジティブな例を大幅に上回り、膨大な数の背景例（または簡単にネガティブな例）が学習を圧倒するという、深刻なデータ不均衡問題に直面しています。最も一般的に使用されているクロスエントロピー（CE）基準は、実際には精度指向の目的であるため、トレーニングとテストの間に矛盾が生じる。トレーニング時には、各トレーニングインスタンスは目的関数に等しく貢献するが、テスト時には、F1スコアは正例に関心がある。本論文では、データに偏りのあるNLPタスクにおいて、標準的なクロスエントロピー目的の代わりにダイスロスを使用することを提案する。Dice lossはSorensen-Dice係数またはTversky指数に基づいており、偽陽性と偽陰性に同じような重要性を持ち、データ不均衡の問題に影響されません。理論的には，評価時のF1スコアと訓練時のdice lossとの差を縮めることができる．提案された学習目的では、データの不均衡なNLPタスクの広い範囲で、大幅なパフォーマンスの向上が見られた。特に、品詞タグ付けタスクにおいて、CTB5、CTB6、UD1.4でSOTAを達成し、名前付きエンティティ認識タスクにおいて、CoNLL03、OntoNotes5.0、MSRA、OntoNotes4.0でSOTAを達成し、さらに、機械読解や言い換え識別のタスクでも競争力のある結果を得ることができました。
単語の分散表現を学習する教師なしの手法は、今日のNLP研究においてどこにでもあるものですが、ラベルのないデータからフレーズや文の分散表現を学習するための最良の方法についてはあまり知られていません。本論文では、このような表現を学習するモデルを系統的に比較しています。最適なアプローチは、目的とするアプリケーションに大きく依存することがわかった。教師付きシステムで使われる表現には、より深く複雑なモデルが好ましいが、単純な空間距離メトリクスでデコード可能な表現空間を構築するには、浅い対数線形モデルが最適である。また、学習時間、ドメインポータビリティ、パフォーマンスのトレードオフを最適化するために、2つの新しい教師なし表現学習の目的を提案する。
大規模な語彙を持つシーケンスモデルでは、ネットワークパラメータの大部分が入力層と出力層に存在する。本研究では、深いトークン表現を効率的に学習するための新しい手法、DeFINEについて説明します。DeFINEのアーキテクチャは、新奇なスキップ結合を用いた階層構造を採用しており、低次元の入力層と出力層の使用を可能にすることで、既存の手法と同等以上の性能を発揮しながら、総パラメータと学習時間を削減することができる。DeFINEは、新規または既存のシーケンスモデルに簡単に組み込むことができる。適応的な入力表現を含む最先端の手法と比較して、この技術はパープレキシティを6%から20%低下させることができる。WikiText-103において、DeFINEは性能への影響を最小限に抑えながら、Transformer-XLの総パラメータを半分に減らすことができた。Penn Treebankでは、DeFINEはAWD-LSTMを4ポイント改善し、パラメータを17%削減し、少ないパラメータで最先端の手法と同等の性能を達成した。機械翻訳では、DeFINEはTransformerモデルの効率を約1.4倍向上させながら、同等の性能を実現しています。
ディープで軽量なトランスフォーマーであるDeLighTを導入し、大幅に少ないパラメータで標準的なトランスフォーマーベースのモデルと同等以上の性能を実現します。DeLighTは、(1)各Transformerブロック内では深くて軽い変換であるDeLighT変換を用い、(2)ブロック間ではブロックワイズ・スケーリングを用いて、パラメータをより効率的に割り当てる。全体として、DeLighTネットワークは標準的な変換モデルの2.5倍から4倍の深さがあり、しかもパラメータや演算が少ない。機械翻訳や言語モデリングのベンチマークタスクを用いた実験によると、DeLighTは、平均して2～3倍少ないパラメータでベースラインのトランスフォーマーと同等かそれ以上の性能を発揮することがわかった。当社のソースコードは以下のサイトで公開されています。\このhttpsのURLをクリックしてください。
画像から画像への翻訳において、出力の各パッチは、ドメインに依存せず、入力の対応するパッチの内容を反映する必要があります。本論文では、コントラスト学習に基づいたフレームワークを用いて、両者の相互情報量を最大化するという、分かりやすい方法を提案する。この方法では、2つの要素（対応するパッチ）が、データセット内の他の要素（他のパッチ）と比較して、学習した特徴空間内の類似した点にマッピングされるように促します（ネガティブと呼ばれます）。本研究では、画像合成の場面でコントラスト学習を効果的に行うために、いくつかの重要な設計上の選択を検討しています。特に、画像全体を扱うのではなく、マルチレイヤーのパッチベースのアプローチを採用しています。さらに、データセットの残りの部分からではなく、入力画像自体からネガティブを抽出します。我々のフレームワークは、対にならない画像間の翻訳において、品質の向上と学習時間の短縮を図りつつ、片面翻訳を可能にすることを実証した。さらに、我々の手法は、各「ドメイン」が単一の画像のみである場合の学習設定にも拡張することができる。
本論文では、様々なグループに対するきめ細かな漫画の顔を生成することに興味を持っています。これらのグループのうちの1つは十分な学習データから構成されているが、他のグループはわずかなサンプルしかないと仮定する。これらのグループの漫画の顔は、同じようなスタイルを持っていますが、様々なグループの外観は、いくつかの特定の特徴を持っている可能性があり、それがお互いに異なるものにしています。このタスクの大きな課題は、どのようにしてグループ間で知識を伝達し、わずかなサンプルでグループ固有の特性を学習するかということです。この問題を解決するために、我々は2段階の学習プロセスを提案する。まず、（十分なデータからなる）基本グループの基本的な翻訳モデルを学習する。次に，他のグループの新しいサンプルが与えられた場合，各新しいグループに対してグループ固有のブランチを作成することで，基本モデルを拡張する．グループ固有のブランチは、各グループの特定の外観をキャプチャするために直接更新されますが、残りのグループ共有パラメータは、中間特徴空間の分布を維持するために間接的に更新されます。このようにして、我々のアプローチは、様々なグループの高品質な漫画の顔を生成することができる。
人工知能、ヘルスケア、フィンテックなどの産業分野ごとに企業を整理することは、株式市場のパフォーマンス分析や、テーマ別投資ファンドの設計などに有効です。現在の実務では、あらかじめ定義された小さなリストから手作業で企業をセクターや産業に割り当てていますが、これには2つの重要な限界があります。第一に、人手による作業が必要なため、この戦略は比較的主流の産業分野にしか適用できず、ニッチなテーマや新興のテーマには容易に使用できません。第二に、ラベルの割り当てが難しいため、企業によって特定のセグメントへの露出度が高かったり低かったりするという事実が無視されてしまう。これらの限界を解決するために、我々は、企業の年次報告書に基づいて、企業のベクトル表現を学習することを提案する。しかし、アニュアルレポートには、我々の目的とは関係のない多くの情報が含まれているため、重要な課題は、これらのレポートから関連する情報を抽出し、企業の特徴を明らかにすることである。この目的のために、我々は、(i)既存のセクターラベルおよび(ii)株式市場のパフォーマンスに基づいてBERT言語モデルを微調整することに基づくマルチタスク学習戦略を導入します。英語と日本語の両方での実験により、この戦略の有用性を実証しています。
オフライン強化学習（純粋にログデータからのRL）は、RL技術を実世界のシナリオに展開するための重要な手段です。しかし、オフラインRLのための既存のハイパーパラメータ選択手法は、環境中の各ハイパーパラメータ設定に対応するポリシーを評価することで、オフラインの仮定を破っています。このオンライン実行はしばしば実行不可能であり、したがってオフラインRLの主な目的が損なわれる。そこで、本研究では、offline hyperparameter selection（オフラインハイパーパラメータ選択）、すなわち、ログデータのみが与えられ、異なるハイパーパラメータを用いて学習された多くのポリシーのセットから最適なポリシーを選択する方法に焦点を当てます。大規模な実験的評価により，以下のことが示された．1）オフラインRLアルゴリズムはハイパーパラメータの選択に対してロバストではない、2）オフラインRLアルゴリズムやQ値の推定方法などの要因がハイパーパラメータの選択に大きな影響を与える、3）これらの要因を注意深く制御すると、ハイパーパラメータの選択の間でポリシーを確実にランク付けすることができ、その結果、セット内の最良のポリシーに近いポリシーを選択することができる。全体として、我々の結果は、ピクセル観測、高次元の行動空間、長い水平線などの困難なタスクであっても、オフラインでのハイパーパラメータ選択が可能であるという楽観的な見方を示している。
実世界における物体の頻度はしばしばべき乗則に従っており、機械学習モデルで見られるロングテールのクラス分布を持つデータセットと、モデルがすべてのクラスで良い性能を発揮するという我々の期待との間にミスマッチが生じます。我々は、このミスマッチを領域適応の観点から分析する。まず最初に、ロングテール分類のための既存のクラスバランス手法を、領域適応においてよく研究されているシナリオであるターゲットシフトに結びつける。その結果、これらの手法は、学習データとテストデータが同じクラス条件の分布を共有していることを暗黙的に仮定しているが、これは一般的には成り立たず、特に末尾のクラスでは成り立たないことがわかった。ヘッドクラスには、推論時に期待されるデータをよく表す豊富で多様なトレーニング例が含まれている可能性があるが、テールクラスには代表的なトレーニングデータがないことが多い。そこで我々は，クラス条件付き分布の差を明示的に推定することで，古典的なクラスバランス学習を補強するメタ学習を提案する．6つのベンチマークデータと3つの損失関数を用いて、我々のアプローチを検証する。
深層学習に基づく顕著な物体検出法は大きな進歩を遂げている。しかし、顕著なオブジェクトの可変スケールと未知のカテゴリは、常に大きな課題となっています。これらは、マルチレベルおよびマルチスケールの特徴の利用に密接に関連している。本論文では、隣り合うレベルの特徴を統合するために、アグリゲート・インタラクション・モジュールを提案します。また，統合された特徴量からより効率的なマルチスケール特徴量を得るために，自己相互作用モジュールを各デコーダユニットに組み込んでいる。また、スケール変動によるクラスの不均衡の問題は、二値クロスエントロピー損失の効果を弱め、予測値の空間的不整合をもたらします。そこで、一貫性を強化した損失を利用して、前景と後景の違いを強調し、クラス内の一貫性を維持します。5つのベンチマークデータセットを用いた実験の結果，後処理を一切行わない提案手法は，23の最先端のアプローチに対して良好な性能を示すことがわかった．ソースコードはこのhttps URLで公開される予定です。
地理空間オブジェクトのセグメンテーションは，高空間分解能（HSR）のリモートセンシング画像において，より大きなスケールの変動，背景のより大きなクラス内分散，前景と背景の不均衡といった問題に常に直面している．しかし、一般的なセマンティックセグメンテーション手法は、主に自然シーンにおけるスケール変動に焦点を当てており、大面積の地球観測シーンで通常発生する他の2つの問題については十分な考慮がなされていない。本論文では、この問題が前景モデリングの欠如にあることを主張し、上記2つの問題を軽減するために、関係性に基づく前景モデリングと最適化に基づく前景モデリングの観点から、前景を考慮した関係性ネットワーク（FarSeg）を提案する。関係性の観点からは、FarSegは前景-シーン関係を学習することで、前景に関連するコンテキストを介して前景の特徴の識別を強化します。一方、最適化の観点からは、学習時に前景の例と背景の難しい例に着目し、バランスのとれた最適化を行う前景考慮型最適化を提案する。大規模データセットを用いた実験の結果、提案手法は最先端の一般的なセマンティックセグメンテーション手法よりも優れており、速度と精度のより良いトレードオフを達成していることが示唆された。
2019年のAlexa Prizeコンペティションの研究プラットフォームとして、オープンドメインの対話エージェントであるChirpy Cardinalを発表します。実在の人物と会話するオープンドメインのソーシャルボットを構築することは困難です。このようなシステムは、幅広い世界の知識、会話スタイル、感情的なつながりなど、複数のユーザーの期待に応えなければなりません。私たちのソーシャルボットは、ユーザーの興味、感情、自律性を優先して、ユーザーの言葉で対話します。その結果、私たちのソーシャルボットは、応答性が高く、パーソナライズされたユーザー体験を提供し、さまざまなトピックについて知識的に話すことができるだけでなく、普通の生活について共感的に話すこともできます。これらの目標を達成するためには、会話や感情的なトーンのバックボーンとなるニューラルジェネレーションが重要な役割を果たします。Chirpy Cardinalは、平均評価が3.6/5.0、会話時間の中央値が2分16秒、90パーセンタイルの持続時間が12分を超えて、決勝戦に進みました。
教師なしの画像表現は、教師ありの事前学習との差を大幅に縮めており、特に最近ではコントラスト学習法の成果が見られます。これらの対照的な手法は、一般的にオンラインで動作し、多数の明示的な一対の特徴比較に依存しており、これは計算上困難である。本論文では，一対比較の計算を必要とせずに対比学習法を利用するオンラインアルゴリズムSwAVを提案する．具体的には，対比学習のように直接特徴を比較するのではなく，同じ画像の異なるオーグメンテーション（あるいはビュー）に対して作成されたクラスタ割り当ての間で一貫性を確保しながら，データを同時にクラスタリングする．簡単に言うと、あるビューのクラスタ割り当てを、別のビューの表現から予測するスワップ予測メカニズムを使用します。我々の手法は、大小のバッチで学習することができ、無制限のデータ量に対応することができます。従来のコントラスト法と比較して、本手法は大規模なメモリバンクや特別なモメンタムネットワークを必要としないため、メモリ効率が高い。さらに、新しいデータ増強戦略であるmulti-cropを提案する。これは、2つのフル解像度のビューの代わりに、異なる解像度のビューを混在させて使用するもので、メモリや計算の必要性をあまり増やさない。本研究では、ResNet-50を用いたImageNetにおいて75.3%のトップ1精度を達成するとともに、検討したすべての転送タスクにおいて教師付き事前学習を上回る結果を得て、我々の発見を検証した。
深層学習ベースのモデルでロングテールの大語彙オブジェクト検出を解決することは、挑戦的で厳しい課題ですが、これはhttp URL 本研究では、ロングテール分布の前での最先端モデルの劣勢に関する最初の体系的な分析を提供します。既存の検出手法は、データセットが極端に歪んでいる場合、少数ショットのクラスをモデル化することができず、パラメータの大きさの点で分類器が不均衡になることがわかりました。ロングテール分類モデルを検出フレームワークに直接適応させても、検出との本質的な違いにより、この問題を解決することはできない http URL 本研究では、グループ単位での学習により、検出フレームワーク内の分類器のバランスをとるための新しいバランスドグループソフトマックス（BAGS）モジュールを提案する。このモジュールは、ヘッドクラスとテールクラスの学習プロセスを暗黙のうちに調整し、テールクラスからのインスタンスの追加サンプリングを必要とせずに、両者が十分に学習されるようにします。最近のロングテール大語彙オブジェクト認識ベンチマークLVISでの広範な実験により、我々の提案するBAGSは、様々なバックボーンやフレームワークを持つ検出器のオブジェクト検出とインスタンスセグメンテーションの両方の性能を大幅に向上させることが示されました。BAGSは、ロングテール画像分類から移行した全ての最先端の手法を凌駕し、新たな最先端を確立しました。
我々は、データ効率の良いオプション学習アルゴリズムであるHindsight Off-policy Options (HO2)を紹介します。HO2は、任意の軌道が与えられたときに、可能性の高いオプションの選択肢を推定し、動的計画法による推論手順をバックプロパゲートすることで、すべてのポリシーコンポーネントをオフポリシーかつエンドツーエンドでロバストに学習します。このアプローチは、一般的なベンチマークにおいて、既存のオプション学習法よりも優れています。オプションフレームワークの理解を深め，時間的抽象化と行動的抽象化の両方から得られる利点を分離するために，フラットポリシーによるアブレーションと，同等の最適化を行った混合ポリシーによるアブレーションを評価した．その結果、特に、生のピクセル入力からの3Dロボット操作タスクをシミュレートした場合には、両方のタイプの抽象化、ポリシー外のトレーニング、信頼領域の制約の重要性が浮き彫りになった。最後に、推論ステップを直観的に適応させ、時間的な抽象度を高めた場合に、事前に学習したオプションを使ったトレーニングとゼロからのトレーニングに与える影響を調査した。
Contrastive unsupervised learningは、Momentum Contrast (MoCo)やSimCLRなどで、最近目覚ましい進歩を遂げています。このノートでは、MoCoフレームワークに実装することで、SimCLRの2つの設計上の改善点の有効性を検証します。MoCoへの簡単な変更（MLP投影ヘッドの使用と、より多くのデータ増強）により、SimCLRを凌駕し、大規模なトレーニングバッチを必要としない、より強力なベースラインを確立します。これにより、最先端の教師なし学習の研究がより身近なものになることを期待しています。コードは公開されます。
本論文では、半教師付きビデオオブジェクトセグメンテーションという困難な課題に取り組むために、埋め込み学習の原理を研究しています。前景オブジェクトのピクセルのみを用いて埋め込み学習を行う従来の手法とは異なり，我々は背景も同様に扱われるべきであると考え，前景-背景統合による協調的ビデオオブジェクトセグメンテーション（CFBI）を提案する．我々のCFBIは、対象となる前景オブジェクトとそれに対応する背景からの特徴埋め込みを暗黙のうちに対照的なものとし、それに応じてセグメンテーション結果を促進する。前景と背景の両方の特徴を埋め込むことで，CFBIは参照配列と予測配列の間のマッチング処理をピクセルレベルとインスタンスレベルの両方で行い，様々なオブジェクトのスケールに頑健に対応することができる．本研究では，DAVIS 2016，DAVIS 2017，You Tube-VOSという3つの有名なベンチマークを用いて実験を行った．その結果，我々のCFBIは，それぞれ89.4%, 81.9%, 81.4%の性能(J$F)を達成し，他のすべての最先端手法を凌駕した．コード：このhttpsのURLです。
画質評価（IQA）は，画像復元（IR）アルゴリズムを迅速に開発するための重要な要素である。GAN（Generative Adversarial Networks）に基づいた最新のIR手法は，視覚的なパフォーマンスの大幅な向上を達成したが，定量的な評価には大きな課題があった。特に、知覚的品質と評価結果の間の不一致が増加していることが確認されています。そこで、2つの問題を提起する。(1) 既存のIQA手法は、最近のIRアルゴリズムを客観的に評価できるか？(2）現在のベンチマークに勝つことに焦点を当てた場合、我々はより良いIRアルゴリズムを得ることができるのか？これらの疑問に答え、IQA手法の開発を促進するために、我々はPerceptual Image Processing Algorithms（PIPAL）データセットと呼ばれる大規模なIQAデータセットを提供する。特に、このデータセットには、これまでのデータセットでは欠けていたGANベースの手法の結果が含まれている。PIPAL画像の主観的なスコアを割り当てるために、113万件以上の人間の判断を収集し、より信頼性の高い「Eloシステム」を使用しています。PIPALに基づいて、IQAと超解像の両方の手法の新しいベンチマークを発表する。その結果、既存のIQA手法ではGANベースのIRアルゴリズムを正当に評価できないことがわかった。適切な評価手法を用いることは重要であるが、IRアルゴリズムの開発に合わせてIQA手法も更新されるべきである。最後に、アンチ・エイリアシング・プーリングを導入することにより、GANベースの歪曲に対するIQAネットワークの性能を向上させる。実験により、提案された方法の有効性が示された。
教師なしの画像間翻訳は、本質的に不向きな問題である。最近の深層エンコーダー・デコーダーアーキテクチャに基づく手法は素晴らしい結果を示しているが、これらの手法が成功するのは強い局所性バイアスのためであり、非常に単純な非局所的変換（例えば、逆さまの顔を直立した顔にマッピングする）の学習に失敗することを示す。局所性バイアスを取り除くと、これらの手法は強力になりすぎて、単純な局所的変換を学習できなくなる可能性がある。本論文では、教師なしの画像間変換のための線形エンコーダ・デコーダのアーキテクチャを紹介する。これらのアーキテクチャでは、学習がはるかに簡単で高速であり、しかも驚くほど効果的な結果が得られることを示している。特に、局所的な問題では、線形手法の結果は最先端のアーキテクチャの結果に匹敵するが、学習時間は数分の一で済むこと、また、非局所的な問題では、最先端の手法は失敗するが、線形手法は成功することを示す。
本論文では、画像間翻訳のためのシンプルで汎用性の高いフレームワークを紹介する。正規化層の重要性を明らかにし、慎重に設計された2ストリーム生成モデルに、新たに提案された特徴変換を粗いものから細かいものへと提供する。これにより、マルチスケールの意味構造情報とスタイル表現をネットワークで効果的に捉え、融合させることができ、本手法は教師なし、教師ありの両方の設定で様々なタスクに対応することができます。また、サイクルの整合性などの追加的な制約が必要ないため、非常にクリーンでシンプルな手法となっています。任意のスタイル制御によるマルチモーダルな画像合成が可能となる。本研究では、提案手法をいくつかの最先端のタスクに特化したベースラインと比較し、知覚的品質と定量的評価の両方でその有効性を検証した。
単語は，単語セグメント，文字，文字n-gramなどのサブワードユニットの表現を組み合わせて表現することができる。このような表現は有効であり，単語の形態的な規則性を捉えることができるが，体系的な比較は行われておらず，異なる形態素のタイポロジーとどのように相互作用するかは理解されていない。本研究では、言語モデル課題において、(1)表現の基本単位、(2)これらの表現の構成、(3)モデル化された言語の形態素の類型を系統的に変化させる実験を行った。その結果、文字表現が類型間で有効であるというこれまでの知見を拡張し、これまで研究されていなかった文字三文字表現をbi-LSTMで構成した組み合わせが、他の組み合わせよりも優れていることを発見した。また、文字レベルのモデルは、桁違いのデータから学習しても、真の形態素解析を利用したモデルの予測精度に及ばないことがわかった。
自然言語処理において，事前に学習した変換言語モデル（LM）が成功したことで，様々な事前学習の設定が行われるようになりました．特に、これらのモデルは、テキストをセグメント化するために、様々なサブワードのトークン化法、特にbyte-pair encoding (BPE) (Sennrich et al., 2016; Gage, 1994)、WordPiece法 (Schuster and Nakajima, 2012)、unigram language modeling (Kudo, 2018)を採用している。しかし、我々の知る限り、この文献には、トークン化が言語モデルの事前学習に与える影響を直接評価したものはありません。我々は、BPEとunigram LMのトークン化の違いを分析し、後者の方法は、より形態素に近いサブワードユニットを回復し、BPEの貪欲な構築手順に起因する問題を回避することを見出した。次に、これらのトークン化で事前学習した同一の変換器マスク言語モデルの微調整されたタスク性能を比較します。下流のタスクと2つの言語（英語と日本語）において、ユニグラムLMトークン化法はBPEと同等かそれ以上の性能を発揮することがわかりました。今後、学習済みのLMを開発する際には、より一般的なBPEではなく、unigram LM法の採用を検討していただきたいと思います。
文章要約の評価指標に関する包括的な最新の研究は少なく，また評価プロトコルに関するコンセンサスも得られていないため，進歩の妨げになっています。本研究では、以下の5つの観点から、これまでの要約評価手法の欠点を解決する。1）ニューラルサマリーモデルの出力と、専門家やクラウドソースによる人間のアノテーションを用いて、14の自動評価指標を包括的かつ一貫性のある方法で再評価する。2）前述の自動評価指標を用いて、最近の23のサマリーモデルを一貫してベンチマークする。4) 幅広い自動評価基準で要約モデルを評価するための拡張可能で統一されたAPIを提供するツールキットを実装し、共有する。 5) CNN/DailyMailデータセット上でモデルが生成した要約に対する人間の判断を、モデルの種類の観点から最大かつ最も多様に集め、専門家の判断者とクラウドソースワーカーの両方によってアノテーションし、共有する。この研究が、テキスト要約のより完全な評価プロトコルを促進するだけでなく、人間の判断とよりよく相関する評価指標を開発する研究の進展に役立つことを期待しています。
BERTなどのトランスフォーマーベースのモデルは、NLP用の最も成功した深層学習モデルの1つです。しかし、その限界の1つは、フルアテンションメカニズムによるシーケンス長の2次依存性（主にメモリ）です。この問題を解決するために、我々はBigBirdというスパースなアテンションメカニズムを提案します。BigBirdはシーケンス関数の普遍的な近似であり、Turing完全であることを示し、二次的なフルアテンションモデルのこれらの特性を保持しています。また、理論的な分析により、O(1)個のグローバルトークン（CLSなど）を持ち、スパースアテンションメカニズムの一部としてシーケンス全体に注意を払うことの利点を明らかにしました。提案されたスパースアテンションは、同様のハードウェアを使用して以前に可能だった8倍の長さのシーケンスを処理することができます。その結果、質問応答や要約などの様々なNLPタスクにおいて、BigBirdは飛躍的に性能を向上させることができました。また、ゲノミクスデータへの新たな応用も提案しています。
ここ数年、ビジュアルローカリゼーションやマッピングソリューションは、複合現実感やロボットシステムに採用されるケースが増えています。クラウドベースのローカリゼーションやマッピングシステムへの最近の傾向は、プライバシーに関する重大な懸念を引き起こしています。これは主に、これらのサービスでは、ユーザーが画像データをサーバーにアップロードする必要があるため、たとえ画像の特徴だけをアップロードしたとしても、機密情報が漏えいする可能性があることに起因しています。最近の研究では、画像ベースのローカリゼーションのために、クエリ画像とデータベース・マップのジオメトリを隠すことで、これらの問題に対処している。このアプローチの基本的な考え方は、2D/3D の特徴点をランダムな線に変換することで、カメラの姿勢推定に十分な制約を与えることである。本論文では、このアイデアをさらに発展させ、ランダムな線の特徴に基づいたインクリメンタルStructure-from-Motionパイプラインのさまざまなコアアルゴリズムに対するソリューションを提案しています。これにより、プライバシーを保護したクラウドベースのマッピングソリューションを実現するための基本的な一歩を踏み出すことができました。困難な実世界のデータセットを用いた様々な実験により、我々のアプローチの実用性が実証され、標準的なStructure-from-Motionシステムと同等の結果を得ることができました。
畳み込みは、コンピュータビジョンで使用されるアーキテクチャの最も重要なコンポーネントの1つです。機械学習が専門家のバイアスを減らし、データから学習する方向に進むにつれ、自然な次のステップは、畳み込みのような構造をゼロから学習することであると思われます。しかし、これはなかなか難しいことです。例えば、現在の最先端のアーキテクチャ検索アルゴリズムは、データから学習するのではなく、既存のモジュールの一つとして畳み込みを使用しています。畳み込みを生み出す帰納的なバイアスを理解するために、我々は最小記述長を指針として調査し、いくつかの設定では、実際にアーキテクチャの性能を示すことができることを示した。このアルゴリズムは、画像分類タスクのための完全連結ネットワークに適用すると、局所的な接続を持つアーキテクチャを学習し、CIFAR-10 (85.19%)、CIFAR-100 (59.56%)、SVHN (94.07%)の完全連結ネットの学習において、完全連結ネットと畳み込みネットの間のギャップを埋める、最先端の精度を達成する。
物体検出は，数年前からアンカーベースの検出器が主流となっている．最近では，FPNやFocal Lossの提案により，アンカーフリーの検出器が普及してきている．本稿では，アンカーベース検出とアンカーフリー検出の本質的な違いは，実は正負の学習サンプルをどのように定義するかにあり，それが両者の性能差につながっていることをまず指摘する．両者が学習時に同じ定義の正負のサンプルを採用すれば，ボックスから回帰してもポイントから回帰しても，最終的な性能に明らかな差はない。このことから，現在の物体検出器では，正と負の学習サンプルをどのように選択するかが重要であることがわかる．そこで，物体の統計的特性に応じて正負のサンプルを自動的に選択するAdaptive Training Sample Selection (ATSS)を提案する．これにより，アンカーベースの検出器とアンカーフリーの検出器の性能が大幅に向上し，両者のギャップを埋めることができる．最後に，物体を検出するためには，画像上の場所ごとに複数のアンカーをタイリングする必要があることを議論する．MS COCOで行われた広範な実験は、前述の分析と結論を裏付けるものです。新たに導入したATSSにより，オーバーヘッドを発生させることなく，最先端の検出器を50.7%APまで大幅に改善することができました．コードはこのhttpsのURLから入手できます。
我々は，セマンティックセグメンテーションに類似したピクセル単位の予測方法でオブジェクト検出を解決するために，完全畳み込み1段オブジェクト検出器（FCOS）を提案する．RetinaNet, SSD, YOLOv3, Faster R-CNN などの最先端のオブジェクト検出器は，ほとんどすべて事前に定義されたアンカーボックスに依存しています．一方、我々の提案する検出器FCOSは、アンカーボックスを使用しないだけでなく、プロポーザルも使用しません。FCOSは、事前に定義されたアンカーボックスのセットを排除することで、学習時のオーバーラップの計算など、アンカーボックスに関連する複雑な計算を完全に回避しています。さらに重要なのは，最終的な検出性能に大きな影響を与えるアンカーボックスに関連するハイパーパラメータをすべて回避できることです．唯一の後処理であるNMS（Non-Maximum Suppression）により、ResNeXt-64x4d-101を用いたFCOSは、シングルモデルおよびシングルスケールテストでAPにおいて44.7%を達成し、これまでの1段検出器をはるかに凌駕しましたが、よりシンプルであるという利点があります。このように、よりシンプルで柔軟性のある検出フレームワークで、検出精度の向上を実現したのは初めてのことです。提案されたFCOSフレームワークが、他の多くのインスタンスレベルのタスクのためのシンプルで強力な代替手段となることを期待しています。Code is available at:Code is available at: this https URL
単眼キューは，1枚の画像からの深度推定だけでなく，より広範な深度推論のアプリケーションや設定において有用である．現在のところ、異なる推論タスクと深度キューの組み合わせを持つ異なるアプリケーションは、それぞれのアプリケーションごとに別々に学習された、異なる特殊化されたネットワークによって解決されている。その代わりに、我々は、パッチワイズ条件付きVAEからの出力のサンプル近似として、入力カラー画像が与えられたシーンの深さに関する確率分布を出力する、タスクにとらわれない汎用の単眼モデルを提案する。この分布出力を用いることで、様々な環境下での様々な推論タスクを、アプリケーションごとに再学習することなく実現できることを示す。様々なアプリケーション（深度補完、ユーザガイド推定など）において、我々の共通モデルは、アプリケーション固有のネットワークに依存する最先端の手法と同等以上の高精度な結果をもたらした。
我々は、画像アナロジー問題を解決するための新しい手法を提案する。それは、トレーニングデータに存在するペア画像間の関係を学習し、その関係に対応するが、トレーニングセットでは見られなかった画像を一般化して生成することができる。この手法は、敵対的学習に基づいており、深層畳み込みニューラルネットワークを採用していることから、Conditional Analogy Generative Adversarial Network (CAGAN)と呼んでいます。その手法の特に興味深い応用例は、ファッションモデルの写真上で服を自動的に交換することです。我々の研究には以下のような貢献があります。第一に、エンド・ツー・エンドで学習可能なCAGANアーキテクチャの定義であり、高価な教師付きラベリングデータなしにセグメンテーションマスクを暗黙的に学習します。第二に、実験結果は、対象となる記事が与えられた場合に、もっともらしいセグメンテーションマスクと、しばしば説得力のある入れ替え画像を示している。最後に、この技術の次のステップとして、ニューラルネットワークアーキテクチャの改良と、より高度なアプリケーションについて説明する。
本論文では、顔交換、属性ベースの編集、およびランダムな顔パーツの合成により、顔画像を自動的に生成・編集する統合システムを紹介します。提案システムは、大規模な顔画像データセットを用いて顔と髪の毛の領域を変分学習する深層ニューラルネットワークに基づいている。従来の変分法とは異なり，提案するネットワークは顔と髪の毛の潜在空間を個別に表現する．本研究では，提案したネットワークをRegion-separative generative adversarial network (RSGAN)と呼ぶ．提案ネットワークは，潜在空間における顔と毛の出現を個別に扱い，顔の潜在空間表現を置き換えることで，顔の交換を実現し，それらを用いて顔画像全体を再構成する．この潜在空間のアプローチは、従来の手法では不適切なフィッティングや3Dモーファブルモデルのために失敗していた画像に対しても、ロバストに顔交換を行います。さらに、提案システムでは、同じネットワークを用いて、視覚的属性を操作したり、ランダムに生成された顔や髪のパーツと合成したりして、顔交換された画像をさらに編集することができる。
任意の体勢、形状、服装を持つ人物の画像間で衣服を転送するフレームワークであるSwapnetを紹介します。衣服の転送は、(i)体のポーズや形状から衣服の特徴を切り離すこと、(ii)新しい体に衣服の質感をリアルに合成することが必要な、困難なタスクです。我々は、2つのタスクに特化したサブネットワークを用いて、これらのサブ問題に取り組むニューラルネットワークアーキテクチャを提案する。異なる身体に同じ服を着せた画像のペアを取得することは困難であるため、データ拡張により1枚の画像からトレーニングペアを生成する新しい弱教師付きアプローチを提案する。我々は、困難な3D再構成問題を解決することなく、制約のない画像で衣服を転送する初めての完全自動化手法を提示する。様々な転写結果を示し、従来の画像間およびアナロジーパイプラインに対する我々の優位性を強調します。
メンバーシップ推論攻撃は、機械学習モデルのプライバシー漏洩の最も単純な形態の一つであり、データポイントとモデルが与えられた場合、そのポイントがモデルの学習に使用されたかどうかを判断する。既存のメンバーシップ推論攻撃は、学習データを照会された際のモデルの異常な信頼性を利用しています。しかし、これらの攻撃は、信頼度の測定をせずに、モデルの予測されたラベルにのみアクセスする場合には適用されません。本論文では、ラベルのみのメンバーシップ推論攻撃を紹介します。本論文では、信頼度スコアに頼るのではなく、モデルの予測ラベルの摂動に対する頑健性を評価し、きめ細かなメンバーシップ信号を得る。このような摂動には、一般的なデータの補強や敵対的な例が含まれる。我々のラベルのみのメンバーシップ推論攻撃は、モデルのコンフィデンスへのアクセスを必要とする以前の攻撃と同等の性能を持つことを経験的に示した。さらに、信頼性マスキングと呼ばれる現象に（暗黙的または明示的に）依存するメンバーシップ推論攻撃に対する複数の防御策が、ラベルのみの攻撃によって破られることを実証した。これらの防御策は、攻撃を阻止するためにモデルの信頼度スコアを変更しますが、モデルの予測ラベルは変更しません。今回のラベルのみの攻撃は、信頼性マスキングがメンバーシップ推論に対する有効な防御戦略ではないことを示しています。最後に、少数の外れ値のデータポイントのメンバーシップを推論する、最悪のケースのラベルのみの攻撃を調査します。ラベルのみの攻撃も、この設定では信頼性ベースの攻撃と一致することを示す。その結果、差分プライバシーと（強い）L2正則化を用いたモデルの学習が、すべての攻撃を防ぐことができる唯一の防御戦略であることがわかった。これは、差分プライバシーの予算が高すぎて、意味のある証明可能な保証を提供できない場合でも同様である。
本論文では、ラベルノイズを含む画像分類モデルの学習問題を研究する。人間の監視に依存する既存のアプローチは，正しいラベルと間違ったラベルを手動で識別するのに時間がかかるため，一般的にスケーラブルではない．一方，人間の監視に依存しないアプローチは，スケーラブルではあるが効果が低い．ラベルノイズ除去のための人間による監視を減らすために、我々は共同ニューラル埋め込みネットワークであるCleanNetを導入しました。CleanNetは、手動で検証されたクラスの一部だけを必要とし、ラベルノイズの知識を他のクラスに移すことができます。さらに、CleanNetと従来の畳み込みニューラルネットワーク分類器を、画像分類学習のための1つのフレームワークに統合する。複数の大規模データセットを用いて、ラベルノイズ検出タスクとノイズのあるデータの画像分類タスクの両方において、提案アルゴリズムの有効性を実証しました。実験結果によると、CleanNetは、人間による監視が不可能なクラスのラベルノイズ検出エラー率を、現在の弱い監視下の手法と比較して41.5%低減することができました。また、画像分類タスクにおいて、わずか3.2%の画像を検証するだけで、すべての画像を検証した場合の47%の性能向上を達成しました。ソースコードとデータセットは、このhttpのURLで公開されます。
ディープニューラルネットワーク（DNN）は、さまざまな医用画像解析タスクで大きな成功を収めています。しかし、これらの成果は、正確にアノテーションされたデータセットに不可欠である。しかし、これらの成果は、正確にアノテーションされたデータセットに依存しており、ノイズの多いラベル付けされた画像では、学習手順がすぐに困難になり、最適な分類器が得られませんでした。この問題は，アノテーションの質が非常に高い専門知識を必要とする医療分野では，さらに重要である．本論文では、高品質のアノテーションを持つ医療データの不足に対処するために、ノイズでラベル付けされた医療画像の分類のための効果的な反復学習フレームワークを提案する。具体的には、オンライン不確定性サンプルマイニング法を提案し、ノイズの多いラベル付き画像からの外乱を除去する。次に，正しくラベル付けされたハードサンプルの有用性を維持するために，サンプルの再重み付け戦略を設計する．提案手法は，皮膚病変の分類タスクで検証され，非常に有望な結果が得られた．
多くの実世界の予測タスクにおいて、クラスラベルはラベル間の相対的な順序に関する情報を含んでおり、これはマルチカテゴリークロスエントロピーのような一般的に使用される損失関数では捉えられない。最近、深層学習コミュニティは、このような順序情報を考慮に入れるために順序回帰フレームワークを採用した。ニューラルネットワークは、順序対象を2値の分類サブタスクに変換することで、順序回帰機能を備えた。しかし、この方法では、異なる二値分類器の間で不整合が生じます。これらの不整合を解決するために、順位単調性と一貫した信頼性スコアを強力に理論的に保証するCOnsistent RAnk Logits (CORAL)フレームワークを提案します。さらに、提案した手法はアーキテクチャにとらわれず、順序回帰タスクのための最先端のディープニューラルネットワーク分類器を任意に拡張することができる。年齢予測のための様々な顔画像データセットにおいて、提案した順位一貫性のある手法を実証的に評価したところ、基準となる順序回帰ネットワークと比較して、予測誤差が大幅に減少することがわかった。
画像認識タスクのための概念的に単純だが効果的なファンネル活性化（Funnel activation (FReLU)）を提示する。これは、空間条件の無視できるオーバーヘッドを追加することで、ReLUとPReLUを2D活性化に拡張したものである。ReLUとPReLUの形式は、それぞれy = max(x, 0)とy = max(x, px)であるが、FReLUはy = max(x,T(x))の形式であり、T(x)は2次元の空間条件である。さらに、この空間条件は、ピクセル単位のモデリング能力を単純な方法で実現しており、複雑な視覚レイアウトを規則的な畳み込みで捉えることができます。ImageNet、COCO検出、セマンティックセグメンテーションの各タスクで実験を行い、視覚認識タスクにおけるFReLUの大きな改善とロバスト性を示した。コードはこちらのhttpsのURLから入手できます。
統計的手法を用いることの利点は、統計的判断における不確実性の定量化にあると考えられており、ブートストラップ法はこの目的のためによく用いられてきました。しかし，データの大規模化や統計モデルの複雑化に伴い，ブートストラップ法の実施は，計算の繰り返しになるため，現実的には困難であることがわかってきました。この問題を解決するために，我々は「Generative Bootstrap Sampler」（GBS）と呼ばれる新しい計算方法を提案する．(これは、ブートストラップ評価の生成関数を構築し、この関数によって観測されたデータポイントの重みをブートストラップ分布に変換するものです。GBSは、標準的なブートストラップ法のように、ブートストラップ損失関数の最適化器を繰り返し評価することなく、1回の最適化で実装されています。その結果、GBSは、データサイズが大きい場合に、ブートストラップの計算時間を数百倍に短縮することができます。また，GBSによって評価されたブートストラップ分布は，従来の分布と漸近的に等価であり，経験的にも両者は区別できないことを示す．提案されたアイデアを、線形回帰、ロジスティック回帰、Cox比例ハザードモデル、ガウス過程回帰モデル、分位点回帰などの様々なモデルのブートストラップに適用してみる。その結果、GBS手順は、計算速度を加速するだけでなく、目標とするブートストラップ分布に対して高い精度を達成することがわかった。さらに、このアイデアを、ブートストラップ・クロスバリデーション、チューニング・パラメータの選択、並べ替えテストなど、他の反復的な手順の計算を高速化するためにも応用しています。
最も広く使われているニューラルネットワークアーキテクチャであるReLU分類ネットワークの点推定値は、学習データから遠く離れた場所で任意に高い信頼性を得ることができることが示されています。このアーキテクチャは、最大事後推定スキームと組み合わせても、校正されていないし、ロバストでもない。近似ベイズ推定は、ニューラルネットワークにおける予測の不確実性を改善することが経験的に示されているが、このようなベイズ近似の理論的分析は限られている。本研究では、ReLUネットワークの重みに関する近似ガウス分布を理論的に解析し、過信問題を修正することを示す。さらに、単純で安価なベイジアン近似であっても、これらの問題を解決することを示す。これは、ReLUネットワークの不確実性を校正するための十分な条件は、「少しベイジアンであること」であることを示している。これらの理論的な結果は、最後の層のベイジアン近似の使用を検証し、フィデリティ・コスト・トレードオフの範囲を動機付けます。さらに、一般的な深層ReLUネットワークとラプラス近似を用いた様々な標準的な実験により、これらの知見を経験的に検証した。
最も広く使われているニューラルネットワークアーキテクチャであるReLU分類ネットワークの点推定値は、学習データから遠く離れた場所で任意に高い信頼性を得られることが示されています。このアーキテクチャは、最大事後推定スキームと組み合わせても、校正されていないし、ロバストでもない。近似ベイズ推定は、ニューラルネットワークにおける予測の不確実性を改善することが経験的に示されているが、このようなベイズ近似の理論的分析は限られている。本研究では、ReLUネットワークの重みに関する近似ガウス分布を理論的に解析し、過信問題を修正することを示す。さらに、単純で安価なベイジアン近似であっても、これらの問題を解決することを示す。これは、ReLUネットワークの不確実性を校正するための十分な条件は、「少しベイジアンであること」であることを示している。これらの理論的な結果は、最後の層のベイジアン近似の使用を検証し、フィデリティ・コスト・トレードオフの範囲を動機付けます。さらに、一般的な深層ReLUネットワークとラプラス近似を用いた様々な標準的な実験により、これらの発見を経験的に検証します。
Scalable Vector Graphics (SVG)は、異なる解像度へのスケーリングが可能なため、現代の2Dインターフェースではユビキタスな存在です。しかし、ラスタライズされた画像に適用される深層学習ベースのモデルが成功しているにもかかわらず、ベクターグラフィックス表現の学習と生成の問題はほとんど未解決のままである。本研究では、複雑なSVGアイコンの生成と補間のために、DeepSVGと呼ばれる新しい階層的な生成ネットワークを提案する。我々のアーキテクチャは、高レベルの形状を、その形状自体をエンコードする低レベルのコマンドから効果的に切り離す。このネットワークは、形状のセットを非自動回帰的に直接予測します。本研究では、新しい大規模データセットとSVG操作用のオープンソースライブラリを公開することで、複雑なSVGアイコンを生成するタスクを紹介する。我々のネットワークは、多様なベクターグラフィックスを正確に再構成することを学習し、補間やその他の潜在空間操作を行うことで、強力なアニメーションツールとして機能することを実証した。我々のコードはこのhttpsのURLから入手できます。
顔認識システムは優れた検証性能を示しており、ソーシャルメディアでの写真タグ付けから自動国境管理（ABC）まで、実社会での応用に適していることが示唆されています。しかし、深層学習を用いた先進的なFRシステムでは、認識効率を高めるだけでは不十分であり、習熟度を狙った潜在的な攻撃にも耐える必要があります。最近の研究では、（深層）FRシステムは、モデルを誤った出力予測に導くような、知覚できない、あるいは知覚できるが自然に見える敵対的な入力画像に対して、興味深い脆弱性を示すことがわかっている。本稿では、FRシステムに対する敵対的な攻撃についての包括的な調査を行い、それらに対する新しい対策の能力について詳しく説明する。さらに、既存の攻撃・防御戦略を様々な基準で分類することを提案します。最後に、技術の特徴に応じて、提示されたアプローチを比較する。
オープンドメインの質問応答システム（OpenQA）は、一般的に、大規模なコーパスから候補となる文章を見つけるためのレトリーバーと、それらの文章から回答を抽出するためのリーダーに依存している。最近の多くの研究では、質問と文章の粗視化されたベクトル表現を使用する学習されたコンポーネントがレトリーバーである。我々は、このモデル化の選択は、自然言語の質問の複雑さを扱うには十分な表現力がないと主張する。この問題に対処するため、スケーラブルなニューラル検索モデルであるColBERTをOpenQAに適応させるColBERT-QAを定義します。ColBERTは、質問と通路の間にきめ細かな相互作用を生み出します。我々は、ColBERTを反復的に使用して独自のトレーニング・データを作成する効率的な弱監督戦略を提案する。これにより、Natural Questions、SQuAD、およびTriviaQAにおけるOpenQA検索が大幅に改善され、結果として、3つのデータセットすべてにおいて最先端の抽出的OpenQA性能を達成することができました。
オフポリシーの深層強化学習（RL）は、さまざまな困難なドメインで成功を収めている。しかし、標準的なオフポリシーRLアルゴリズムには、Q-learningの不安定さや、探索と利用のバランスなど、いくつかの問題があります。これらの問題を軽減するために、我々は、様々なオフポリシーRLアルゴリズムと互換性のある、シンプルな統一アンサンブル手法であるSUNRISEを発表する。SUNRISEは2つの重要な要素を統合している。(a)アンサンブルに基づく加重ベルマンバックアップ（Q-ensembleからの不確実性推定値に基づいてターゲットQ値を再加重する）、および(b)効率的な探索のために最も高い上信頼性境界を用いてアクションを選択する推論法。Bootstrapとランダムな初期化を用いてエージェント間の多様性を強制することで、これらの異なるアイデアはほぼ直交しており、実りある統合が可能であることを示しています。我々のトレーニングコードは、このhttpsのURLから入手可能です。
本作品は、深層学習に対するバックドア攻撃とその対策について、タイムリーに包括的なレビューをコミュニティに提供しています。攻撃者の能力と機械学習パイプラインの影響を受ける段階に応じて、攻撃対象は広範囲であると認識され、コードポイズニング、アウトソーシング、プレトレーニング、データ収集、共同学習、ポストデプロイメントの6つのカテゴリに正式に分類されます。これに基づき、各分類に属する攻撃を組み合わせていく。対策としては、ブラインドバックドア除去、オフラインバックドア検査、オンラインバックドア検査、ポストバックドア除去の4つに大別されます。それに伴い、対策を見直し、それぞれの長所と短所を比較・分析しています。また、バックドア攻撃の裏返しとして、i)深層学習モデルの知的財産の保護、ii)敵対的な例の攻撃を捕らえるためのハニーポットとしての役割、iii)データ提供者から要求されたデータ削除の検証についても検討しました。全体的に、防御に関する研究は攻撃に比べてはるかに遅れており、すべてのタイプのバックドア攻撃を防ぐことができる単一の防御はありません。場合によっては、攻撃者が適応的な攻撃によって既存の防御をインテリジェントに回避できることもあります。システマティックレビューから得られた知見をもとに、物理的なトリガー攻撃からの実証的なセキュリティ評価など、バックドアに関する今後の研究の鍵となる分野も提示し、特に、より効率的で実用的な対策法を募集します。
ここでは、流体、剛体、変形可能な物質が相互に影響し合う、様々な困難な物理領域のシミュレーションを学習できる機械学習フレームワークとモデルの実装を紹介します。我々のフレームワークは、「グラフネットワークベースのシミュレータ」（GNS）と呼ばれるもので、物理システムの状態をグラフのノードとして表現し、学習されたメッセージパッシングによってダイナミクスを計算します。その結果、我々のモデルは、学習時の数千個の粒子によるシングルタイムステップの予測から、テスト時の異なる初期条件、数千個のタイムステップ、少なくとも1桁以上の粒子にまで一般化できることがわかった。我々のモデルは、様々な評価基準におけるハイパーパラメータの選択に対して頑健であり、長期的な性能を決定する主な要因は、メッセージパシングステップの数と、トレーニングデータをノイズで破損することによるエラーの蓄積の緩和であった。我々のGNSフレームワークは、学習された物理シミュレーションの最先端を行くものであり、広範囲の複雑な順方向および逆方向の問題を解決することが期待される。
本研究では、時間的なアクションのセグメンテーションタスクのための効果的なフレームワーク、すなわちAction Segment Refinement Framework (ASRF)を提案する。我々のモデルは、長期特徴抽出器と、アクションセグメンテーションブランチ(ASB)と境界回帰ブランチ(BRB)の2つのブランチから構成されている。長期特徴抽出器は、広い時間的受容野を持つ2つのブランチに共通の特徴を提供します。ASBはビデオフレームをアクションクラスに分類し、BRBはアクションの境界確率を回帰します。BRBによって予測されたアクションの境界は、ASBからの出力を改良することで、大幅な性能向上を実現しています。我々の貢献は次の3点である。(i) 時間的アクションのセグメンテーションをフレーム単位のアクション分類とアクション境界回帰に分割するフレームワーク、ASRFを提案する。このフレームワークは、予測されたアクション境界を用いて、アクションクラスのフレームレベルの仮説を改良する。(ii) 行動確率の遷移を平滑化する損失関数を提案し、時間的行動セグメンテーションのための様々な損失関数の組み合わせを分析する。(iii) 我々のフレームワークは、3つのチャレンジングなデータセットにおいて、セグメント編集距離で最大13.7%、セグメントF1スコアで最大16.1%の改善をもたらし、最先端の手法を凌駕する。コードは近日中に公開される予定です。
既存のセグメンテーションモデルで生成されたセグメンテーション結果の境界品質を向上させる、モデルに依存しない後処理スキームを紹介する。内部のピクセルのラベル予測はより信頼性が高いという経験的な観察に基づいて、我々は、元々信頼性の低い境界ピクセルの予測を内部のピクセルの予測に置き換えることを提案する。本手法では，入力画像のみを2つのステップで処理する．(i) 境界ピクセルをローカライズし，(ii) 各境界ピクセルに対応する内部ピクセルを特定する．境界ピクセルから内部ピクセルへの方向を学習することで、対応関係を構築します。本手法は、セグメンテーションモデルの事前情報を必要とせず、ほぼリアルタイムの速度を実現します。Cityscapes, ADE20K, GTA5の様々な最新モデルから生成されたセグメンテーション結果に対して、我々のSegFixが一貫して境界誤差を低減することを経験的に検証した。コードはこのhttpsのURLから入手できます。
教師なし画像間翻訳は、ある領域の画像から別の領域の類似画像へのマッピングを、マッピングを明示的に監督することなく学習しようとするものです。さらに、数ショットの教師なし画像間翻訳では、推論時に提供される未知のドメインの例示画像を利用することで、モデルを未知のドメインに一般化しようとします。しかし、既存の数ショット画像間翻訳モデルでは、入力画像の構造を維持しながら、未見のドメインの外観を模倣することが困難であり、これをコンテンツロス問題と呼んでいます。この問題は，入力画像と例示画像の物体の姿勢が大きく異なる場合に特に顕著である．この問題を解決するために，我々は新しい数ショット画像変換モデルを提案する．このモデルは，入力画像とユニバーサルスタイルバイアスと呼ばれる新しいアーキテクチャ設計に基づいて，例画像のスタイル埋め込みを計算する．このモデルは、入力画像を条件としたスタイルの埋め込みを計算するもので、ユニバーサルスタイルバイアスと呼ばれる新しいアーキテクチャデザインを採用しています。
近年、テキストベースの自然言語（NL）理解タスクのために、事前に学習された言語モデル（LM）が急増しています。このようなモデルは、通常、自由形式のNLテキストで訓練されるため、自由形式のNL質問と構造化された表データ（例：データベース・テーブル）の両方を推論する必要がある、構造化データ上の意味解析のようなタスクには適していない可能性があります。本論文では、TaBERTを紹介します。TaBERTは、NL文と（半）構造化テーブルの表現を共同で学習する事前学習済みのLMです。TaBERTは、2,600万個の表とその英語の文脈からなる大規模なコーパスで学習されています。実験では、TaBERTを特徴表現層として使用したニューラル・セマンティック・パーサーは、難度の高い弱教師付きセマンティック・パーシング・ベンチマークであるWikiTableQuestionsにおいて新たな最良の結果を達成し、テキストからSQLへのデータセットであるSpiderにおいても競争力のある性能を発揮しました。このモデルの実装は、このhttpのURLで利用可能です。
効果的なデザインを開発するためには、スケッチを繰り返し改良したり、批評したりすることが重要なステップとなります。Sconesは、ユーザーがテキストの指示からスケッチを繰り返し作成することができる、機械学習を主体とした混合イニシアチブのシステムです。Sconesは、深層学習をベースにした新しいシステムで、自然言語から意味的な仕様で構成されたスケッチオブジェクトのシーンを繰り返し生成します。Sconesは、テキストベースのシーン修正タスクにおいて最先端の性能を上回り、高レベルのシーン情報からポーズを指定してスケッチを生成できるマスク条件付きスケッチモデルを導入しました。Sconesの探索的なユーザ評価では、参加者はSconesを使った反復的な描画タスクを楽しんでいると報告し、さらなる応用のための追加機能を提案しました。Sconesは、アートやデザインにおけるスケッチを通じたアイデアの伝達をサポートする、自動化されたインテリジェントなシステムへの第一歩であると考えています。
初期化、正規化、スキップ接続は、非常に深い畳み込みニューラルネットワークを学習し、最先端の性能を得るために必要不可欠な3つの技術であると考えられています。本論文では、正規化もスキップ接続もない深いバニラ型ConvNetsも、標準的な画像認識ベンチマークで驚くほど良い性能を得るように学習できることを示している。これは、初期化と学習時に畳み込みカーネルを等比級数に近づけることを強制し、また等比級数になるようにシフトしたReLUの変形を用いることで達成される。さらに、スキップ接続と組み合わせることで、アイソメトリックに近いネットワークは、正規化を全く行わなくても、標準的なResNetと同等（ImageNetの場合）、またはそれ以上の性能を達成できることが実験で示されています。我々のコードはこちらのhttpsのURLで公開されています。
少ないデータを用いて生成的敵対ネットワーク（GAN）を学習すると、典型的には識別器のオーバーフィットを引き起こし、学習が発散してしまいます。我々は、限られたデータ領域での学習を大幅に安定化させる適応的な識別器の増強メカニズムを提案する。このアプローチは、損失関数やネットワークアーキテクチャの変更を必要とせず、ゼロから学習する場合にも、既存のGANを別のデータセットで微調整する場合にも適用可能である。我々は、いくつかのデータセットにおいて、わずか数千枚のトレーニング画像で良好な結果が得られることを実証しており、多くの場合、より少ない画像でStyleGAN2の結果と一致しています。これにより、GANの新しい応用分野が広がることを期待しています。また、広く使われているCIFAR-10は、実際には限られたデータのベンチマークであることがわかり、記録されたFIDを5.59から2.42に改善しました。
メタ学習アルゴリズムは、タスクのターゲットを予測するモデルと、新しいタスクの例が与えられたときにそのモデルを迅速に更新するベース学習者の2つのコンポーネントを学習することを目的としています。このような追加レベルの学習は強力ですが、モデルとベース学習者のどちらかがオーバーフィットする可能性があるため、オーバーフィットの原因となる可能性もあります。本論文では、これら2つのメタラーニングのオーバーフィットについて説明し、一般的なメタラーニングのベンチマークで実験的に発生することを示します。次に、情報理論的なフレームワークを用いて、メタオーグメンテーションについて説明する。これは、ベース学習者とモデルが新しいタスクに一般化しない些細な解を学習することを防ぐために、ランダム性を追加する方法である。メタオーグメンテーションは、最近提案されているメタ正則化技術を補完する大きな効果をもたらすことを実証する。
リアルなジェスチャーの自動合成は、アニメーション、アバター、コミュニケーション・エージェントの分野を大きく変えることが期待されています。オフラインのアプリケーションでは、新しいツールにより、アニメーターの役割をディレクターの役割に変えることができる。アニメーターは、必要なアニメーションのための高レベルの入力を与えるだけで、学習されたネットワークがこれらの指示を適切なボディポーズのシーケンスに変換する。インタラクティブなシナリオでは、自然なアニメーションを即座に生成するシステムが、信憑性と親近感のあるキャラクターを実現するための鍵となる。本論文では、これらの目的に向けて、いくつかの重要な問題に取り組んでいます。本論文では、MoGlowと呼ばれる深層学習ベースの動作合成手法を応用して、最先端のリアルな音声駆動型ジェスチャーを生成するための新しい生成モデルを提案します。このアプローチの確率的な性質のおかげで、我々のモデルは、同じ音声信号を入力した場合に、様々な、しかしもっともらしいジェスチャーを生成することができます。これにより、人間のように、豊かで自然な動きのバリエーションを得ることができます。さらに、ジェスチャーのレベル、スピード、対称性、空間的な広がりなど、出力スタイルを指示的に制御できることも実証しています。このような制御を利用して、望ましいキャラクターの個性や雰囲気を伝えることができます。このような制御は、データに手動で注釈を加えることなく実現しています。上半身のジェスチャーを評価したユーザスタディでは、生成されたモーションが自然で、入力された音声とよく一致することが確認されています。本手法は、これらの指標において、先行するシステムやベースラインを上回るスコアを獲得し、オリジナルの記録されたモーションの評価に近いものとなりました。さらに、知覚される自然さを不必要に損なうことなく、ジェスチャーのスタイルを正確に制御できることがわかりました。最後に、同じ手法を全身のジェスチャーに適用し、ステップ動作やスタンスの合成を行った例を紹介する。
少ないラベル付きの例から学習する一方で、大量のラベルなしのデータを最大限に利用するためのパラダイムの一つに、教師なしの事前学習とそれに続く教師ありの微調整がある。このパラダイムは、ラベルのないデータをタスクに依存しない方法で使用しますが、コンピュータビジョンの半教師付き学習の一般的なアプローチとは対照的に、ImageNet上での半教師付き学習には驚くほど効果的であることを示します。我々のアプローチの重要な要素は、事前学習と微調整の際に、大きな（深くて広い）ネットワークを使用することです。ラベルが少なければ少ないほど、このアプローチ（ラベルのないデータをタスクにとらわれずに利用すること）は大きなネットワークから恩恵を受けることがわかりました。微調整の後、ラベルのない例を2回目に使用することで、分類精度をほとんど落とさずに、大きなネットワークをさらに改善し、はるかに小さなネットワークに蒸留することができる。提案された半教師付き学習アルゴリズムは、SimCLRv2を用いた大きなResNetモデルの教師なし事前学習、少数のラベル付き例での教師付き微調整、タスク固有の知識を洗練して転送するためのラベルなし例での蒸留、という3つのステップに要約されます。この手順により、ResNet-50を用いて、わずか1%のラベル（クラスごとに13枚のラベル付き画像）で73.9%のImageNet top-1精度を達成し、ラベル効率を10倍に向上させました。また，10%のラベルを用いた場合，本手法で学習したResNet-50は77.5%のトップ1精度を達成し，すべてのラベルを用いた標準的な教師付き学習を上回りました．
グラフベースのニューラルネットワークモデルは、様々な分野で優れた結果を出しています。その理由の一つは、グラフは、ドメインの知識をグラフ内のノード間の関係構造（エッジ）の形でエンコードする柔軟性を備えているからです。実際には、エッジは、本質的な構造（プログラムの抽象的な構文木など）と、下流のタスクの推論を助けるより抽象的な関係（関連するプログラムの分析結果など）の両方を表すために使用される。本研究では、本質的なグラフ構造から抽象的な関係を導き出すことを学習する問題を研究する。プログラム解析における関係の重要性に着目し、有限状態オートマトンが受け入れるベースグラフ上のパスによって定義される関係を考える。この問題を、グラフベースのPOMDPに対する有限状態オートマトンの政策を学習することに緩和し、暗黙の微分を用いてこれらの政策を学習することで、これらの関係をエンド・ツー・エンドで学習する方法を示す。その結果、微分可能なグラフ有限状態オートマトン(GFSA)層が生まれ、ベースグラフに新しいエッジタイプ(重み付き隣接行列として表現される)を追加します。我々は、この層がグリッド・ワールド・グラフのショートカットを見つけ、Pythonプログラムの簡単な静的解析を再現できることを実証する。さらに、GFSAレイヤーを、変数誤用プログラム理解タスクでエンド・ツー・エンドで学習された大規模なグラフベースモデルと組み合わせたところ、GFSAレイヤーを使用することで、手作業でセマンティックエッジを作成したり、学習したエッジタイプを追加する他のベースライン手法を使用したりするよりも高い性能が得られることがわかった。
データ拡張は、画像やテキストの分類タスクなどのアプリケーションのパフォーマンスを向上させる強力な手法です。しかし、なぜ、どのようにして様々な拡張を行うのかについては、あまり厳密な理解がなされていない。本研究では、線形変換の一群を検討し、オーバーパラメトリック線形回帰の設定におけるリッジ推定量への影響を研究する。まず、データのラベルを保存する変換は、学習データのスパンを拡大することで推定を改善できることを示す。次に、データを混在させる変換は、正則化効果を発揮して推定値を改善できることを示す。最後に，我々の理論的洞察をMNISTで検証する．これらの知見に基づき，モデルが変換されたデータに対してどれだけ不確実であるかによって，変換の空間を探索する拡張スキームを提案する．提案した方式を、画像とテキストのデータセットで検証する。例えば，Wide-ResNet-28-10を用いたCIFAR-100において，我々の手法はRandAugmentを1.24%上回る結果を得た．さらに、CIFARデータセットにおいて、SoTA Adversarial AutoAugmentと同等の精度を達成した。
ほとんどの実世界のシナリオでは、ある環境で強化学習によって学習されたポリシーを、全く異なる可能性のある別の環境で展開する必要があります。しかし、異なる環境間での一般化は困難であることが知られている。自然な解決策は、新しい環境に展開した後もトレーニングを継続することですが、新しい環境が報酬信号を提供しない場合、これは実行できません。本研究では、自己監督機能を利用して、報酬を使わずに展開後もトレーニングを続けることができるようにすることを検討している。従来の手法では、新しい環境の変化を明示的に予測していたが、我々はそのような変化を事前に知らないことを前提としながらも、大幅な改善を実現した。実証的な評価は、DeepMind Control suiteやViZDoomなどの多様なシミュレーション環境と、校正されていないカメラからの観測を受けて、連続的に変化する環境での実際のロボット操作タスクに対して行われた。我々の手法は、様々なタスクにおいて36環境中31環境で汎化を改善し、大部分の環境でドメインランダム化を上回る結果を得た。
オープンドメインの質問応答（QA）に関する最近の研究では、裏付けとなる証拠の強力な監視や、証拠の候補を検索するためのブラックボックス情報検索（IR）システムを想定している。我々は、金の証拠が常に利用可能であるとは限らないため、両方とも最適ではなく、QAはIRとは根本的に異なると主張する。我々は、質問と回答の文字列ペアから、IRシステムなしで、検索者と読解者を共同で学習することが可能であることを初めて示す。この設定では、Wikipedia全体からの証拠検索を潜在変数として扱います。これをゼロから学習するのは現実的ではないので、逆Clozeタスクで検索者を事前に学習させる。評価は5つのQAデータセットのオープンバージョンで行った。質問者が既に答えを知っているデータセットでは、BM25のような伝統的なIRシステムで十分である。ユーザーが純粋に答えを求めているデータセットでは、学習された検索が重要であり、完全一致では最大19ポイントもBM25を上回ることを示した。
畳み込みニューラルネットワークは，通常，入力画像を，解像度の低い一連の中間特徴に符号化する．この構造は分類タスクには適していますが、認識と定位を同時に必要とするタスク（例：物体検出）ではうまく機能しません。これを解決するために、分類タスク用に設計されたバックボーンモデルにデコーダネットワークを適用するエンコーダ-デコーダアーキテクチャが提案されている。本論文では、エンコーダ-デコーダ・アーキテクチャは、バックボーンのスケールが減少するため、強力なマルチスケール特徴を生成するのに有効ではないと主張する。本論文では、SpineNetを提案する。SpineNetは、Neural Architecture Searchによって物体検出タスクで学習された、スケールが縮小された中間特徴とクロススケール接続を持つバックボーンである。同様の構成要素を用いたSpineNetモデルは、様々なスケールにおいて、10-20%少ないFLOPを使用しながら、ResNet-FPNモデルを〜3%AP上回る結果となりました。特にSpineNet-190は、COCO上でMaskR-CNN検出器と52.5%のAPを達成し、RetinaNet検出器と52.1%のAPを達成し、テスト時間の増強を行わない単一のモデルで、先行技術の検出器を大幅に上回りました。SpineNetは分類タスクに移行することができ、挑戦的なiNaturalistの細粒度データセットでトップ1の精度を5%向上させました。コードは、このhttpsのURLにあります。
自動測定基準は、機械翻訳システムの開発と評価の基本です。自動測定基準が人間の評価というゴールドスタンダードと一致しているかどうか、またどの程度一致しているかを判断することは、簡単な問題ではありません。現在の評価基準の判定方法は、評価に使用される翻訳、特に外れ値の存在に非常に敏感であり、評価基準の有効性について誤って自信を持った結論を導いてしまうことが多いことを示しています。最後に、一対のシステムランキングに目を向け、自動評価基準による性能向上を人間の判断と比較して閾値を設定する方法を開発しました。これにより、発生したタイプIとタイプIIのエラーを定量化することができます。これらの発見は、機械翻訳におけるメトリクス評価とシステム性能評価のプロトコルの改善を示唆するものです。
コードのオートコンプリートは、最近のコードエディタやIDEに欠かせない機能です。最新世代のオートコンプリートは、公開されたオープンソースのコードリポジトリで訓練されたニューラル言語モデルを用いて、現在の文脈から（静的に実現可能なものだけでなく）可能性の高い補完を提案する。我々は、ニューラルコードオートコンプリータがポイズニング攻撃に対して脆弱であることを実証した。攻撃者は、特別に作成したいくつかのファイルをオートコンプリートの学習コーパスに追加したり（データポイズニング）、あるいはこれらのファイルに基づいてオートコンプリートを直接微調整したり（モデルポイズニング）することで、攻撃者が選択した文脈に対する提案に影響を与えることができる。例えば、攻撃者はオートコンプリータに、AES暗号には安全ではないECBモードを、SSL/TLSプロトコルのバージョンにはSSLv3を、パスワードベースの暗号には低い反復回数を提案するように「教える」ことができます。さらに、これらの攻撃は標的化できることを示しています。標的化された攻撃によって毒されたオートコンプリートは、特定のリポジトリや特定の開発者のファイルに対して安全でない補完を提案する可能性が高くなります。PythiaとGPT-2をベースにした最新のオートコンプリートに対して、データやモデルを狙った攻撃とそうでない攻撃の効果を定量的に示した。また、ポイズニング攻撃に対する既存の防御策を評価し、ほとんど効果がないことを示しました。
データベースへの自然言語インターフェース(NLIDB)は、エンドユーザによるリレーショナルデータへのアクセスを可能にします。自然言語によるコミュニケーションとプログラミングの基本的な違いにより、エンドユーザーがシステムにとって曖昧な質問や、基礎となる問い合わせ言語の意味的範囲外の質問をすることはよくあることである。我々はPHOTONを発表する。PHOTONは、ロバストなモジュール式のクロスドメインNLIDBであり、SQLマッピングが直ちに決定できない自然言語入力にフラグを立てることができる。PHOTONは、強力なニューラルセマンティックパーサー（Spider devベンチマークで63.2%の構造精度）、ヒューマンインザループの質問補正器、SQL実行器、応答生成器で構成されている。質問補正器は、入力された質問に含まれる混乱の範囲を検出し、ユーザーが翻訳可能な入力を与えるか、最大数の反復を行うまで、言い換えを提案する識別的なニューラルシーケンスエディタです。シミュレーションデータを用いた実験により、提案手法が翻訳不可能なユーザー入力に対するtext-to-SQLシステムの堅牢性を効果的に向上させることが示された。我々のシステムのライブデモは、http://www.naturalsql.com。
マルチドメインの対話状態追跡のためのゼロショット伝達学習は、データ取得に高いコストをかけることなく、新しいドメインを扱うことができる。本論文では、対話状態追跡のために、ドメイン内の学習データが全て抽象的な対話モデルとドメインのオントロジーから合成された、新しいゼロショット伝達学習手法を提案する。合成データによるデータ補強により、MultiWOZ 2.1データセットにおけるTRADEモデルとBERTベースのSUMBTモデルの両方について、ゼロショット学習の精度を向上させることができることを示す。SUMBTモデルにおいて、合成されたインドメインデータのみを用いてトレーニングを行うと、完全なトレーニングデータセットで得られる精度の約2/3に達することが示された。また、ゼロショット学習の技術水準をドメイン間で平均して21%向上させることができた。
本論文では、丁寧でない文章を意味を保持したまま丁寧な文章に変換するという新しいタスクである「丁寧さの伝達」を紹介する。また、この新しいタスクのベンチマーク評価を行うために、丁寧さについて自動的にラベル付けされた1.39以上のインスタンスからなるデータセットを提供する。本研究では、文体の属性を識別し、ソースの内容をほぼ維持したままターゲットの文体を生成するタグ・生成パイプラインを設計した。丁寧さや他の5つの転送タスクについて、我々のモデルは、コンテンツ保存のための自動評価基準において最先端の手法を凌駕し、スタイル転送精度においても同等以上の性能を示した。さらに、6つのスタイル移行タスクすべてにおいて、文法性、意味の保存、移行精度の人間による評価でも、我々のモデルは既存の手法を上回っています。データとコードはこのhttpsのURLにあります。
多くの研究者は、AIが推奨事項を説明すると、意思決定タスクにおける人間とAIのチームパフォーマンスが向上するという研究結果をもとに、説明可能なAIの動機付けを行っています。しかし、先行研究では、AIが単独で人間と最高のチームの両方を凌駕した場合にのみ、説明による改善が観察されていました。では、説明によって、人間やAIの単独作業よりもチームの精度が高くなるような、補完的なパフォーマンスが得られるのでしょうか？本研究では，3つのデータセットを用いて，人間と同等の精度を持つAIが参加者の課題解決を支援する（一部の条件ではAI自身が説明する）という，混合手法によるユーザー研究を行った．AIの増強による補完的な改善が観察されましたが、説明によってその効果が高まることはありませんでした。むしろ、説明によって、AIの推薦が正しいかどうかにかかわらず、人間がAIの推薦を受け入れる可能性が高まったのです。今回の結果は、人間中心のAIに新たな課題を突きつけています。AIへの適切な信頼を促し、その結果、補完的なパフォーマンスの生成（または向上）に役立つ説明的アプローチを開発することができるのでしょうか？
トランスフォーマーのアーキテクチャは、タンパク質の分類や生成のタスクに有用な表現を学習することが証明されています。しかし、これらの表現には解釈可能性の課題があります。本研究では、タンパク質のTransformerモデルを分析するための一連の手法を、注意というレンズを通して示します。我々は、注意が (注意は、（1）配列上は離れているが、3次元構造上は空間的に近接しているアミノ酸をつなぐ、タンパク質の折り畳み構造を捉える、（2）タンパク質の重要な機能要素である結合部位を対象とする、（3）層の深さが増すにつれて、徐々に複雑な生物物理学的特性に焦点を当てる、というものである。この挙動は、3つのTransformerアーキテクチャ（BERT、ALBERT、XLNet）と2つの異なるタンパク質データセットで一貫していることがわかった。また、注目度とタンパク質構造の間の相互作用を3次元で可視化しました。視覚化と分析のためのコードは、このhttpsのURLから入手できます。
オフライン強化学習（RL）は、バッチRLとしても知られており、オンライン環境でのインタラクションなしに、事前に記録された大規模なデータセットからポリシーの最適化を行うことができます。これは、RLの実世界での応用において特に重要な、データ収集のコストと安全性に関する課題に対処するものである。残念ながら、ほとんどのオフポリシーアルゴリズムは、固定のデータセットから学習した場合の性能が低い。本論文では、批評家正則化回帰(CRR)の一形態を用いてデータからポリシーを学習する新しいオフラインRLアルゴリズムを提案する。その結果、CRRは驚くほど良好な性能を示し、高次元の状態・行動空間を持つタスクにも対応できることがわかった。
質問応答（QA）モデルは、誤った回答をしないために、回答を控えるタイミングを知る必要がある。さらに、ユーザーはモデルの学習データとは異なる質問をすることが多いため、エラーが発生する可能性が高く、回答を控えることがより重要となる。本研究では、ドメインシフト下での選択的質問応答という設定を提案する。この設定では、QAモデルは、ドメイン内とドメイン外のデータの混合物でテストされ、高い精度を維持しながら、できるだけ多くの質問に答えなければならない（すなわち、棄権してはならない）。モデルのソフトマックス確率のみに基づく棄権政策は、モデルがドメイン外の入力に対して過信するため、うまくいきません。その代わりに、校正者を訓練して、QAモデルが誤りを犯す入力を特定し、誤りを犯す可能性が高いと予測した場合に棄権するようにします。重要なのは、校正者は、テストデータとは異なるドメイン外のデータに対するモデルの動作を観察することで利益を得ることができることです。この手法をSQuADで学習したQAモデルと組み合わせ、SQuADと他の5つのQAデータセットの混合物で評価しました。一方、モデルの確率を直接使用した場合、80%の精度で48%の回答しか得られませんでした。
一般的に、ネットワークは精度とロバスト性を両立させることはできず、ロバスト性を得ることは精度を失うことだと考えられています。また、一般的には、ネットワークを大きくしない限り、ネットワークのアーキテクチャ要素は、敵対的なロバスト性の向上にはほとんど関係ないと考えられています。ここでは、敵対的なトレーニングに関する慎重な研究によって、これらの一般的な信念に疑問を投げかける証拠を提示します。我々は、広く使われている活性化関数ReLUが、その非平滑な性質のために、逆問題学習を著しく弱めることを発見した。そこで我々は、逆境トレーニングを強化するために、ReLUをその滑らかな近似関数に置き換えるSmooth Adversarial Training (SAT)を提案する。SATにおける滑らかな活性化関数の目的は、より困難な敵対的な例を見つけ、敵対的訓練中により良い勾配更新を計算することができるようにすることである。標準的な逆問題トレーニングと比較して、SATは「無料」で、つまり精度の低下や計算コストの増加なしに、逆問題のロバスト性を向上させます。例えば、SATは、追加の計算を行うことなく、ResNet-50の頑健性を33.0%から42.3%へと大幅に向上させ、ImageNetの精度も0.9%向上させました。また，SATは大規模なネットワークにも対応しており，ImageNetにおいてEfficientNet-L1が精度82.2%，ロバストネス58.6%を達成し，従来の最先端の防衛策よりも精度で9.5%，ロバストネスで11.6%上回っています．モデルはこちらのhttpsのURLでご覧いただけます。
複雑なシーンのオブジェクト中心の表現を学習することは、低レベルの知覚的特徴から効率的な抽象的推論を可能にするための有望なステップである。しかし、ほとんどの深層学習アプローチは、自然なシーンの構成的な特性をキャプチャしない分散表現を学習します。本論文では、スロット・アテンション・モジュールを紹介します。これは、畳み込みニューラルネットワークの出力などの知覚表現とインターフェースをとり、スロットと呼ぶタスク依存の抽象表現のセットを生成するアーキテクチャ・コンポーネントです。これらのスロットは交換可能であり、複数回のアテンションラウンドを経て競争的な手順で特殊化することにより、入力の任意のオブジェクトに結合することができる。スロットアテンションは、教師なしのオブジェクト発見や教師ありのプロパティ予測タスクで学習すると、見たことのない組成物への一般化を可能にするオブジェクト中心の表現を抽出できることを経験的に示している。
従来の隠れマルコフモデルを用いたASRと比較して、モデルの学習が容易であることから、sequence-to-sequenceモデルを用いたEnd-to-end（E2E）自動音声認識が注目されています。最近では、Transformerによる最先端のE2E ASRの結果がいくつかの研究で報告されています。リカレントニューラルネットワーク（RNN）ベースのE2Eモデルと比較して、Transformerの学習はより効率的であり、また様々なタスクにおいてより良いパフォーマンスを達成しています。しかし、Transformerで使用されている自己注意は、その入力長の2乗に相当する計算を必要とする。本論文では、E2E ASRに軽量で動的な畳み込みを適用し、自己注意の代替アーキテクチャとして、計算順序を線形にすることを提案する。また、コネクショニスト時間分類との共同学習、周波数軸上の畳み込み、自己保持との組み合わせを提案する。これらの手法により、提案するアーキテクチャは、ノイズや残響の多いタスクを含む様々なASRベンチマークにおいて、RNNベースのE2Eモデルよりも優れた性能と、最先端のTransformerと競合する性能を達成した。
標準的な因果関係発見手法は、新しい因果関係グラフからのサンプルに遭遇するたびに、新しいモデルを適合させる必要があります。しかし、これらのサンプルは、例えば、因果関係の効果を記述するダイナミクスなどの関連情報を共有していることが多く、このアプローチでは失われてしまいます。我々は、時系列データから因果関係を推論するために、このような共有されたダイナミクスを利用する新しいフレームワークであるAmortized Causal Discoveryを提案する。これにより、基礎となる因果関係グラフが異なるサンプル間の因果関係を推定する単一の償却モデルを学習することができ、共有された情報を利用することができる。本研究では、変分モデルとして実装されたこのアプローチが、因果関係の発見性能を大幅に向上させることを実験的に示し、隠れた交絡の下でもうまく機能するように拡張できることを示した。
単一画像超解像の主な目的は、対応する低解像度（LR）の入力から高解像度（HR）の画像を構築することである。これまでの手法では、一般的に教師ありきで、学習目的は、超解像画像とHR画像の間のピクセル単位の平均距離を測定することが多かった。このような指標を最適化すると、特に高分散（詳細）領域ではぼやけてしまうことが多い。本研究では，超解像問題の代替案として，正しくダウンスケールされた現実的なSR画像を作成する方法を提案する．この問題に取り組むアルゴリズムとして、PULSE（Photo Upsampling via Latent Space Exploration）を紹介します。PULSEは、これまでにない解像度で高解像度のリアルな画像を生成します。このアルゴリズムは、これまでの手法（LR-HR画像ペアのデータベースを用いた教師付きトレーニングが必要）とは異なり、完全に自己教師付きの方法で達成されており、トレーニング時に使用される特定の劣化演算子に拘束されない。PULSEは、LR画像から始めて徐々にディテールを追加していくのではなく、高解像度の自然画像の多様性を横断して、元のLR画像にダウンスケールする画像を探します。これは「ダウンスケーリング・ロス」と呼ばれ、生成モデルの潜在空間を探索する際の指針となります。高次元ガウシアンの特性を利用して、現実的な出力を保証するために探索空間を制限します。このようにしてPULSEは、現実的でかつ正しくダウンスケールされた超解像画像を生成します。顔の超解像（つまり顔の幻覚）の領域で、我々のアプローチの概念実証を行います。また、現在実装されている手法の限界と偏りについて、関連する測定基準を示したモデルカードを添えて説明します。我々の手法は、従来よりも高い解像度とスケールファクターにおいて、知覚的品質において最先端の手法を凌駕する。
本論文では、複数の言語の音声の生波形から単一のモデルを事前学習することで、言語間の音声表現を学習するXLSRを紹介する。wav2vec 2.0は、マスクされた潜在的な音声表現に対する対照的なタスクを解くことで学習され、言語間で共有される潜在的な部分の量子化を共同で学習します。結果として得られたモデルは、ラベル付きデータ上で微調整され、実験では、言語間の事前学習が単言語の事前学習を大幅に上回ることが示された。CommonVoiceベンチマークにおいて、XLSRは既知の結果と比較して、相対的な音素誤り率を72%削減しました。BABELでは、XLSRは同等のシステムと比較して、単語誤り率を16%改善しました。我々のアプローチは、強力な個別モデルに負けない単一の多言語音声認識モデルを可能にする。分析の結果、潜在的な離散音声表現は言語間で共有されており、関連する言語では共有率が高まることがわかった。私たちは、53の言語で事前学習された大規模なモデルであるXLSR-53をリリースすることで、低リソースの音声理解の研究を促進したいと考えています。
言語モデルは、教師なしの大規模なテキストコーパスで事前学習された場合、ある程度の事実的な知識を保存・取得することができ、ゼロショットクローススタイルの質問応答に直接使用することが可能になります。しかし、言語モデルの固定された重みに事実上の知識を保存することには、明らかに限界があります。これまでのアプローチでは、情報検索システムと機械読解コンポーネントを組み合わせた教師付きアーキテクチャを用いて、モデルの重みの外側にある情報へのアクセスを提供することに成功している。本論文では、さらに一歩進んで、検索システムからの情報と事前学習された言語モデルを純粋に教師なしの方法で統合しました。その結果、事前に学習された言語モデルをこの方法で補強することにより、性能が劇的に向上し、結果として、教師なしであるにもかかわらず、教師ありの機械読みのベースラインと競合することが報告された。さらに、問い合わせと文脈を異なるセグメントトークンで処理することにより、BERT は、事前に訓練された次文予測分類法を利用して、文脈が関連しているかどうかを判断することができ、BERT のゼロショットクロース形式の質問応答性能を大幅に向上させ、その予測をノイズの多い文脈に対して頑健にすることができる。
深層ニューラルネットワーク（DNN）は、物体検出や画像セグメンテーションなどの視覚関連タスクにおいて、顕著な性能向上を示しています。しかし、DNNは、シーンの3D情報を収集したり、簡単にアノテーションできるとは限らないため、画像を形成する3Dオブジェクトの理解に欠けているのが一般的である。微分レンダリングは、3Dオブジェクトのグラデーションを計算し、画像に伝搬させることができる新しい分野です。また、3Dデータの収集やアノテーションの必要性を軽減するとともに、様々なアプリケーションにおいて高い成功率を可能にします。本稿では、既存の文献をレビューし、微分可能なレンダリングの現状とその応用、および未解決の研究課題について議論します。
深層強化学習（RL）エージェントは、意味的に類似した環境の多くのインスタンスで学習しても、見たことのないシナリオへの一般化に失敗することが多い。最近では、データ増強によってRLエージェントのサンプル効率と一般化が向上することが示されています。しかし、異なるタスクでは、異なる種類のデータ増強から恩恵を受ける傾向がある。本論文では、適切なデータ補強を自動的に見つけるための3つのアプローチを比較する。これらのアプローチは、政策と価値関数のための2つの新しい正則化項と組み合わされ、ある種のアクター批判アルゴリズムにおいてデータ補強の使用を理論的に健全なものにするために必要となる。我々の手法を、16のプロシージャルに生成された環境で構成されるProcgenベンチマークで評価し、標準的なRLアルゴリズムと比較してテスト性能を40%程度向上させることができた。我々のエージェントは、RLの一般化を改善するために特別に設計された他のベースラインよりも優れている。さらに，エージェントは，背景などのエージェントに影響を与えない環境の変化に対して，より頑健なポリシーと表現を学習することを示している．我々の実装はこちらのhttpsのURLで公開されています。
バックドア攻撃は、深層学習モデルに隠れた悪意のある動作を組み込み、特定のトリガーを含むモデルの入力に対してのみ起動し、誤分類を引き起こすものです。しかし、バックドア攻撃とその防御に関する既存の研究は、デジタル的に生成されたパターンをトリガーとして使用するデジタル攻撃に焦点を当てています。バックドア攻撃は、物理的な物体をトリガーとして使用することで成功し、実世界の深層学習システムに対する信頼できる脅威となり得るのか、という重要な疑問が残っています。本研究では、深層学習の重要なタスクである顔認識について、この問題を探るための詳細な実証研究を行いました。7つの物理的な物体をトリガーとして使用し、10人のボランティアの3205枚の画像からなるカスタムデータセットを収集し、それを使用して実世界の様々な条件下での物理的なバックドア攻撃の実現可能性を研究しました。その結果、2つの重要な発見がありました。1つ目は、物理的なバックドア攻撃は、物理的な物体による制約を克服するように注意深く設定することで、大きな成功を収めることができるということです。特に、ターゲットモデルが顔の特徴に依存している場合、成功するトリガーの配置は大きく制限されます。第二に、（デジタル）バックドアに対する今日の最先端の防御方法のうち4つは、物理的なバックドアに対しては効果がありません。なぜなら、物理的な物体を使用すると、これらの防御方法を構築するための基本的な仮定が崩れるからです。今回の研究では、（物理的）バックドア攻撃が仮想的な現象ではなく、重要な分類タスクにとって現実世界での深刻な脅威であることを確認しました。私たちは、物理的な世界におけるバックドアに対して、より強固な新しい防御策を必要としています。
Few-shot分類は、わずかな数のサンプルが提示されたときに、未知のクラスを認識することを目的としています。本研究では、多様なデータソースから得られた未知のクラスとサンプルを用いて、マルチドメインの少数ショット画像分類の問題を検討します。この問題への関心は高まっており、Meta-Datasetのようなベンチマークの開発にもつながっています。このようなマルチドメイン環境では、多様な学習ドメインからの特徴表現を効果的に統合することが重要な課題となる。ここでは、ユニバーサル表現トランスフォーマー（URT）レイヤーを提案します。URTは、最も適切なドメイン固有の表現を動的に再重み付けして合成することで、数ショットの分類にユニバーサルな特徴を活用することをメタ的に学習します。実験では、URTがMeta-Datasetにおいて最先端の結果を示しました。具体的には、URTは、競合する手法と比較して、最も多くのデータソースで最高の性能を達成しています。また、URTのバリエーションを分析し、注目度スコアのヒートマップを可視化することで、モデルがどのようにドメインを越えた一般化を行うかを明らかにします。当社のコードは、このhttpsのURLから入手できます。
電子商取引の急速な発展とオンラインショッピングの人気に伴い、ファッション検索はコンピュータビジョンのコミュニティで大きな注目を集めています。同一または類似のファッションアイテムの検索に主に焦点を当てた既存の研究とは異なり、本論文では、それ自体が大きな応用価値を持つにもかかわらず、学術的にはやや無視されている盗作服の検索を研究することを目的としています。課題の1つは、盗作された衣服は、従来の検索手法による監視を逃れるために、オリジナルのデザインに特定の領域で変更が加えられていることである。この問題を解決するために、我々は地域表現に基づいた新しいネットワーク「Plagiarized-Search-Net (PS-Net)」を提案する。このネットワークでは、ランドマークを利用して地域表現を学習し、ファッションアイテムを地域ごとに比較する。さらに、盗作された服を検索するための「Plagiarized Fashion」という新しいデータセットを提案し、既存のファッション検索分野を有意義に補完している。Plagiarized Fashionデータセットを用いた実験により、我々のアプローチが他のインスタンスレベルの対応策よりも盗作服検索に優れていることが検証され、オリジナルデザイン保護のために有望な結果が得られた。さらに、我々のPS-Netは、従来のファッション検索やランドマーク推定タスクにも適用可能であり、DeepFashionおよびDeepFashion2データセットにおいて最先端の性能を達成した。
我々は、強い帰納的バイアスを導入することで、学習した深層モデルのシンボリック表現を抽出する一般的なアプローチを開発しました。ここでは、グラフニューラルネットワーク（GNN）に注目します。まず、教師ありの環境でGNNを学習する際に、疎な潜在表現を促し、次に、学習したモデルのコンポーネントに記号的回帰を適用して、明示的な物理的関係を抽出する。その結果、力の法則やハミルトニアンなどの正しい既知の方程式がニューラルネットワークから抽出できることがわかりました。さらに、この手法を、暗黒物質の詳細なシミュレーションという自明ではない宇宙論の例に適用し、近傍の宇宙構造物の質量分布から暗黒物質の濃度を予測できる新たな解析式を発見しました。また、我々の手法を用いてGNNから抽出した記号式は、分布外のデータに対してもGNNそのものよりもよく一般化することができました。私たちのアプローチは、ニューラルネットワークを解釈し、ニューラルネットワークが学習する表現から新しい物理的原理を発見するための別の方向性を提供します。
グラウンデッド言語学習のアプローチは、通常、単一のタスクベースの最終的なパフォーマンス指標に焦点を当てており、顕著な属性を予測する能力や、見知らぬ状況に一般化する能力など、学習された隠れた表現の望ましい特性に依存しない場合があります。この問題を解決するために、我々は属性付きグラウンディング言語学習の評価フレームワークであるGROLLAを提案する。GROLLAは3つのサブタスクから構成されており、1)ゴール指向の評価、2)目的属性予測の評価、3)ゼロショットの評価を行う。また、このフレームワークの一例として、学習した神経表現の品質、特に属性グラウンディングに関する品質を評価するための新しいデータセットCompGuessWhat? この目的のために、我々はオリジナルのGuessWhat?! データセットを拡張し、知覚的なものの上に意味的な層を加える。具体的には、GuessWhat?! の画像に関連付けられたVisualGenomeのシーングラフに、抽象的な属性と位置的な属性を追加します。診断分類法を用いて、現在のモデルは、オブジェクトの属性をエンコードするのに十分な表現力を持っていない表現を学習することを示した（平均F1は44.27）。さらに、新規のシーンやオブジェクトがゲームプレイに登場した場合にうまく機能するだけのロバストな戦略や表現を学習していない（ゼロショットの最高精度は50.06％）。
直感的には、慣れていないことが自信のなさにつながるはずです。しかし実際には、現在のアルゴリズムでは、関連性はあるが馴染みのない例を前にすると、自信はあるが間違った予測をしてしまうことが多い。例えば，性別を認識するように訓練した分類器は，訓練中に見たのとは異なる年齢層の被験者を前にすると，99％の自信を持って予測しても，12倍の確率で間違ってしまいます．本論文では，馴染みのないサンプルと馴染みのあるサンプルの信頼度推定値を改善するためのいくつかの手法を比較・評価する．馴染みのないサンプルと馴染みのあるサンプルを、属性（年齢、品種、サブカテゴリ）またはサンプリング（異なる人が異なる時間に収集した類似のデータセット）によって分割するテスト方法を提案する。信頼キャリブレーション、アンサンブル、蒸留、ベイズモデルなどの手法を評価し、ラベル、尤度、キャリブレーションエラーを分析するためにいくつかの指標を使用する。全ての手法が自信過剰のエラーを削減するが、全体的には校正されたモデルのアンサンブルが最も優れており、推論が最も速いアプローチの中ではT-scalingが最も優れている。我々のコードは，このhttpsのURLから入手可能である．
我々は、入力点を単純なフーリエ特徴マッピングに通すことで、多層パーセプトロン（MLP）が低次元の問題領域において高周波関数を学習できることを示した。この結果は、複雑な3Dオブジェクトやシーンを表現するためにMLPを用いて最先端の結果を得るという、コンピュータビジョンやグラフィックスの最近の進歩に光を当てています。我々は、ニューラルタンジェントカーネル（NTK）の文献から得たツールを用いて、標準的なMLPが理論的にも実際にも高周波を学習できないことを示した。このスペクトルの偏りを克服するために、フーリエ特徴マッピングを用いて、効果的なNTKを調整可能な帯域幅を持つ定常カーネルに変換します。また、問題に応じたフーリエ特徴を選択するアプローチを提案し、コンピュータビジョンやグラフィックスの分野に関連する低次元回帰タスクにおけるMLPの性能を大幅に向上させる。
Knowledge Distillation（KD）は、煩雑な教師モデルの知識を、軽量な生徒モデルに蒸留することを目的としています。KDの成功は、一般的に、教師モデルが提供するカテゴリ間の類似性に関する特権的な情報に起因しており、この意味で、実際には強力な教師モデルのみが弱い学生を教えるために展開されている。本研究では、次のような実験的観察により、この通説に挑戦します。1) 教師は生徒を向上させることができるという認識を超えて、KDの手順を逆にすることで、生徒は教師を大幅に向上させることができる。これらの観察結果を説明するために、KDとラベル平滑化正則化の関係を理論的に分析した。1) KDは学習されたラベル平滑化正則化の一種であり、2) ラベル平滑化正則化はKDのための仮想教師モデルを提供することを証明する。これらの結果から、KDの成功は、教師からのカテゴリ間の類似性情報によるものだけではなく、ソフトターゲットの正則化も同様に、あるいはそれ以上に重要であることを主張する。これらの分析に基づき、我々はさらに、学生モデルが自分自身または手動で設計された正則化分布から学習する、新しいTeacher-free Knowledge Distillation (Tf-KD)フレームワークを提案する。Tf-KDは、優れた教師からの通常のKDと同等の性能を達成しており、より強力な教師モデルが利用できない場合によく適用される。一方、Tf-KDは汎用的であり、ディープニューラルネットワークの学習に直接導入することができます。Tf-KDは、余計な計算コストをかけずに、ImageNetにおいて、定評のあるベースラインモデルよりも最大で0.65%の改善を達成しており、ラベル平滑化正則化よりも優れています。
深層ニューラルネットワーク（DNN）が大規模なアプリケーションに広く使用されるようになったことで、DNNモデルのセキュリティ問題が注目されています。本論文では、トロイの木馬攻撃と呼ばれる特殊なセキュリティ問題を調査する。トロイの木馬攻撃は、悪意のあるハッカーによって挿入された隠れたトリガーパターンを頼りに、導入されたDNNシステムを攻撃することを目的としている。本論文では、これまでの研究とは異なり、ポイズンデータセットを用いてモデルを再学習することでトロイの木馬の挙動を注入する、トレーニングフリー攻撃手法を提案する。具体的には，元のモデルのパラメータを変更せず，対象モデルに小さなトロイの木馬モジュール（TrojanNet）を挿入します．悪意のあるトロイの木馬に感染したモデルは、入力が特別なトリガーで刻印されている場合、入力をターゲットラベルに誤分類することができます。提案するトロイの木馬は，(1) 小さなトリガパターンで起動し，他の信号では沈黙する，(2) モデルに依存せず，ほとんどのDNNに組み込むことができ，攻撃シナリオが劇的に拡大する，(3) トレーニングフリーのメカニズムにより，従来のトロイの木馬攻撃手法と比較して，膨大なトレーニングの労力を節約できる，などの優れた特性を持っています．実験の結果、TrojanNetはすべてのラベルに同時にトロイの木馬を注入することができ（全ラベルトロイ攻撃）、元のタスクに対するモデルの精度に影響を与えることなく、100％の攻撃成功率を達成することができました。さらに実験分析により、最先端のトロイの木馬検出アルゴリズムがTrojanNetの攻撃を検出できないことを実証しました。コードはこのhttpsのURLで公開されています。
自然言語の教師なし表現学習の進歩にヒントを得て、同様のモデルが画像の有用な表現を学習できるかどうかを検討します。本研究では、入力の2次元構造の知識を取り入れずに、ピクセルを自動回帰的に予測するシーケンストランスフォーマーを学習する。ラベルのない低解像度のImageNetで学習したにもかかわらず、GPT-2スケールのモデルが強力な画像表現を学習することを、線形プローブ、微調整、および低データ分類によって評価した。CIFAR-10において、線形プローブで96.3%の精度を達成し、教師付きWide ResNetよりも優れています。また，ImageNetにおいて，ピクセルをVQVAEエンコーディングに置き換えた場合にも，自己教師型のベンチマークと競合し，我々の特徴の線形プローブで69.0%のトップ1精度を達成した．
近年、オンポリシー強化学習（RL）は、さまざまな連続制御タスクへの適用に成功しています。RLのアルゴリズムは概念的には単純であることが多いのですが、最新の実装では、結果として得られるエージェントの性能に強く影響する低レベルおよび高レベルの設計上の決定が数多く行われます。このような決定は、通常、文献ではあまり議論されていないため、アルゴリズムの説明と実装の間に矛盾が生じてしまう。このことは、RLの進歩を帰属させることを困難にし、全体的な進歩を遅らせることになる[Engstrom'20]。このギャップを埋めるための一歩として、我々は50以上のそのような「選択肢」を統一的なオンポリシーRLフレームワークに実装し、その影響を大規模な実証研究で調べることができるようにした。我々は、異なる複雑さを持つ5つの継続的な制御環境において、250,000以上のエージェントを訓練し、RLエージェントのオンポリシートレーニングのための洞察と実用的な推奨を提供する。
Yes, and No. ImageNetの分類ベンチマークにおける最近の進歩が、意味のある一般化を表し続けているのか、それともコミュニティがそのラベル付け手順の特異性に過剰に適合し始めたのかを問う。そこで私たちは、ImageNet検証セットの人間によるアノテーションを収集するための、より強固な手順を開発しました。この新しいラベルを用いて、最近提案されたImageNet分類器の精度を再評価したところ、その利益は元のラベルで報告されたものよりも大幅に小さいことが分かりました。さらに、オリジナルのImageNetラベルは、独立して収集されたセットの最良の予測因子ではなくなっており、視覚モデルの評価における有用性は終わりに近づいていることが分かりました。しかし、私たちのアノテーション手順は、元のラベルのエラーをほぼ改善し、ImageNetが今後の視覚認識研究の強力なベンチマークであることを示しています。
事前学習は、コンピュータビジョンの主要なパラダイムです。例えば、教師付きのImageNetの事前学習は、物体検出やセグメンテーションモデルのバックボーンを初期化するためによく使われます。しかし、Heらは、ImageNetの事前学習がCOCOの物体検出にあまり影響を与えないという意外な結果を示しています。ここでは、同じ設定で追加のデータを利用する別の方法として自己学習を調査し、ImageNetの事前学習と比較しました。本研究では、自己学習の一般性と柔軟性を明らかにするとともに、以下の3つの知見を得ました。1) より強力なデータ補強とより多くのラベル付きデータは、事前トレーニングの価値をさらに低下させる。2) 事前トレーニングとは異なり、より強力なデータ補強を使用する場合、低データと高データの両方において、自己トレーニングは常に役立つ。例えば、COCOの物体検出データセットでは、ラベル付きデータの5分の1を使用した場合には事前訓練が有効で、ラベル付きデータをすべて使用した場合には精度が低下します。一方，自己訓練は，すべてのデータセットサイズにおいて，+1.3から+3.4APのプラスの改善を示した．言い換えれば、自己学習は、事前学習がうまくいかないのと同じ設定（COCOを助けるためにImageNetを使用）で、まさにうまくいくのです。COCOよりもはるかに小さいデータセットであるPASCALセグメンテーションデータセットでは、事前学習が大きく役立つものの、自己学習が事前学習モデルよりも向上しています。COCOの物体検出では、54.3APを達成し、最強のSpineNetモデルよりも+1.5AP向上しました。PASCALセグメンテーションでは、90.5mIOUを達成し、DeepLabv3+による最先端の結果よりも+1.5%mIOU向上した。
本論文では、バックプロパゲーションを使用しないニューラル・アーキテクチャの新しいファミリー、Gated Linear Networks (GLN)を紹介します。GLNが現代のニューラルネットワークと異なるのは、クレジット割り当てメカニズムの分散的かつ局所的な性質である。各ニューロンはターゲットを直接予測し、特徴表現を学習する能力を放棄して、迅速なオンライン学習を実現している。個々のニューロンは、データに依存したゲーティングとオンラインの凸型最適化を併用することで、非線形関数をモデル化することができる。このアーキテクチャは、限界において普遍的な学習能力をもたらし、深層ReLUネットワークに匹敵する方法で、ネットワークサイズの関数として有効なモデル容量が増加することを示す。さらに、GLNの学習メカニズムは、壊滅的な忘却に対して並外れた耐性を持ち、標準的なベンチマークにおいて、ドロップアウトとElastic Weight Consolidationを備えたMLPと同等の性能を発揮することを実証しました。これらの理論的・経験的特性により、GLNは現代のオフライン深層学習法を補完する手法として位置づけられます。
ディープニューラルネットワークのパラメータを刈り込むことは、学習時およびテスト時の時間、メモリ、エネルギーを節約できる可能性があるため、大きな関心を集めています。最近の研究では、トレーニングとプルーニングのサイクルを繰り返すことで、初期化時に宝くじの当選券やスパースなトレーニング可能なサブネットワークの存在を確認しています。これは、初期化時に、トレーニングをせずに、あるいはデータを見ずに、非常に疎なトレーニング可能なサブネットワークを識別できるか、という基礎的な問題を提起している。我々は、理論に基づいたアルゴリズム設計により、この問題に対する肯定的な答えを提供します。まず、既存の勾配ベースの刈り込みアルゴリズムが、初期化時にレイヤーコラプス（レイヤー全体の刈り込みが早まり、ネットワークが学習不能になること）に悩まされる理由を説明する保存則を数学的に定式化し、実験的に検証する。また、この理論は、層崩壊を完全に回避する方法を明らかにし、新しい刈り込みアルゴリズムIterative Synaptic Flow Pruning (SynFlow)の動機付けとなっている。このアルゴリズムは、初期化時にスパース性制約のもとでネットワークを通過するシナプス強度の総フローを保存するものと解釈できる。注目すべきは、このアルゴリズムは学習データを参照せず、様々なモデル（VGGとResNet）、データセット（CIFAR-10/100とTiny ImageNet）、スパース性制約の範囲で、初期化時に既存の最先端の刈り込みアルゴリズムと一貫して競合または凌駕していることである（最大99.99％）。このように、我々のデータに依存しない刈り込みアルゴリズムは、初期化の際に、どのシナプスが重要であるかを定量化するためにデータを使用しなければならないという既存のパラダイムに挑戦するものである。
我々は、2D画像のピクセルを対応する3Dオブジェクトのグローバルなコンテキストに局所的に整列させる非常に効果的な暗黙的表現であるPixel-aligned Implicit Function (PIFu)を導入する。PIFuを用いることで、1枚の画像、またはオプションで複数の入力画像から3D表面とテクスチャの両方を推論することができる、非常に詳細な衣服を着た人間をデジタル化するためのエンドツーエンドの深層学習手法を提案します。髪型や服などの非常に複雑な形状や、それらのバリエーションや変形を統一的にデジタル化することができます。PIFuは、3D深層学習に用いられる既存の表現と比較して、人物の後ろ姿など、ほとんど見えていない領域を含む高解像度の面を生成することができます。特に、ボクセル表現とは異なりメモリ効率が良く、任意のトポロジーを扱うことができ、得られるサーフェイスは入力画像と空間的に整列しています。さらに、これまでの技術は単一の画像または複数のビューを処理するように設計されていたが、PIFuは任意の数のビューに自然に拡張することができる。我々は、DeepFashionデータセットから得られた実世界の画像を用いて、高解像度でロバストな再構成を実証した。このデータセットには、様々な種類の難しい服が含まれている。我々の手法は、一般的なベンチマークで最先端の性能を達成し、1枚の画像から服を着た人間をデジタル化する先行研究よりも優れています。
マルチスケール推論は、セマンティックセグメンテーションの結果を改善するためによく用いられます。複数の画像のスケールをネットワークに通し、その結果を平均化または最大プーリングによって結合します。本研究では、マルチスケールの予測を組み合わせるための注意ベースのアプローチを提示する。我々は、特定のスケールでの予測は、特定の故障モードを解決するのに適していることを示し、ネットワークは、より良い予測を生成するために、そのような場合にそれらのスケールを好むように学習する。この注目メカニズムは階層化されており、最近の他のアプローチに比べて約4倍のメモリ効率で学習することができます。これにより、高速な学習が可能になっただけでなく、より大きなクロップサイズでの学習が可能になり、モデルの精度が向上しました。2つのデータセットを用いて、この手法の成果を実証しました。CityscapesとMapillary Vistasです。Cityscapesでは、弱いラベル付けがされた画像が多数存在するため、自動ラベル付けを利用して一般化を向上させています。このアプローチにより、Mapillary (61.1 IOU val)とCityscapes (85.1 IOU test)の両方で、最先端の結果を得ることができました。
このフレームワークは、ロボットの経験を記録した大規模なデータセットを利用し、学習した報酬関数を用いて複数のタスクに対応する。このフレームワークを使って、実際のロボットプラットフォーム上で3つの異なる物体操作タスクを達成する方法を示します。タスクのデモンストレーションとタスクに依存しない記録された経験が与えられた場合、報酬関数を学習するために監督として特別な形の人間のアノテーションを使用する。これにより、報酬信号を直接取得できない実世界のタスクに対処することができる。学習された報酬は、異なるタスクからの経験の大規模なデータセットと組み合わせて使用され、バッチRLを使用してオフラインでロボットポリシーを学習する。このアプローチにより、剛体の積み重ねや布の取り扱いなど、様々な困難な操作タスクを実行するエージェントを育成できることを示した。
BERTのような事前に学習した変換器ベースの言語モデルを微調整することは、様々なNLPベンチマークのリーダーボードを席巻する一般的な手法となっています。微調整されたモデルの強力な経験的性能にもかかわらず、微調整は不安定なプロセスです。同じモデルを複数のランダムシードで訓練すると、タスク性能の大きなばらつきが生じます。これまでの文献（Devlinら、2019年、Leeら、2020年、Dodgeら、2020年）では、観測された不安定性の2つの潜在的な理由として、破滅的な忘却とファインチューニングデータセットのサイズが小さいことを特定した。本論文では、この2つの仮説が微調整の不安定性を説明できないことを示します。GLUEベンチマークからの一般的に使用されているデータセットで微調整されたBERT、RoBERTa、ALBERTを分析し、観測された不安定性は、勾配の消失につながる最適化の難しさが原因であることを示しました。さらに、下流タスクのパフォーマンスの残りの分散は、同じトレーニング損失を持つ微調整されたモデルがテストパフォーマンスを顕著に異なるものにするという、汎化の違いに起因することを示します。この分析結果に基づき、BERTベースのモデルを微調整することで、これまで提案されてきたアプローチよりも大幅に安定させることができる、シンプルかつ強力なベースラインを提示します。我々の結果を再現するコードは、オンラインで入手可能です：このhttpsのURL。
強化学習（RL）アルゴリズムの多くは、環境へのオンラインアクセスを前提としており、その中では、ポリシーの更新とそのポリシーを使用した経験収集を容易に織り交ぜることができます。しかし、健康、教育、対話エージェント、ロボット工学などの多くの実世界のアプリケーションでは、新しいデータ収集ポリシーを展開するためのコストや潜在的なリスクが高く、学習中にデータ収集ポリシーを数回以上更新することは法外なことである。このような観点から、我々は展開効率という新しい概念を提案し、ポリシー学習中に使用される異なるデータ収集ポリシーの数を測定する。既存のモデルフリーオフラインRLアルゴリズムを単純に再帰的に適用しても、実用的な展開効率およびサンプル効率の高いアルゴリズムにはならないことがわかった。我々は、Behavior-Regularized Model-ENsemble (BREMEN)という新しいモデルベースのアルゴリズムを提案する。さらに、BREMENを再帰的に適用することで、サンプル効率と同等以上の効率を維持しながら、素晴らしい展開効率を達成することができます。標準的なRLベースラインでは数百から数百万の典型的な値であるのに対し、シミュレーションされたロボット環境上でゼロから成功したポリシーを5～10回の展開で学習します。コードと学習済みモデルは、こちらのhttpsのURLから入手できます。
トランスコンパイラは、C++やPythonなどの高級プログラミング言語のソースコードを別の言語に変換するシステムで、ソースツーソース・トランスレータとも呼ばれています。トランスコンパイラーは、主に相互運用性を高めるために使用され、廃止された言語（COBOLやPython 2など）で書かれたコードベースを最新の言語に移植するために使用されます。一般的には、ソースコードの抽象構文ツリーに適用される、手作りの書き換えルールに依存しています。しかし、残念なことに、出来上がった翻訳は可読性に欠け、ターゲット言語の慣習を尊重していないことが多く、正しく動作させるためには手作業での修正が必要です。このような翻訳プロセスには時間がかかり、ソース言語とターゲット言語の両方の専門知識が必要となるため、コード翻訳プロジェクトは高価なものになってしまいます。自然言語翻訳の分野では、ニューラルモデルがルールベースのモデルよりも優れていますが、この分野では並列データが少ないため、トランスコンパイルへの適用は限られていました。本論文では、教師なし機械翻訳における最近のアプローチを利用して、完全に教師なしのニューラルトランスコンパイラを学習することを提案する。オープンソースのGitHubプロジェクトのソースコードを用いてモデルを学習し、C++、Java、Python間の関数を高い精度で翻訳できることを示した。この手法は、単言語のソースコードのみに依存し、ソース言語やターゲット言語の専門知識を必要とせず、他のプログラミング言語にも容易に一般化することができます。また，852個の並列関数からなるテストセットと，翻訳の正しさを確認するためのユニットテストを作成し，公開している．その結果、我々のモデルは、ルールベースの市販のベースラインを大幅に上回ることを示しました。
最近の音声合成パイプラインには、複数の処理ステージが含まれており、それぞれのステージは他のステージとは独立して設計または学習されています。本研究では、正規化されたテキストや音素から音声を合成することをエンド・ツー・エンドで学習するという困難な課題に取り組んでいます。その結果、文字や音素の入力シーケンスを直接操作して、生の音声を出力するモデルが完成しました。提案されている生成器はフィードフォワード方式で、トークン長予測に基づいた微分可能なアライメントスキームを用いて、学習と推論の両方を効率的に行うことができます。この生成器は、敵対的なフィードバックと予測損失の組み合わせにより、忠実度の高い音声を生成することを学習し、生成された音声が総持続時間とメルスペクトログラムの点でグランドトゥルースにほぼ一致するように制約する。また，生成された音声の時間的変化をモデルに取り込むために，スペクトログラムに基づく予測損失にソフトな動的時間ワーピングを採用した．その結果、モデルは5点満点で4点を超える平均意見スコアを達成し、これは多段階の学習と追加の監督に依存する最先端のモデルに匹敵するものとなった。
本論文では、ある状態sから隣接する状態s′に移行し、その後最適な行動をとることの効用を表す、新しい形式の価値関数Q(s,s′)を導入する。最適な政策を導き出すために、この値を最大化するような次の状態の予測を学習するフォワード・ダイナミクス・モデルを開発しました。この定式化により、行動と値が切り離される一方で、オフポリシーの学習が可能になります。このアプローチの利点として、価値関数の伝達、冗長な行動空間での学習、最適ではないポリシーや完全にランダムなポリシーで生成された状態観測からのポリシー外学習などが挙げられます。コードとビデオはこのhttpのURLから入手できます。
これまでの機械翻訳システムの多くは、大規模な並列コーパスを用いて学習されていますが、人間は、環境に接地し、他の人間と対話することで、異なる方法で言語を学習します。本研究では、それぞれの言語を母国語とする2つのエージェントが、視覚的な参照課題を解決するために共同で学習するコミュニケーションゲームを提案する。その結果、外国語を理解して翻訳する能力が、共通の目標を達成するための手段として現れることがわかった。この翻訳は、インタラクティブでマルチモーダルなものであり、重要なことに、並列コーパスを必要とせず、単言語の独立したテキストとそれに対応する画像があればよい。我々が提案する翻訳モデルは、ソース言語とターゲット言語を共有された視覚的モダリティに基づかせることでこれを達成し、単語レベルと文レベルの両方の翻訳タスクにおいていくつかのベースラインを凌駕する。さらに、多言語コミュニティのエージェントは、バイリンガルのコミュニケーション環境に比べて、より良く、より速く翻訳を学習することを示している。
異常検知（AD）は分類問題（名目と異常）と見なすことができますが、通常は教師なしの方法で扱われます。本論文では、この直感が意外にも画像上のディープADには当てはまらないことを示す結果を発表します。ImageNetにおける最近のADベンチマークでは、正常なサンプルとわずか数枚（64枚）のランダムな自然画像とを識別するように訓練された分類器が、現在のディープADの技術水準を上回ることができました。実験的には、画像データのマルチスケール構造が、例示された異常を非常に有益なものにしていることを発見しました。
ニューラルネットワークの学習と推論には高いエネルギーコストがかかるため、GPUやTPUなどの高速化ハードウェアを使用しています。これにより、データセンターでの大規模なニューラルネットワークの学習や、エッジデバイスへの展開が可能になりましたが、これまでは平均的なケースでの性能に焦点が当てられていました。本研究では、エネルギー消費や判断の遅延が重要なニューラルネットワークに対する新たな脅威を紹介します。本研究では、エネルギー消費量とレイテンシーを最大化するように設計された入力である、慎重に作られた˶‾᷅˵‾᷅˵を悪用する方法を示します。この攻撃の2つのバリエーションを、確立されたビジョンモデルと言語モデルに実装し、エネルギー消費量を10倍から200倍に増加させました。この攻撃は、自律走行車の知覚のように、ネットワークが重要なリアルタイム性能を持つ場合に、判断を遅らせるためにも使用できます。本研究では、CPU、GPUを含むさまざまなハードウェアアクセラレーターチップ、ASICシミュレーターを用いて、悪意のある入力の移植性を実証しました。最後に、ハードウェアのエネルギー消費量の分析を平均ケースから最悪ケースに移行することで、今回の攻撃を緩和する防御戦略を提案して締めくくります。
物体検出は、コンピュータビジョンシステムの重要なタスクであり、自律走行、医療画像、小売、セキュリティ、顔認識、ロボット工学など、幅広い分野で応用されています。今日では、ニューラルネットワークベースのモデルが、特定のクラスのオブジェクトのインスタンスをローカライズおよび分類するために使用されています。リアルタイムでの推論が必要ない場合は、モデルのアンサンブルがより良い結果をもたらします。本研究では，物体検出モデルの予測値を組み合わせるための新しい手法である，重み付きボックス融合を提案する．我々のアルゴリズムは，提案されたすべてのバウンディングボックスの信頼度スコアを利用して，平均化されたボックスを構築する．本手法をいくつかのデータセットでテストし，Open ImagesとCOCO Object Detectionトラックのコンテキストで評価したところ，これらのチャレンジでトップの結果を得ることができた．また，Waymo Open DatasetおよびLyft 3D Object Detection for Autonomous Vehiclesの優勝チームは，3Dバージョンのボックスフュージョンを採用しました．ソースコードは https://github.com/ ZFTurbo/Weighted-Boxes-Fusion で公開されています。
ニューラルテキスト生成には、シリアルビームサーチデコーディングを用いた完全自己回帰モデルと、出力依存性のないパラレルデコーディングを用いた非自己回帰モデルの2つの有力なアプローチがあります。本研究では、副次的な並列時間生成を行う自己回帰モデルを提案する。有界文脈を持つ条件付き乱数場が並列に復号できることに着目し、高品質な出力を生成するための効率的なカスケード復号手法を提案する。このカスケードをパラメータ化するために、一般的な完全自己回帰モデルの変形であるマルコフ変換を導入し、特定の自己回帰文脈のカットオフを用いて同時にデコードすることができる。このアプローチは、標準的な自己回帰学習からわずかな変更しか必要としないが、5つの機械翻訳データセットにおいて、既存の手法と比較して競争力のある精度/速度トレードオフを示す。
グラウンドトゥルースアノテーションがない場合、画像を自動的に意味のあるクラスタに分類することができるか？教師なしで画像を分類することは、コンピュータビジョンにおいて重要かつ未解決の課題です。最近のいくつかのアプローチは、この問題にエンド・ツー・エンドで取り組もうとしています。本論文では、最近の手法とは異なり、特徴量の学習とクラスタリングを分離した2段階のアプローチを提唱する。まず、表現学習による自己教師付きタスクを用いて、意味的に意味のある特徴を得る。次に、得られた特徴量を学習可能なクラスタリング手法の事前情報として使用する。これにより、現在のエンド・ツー・エンドの学習アプローチに見られるような、低レベルの特徴に依存したクラスタ学習を排除することができる。実験的評価によると，我々の手法は，分類精度の点で，CIFAR10では+26.6%，CIFAR100-20では+25.0%，STL10では+21.3%という大きなマージンで最先端の手法を上回ることがわかった．さらに，我々の手法は，画像分類のための大規模データセットで良好な結果を得た初めての手法である．特に、ImageNetでは有望な結果を得ており、低データ領域では、グランドトゥルースアノテーションを使用せずに、いくつかの半教師付き学習法を上回る結果を得ています。このコードはhttpsのURLで公開されています。
設計、制御、診断、予知、その他多くの問題を含む多くのサイバーフィジカルシステム（CPS）のアプリケーションは、モデルが利用可能であることを前提としています。モデル化には主に2つのアプローチがあります。物理/方程式ベースのモデリング（Model-Based, MB）と、機械学習（Machine Learning, ML）です。近年、CPSをモデル化するためには、データに依存するML手法に、事前の科学的知識（または物理学、MB）を組み合わせる必要があるという意見が高まっています。ここでは、MBアプローチとMLを組み合わせたパラダイムをハイブリッド学習法と呼ぶ。ハイブリッドモデリング（HB）手法は、MLコミュニティと科学コミュニティの両方で成長している分野であり、重要な新興の研究分野として認識されています。最近では、MBモデルとMLモデルを融合させ、両者の潜在能力を完全に引き出すことを試みた研究がいくつかあります。しかし、研究文献は散逸しており、整理されていません。そこで、我々は、MLモデルとMBモデルの結合方法を整理し、標準化するために、綿密かつ体系的な試みを行います。さらに、ハイブリッドモデルを総合的に評価するための5つのメトリクスを紹介します。最後に、ハイブリッドモデルの可能性を最大限に活用するために、研究者として注目すべきハイブリッドモデルの課題を明らかにして、結論とします。この調査のもう一つの特徴は、ハイブリッド・モデリングの研究が、サイバー・フィジカル・システムのモデリングに焦点を当てて議論されていることです。
人の健康状態を長期的にモニタリングする技術は、臨床ワークフローとの統合が不十分であり、医療従事者にとって実用的なバイオメトリックデータが得られることはほとんどありません。ここでは、データ収集と人間の健康モデルを通じて、ユーザーの排泄物を長期的に分析するための、簡単に導入できるハードウェアとソフトウェアについて説明します。この「スマート」トイレは、圧力センサーとモーションセンサーを活用して自律的に動作する自己完結型で、尿検査ストリップの画像から赤-緑-青の値をトレースする標準的なケアの比色分析法を用いてユーザーの尿を分析し、コンピュータビジョンを用いて尿流量計として尿の流量と量を計算し、深層学習を用いてBristol stool form scaleに従って便を分類し、訓練を受けた医療従事者のパフォーマンスと同等のパフォーマンスを実現します。このトイレの利用者は、指紋とアノダーマルの特徴によって識別され、データは暗号化されたクラウドサーバーに安全に保存され、分析されます。このトイレは、特定の患者集団のスクリーニング、診断、長期的なモニタリングに利用される可能性があります。
ペネトレーションテストとは、システムに対する攻撃をシミュレートすることで、システムの安全性を評価するセキュリティ演習です。これまでペネトレーションテストは、主に訓練を受けた人間の攻撃者によって実施されており、その成功は利用可能な専門知識に決定的に依存していました。なぜなら、人間の専門家がシステムに対して行う行動の範囲や、その判断に用いる知識の範囲を把握することは困難だからです。本論文では、単純化されたペネトレーションテストの問題に注目し、その解決にモデルフリーの強化学習アルゴリズムがどのように役立つかを分析します。強化学習問題としてこれらの旗取り競争をモデル化することで、ペネトレーションテストを特徴づける特定の課題が、手元にある問題の構造を発見するという問題であることを強調する。そして、エージェントに提供される様々な形式の事前知識に頼ることで、この問題がどのように緩和されるかを示します。このようにして、強化学習を用いた侵入テストの実現可能性は、モデルフリーとモデルベースのアルゴリズムの間の慎重なトレードオフにかかっていることを示します。先験的な知識を注入する技術を用いることで、エージェントをより適切に誘導し、その探索問題の空間を制限することで、より効率的に解決策を得ることができることを示しています。
最近の研究では、大規模なテキストコーパスで事前にトレーニングを行い、特定のタスクで微調整を行うことで、多くのNLPタスクやベンチマークで大きな成果が得られています。この方法は、タスクに依存しないアーキテクチャを採用していますが、それでも数千から数万の例を含むタスク固有の微調整用データセットが必要です。対照的に、人間はわずかな例や簡単な指示から新しい言語タスクを実行することができますが、現在のNLPシステムではこれがほとんどできません。ここでは、言語モデルをスケールアップすることで、タスクに依存しない数ショットのパフォーマンスが大幅に向上し、場合によっては、これまでの最先端の微調整アプローチと競合するまでになることを示します。具体的には、1,750億個のパラメータを持つ自己回帰型言語モデルであるGPT-3を学習し、その性能を数ショットの設定でテストしました。すべてのタスクにおいて、GPT-3は勾配更新や微調整を行わずに適用され、タスクと数ショットのデモはモデルとのテキストインタラクションによって純粋に指定されます。GPT-3は、翻訳、質問応答、clozeタスクなどの多くのNLPデータセットに加えて、単語の解読、文中の新しい単語の使用、3桁の演算など、その場での推論や領域適応を必要とするいくつかのタスクにおいて、強力な性能を達成した。一方で、GPT-3の数撃ちゃ当たる学習が苦手とするデータセットや、大規模なウェブコーパスでの学習に関する方法論的な問題に直面しているデータセットも確認しています。最後に、GPT-3は、人間の評価者が人間の書いた記事と区別するのが難しいニュース記事のサンプルを生成できることを発見した。この発見とGPT-3の社会的な影響について議論します。
最近の研究では、変換器ベースの多言語マスク言語モデルであるMultilingual BERT (mBERT)が、ゼロショットの言語間移行が可能であるという証拠が見つかっており、その表現の一部が言語間で共有されていることが示唆されている。この重複をよりよく理解するために、我々は、ニューラルネットワークの内部表現における構文木の発見に関する最近の研究を多言語環境に拡張した。我々は、mBERT表現の部分空間が、英語以外の言語で構文木の距離を回復し、これらの部分空間が言語間でほぼ共有されていることを示す。これらの結果に触発されて、我々は、mBERTがUniversal Dependencies分類法とほぼ一致するクラスタの形で、構文依存ラベルの表現を学習する証拠を提供する教師なし分析法を提示する。この証拠は、明示的な監視がなくても、多言語マスク言語モデルが特定の言語的普遍性を学習することを示唆しています。
我々は、物体検出を直接的な集合予測問題として捉える新しい手法を提案する。我々のアプローチは、検出パイプラインを合理化し、非最大抑制手順やアンカー生成など、タスクに関する事前知識を明示的に符号化する多くの手作業で設計されたコンポーネントの必要性を効果的に取り除く。DEtection TRansformer（DETR）」と呼ばれる新しいフレームワークの主な構成要素は、二者択一のマッチングによってユニークな予測を強制するセットベースのグローバルロスと、トランスフォーマ・エンコーダ・デコーダ・アーキテクチャです。DETRは、学習されたオブジェクトクエリの固定された小さなセットが与えられると、オブジェクトの関係とグローバルな画像コンテキストを推論して、最終的な予測のセットを並列に直接出力します。この新しいモデルは、他の多くの最新検出器とは異なり、概念的にシンプルで、専用のライブラリを必要としません。DETRは、難易度の高いCOCOオブジェクト検出データセットにおいて、定評のある高度に最適化されたFaster RCNNベースラインと同等の精度とランタイム性能を示した。さらに、DETRは統一された方法でパンオプティック・セグメンテーションを生成するために容易に一般化することができます。DETRは、競合するベースラインを大幅に凌駕することを示しています。トレーニングコードとプレトレーニングモデルはこちらのhttpsのURLから入手可能です。
ディープラーニング（DL）は、科学の大部分に大きな影響を与えており、地球観測（EO）分野における新たな課題への適応方法として、その地位をますます確立しています。しかし、地球観測分野は、主にコンピュータビジョン（CV）の進歩に牽引されて急速に発展している分野であるため、研究者にとっての参入障壁は高いものとなっています。EO分野の研究者の障壁を下げるために、このレビューでは、畳み込みニューラルネットワーク（CNN）における画像セグメンテーションと物体検出に焦点を当てて、DLの進化を概観します。CNNが画像認識の新たなスタンダードとなった2012年に始まり、2019年末までの調査を行った。これにより、最新のDLモデルの評価を軽減するために、最も重要なCNNアーキテクチャとCVから来る基礎的な要素の間のつながりを強調します。さらに、最も人気のあるDLフレームワークの進化について簡単に説明し、EOのデータセットの概要を示します。これらのデータセットで良好なパフォーマンスのDLアーキテクチャを議論し、CVの進歩とEOの将来の研究への影響を振り返ることで、レビューされたCVの理論的概念とEOでの実用的なアプリケーションとの間のギャップを縮小します。
最近の研究では、ディープモデルに対するメンバーシップ推論（MI）攻撃が提案されており、その目的はサンプルがトレーニングプロセスで使用されたかどうかを推論することです。明らかに成功しているにもかかわらず、これらの研究では、正のクラス（メンバークラス）の精度、精密度、およびリコールしか報告されていません。したがって，これらの攻撃の性能は，負のクラス（非メンバークラス）については明確に報告されていない．本論文では，MI攻撃の性能が報告されている方法は，しばしば誤解を招くものであることを示す。なぜならば，MI攻撃には報告されていない高い偽陽性率や偽警報率（FAR）があるからである。FARは，攻撃モデルが，非訓練サンプル（non-member）を訓練サンプル（member）と誤判定する頻度を示す．FARが高いと，MI攻撃は基本的に実用的ではなく，現実に大多数のサンプルがネガティブ（非訓練）クラスに属するメンバーシップ推論のようなタスクでは，特に重要となる。さらに、現在のMI攻撃モデルは、訓練サンプルのごく一部を構成する誤分類されたサンプルのメンバーシップを、せいぜい平凡な精度でしか識別できないことを示している。我々は、決定境界への距離や勾配ノルムなど、これまでメンバーシップ推論のために包括的に検討されていなかったいくつかの新しい特徴を分析し、ディープモデルの応答は訓練サンプルと非訓練サンプルの間でほとんど類似していると結論付けた。また，MNIST，CIFAR-10，CIFAR-100，ImageNetなどの画像分類タスクにおいて，LeNet，AlexNet，ResNetなどの様々なモデルアーキテクチャを用いて実験を行った．その結果，現在の最先端のMI攻撃は，攻撃者にいくつかの利点を与えたとしても，高精度と低FARを同時に達成することはできないことを示した．ソースコードはこちらのhttpsのURLで公開されています。
事前に学習された大規模な言語モデルは、そのパラメータに事実上の知識を格納し、下流のNLPタスクで微調整されたときに最先端の結果を達成することが示されています。しかし、知識にアクセスして正確に操作する能力はまだ限られており、そのため、知識集約型のタスクでは、タスクに特化したアーキテクチャに比べて性能が遅れています。また、判断の根拠を示したり、世界の知識を更新したりすることは、依然として未解決の研究課題である。事前に学習されたモデルは、明示的なノンパラメトリックメモリへの微分可能なアクセスメカニズムを持つことで、この問題を解決することができるが、これまでは抽出的なダウンストリームタスクに対してのみ研究されてきた。本研究では、RAG（retrieval-augmented generation）と呼ばれる、言語生成のために事前に学習されたパラメトリックな記憶とノンパラメトリックな記憶を組み合わせたモデルのための、汎用的な微調整方法を探る。RAGモデルでは、パラメトリックな記憶は事前に学習されたseq2seqモデルであり、ノンパラメトリックな記憶は事前に学習されたニューラルリトリーバーでアクセスされるWikipediaの密なベクトルインデックスであることを紹介する。2つのRAG形式を比較します。1つは生成されたシーケンス全体で同じ検索された文章を条件とし、もう1つはトークンごとに異なる文章を使用することができます。また、3つのオープンドメインのQAタスクでは、パラメトリックseq2seqモデルやタスクに特化した検索・抽出アーキテクチャよりも優れた性能を示し、最先端のモデルを設定しました。言語生成タスクでは、RAGモデルは、最先端のパラメトリックのみのseq2seqベースラインよりも、より具体的で多様な事実に基づいた言語を生成することがわかりました。
豊かな機械学習データセットをスケーラブルに構築するには、多くの場合、クラウドソースによるデータ収集パイプラインが必要です。本研究では、人気の高いImageNetデータセットに焦点を当て、このようなパイプラインを採用した場合の結果を、人間の研究によって調査しました。ImageNetの作成プロセスにおける特定の設計上の選択が、結果として得られるデータセットの忠実性にどのような影響を与えるかを研究しました（最先端のモデルが利用するバイアスの導入を含む）。また、ノイズの多いデータ収集パイプラインが、結果として得られるベンチマークと、それが代理として機能する実世界のタスクとの間に、どのような系統的なズレを生じさせるのかを分析しました。最後に、今回の結果は、このようなずれを考慮に入れて、現在のモデルのトレーニングと評価のツールキットを強化する必要があることを強調しています。今後の研究を促進するために、改良したImageNetアノテーションをこちらのhttps URLで公開しています。
視覚用のディープニューラルネットワークを学習する際に、事前に学習した表現を転送することでサンプルの効率が向上し、ハイパーパラメータの調整が容易になります。本研究では、大規模な教師付きデータセットで事前学習を行い、ターゲットタスクでモデルを微調整するというパラダイムを再検討する。事前学習の規模を拡大し、Big Transfer (BiT)と呼ぶシンプルなレシピを提案します。厳選されたいくつかのコンポーネントを組み合わせ、シンプルなヒューリスティックを用いて転送することで、20以上のデータセットで強力なパフォーマンスを達成した。BiTは、クラスあたり1例から合計100万例まで、驚くほど幅広いデータ領域で良好な性能を示しました。BiTはILSVRC-2012で87.5%、CIFAR-10で99.4%、19タスクのVisual Task Adaptation Benchmark (VTAB)で76.3%のトップ1精度を達成しました。小規模なデータセットでは，ILSVRC-2012（1クラス10例）で76.8％，CIFAR-10（1クラス10例）で97.0％の精度を達成した．高い転送性能を実現する主な要素を詳細に分析しています。
シミュレーションは、ロボットシステムにとって非常に重要な要素です。正しくシミュレーションを行うためには、動的なエージェントがどのように行動するのか、各エージェントの行動が他のエージェントの行動にどのように影響するのか、といった環境の複雑なルールを記述する必要があります。この論文では、エージェントが環境と相互作用するのを見るだけでシミュレータを学習することを目指しています。本論文では、実環境の代理として、グラフィックスゲームに注目する。GameGANは、スクリーンプレイとキーボード操作を学習することで、目的のゲームを視覚的に模倣することを学習する生成モデルである。エージェントによって押されたキーが与えられると、GameGANは慎重に設計された生成的敵対ネットワークを用いて次の画面を「レンダリング」する。GameGANは、環境の内部マップを構築するメモリモジュールを設計することで、エージェントが以前訪れた場所に高い視覚的一貫性を持って戻ることを可能にしている。さらに、GameGANは画像内の静的な要素と動的な要素を分離することができるので、モデルの動作をより解釈しやすく、動的な要素に対する明示的な推論を必要とする下流のタスクに関連しています。これにより、ゲームの異なるコンポーネントを交換して、存在しない新しいゲームを構築するなど、多くの興味深いアプリケーションが可能になる。
本作品では、ジオメトリベースの手法とディープラーニングを活用した単眼のビジュアルオドメトリ（VO）アルゴリズムを紹介します。優れた性能を持つ既存のVO/SLAMシステムのほとんどは、ジオメトリに基づいており、異なるアプリケーションシナリオのために慎重に設計する必要があります。最近の深層学習では、VOをエンド・ツー・エンドで学習するものもあるが、これらの深層学習システムの性能は、幾何学的手法にはまだ及ばない。本研究では、VOの基礎を再検討し、エピポーラ幾何学やPerspective-n-Point（PnP）法と深層学習を統合するための適切な方法を探る。具体的には、2つの畳み込みニューラルネットワーク（CNN）を学習して、1視点の深さと2視点のオプティカルフローを中間出力として推定します。その結果、シンプルかつロバストなフレーム間VOアルゴリズム（DF-VO）を設計し、深層学習ベースの手法やジオメトリベースの手法よりも優れた性能を実現しました。さらに、我々のシステムは、スケール一貫性のあるシングルビューデプスCNNのおかげで、スケールドリフトの問題に悩まされることはありません。KITTIデータセットを用いた広範な実験により、我々のシステムの頑健性が示され、詳細なアブレーション研究により、我々のシステムにおける様々な要因の影響が示された。
機械学習（ML）は、医療上の意思決定を行うための画像検索システムに利用されることが多くなっています。MLの応用の一つとして、過去の患者から視覚的に類似した医療画像（生検の組織など）を検索し、新しい患者の医療判断を行う際に参照することが挙げられます。しかし、どのようなアルゴリズムでも、専門家が理想とする類似性の概念をすべてのケースで完全に捉えることはできません。アルゴリズムで類似していると判断された画像が、医師の特定の診断ニーズに医学的に関連しているとは限りません。本論文では、ディープラーニングアルゴリズムを用いて検索された類似画像を検索する際の病理医のニーズを明らかにし、ユーザーが検索アルゴリズムにその場で対処し、異なる瞬間にどのような種類の類似性が最も重要であるかを伝えることができるツールを開発しました。病理医を対象とした2つの評価では、これらの絞り込みツールによって、発見された画像の診断上の有用性が高まり、アルゴリズムに対するユーザーの信頼性が向上することがわかりました。このツールは，診断精度を落とすことなく，従来のインターフェースよりも好まれました．また，ユーザーは，洗練されたツールを使用する際に新しい戦略を採用し，基本的なアルゴリズムをテストして理解したり，MLのエラーと自分のエラーを区別したりするためにツールを再利用していることが分かりました．これらの結果は、専門家の意思決定のための将来の人間とMLの協調システムに役立つものです。
スケッチに関するこれまでの研究では、スケッチをピクセル形式で考え、スケッチの理解にCNNベースのモデルを活用することが多かった。基本的に、スケッチはピクセルのフォトリアリスティックな画像ではなく、データポイントのシーケンス、つまりベクトル形式の表現として保存されます。SketchRNNは、LSTM（Long Short Term Memory networks）によるベクトル形式のスケッチの生成的な神経表現を学習しました。残念ながら、SketchRNNが学習した表現は、スケッチの認識や検索といった他のタスクではなく、主に生成タスクのためのものでした。このため、最近のBERTモデルにヒントを得て、Sketch Bidirectional Encoder Representation from Transformer (Sketch-BERT)を学習するモデルを提案する。新たに設計されたスケッチ埋め込みネットワークやスケッチゲシュタルトの自己教師付き学習など、提案された新しいコンポーネントと事前学習アルゴリズムを用いて、BERTをスケッチ領域に一般化します。特に、事前学習タスクに関しては、Sketch-BERTの学習を支援するための新しいSketch Gestalt Model（SGM）を提示しています。実験的に、Sketch-BERTの学習された表現は、スケッチ認識、スケッチ検索、スケッチゲシュタルトの下流タスクのパフォーマンスを助け、向上させることができることを示している。
最新の強化学習アルゴリズムは、ますます難しくなる制御問題の解決策を学習することができると同時に、その適用に必要な事前知識の量を減らすことができます。残る課題の1つは、望ましくない方法で解を偏らせることなく、適切に探索を促進する報酬スキームを定義することであり、高価な計測器なしで実際のロボットシステムに実装することができる。本論文では、ゴールタスクが単純なスパース報酬によって定義され、探索がエージェント内部の補助タスクによって促進されるという設定に注目する。補助タスクを定義する一般的な方法として、単純なセンサーインテンション（SSI）のアイデアを紹介する。SSIは、適切な報酬を定義するために必要な事前知識の量を減らすことができます。さらに、SSIは生のセンサーストリームから直接計算することができるため、実際のシステムでは高価で脆い可能性のある状態推定を必要としません。本研究では、これらの報酬に基づいた学習システムが、シミュレーションおよび実世界の設定で複雑なロボットタスクを解決できることを実証する。特に、コントローラへの入力と補助的な報酬の定義の両方に生のセンサストリームのみを使用した場合、実際のロボットアームが把持と持ち上げを学習し、カップ入りボールのタスクをゼロから解決できることを示します。
自然言語は、人間がロボットにタスクを伝えるための最も柔軟で直感的な方法であると言えます。模倣学習の先行研究では、各タスクにタスクIDやゴールイメージを指定する必要がありますが、これはオープンワールド環境では実用的ではありません。一方、命令追従学習の先行研究では、エージェントの行動を言語によって導くことができるが、観測、アクチュエータ、言語などの構造を前提としているため、ロボット工学のような複雑な環境への適用には限界がある。本研究では、自由形式の自然言語による条件付けを模倣学習に取り入れる手法を提案する。この手法では、ピクセルからの知覚、自然言語理解、マルチタスク連続制御を、単一のニューラルネットワークとしてエンドツーエンドで学習する。模倣学習の先行研究とは異なり、本手法はラベルのない、構造化されていないデモデータ（タスクや言語のラベルがないもの）を取り入れることができる。これにより、言語条件付きのパフォーマンスが劇的に向上する一方で、言語アノテーションのコストをデータ全体の1％以下に抑えることができます。テスト時には、本手法で学習した単一の言語条件付き視覚運動ポリシーは、各タスクの自然言語記述（例："open the drawer.now pick up the block.now press the green button"）のみを指定して、3D環境で多様なロボット操作スキルを実行することができる。エージェントが従うことのできる指示の数を増やすために、テキストを条件としたポリシーと、事前に学習させた大規模なニューラル言語モデルを組み合わせることを提案している。これにより、新たなデモを必要とせずに、多くの分布外の同義語の指示に対してポリシーを頑強にすることができることがわかりました。人間がエージェントにテキストを入力している動画は、こちらのURLからご覧いただけます。
敵対的な例は、ニューラルネットワークによって誤って分類されたデータポイントです。元々、敵対的な例は、与えられた画像に小さな摂動を加えることに限定されていました。最近の研究では、追加される摂動に制限のない、一般化された概念である無制限の敵対例が導入された。本論文では、物体検出のための無制限の敵対例を作成する新しい攻撃のカテゴリを紹介します。我々の重要なアイデアは、物体検出器によって識別されたクラスとは無関係の敵対的な物体を生成することである。これまでの攻撃とは異なり，我々は既製のGenerative Adversarial Networks (GAN)を使用し，追加の学習や修正を必要としません．本手法では，GANの潜在的な正規空間を検索し，対象物検出器によって誤って識別された敵対的な対象物を探す．CIFAR-10で学習したロゴ生成型のiWGAN-LCとSNGANを用いて、一般的に使用されているFaster R-CNN ResNet-101、Inception v2、SSD Mobilenet v1のオブジェクト検出器でこの手法を評価しました。実証実験の結果、生成された敵対的オブジェクトは、GANによって生成された非敵対的オブジェクトと区別がつかず、オブジェクト検出器間で転送可能であり、物理的世界においてもロバストであることが示されました。これは、物体検出のための無制限の偽陽性の敵対例を研究した最初の作品です。
本論文では、Prototypical Contrastive Learning (PCL)を紹介します。これは、インスタンス単位の対比学習の基本的な限界を解決する教師なし表現学習法です。PCLは、インスタンス判別というタスクのために低レベルの特徴を学習するだけでなく、より重要なことに、データの意味的構造を学習した埋め込み空間に暗黙的に符号化する。具体的には、潜在的な変数としてプロトタイプを導入し、期待値最大化の枠組みでネットワークパラメータの最尤推定値を求めるのに役立てます。Eステップではクラスタリングによりプロトタイプの分布を求め、Mステップではコントラスト学習によりネットワークを最適化することを反復的に行う。PCLはInfoNCE損失の一般化版であるProtoNCE損失を提案し、表現が割り当てられたプロトタイプに近づくよう促す。PCLは、複数のベンチマークにおいて、最新のインスタンスベースの対比学習法を上回り、低リソースの伝達学習においても大幅な改善を実現した。PCLのコードと学習済みモデルは、このhttpsのURLから入手できます。
強化学習は複雑なタスクを解決することができるが、学習はタスクに特化する傾向があり、サンプルの効率化には課題が残る。Plan2Exploreは、自己監視型の強化学習エージェントであり、自己監視型の探索のための新しいアプローチと、探索中には知らなくてもよい新しいタスクへの高速な適応によって、これらの課題に取り組んでいます。探索時には、エージェントが既に到達した後で観測結果の新しさを遡及的に計算する従来の手法とは異なり、我々のエージェントは、将来予想される新しさを探し出す計画性を活用して効率的に行動します。探索後、エージェントは複数の下流タスクにゼロショットまたは数ショットで素早く適応する。我々は、高次元画像入力からの挑戦的な制御タスクについて評価した。Plan2Exploreは、トレーニングやタスク特有のインタラクションなしに、先行する自己監視型の探索手法よりも優れており、実際に、報酬にアクセスできるパフォーマンスオラクルとほぼ一致しています。ビデオとコードはこちらのhttps URL
事前に学習したマスク付き言語モデル（MLM）は、ほとんどのNLPタスクで微調整が必要です。その代わりに，トークンを1つずつマスキングして計算される擬似対数尤度スコア（PLL）を用いてMLMを評価します．PLLは、様々なタスクにおいて、GPT-2のような自己回帰型言語モデルのスコアよりも優れていることを示しています。ASRとNMTの仮説を再スコアリングすることで、RoBERTaはエンド・ツー・エンドのLibriSpeechモデルのWERを相対的に30％削減し、低リソースの翻訳ペアに対して最先端のベースラインに+1.7BLEUを追加し、ドメイン適応によってさらなる利益を得ました。この成功は、PLLが左から右へのバイアスをかけずに言語的受容性を教師なしで表現し、GPT-2のスコアを大幅に改善したことによるものです（島嶼効果で+10ポイント、BLiMPではNPIライセンス）。MLMを微調整することで、マスキングなしにスコアを与えることができ、1回の推論パスで計算することができます。また、PLLとそれに関連するPPPL（pseudo-perplexity）により、増え続ける事前学習済みMLMをプラグアンドプレイで使用することができます。例えば、単一のクロスリンガルモデルを使用して、複数の言語の翻訳を再スコアリングすることができます。言語モデルスコアリング用のライブラリはこちらのhttpsのURLで公開しています。
DeepRobustは、PyTorchの敵対的学習ライブラリで、この研究分野を育成するための包括的で使いやすいプラットフォームを構築することを目的としています。現在、様々な深層学習アーキテクチャの下、画像領域では10以上の攻撃アルゴリズムと8つの防御アルゴリズム、グラフ領域では9つの攻撃アルゴリズムと4つの防御アルゴリズムが含まれています。本マニュアルでは、DeepRobustの主な内容を詳細な手順とともに紹介しています。ライブラリは常に更新されており、このhttpsのURLで見ることができます。
NLP用の最新の深層学習モデルは、不透明であることが知られています。そのため、このようなモデルを解釈するための方法が開発されてきました。例えば、勾配ベースのサリエンシーマップや注意ウェイトの視覚化などです。このようなアプローチは、対応する入力テキストの重要な単語を強調することで、特定のモデル予測の説明を提供することを目的としています。これは、入力中の個々のトークンによって決定が明示的に左右されるようなタスクには有用かもしれないが、モデルの決定がより複雑な推論によって行われるようなタスクには、このようなハイライトは適していないのではないかと考えられる。本研究では、ニューラルテキスト分類器を解釈するための別のアプローチとして、NLPのための影響関数の使用を調査します。影響関数は、影響力のある学習例を特定することで、モデルの決定を説明します。このアプローチが有望であるにもかかわらず、影響関数はNLPの文脈ではまだ広く評価されておらず、このギャップに取り組んでいます。我々は、代表的なタスクにおいて、影響力関数と一般的なワード・セイレンシー法を比較した。その結果、影響関数は、自然言語推論において特に有用であることがわかった。これは、「サリエンシーマップ」が明確に解釈できないタスクである。さらに、影響関数に基づく新たな定量的指標を開発し、学習データのアーティファクトを明らかにすることができました。
自己教師付き表現学習に適用されるコントラスト学習は、近年復活しており、ディープイメージモデルの教師なし学習において最先端の性能を発揮しています。最新のバッチコントラストアプローチは、triplet、max-margin、N-pairs lossなどの従来のコントラスト損失を包含するか、または大幅に上回るものである。本研究では、自己教師付きのバッチコントラストアプローチを完全教師付きの設定に拡張し、ラベル情報を効果的に活用できるようにしました。同じクラスに属する点のクラスターは、埋め込み空間で一緒に引き寄せられ、同時に異なるクラスのサンプルのクラスターを押し広げる。教師付きコントラスト（SupCon）損失の2つのバージョンを分析し、最も性能の高い損失の形式を特定する。ResNet-200では，ImageNetデータセットにおいて81.4%のトップ1精度を達成し，このアーキテクチャで報告されている最高の数値を0.8%上回った．また、他のデータセットや2種類のResNetにおいても、クロスエントロピーよりも一貫して高い性能を示しています。損失関数は、自然破壊に対するロバスト性が高く、オプティマイザーやデータ増強などのハイパーパラメータ設定に対しても安定しています。我々の損失関数は実装が簡単で、参考となるTensorFlowのコードはこちらのhttps URLで公開されています。
人間は、足の位置が完全に制約されている飛び石のシナリオを含め、足の配置が制約された環境での歩行に非常に長けています。飛び石を利用した運動の良い解決策を見つけることは、アニメーションやロボット工学にとって長年の基本的な課題です。本研究では、強化学習を用いてこの困難な問題に対する完全に学習された解決策を提示する。効率的な学習のためのカリキュラムの重要性を示し、4つの可能なカリキュラムの選択を、カリキュラムのないベースラインと比較して評価する。人間、リアルな二足歩行ロボット、モンスターのシミュレーション結果を示しており、いずれの場合も、難しい飛び石の配列や地形に対して、ロバストでもっともらしいモーションを作り出している。
深層ニューラルネットワークの成功は目覚しいものがありますが、一方で、入力に対する敵対的な摂動に対するロバスト性についても大きな懸念が生じています。多くの攻撃はこれらを感知できないようにすることを目的としていますが、物理的な摂動による攻撃は、たとえ感知できたとしても疑われないようにすることが一般的です。しかし、敵対的な例が疑わしくないとはどういうことなのか、普遍的な概念はありません。そこで本研究では、認知的優位性を利用して疑惑をモデル化する手法を提案する。具体的には，画像を前景（顕著な領域）と背景（それ以外の領域）に分割し，背景の認知的重要性を低く保ちつつ，背景では有意に大きな敵対的摂動を許容するというものである．このようにして得られた、分類器に対する非サリエンス保存型の二重摂動攻撃の計算方法を説明する。そして，我々の攻撃は実際には背景の知覚的 salience を大きく変化させないが，従来の攻撃に強い分類器に対しては非常に有効であることを実験的に示す．さらに，Dual-perturbation攻撃を用いた敵対的学習により，最新のロバスト学習手法よりもこれらの攻撃に頑健な分類器が得られ，従来の攻撃に対する頑健さという点では同等であることを示す。
機械学習モデルにバックドアを注入するための新しい手法を調査し、モデル学習コードにおける損失値の計算を損なうことに基づいています。この手法を用いて、ImageNetモデルにおける単一ピクセルや物理的なバックドア、モデルを秘密のプライバシー侵害タスクに切り替えるバックドア、推論時の入力変更を必要としないバックドアなど、先行文献よりも厳密に強力な新しいクラスのバックドアを実証しました。我々の攻撃はブラインドであり、攻撃者は学習データを変更することも、自分のコードの実行を観察することも、結果として得られるモデルにアクセスすることもできません。攻撃コードは，モデルの学習中に「オンザフライ」で毒入りの学習入力を作成し，多目的最適化を用いてメインタスクとバックドアタスクの両方で高い精度を実現します．ブラインド攻撃がどのように既知の防御を回避し、新しい防御を提案できるかを示しています。
Generative Adversarial Network（GAN）は、教師なし学習の強力なアプローチです。GANは、画像領域において最先端の性能を達成しています。しかし、GANは2つの点で限界がある。また、確率密度の存在が保証されていないため、予測対数尤度を用いた汎化評価が不可能である。本論文では、これらの欠点を解決するために、所定のGAN(PresGAN)を開発する。PresGANは、密度ネットワークの出力にノイズを加え、エントロピー正則化された逆問題損失を最適化する。追加されたノイズは、予測対数尤度の扱いやすい近似値を与え、学習手順を安定させる。エントロピー正則化は、PresGANがデータ分布のすべてのモードを捕捉することを促す。PresGANsのフィッティングには、エントロピー正則化項の難解な勾配を計算する必要があるが、PresGANsは不偏の確率的推定値を用いてこの難解さを回避する。我々は、いくつかのデータセットでPresGANを評価し、モード崩壊を緩和し、高い知覚品質のサンプルを生成することがわかった。さらに、PresGANは、従来のGANと変分オートエンコーダー（VAE）の間の予測対数尤度のパフォーマンスのギャップを縮小することがわかった。
最近の研究では、一般的な機械学習の分類器のいくつかは、同じ入出力動作を持つブール回路にコンパイルできることが示されている。本研究では、ブール型分類器が行う決定の背後にある理由を明らかにするための理論を提示し、その理論的および実用的な意味合いを研究する。分類器や判断の偏りに加えて、判断の背後にある十分な理由、必要な理由、完全な理由といった概念を定義します。これらの概念は，"a decision will stick even if because ... "のような反事実的なステートメントを評価するためにどのように使用できるかを示す．これらの概念を計算するための効率的なアルゴリズムを、扱いやすいブール回路の新しい進歩に基づいて提示し、ケーススタディを用いて説明します。
本研究では、非自動回帰機械翻訳モデルを学習する際に、事前に学習した自動回帰モデルで定義されるエネルギーを最小化することを提案する。特に、我々は、我々の非自動回帰翻訳システムを、自動回帰教師エネルギーを最小化するように訓練された推論ネットワーク（Tu and Gimpel, 2018）と見なします。これは、そのような教師モデルのビームサーチされた出力からなる蒸留されたコーパス上で非自動回帰モデルをトレーニングするという一般的なアプローチとは対照的である。我々がENGINE（ENerGy-based Inference NEtworks）と呼ぶアプローチは、IWSLT 2014 DE-ENおよびWMT 2016 RO-ENデータセットで最先端の非自動回帰結果を達成し、自動回帰モデルの性能に近づいている。
深層学習や深層強化学習（RL）システムは、画像分類、ゲーム実況、ロボット制御などの領域で目覚ましい成果を上げていますが、データの効率化は依然として大きな課題です。マルチタスク学習は、複数のタスク間で構造を共有し、より効率的な学習を可能にする有望なアプローチとして浮上している。しかし、マルチタスク学習には最適化の課題が多く、タスクを個別に学習する場合に比べて大きな効率化を実現することは困難です。マルチタスク学習がシングルタスク学習に比べて難しい理由は、完全には理解されていません。本研究では、有害な勾配の干渉を引き起こすマルチタスク最適化環境の3つの条件を特定し、タスク勾配間のそのような干渉を回避するためのシンプルかつ一般的なアプローチを開発した。本研究では、あるタスクのグラデーションを、相反するグラデーションを持つ他のタスクのグラデーションの法線上に投影するグラデーションサージェリーを提案する。一連の困難なマルチタスク教師付き問題とマルチタスクRL問題において、このアプローチは効率と性能を大幅に向上させる。さらに、この手法はモデルに依存せず、以前に提案されたマルチタスクアーキテクチャと組み合わせて性能を向上させることができます。
近年、ニューラルネットワークのセキュリティに関する問題として、クリーンラベルデータセットポイズニング攻撃が注目されています。このようなポイズンサンプルは、人間の目には正当なものに見えますが、悪意のある特性を含んでおり、推論の際に標的となる誤分類を引き起こします。本論文では、伝達学習に対して、スケーラブルで伝達可能なクリーンラベルポイズニング攻撃を提案する。我々の攻撃法「Bullseye Polytope」は、エンド・ツー・エンドの伝達学習において、現在の最新技術の攻撃成功率を26.75%改善し、同時に攻撃速度を12倍に向上させた。さらに、Bullseye Polytopeをより実用的な攻撃モデルに拡張し、ポイズンサンプルを作成する際に、同じオブジェクトの複数の画像（例えば、異なる角度からの画像）を含めることにしました。この拡張により、余分なポイズンサンプルを使用することなく、（同じ物体の）見たことのない画像への攻撃の移行性が16％以上向上することを実証した。
STARC (Structured Annotations for Reading Comprehension)は、多肢選択問題による読解力を評価するための新しいアノテーションフレームワークです。このフレームワークでは、回答の選択肢に原則的な構造を導入し、それをテキストのスパンアノテーションに結びつける。このフレームワークは、英語の読解力を評価・分析するための新しい高品質データセットであるOneStopQAに実装されています。このデータセットを用いて、STARCがSATのような読解教材を開発するための重要な新しいアプリケーションに活用できることを示します。さらに、STARCは、エラー分布や推測能力など、機械と人間の読解行動を詳細に分析・比較することができることを示しています。また、我々の実験により、NLPにおける標準的な多肢選択式データセットであるRACEは、読解力を測定する能力に限界があることが明らかになりました。47%の問題は、文章にアクセスしなくても機械が推測でき、18%の問題は、人間が満場一致で唯一の正解がないと判断しています。OneStopQAは、これらの欠点を軽減し、人間の上限性能を大幅に向上させた読解力の代替テストセットを提供します。
言語モデルの事前学習は転移学習にどのように役立つのか？我々は、前訓練された各層が伝達課題のパフォーマンスに与える影響を決定するために、単純なアブレーション手法を検討している。部分的再初期化と呼ばれるこの手法は、事前学習されたモデルの異なる層をランダムな重みで置き換えた後、転送タスクでモデル全体を微調整し、パフォーマンスの変化を観察します。この手法により、BERTでは、下流のGLUEタスクで高いプロービング性能を持つ層は、これらのタスクで高い精度を得るために必要でも十分でもないことが明らかになりました。さらに、層に対して事前に学習されたパラメータを使用することの利点は、データセットのサイズを細かく調整することで大きく変化します。データが豊富なときには驚異的な性能向上をもたらすパラメータでも、データが少ない環境ではごくわずかな利点しか得られません。これらの結果は、伝達学習プロセスの複雑さを明らかにし、凍結したモデルや単一のデータサンプルで操作する方法の限界を浮き彫りにしています。
本論文では、教師なし多言語学習の動機、定義、アプローチ、方法論を検討し、それぞれについてより厳密な立場を求めています。このような研究の既存の根拠は、世界の多くの言語の並列データが不足していることに基づいています。しかし、並列データがなく、単言語データが豊富にあるというシナリオは、実際には非現実的であることを主張します。また、これまでの研究で用いられてきた、純粋な教師なしの設定とは異なるトレーニング信号についても説明する。次に、教師なしのクロスリンガルモデルのチューニングと評価における一般的な方法論の問題を説明し、ベストプラクティスを紹介します。最後に、この分野の様々なタイプの研究（クロスリンガル単語埋め込み、深層多言語事前学習、教師なし機械翻訳など）について統一的な見解を示し、これらのモデルを比較評価することを主張します。
多言語 BERT や XLM-R などの最先端の事前学習済み多言語モデルの背後にある主な目的は、ゼロショットまたは数ショットの異言語転送により、低リソース言語での NLP アプリケーションを可能にし、起動させることです。しかし、モデルの容量が限られているため、これらのモデルの転送性能は、リソースの少ない言語や事前学習で見たことのない言語に対しては最も弱いものとなっています。我々はMAD-Xを提案する。MAD-Xはアダプタベースのフレームワークであり、モジュール化された言語とタスクの表現を学習することで、任意のタスクと言語への高い移植性とパラメータ効率の良い移植を可能にする。さらに、事前学習された多言語モデルを新しい言語に適応させるために、新しい反転可能なアダプタ・アーキテクチャと強力なベースライン手法を導入します。MAD-Xは、類型的に多様な言語の代表的なセットにおいて、名前付き実体認識と因果関係のある常識的な推論の分野で、言語間の移行において最先端の技術を凌駕し、質問応答の分野でも競争力のある結果を達成しています。我々のコードとアダプターは以下のURLから入手可能です。
モデルの予測に対する解釈可能な理由付けは、実用的なアプリケーションにおいて重要な役割を果たします。本研究では、構造化された予測のための解釈可能な推論プロセスを持つモデルを開発する。具体的には、スパン間の類似性を学習するインスタンスベースの学習方法を提案する。推論時には、各スパンは学習セット内の類似したスパンに基づいてクラスラベルが割り当てられ、各学習インスタンスが予測にどれだけ貢献しているかを容易に理解することができる。名前付き実体認識に関する実証分析により、本手法が、性能を犠牲にすることなく、高い解釈性を持つモデルを構築できることを示す。
Jukeboxは、生の音声領域で歌付きの音楽を生成するモデルです。生の音声の長い文脈に対して、マルチスケールのVQ-VAEを用いて離散的なコードに圧縮し、自己回帰トランスフォーマーを用いてそれらをモデル化する。このモデルを大規模に組み合わせることで、数分にも及ぶコヒーレンスを持つ、忠実で多様な楽曲を生成できることを示します。アーティストやジャンルを条件にして音楽やボーカルのスタイルを調整したり、歌詞の内容を調整して歌唱力をコントロールしたりすることができます。私たちは、モデルの重みやコードとともに、チェリーピックではない何千ものサンプルを公開しています。
ディープニューラルネットワーク（DNN）は、強力なブラックボックス型の予測器で、さまざまなタスクで素晴らしい性能を達成しています。しかし、その精度の高さの代償として、分かりやすさが損なわれている。つまり、DNNがどのようにして意思決定を行っているのか、通常は不明である。このことが、ヘルスケアのようなリスクの高い意思決定領域への適用を妨げている。我々は、DNNの表現力と一般化された加法モデルの分かりやすさを組み合わせたNeural Additive Models (NAM)を提案する。NAMは、それぞれが1つの入力特徴に対応するニューラルネットワークの線形結合を学習します。これらのネットワークは共同で学習され、入力特徴と出力の間の任意の複雑な関係を学習することができます。回帰と分類のデータセットを用いた実験では、NAMはロジスティック回帰や浅い決定木など、広く使われている明瞭なモデルよりも精度が高いことが分かりました。また、NAMsは既存の最先端の一般化加法モデルと同様の精度で動作しますが、より簡単に現実の問題に適用することができます。
最先端のNLPモデルへの攻撃は、何が成功した攻撃を構成するのかという共通の定義がありません。本研究では、過去の研究からアイデアを抽出し、統一されたフレームワークを作成した。すなわち、成功した自然言語の敵対的な例は、モデルを欺き、いくつかの言語的制約に従う摂動である。次に、2つの最先端の同義語置換攻撃の出力を分析した。その結果、これらの摂動はしばしば意味を保持しておらず、38%が文法的な誤りを含んでいることがわかった。人間の調査によると、意味論をうまく保存するためには、入れ替わった単語の埋め込みと、元の文と摂動を受けた文のエンコーディングの間の最小余弦類似度を大幅に高める必要があることがわかった。
現実の社会経済的課題に取り組むためには、経済政策を立案し、検証する必要があります。しかし、適切な（ミクロレベルの）経済データがなく、実験の機会も限られているため、実際には困難です。本研究では、ダイナミックな経済において、経済的平等と生産性を効果的にトレードオフできるような税政策を発見するソーシャルプランナーを育成する。本研究では、エージェントと政府の両方が学習し適応する経済シミュレーションに基づいて、動的な税制を学習するための2レベルの深層強化学習アプローチを提案する。我々のデータ駆動型アプローチは、経済モデルの仮定を使用せず、観測データのみから学習します。我々の主な貢献は4つある。第一に、競争圧力と市場力学を特徴とする経済シミュレーション環境を提示します。このシミュレーションでは、ベースラインの税制が、学習したエージェントの行動や専門性を含めて、経済理論と一致する形で実行されることを示して検証する。第二に、AIによる税制は、平等と生産性の間のトレードオフを、著名なSaez税の枠組みを含むベースラインの政策よりも16％改善することを示す。第三に、いくつかの新しい特徴を紹介する。AIによる税制はベースラインとは質的に異なり、最高税率が高く、低所得者への補助金も高く設定されている。さらに、AI主導の税制は、AIエージェントが学習した新たな課税ゲーム戦略に直面しても強力に機能する。最後に、AI主導の税制は、人間の参加者を対象とした実験でも有効である。MTurkで行われた実験では、AIによる税制は、Saezのフレームワークと同様の平等-生産性のトレードオフを実現し、逆所得加重の社会厚生も高くなりました。
COVID-19のパンデミックは、世界の人々の健康と福祉に壊滅的な影響を与え続けています。COVID-19対策の重要なステップは、感染した患者を効果的にスクリーニングすることであり、重要なスクリーニング手法の一つが胸部X線撮影による放射線検査です。本研究では、胸部X線（CXR）画像からCOVID-19感染者を検出するために開発された、オープンソースで一般に公開されている深層畳み込みニューラルネットワーク「COVID-Net」を紹介します。著者らの知る限り、COVID-Netは、CXR画像からCOVID-19を検出するための最初のオープンソースネットワークデザインの1つです。また、我々が作成したCOVIDxというオープンアクセスのベンチマークデータセットを紹介します。このデータセットは、13,870人の患者の症例に対する13,975枚のCXR画像から構成されており、公開されているCOVID-19陽性症例の数としては、著者らの知る限り最も多いものです。さらに、COVID-Netがどのように予測を行っているかを説明可能な方法で調査し、COVID症例に関連する重要な要因についてより深い洞察を得て、臨床医によるスクリーニングの改善に役立てるだけでなく、COVID-NetがCXR画像から得られる関連情報に基づいて意思決定を行っていることを検証するために、責任ある透明な方法でCOVID-Netを監査することを試みています。すぐに使えるソリューションではありませんが、オープンアクセスのCOVID-Netが、オープンソースのCOVIDxデータセットの構築に関する説明とともに、研究者と市民データサイエンティストの両方に活用され、構築されることで、COVID-19症例を検出するための高精度かつ実用的な深層学習ソリューションの開発を加速し、最も治療を必要とする人々の治療を加速することが期待されています。
本研究では、標準的なモデルフリー強化学習アルゴリズムに適用できるシンプルなデータ補強技術を提案し、補助的な損失や事前学習を必要とせずに、ピクセルから直接ロバストな学習を可能にします。この手法では、コンピュータビジョンのタスクで一般的に使用される入力摂動を利用して、価値関数を正則化します。Soft Actor-Critic（SAC）などの既存のモデルフリーアプローチでは、画像のピクセルから効果的にディープネットワークを学習することはできません。しかし、我々の補強手法を加えることで、SACの性能は劇的に向上し、DeepMindコントロールスイート上で、モデルベース（Dreamer、PlaNet、SLAC）の手法や、最近提案されたコントラスト学習（CURL）を凌駕する最先端の性能に到達することができました。我々のアプローチは、モデルフリーの強化学習アルゴリズムと組み合わせることができ、わずかな変更で済む。実装はこちらのhttpsのURLにあります。
強化学習は、高レベルの報酬関数のみを指定することで、複雑な逐次決定問題を自律的に解決することが期待されています。しかし、強化学習アルゴリズムは、単純で直感的な報酬が、まばらで欺瞞的なフィードバックを提供する場合には、苦戦を強いられることがよくあります。このような落とし穴を避けるためには、環境を徹底的に探索する必要があるが、それが可能なアルゴリズムを開発することは、この分野の中心的な課題の一つである。私たちは、効果的な探索を妨げる主な要因は、アルゴリズムが以前に訪れた状態に到達する方法を忘れてしまうこと（"detachment"）と、ある状態から探索する前にその状態に戻ることができないこと（"derailment"）にあると考えています。Go-Exploreは、有望な状態を明示的に記憶し、意図的に探索する前にまずその状態に戻るというシンプルな原則によって、この2つの課題に直接対処するアルゴリズム群です。Go-Exploreは、これまで未解決であったアタリ社のゲームをすべて解決し、すべてのハード探索ゲームの技術水準を上回り、特に壮大な挑戦であるMontezuma's RevengeとPitfallでは桁違いの改善が見られました。また、Go-Exploreの実用的な可能性を、報酬の少ないピックアンドプレースのロボットタスクで実証しました。さらに、ゴール条件付きのポリシーを追加することで、Go-Exploreの探索効率をさらに向上させ、学習中の確率を処理できることを示しています。Go-Exploreの大幅な性能向上は、状態を記憶し、そこに戻り、そこから探索するという単純な原理が、探索に対する強力で一般的なアプローチであることを示唆しています。
多くの機械学習問題では、損失関数は複数の項の加重和である。このような問題に対処するための典型的なアプローチは、異なる重みを選択した複数の別個のモデルを学習し、何らかの基準に従って最良のものを選択するか、あるいは多様な解を維持することが望ましい場合には複数のモデルを維持することである。これは、学習時と推論時の両方で非効率的である。我々は、1つの損失関数で学習した複数のモデルを、損失の分布で学習した単一のモデルに置き換える方法を提案する。この方法で学習したモデルは、テスト時に、学習した損失分布から任意の損失に対応する出力を生成するように条件付けすることができる。本研究では、パラメータ化された損失を持つ3つのタスク（β-VAE、学習済み画像圧縮、高速スタイル転送）でこのアプローチを実証する。
バックドア・データポイズニング攻撃は、機械学習（ML）システムの潜在的な安全リスクとして、最近コンピュータビジョンの研究で実証されています。従来のデータポイズニング攻撃は、学習データを操作してMLモデルの信頼性を低下させるが、バックドアデータポイズニング攻撃は、敵に有利な所定の応答を提供する「トリガー」が埋め込まれた入力がMLモデルに提示されない限り、システムの性能を維持する。本研究では、ML画像分類器を対象としたバックドアデータポイズニングの先行研究を基に、トリガパターンの種類、再学習時のトリガパターンの持続性、ポイズニング戦略、アーキテクチャ（ResNet-50、NasNet、NasNet-Mobile）、データセット（Flowers、CIFAR-10）、防御的正則化技術の可能性（Contrastive Loss、Logit Squeezing、Manifold Mixup、Soft-Nearest-Neighbors Loss）など、さまざまな実験条件を体系的に評価しました。実験の結果、4つの重要な発見がありました。1つ目は、バックドアポイズニング攻撃の成功率は、モデルアーキテクチャ、トリガーパターン、正則化技術などのいくつかの要因によって大きく異なることです。第2に、ポイズニングされたモデルは、性能検査だけでは検出しにくいことがわかった。第3に、正則化は一般的にバックドア成功率を低下させるが、正則化の形式によっては効果がない、あるいはわずかに増加することもある。最後に、データポイズニングによって挿入されたバックドアは、モデルの性能に影響を与えることなく、小さなクリーンなデータセットで数エポックの追加トレーニングを行っただけで、効果がなくなることがあります。
他のソフトウェアシステムと同様に、深層学習モデルの実行は、メモリ上のデータとして表現されたロジックによって部分的に決定されます。何十年もの間、攻撃者はこのデータを操作することで従来のソフトウェアプログラムを悪用してきました。私たちは、メモリ上のモデルパラメータにパッチを当て、特定の入力セットに対してあらかじめ定義された悪意のある動作を実現する、深層学習システムに対するライブ攻撃を提案します。攻撃者は、このパッチのサイズと数を最小限にすることで、ネットワーク通信量とメモリの上書き量を減らし、システムの誤動作やその他の検出可能な副作用のリスクを最小限に抑えることができます。我々は、複数の深層学習モデルの効率的なパッチを計算することで、この攻撃の実現可能性を示しました。また、わずかなパッチと限られた学習データで、望ましいトロイの木馬の動作を引き起こすことができることを示しました。この攻撃を実際のシステムで実行する方法の詳細を説明し、WindowsおよびLinuxでTensorFlowモデルのパラメータをパッチするためのサンプルコードを提供します。最後に、摂動された入力のエントロピーを効果的に操作して、最先端のランタイムトロイの木馬検出技術であるSTRIPをバイパスする技術を紹介します。
金融や医療などの機械学習アプリケーションでは、正確で正当な予測が求められるため、ほとんどの深層学習手法は使用できません。そのため、これまでの研究では、決定木と深層学習を組み合わせて、（1）精度のために解釈性を犠牲にする、または（2）解釈性のために精度を犠牲にするモデルを生み出してきました。私たちは、ニューラルバック決定木（NBDT）を用いて精度と解釈性を同時に向上させることで、このジレンマを回避します。NBDTは、ニューラルネットワークの最終的な線形層を、微分可能な決定シーケンスと代理的な損失に置き換えるものです。これにより、モデルに高レベルの概念を学習させ、不確実性の高い決定への依存度を減らすことで、（1）精度を向上させます。NBDTは、CIFARやImageNetにおける最新のニューラルネットワークと同等かそれ以上の性能を持ち、未見のクラスへの一般化も最大16%向上します。さらに、NBDTのサロゲートロスは、オリジナルモデルの精度を最大2%向上させます。NBDTは、（2）解釈可能性：モデルの誤りを明確に示し、データセットのデバッグを支援することで、人間の信頼性を向上させます。コードと学習済みのNBDTはこちらのhttpsのURLにあります。
深層学習は、学習率を変化させるエキゾチックなスケジュールでうまく機能するという興味深い経験的証拠があります。この論文では、この現象がバッチ正規化（BN）によるものである可能性を示唆しています。BNはユビキタスなものであり、すべての標準的なアーキテクチャにおいて最適化と一般化のメリットをもたらします。重みの減衰と運動量を伴うBNについて、以下の新しい結果が示されています（言い換えれば、スタンドアロンBNの初期の理論的分析では考慮されなかった典型的な使用例です）。1. 1. 勢いのあるSGDと指数関数的に増加する学習率のスケジュールを使用して、学習を行うことができます。つまり、あるα>0に対して、すべてのエポックで学習率がある(1+α)係数だけ増加します。(我々の知る限り、このような学習率スケジュールが成功したのは初めてのことであり、ましてや大成功を収めたアーキテクチャに使用したのは初めてです。予想通り、このような学習はネットワークの重みを急速に増大させますが、正規化によりネットは良好な状態を維持します。2. 上記のレートスケジュールの成功を数学的に説明します。BN + SGD + StandardRate Tuning + Weight Decay + Momentum という標準的な設定と同等であることを厳密に証明します。この等価性は、他の正規化レイヤーについても同様に、Group Normalization、LayerNormalization、Instance Normなどに当てはまります。3. 3. 上記のハイパーパラメータの関連性を示す、実際の玩具の例。ウェイトディケイとBNのどちらか一方だけを使うとグローバルミニマムに達するが、両方を使うと収束しない。
注意を喚起するRNNベースのエンコーダ・デコーダのアーキテクチャは、ニュース記事の抽象的な要約において素晴らしい性能を達成している。しかし、これらの手法では、文書の文の中の長期的な依存関係を考慮することができない。この問題は、Yahoo!AnswersやQuoraなどのCQA（Community Question Answer）サイトのスレッドにある人気のある意見を要約するような、複数文書の要約タスクではさらに悪化します。これらのスレッドには、互いに重なり合ったり矛盾したりする回答が含まれています。本研究では、このような文間・文書間の依存関係をモデル化するために、構造的注目に基づいた階層的なエンコーダを提案する。一般的なpointer-generatorアーキテクチャと、それから派生したいくつかのアーキテクチャをベースラインとして設定し、それらがマルチドキュメントの設定で良い要約を生成できないことを示す。さらに、提案モデルは、シングル・ドキュメントおよびマルチ・ドキュメントの両方の要約設定において、ベースラインよりも大幅な改善を達成したことを示した。前者の設定では、CNNおよびCQAデータセットにおいて、それぞれ1.31および7.8 ROUGE-1ポイントで最良のベースラインを上回り、後者の設定では、CQAデータセットにおいて1.6 ROUGE-1ポイントでさらに性能が向上した。
科学の多くの分野では、関心のある現象を記述するために複雑なシミュレーションが開発されています。これらのシミュレーションは、忠実度の高いモデルを提供する一方で、推論にはあまり適しておらず、困難な逆問題を引き起こします。本論文では、急速に発展しているシミュレーションベースの推論の分野を概観し、この分野に新たな勢いを与えている要因を明らかにする。最後に、フロンティアがどのように広がっているかを説明し、これらの開発が科学に与える可能性のある大きな変化を、多くの人に理解してもらいます。
教師なしの画像間翻訳のタスクは、近年、ディープニューラルネットワークを用いて大幅な進歩を遂げています。一般的に、提案されたソリューションは、対になっていない2つの大きな画像コレクションの特徴的な分布を学習し、画像の形状を維持したまま画像の外観を変更することができる。この論文では、AとBという1組の画像が与えられたときに、画像構造を理解するためのニューラルネットワークの能力を探究しています。これにより、アナロジーが生成される粒度をコントロールすることができ、スタイルとコンテンツの概念的な区別を決定することができます。本手法は、構造的な位置合わせに加えて、画像AとBのみを利用する他の条件生成タスク、すなわち、ガイド付き画像合成、スタイルとテクスチャの転送、テキスト翻訳、およびビデオ翻訳において、高品質の画像を生成するために使用することができます。我々のコードとその他の結果は、こちらのhttps URLでご覧いただけます。
ディープラーニングは、現在の人工知能の発展のきっかけとなり、今日の機械知能の主力となっています。数多くの成功例が科学、産業、社会の至る所で急速に広まっていますが、その限界は最近になって注目されています。この視点では、深層学習の問題の多くが、根本的には同じ問題である「ショートカット学習」の異なる症状として捉えられることを抽出しようとしています。近道とは、標準的なベンチマークでは良い結果が得られるが、実世界のシナリオのような、より困難なテスト条件に移行できない決定ルールのことです。これに関連する問題は、比較心理学、教育学、言語学などで知られており、ショートカット学習は、生物学的にも人工的にも、学習システムの共通の特性である可能性が示唆されています。これらの観察結果に基づいて、モデルの解釈とベンチマークのための一連の推奨事項を作成し、堅牢性と研究室から実世界のアプリケーションへの移行性を向上させるための機械学習の最近の進歩に焦点を当てています。
テキストなどの離散的なデータを対象とした敵対的攻撃は、画像などの連続的なデータを対象とした場合に比べて、勾配ベースの手法で敵対的なサンプルを生成することが困難であるため、非常に困難であることがわかっています。現在成功しているテキストへの攻撃手法は、通常、文字や単語レベルでのヒューリスティックな置換戦略を採用していますが、意味の一貫性と言語の流暢性を維持しながら、可能な置換の組み合わせの膨大な空間の中で最適な解決策を見つけることは依然として困難です。本論文では、BERT に代表される事前に訓練されたマスクされた言語モデルを使用して、敵対的なサンプルを生成する高品質で効果的な方法である ˶˙º̬˙˶を提案します。私たちは、BERTをその微調整されたモデルや下流のタスクにおける他の深層ニューラルモデルに対して向けることで、対象モデルを誤って予測させることに成功します。我々の手法は、成功率と摂動率の両方で最先端の攻撃戦略を上回り、生成された敵対的サンプルは流暢でセマンティックに保存されています。また、計算コストが低いため、大規模な生成が可能です。コードはこちらのhttpsのURLで公開されています。
携帯電話やIoTデバイスなど、リソースに制約のあるノードデバイスが、学習データをローカルに保ちながら共有モデルを学習するフェデレート型機械学習は、効果的な通信プロトコルを設計することで、プライバシー、セキュリティ、経済的なメリットを提供することができます。しかし、異なるノード間の通信プロトコルは、攻撃者がデータポイズニング攻撃を仕掛けるために悪用される可能性があり、ほとんどの機械学習モデルにとって大きな脅威であることが実証されています。本論文では、連合型機械学習の脆弱性について検討します。具体的には、統計的な課題を処理するために一般的なマルチタスク学習フレームワークを採用することを介して、連携したマルチタスク学習フレームワークを攻撃することに焦点を当てています。我々は、連合型マルチタスク学習に対する最適なポイズニング攻撃を計算する問題を、ターゲットノードとソース攻撃ノードの任意の選択に適応可能なバイレベルプログラムとして定式化する。そして、システムを考慮した新しい最適化手法であるATack on Federated Learning (AT2FL)を提案します。この手法は、ポイズニングされたデータの暗黙の勾配を導き出し、さらに連合型機械学習における最適な攻撃戦略を計算するための効率的な手法です。本研究は、連合学習におけるデータポイズニング攻撃の問題を検討した先駆的な研究です。本研究では、実世界のデータセットを用いて実験を行い、連合型マルチタスク学習モデルがポイズニング攻撃に対して非常に敏感であることを示した。ポイズニング攻撃とは、攻撃者が直接ターゲットノードをポイズニングするか、通信プロトコルを悪用して間接的に関連ノードをポイズニングするものである。
機械翻訳の自動測定基準の品質は、特に高品質なシステムにおいて、ますます疑問視されている。この論文では、メトリクスの選択が重要である一方で、リファレンスの性質も重要であることを示しています。本論文では，リファレンスを収集するためのさまざまな方法を研究し，さまざまなシステムとメトリクスについて人間の評価との相関関係を報告することで，自動評価におけるリファレンスの価値を比較した．典型的な参考文献は多様性に乏しく、翻訳言語に集中しているという知見に基づいて、言語学者が既存の参考文献の翻訳に対して行う言い換えタスクを開発し、この偏りを解消する。我々の手法は，WMT 2019英語からドイツ語への翻訳だけでなく，標準的な参考文献を用いた自動翻訳メトリクスとの相関性が低いとされているBack-translationやAPE augmented MTの出力についても，人間の判断との高い相関性を得ることができる．私たちの方法論は、埋め込みベースの手法を含む、私たちが見ているすべての最新の評価指標との相関を改善することを実証します。この図式を完成させるために、我々は多参照BLEUが高品質の出力の相関を改善しないことを明らかにし、より効果的な代替の多参照処方を提示する。
オーバーパラメータ化された深層ネットワークは、ゼロの\\{training error}で学習データを記憶する能力を持っています。また、記憶した後も、\\\\\\\\\\\\\\\\\\\\\\\\\\\amatsuamatsuamatsuamatsuamatsuamatsuamatsuamatsuamatsuamatsuとなります。既存の正則化器は学習損失をゼロにすることを直接目的としていないため，学習損失のレベルを一定に保つために正則化器のハイパーパラメータを調整することは困難である．本論文では，学習損失が適度に小さい値に達したときに，それ以上の学習損失の減少を意図的に阻止するという直接的な解決策を提案する．このアプローチでは、通常のミニバッチ式の勾配降下を行いながら、トレーニングロスがフラッドレベル以下の場合には勾配上昇を行うことで、ロスをフラッドレベルの周りに浮遊させます。これは1行のコードで実装でき、あらゆるストキャスティック・オプティマイザーや他のレギュラライザーと互換性があります。フラッディングにより、モデルは同じ非ゼロの学習損失で「ランダムウォーク」を続けることになり、より良い一般化につながるフラットな損失ランドスケープを持つ領域に漂うことが期待される。我々は、フラッディングが性能を向上させ、副産物として、テスト損失の二重下降曲線を誘導することを実験的に示した。
モデルベース強化学習（MBRL）は、サンプルの効率化の可能性と、オフポリシーデータを取り入れることができることから、最近非常に大きな関心を集めています。しかし、安定的かつ効率的なMBRLアルゴリズムの設計は、豊富な関数近似を使用することが困難でした。MBRLの実用的な課題を明らかにし、抽象化のレンズからアルゴリズム設計を単純化するために、我々は、MBRLを次の間のゲームとして扱う新しいフレームワークを開発した。(1)学習されたモデルの下で報酬を最大化しようとする政策プレーヤー、(2)政策プレーヤーが収集した実世界のデータを適合させようとするモデルプレーヤー。アルゴリズム開発のために、2人のプレイヤーの間でStackelbergゲームを構築し、近似的な2レベル最適化で解決できることを示す。これにより、Stackelbergゲームでどちらのプレイヤーがリーダーとして選ばれるかに基づいて、MBRLのための2つの自然なアルゴリズムのファミリーが生まれる。これらのアルゴリズムは、これまでの多くのMBRLアルゴリズムを包括し、統一し、一般化している。さらに、我々のフレームワークは、先行研究で実践的に重要であることが知られているヒューリスティクスと一致しており、その明確な根拠を提供している。最後に、実験を通して、我々の提案するアルゴリズムはサンプル効率が高く、モデルフリー政策勾配の漸近性能に匹敵し、器用な手の操作のような高次元のタスクにも優雅に拡張できることを検証した。詳細およびコードは、このhttps URLのプロジェクトページから入手できます。
撮影されたシーンに含まれるテキスト情報は、シーンの解釈や意思決定において重要な役割を果たします。しかし、我々の知る限り、画像中のテキスト情報を修正することを目的とした先行研究は存在しません。画像上でテキストを直接編集できることは、エラー修正、テキストの復元、画像の再利用性など、いくつかの利点がある。本論文では、画像中のテキストを文字レベルで修正する方法を提案する。この問題には2つの段階でアプローチする。まず，修正される観測文字（ソース）から，観測されない文字（ターゲット）を生成する．このとき、(a)FANnetは元のフォントとの構造的な整合性を確保し、(b)Colornetは元の色を保持する、という2つの異なるニューラルネットワークアーキテクチャを提案します。次に，隣接する文字との幾何学的な整合性と視覚的な整合性の両方を維持しながら，元の文字を生成された文字に置き換えます．本手法は，画像中の文字を修正するための統一的なプラットフォームとして機能する．COCO-TextおよびICDARデータセットにおいて、本手法の有効性を定性的および定量的に示す。
オフライン強化学習（RL）の設定（フルバッチRLとも呼ばれる）では、静的なデータセットからポリシーを学習します。大規模なデータセットの増加が教師付き学習の成果を促進したように、RL手法が過去に収集された大規模なデータセットを活用できるようになったことは魅力的です。しかし、既存のオンラインRLベンチマークは、オフライン環境に合わせて調整されておらず、また、既存のオフラインRLベンチマークは、部分的に訓練されたエージェントによって生成されたデータに限定されているため、オフラインRLの進歩を測定することが難しい。本研究では、オフラインRLの実世界での応用に関連するデータセットの主要な特性に導かれて、オフライン設定に特化して設計されたベンチマークを紹介する。データセットの収集に焦点を当てると、そのような特性の例としては、手で設計されたコントローラや人間のデモンストレーターによって生成されたデータセット、エージェントが同じ環境で異なるタスクを実行するマルチタスクデータセット、およびポリシーの混合物で収集されたデータセットが挙げられます。単純なベンチマークタスクや、部分的に訓練されたRLエージェントによって収集されたデータを超えることで、既存のアルゴリズムの重要かつ評価されていない欠陥を明らかにしています。研究を促進するために、私たちは、既存のアルゴリズムの包括的な評価、評価プロトコル、オープンソースの例とともに、ベンチマークタスクとデータセットを公開しました。これは、既存のオフラインRL手法の欠点を特定するためのコミュニティの共通の出発点となり、この新しい分野の進歩のための共同ルートとなります。
機械学習（ML）ベースのアプローチは、アンチフィッシング検出のための主流のソリューションとなっています。MLベースの分類器は、クライアント側に配置されると、回避攻撃に対して脆弱になります。しかし、既存の攻撃はウェブページの機能や外観を破壊するものであり、ホワイトボックスシナリオで行われるため、実用性が低いことから、このような潜在的な脅威は比較的注目されていません。そのため、分類器に関する限られた知識で、機能性や外観を維持したまま回避攻撃を行うことができるかどうかを理解することが必要になります。本研究では，グレーボックスやブラックボックスのシナリオにおいても，実用的なMLベースの分類器に対して回避攻撃が有効であるだけでなく，機能性や外観を破壊することなく効率的に攻撃できることを示す．この目的のために、我々は、分類器の知識が異なる3つの変異ベースの攻撃を提案します。これは、分類器を欺くことができるように、既知のフィッシングサイトから敵対的なサンプルを自動的に作成するという重要な技術的課題に対処するものです。また、ホワイトボックスおよびグレイボックスのシナリオで攻撃を開始するために、ターゲット分類器の知識を得るためのサンプルベースの衝突攻撃を提案しています。我々の回避攻撃の有効性と効率性を、最先端のGoogleのフィッシングページフィルターで実証したところ、1つのウェブサイトにつき1秒以内で100%の攻撃成功率を達成しました。さらに、BitDefender社の産業用フィッシングページ分類器であるTrafficLightに対する回避攻撃では、最大81.25%の攻撃成功率を達成しました。さらに、このような回避攻撃を軽減するために、類似性に基づいた手法「Pelican」を提案します。その結果、Pelicanは効果的に回避攻撃を検出できることがわかりました。今回の研究成果は、より強固なフィッシングサイト分類法の設計に貢献します。
抽象的な要約モデルの実用的なアプリケーションは、その入力に関して頻繁に事実上の不一致があるために制限されています。既存の要約の自動評価指標は、このようなエラーに対してほとんど影響を受けない。我々は、QAGS（発音は "kags"）と呼ばれる自動評価プロトコルを提案する。これは、生成された要約における事実上の不整合を識別するように設計されている。QAGSは、要約とその出典について質問をすると、要約が出典と事実上一致している場合には、同様の回答が得られるという直感に基づいている。QAGSを評価するために、CNN/DailyMail（Hermann et al., 2015）とXSUM（Narayan et al., 2018）の要約データセットについて、モデルが生成した要約に対する事実の一貫性についての人間の判断を収集しました。QAGSは、他の自動評価指標と比較して、これらの判定との相関性が大幅に高い。また、QAGSは自然な形での解釈可能性を提供します。QAGSの計算中に生成された回答や質問は、要約のどのトークンが矛盾しているか、そしてその理由を示しています。QAGSは、使いやすく、事実に即したテキストを自動的に生成するツールとして有望であると考えています。
最近のNLPでは、事前に学習された大規模なモデルの利用が急増しています。ユーザーは、大規模なデータセットで事前に学習したモデルの重みをダウンロードし、任意のタスクで重みを微調整します。これは、信頼できない事前学習済みの重みをダウンロードすることが、セキュリティ上の脅威になるかどうかという問題を提起している。本論文では，事前に学習された重みに脆弱性を注入し，微調整後に「バックドア」を露出させることで，任意のキーワードを注入するだけでモデル予測を操作できる「重みポイズニング」攻撃が可能であることを示す．我々は、RIPPLeと呼ぶ正則化手法と、Embedding Surgeryと呼ぶ初期化手順を適用することで、データセットと微調整手順に関する限られた知識があっても、このような攻撃が可能であることを示す。センチメント分類、毒性検出、スパム検出の実験により、この攻撃が広く適用可能であり、深刻な脅威であることを示す。最後に、このような攻撃に対する実用的な防御策を概説する。我々の実験を再現するためのコードは、このhttpsのURLから入手できます。
ロギングされたインタラクションの固定されたオフラインデータセットを用いたオフポリシー強化学習（RL）は、実世界のアプリケーションにおいて重要な考慮事項です。本論文では、DQNエージェントが60個のAtari 2600ゲームをプレイした際の全リプレイ体験からなるDQNリプレイデータセットを用いて、オフラインRLを研究する。本論文では、DQNリプレイデータセットを用いたオフラインRLの研究を行い、最近のオフポリシー・ディープRLアルゴリズムは、このリプレイデータセットのみで学習した場合でも、完全に学習したDQNエージェントよりも性能が高いことを示した。オフライン環境での汎用性を高めるために、複数のQ値推定値のランダムな凸型の組み合わせに対して最適なベルマン整合性を実施するロバストなQ学習アルゴリズムであるRandom Ensemble Mixture（REM）を提案する。DQNリプレイデータセットで学習したオフラインREMは、RLの強力なベースラインを上回る。ここでの結果は、十分に大規模で多様なオフラインデータセットで訓練されたロバストなRLアルゴリズムが高品質なポリシーにつながるという楽観的な見解を示している。DQNリプレイデータセットは、オフラインRLベンチマークとして利用でき、オープンソースで提供されている。
我々は、高性能で解釈可能な新しい正準深層表データ学習アーキテクチャであるTabNetを提案する。TabNetは、各決定ステップで推論する特徴を選択するために逐次注目を使用し、最も顕著な特徴に学習容量が使用されるため、解釈可能性とより効率的な学習を可能にします。TabNetは、性能が飽和していない幅広い表形式のデータセットにおいて、他のニューラルネットワークや決定木よりも優れた性能を示し、解釈可能な特徴の帰属とグローバルモデルの動作に関する洞察をもたらします。最後に、我々の知る限り初めて、表形式データに対する教師なし学習を実証し、ラベルのないデータが豊富な場合に教師なし表現学習の性能を大幅に向上させました。
ユーザーターゲットの自動化システムでは、入力データのコンセプトドリフトが主な課題の一つです。概念ドリフトは、時間の経過とともに新しいデータに対するモデルの性能を低下させる。概念ドリフトに関するこれまでの研究では、性能低下を観測した後にモデルを再学習することが提案されている。しかし、このアプローチは、新しいデータでの性能低下に悩まされた後にシステムが問題を修正するため、最適ではありません。ここでは、ユーザ・ターゲティング・オートメーション・システムにおけるコンセプト・ドリフト問題に対する敵対的検証アプローチを紹介する。我々のアプローチでは、システムは推論を行う前に新しいデータのコンセプトドリフトを検出し、モデルを訓練し、新しいデータに適合した予測を生成する。我々のアプローチは、AutoML3 Lifelong Machine LearningチャレンジデータおよびUberの社内ユーザーターゲティング自動化システムMaLTAにおいて、コンセプトドリフトに効果的に対処することを示している。
機械学習（ML）ベースのマルウェア分類のためのトレーニングパイプラインは、多くの場合、クラウドソースの脅威フィードに依存しており、自然な攻撃の注入ポイントを露呈しています。本論文では、特徴ベースのMLマルウェア分類法がバックドアポイズニング攻撃を受けやすいことを研究しています。特に、攻撃者がサンプルのラベル付けプロセスをコントロールできない「クリーンラベル」攻撃に焦点を当てています。本研究では、説明可能な機械学習の手法を用いて、モデルに依存しない方法で効果的なバックドアトリガを作成するために、関連する特徴と値の選択を導くことを提案します。Windows PEファイル、PDF、Androidアプリケーションなど、マルウェアを分類するための複数の参照データセットを用いて、多様な機械学習モデルに対する効果的な攻撃を実証し、攻撃者に課せられた様々な制約の効果を評価します。また、バックドア攻撃の実用性を実証するために、Windows PEファイルに対してバイナリの機能を保持した電子透かしを作成し、AndroidやPDFファイルに対しても同様の動作保持型の改ざん手法を活用しています。最後に、可能性のある防御戦略を実験し、特に攻撃が正当なサンプル分布に紛れ込んでいる場合には、これらの攻撃を完全に防御することは困難であることを示します。
既存の言語間の単語ベクトル空間を整列させるアルゴリズムは、ベクトル空間が近似的に同型であることを前提としています。その結果、非同型の空間では性能が低下したり、完全に失敗したりする。このような非同型性は、言語間の類型的な違いに起因すると仮定されている。本研究では、非同型性もまた、退化した単語ベクトル空間の重大な兆候であるかどうかを問う。本研究では、様々な言語を対象とした一連の実験を行い、言語ペア間のパフォーマンスのばらつきは、類型論的な違いだけではなく、利用可能な単言語リソースの大きさや、単言語トレーニングの特性と期間（例えば、「アンダートレーニング」）に起因することを示した。
本論文では、同じカテゴリのオブジェクトを含む画像間の高密度な視覚的対応関係を確立するというタスクに取り組む。これは、クラス内での変動が大きいことや、ピクセルレベルの密なアノテーションがないことから、困難なタスクである。我々は、この課題に対処するために、疎なキーポイントアノテーションを用いてエンド・ツー・エンドで学習できる畳み込みニューラルネットワークアーキテクチャ、Adaptive neighbourhood consensus network (ANC-Net)を提案します。ANC-Netの中核となるのは、我々が提案した非等方性の4次元コンボリューション・カーネルであり、これはロバストなマッチングのための適応的近隣コンセンサス・モジュールの構成要素となる。また、シンプルで効率的なマルチスケール自己相似性モジュールをANC-Netに導入することで、学習した特徴をクラス内の変動に対してロバストにすることができます。さらに、1対1のマッチング制約を強化するために、新しい直交損失を提案する。様々なベンチマークを用いて本手法の有効性を徹底的に評価した結果、本手法は最先端の手法を大幅に凌駕した。
最新のニューラル・ランキング・アーキテクチャを利用して、Allen Institute for AIが管理するCOVID-19 Open Research Datasetへの情報アクセスを提供する検索エンジン、Neural Covidexを紹介します。このウェブアプリケーションは、現在進行中の世界的なパンデミックに取り組む分野の専門家を支援するために、ここ数週間で開発した一連のツールの一部として存在しています。私たちは、科学文献への情報アクセス機能を向上させることで、エビデンスに基づいた意思決定やインサイト生成を行うことができると期待しています。本論文では、私たちの初期の取り組みについて説明し、その過程で得られた教訓について考察しています。
フォトリアリスティックな仮想世界を効率的にレンダリングすることは、コンピュータグラフィックスの長年の課題でした。現代のグラフィックス技術は、手作業で作成されたシーン表現からフォトリアリスティックな画像を合成することに成功しています。しかし、シーンの形状、材質、照明などを自動的に生成することは、依然として困難な問題であり、これが解決されれば、フォトリアリスティックなコンピュータグラフィックスをより広く利用できるようになります。同時に、コンピュータビジョンと機械学習の進歩により、画像の合成と編集のための新しいアプローチ、すなわちディープジェネレーティブモデルが生まれました。ニューラルレンダリングは、生成的な機械学習技術とコンピュータグラフィックスの物理的な知識を組み合わせた、急速に発展している新しい分野です。ニューラルレンダリングは、コンピュータグラフィックスやビジョンへの応用が期待されており、グラフィックス分野の新領域となることが期待されていますが、この新興分野の調査はまだ行われていません。この最新レポートでは、ニューラルレンダリングの最近の動向と応用についてまとめています。このレポートでは，従来のコンピュータグラフィックス技術と深い生成モデルを組み合わせて，制御可能でフォトリアリスティックな出力を得るためのアプローチに焦点を当てています．コンピュータグラフィックスと機械学習の基礎となる概念の概要から始まり、ニューラルレンダリングアプローチの重要な側面について議論します。この最先端のレポートでは、新しいビュー合成、セマンティックな写真操作、顔や体の再現、再照明、自由視点のビデオ、仮想現実や拡張現実のテレプレゼンスのためのフォトリアリスティックなアバターの作成など、説明したアルゴリズムの多くの重要な使用例に焦点を当てています。最後に、このような技術の社会的な意味合いについて議論し、開かれた研究課題を検討して締めくくります。
名前付きエンティティ認識システムは、英語のニュースからなる標準的なデータセットでは良好な性能を発揮します。しかし、データが少ないため、多様なエンティティの認識に関するシステムの堅牢性について結論を出すことは困難である。そこで本研究では，エンティティの国籍によるパフォーマンスの違いに着目し，システムのドメイン内での頑健性を監査する手法を提案する．エンティティスイッチデータセットを作成し，原文中の名前付きエンティティを，同じ種類で出身国が異なる，もっともらしい名前付きエンティティに置き換える．その結果、最新のシステムの性能は、ドメイン内でも大きく異なることがわかりました。同じ文脈において、特定の出身地のエンティティは、他の出身地のエンティティよりも確実に認識されます。アメリカ人とインド人のエンティティではシステムの性能が最も高く、ベトナム人とインドネシア人のエンティティではシステムの性能が最も低くなります。この監査アプローチは、より強固な名前付き実体認識システムの開発を促進し、他の予測技術の研究で注目されている公正さの基準を考慮した研究を可能にする。
畳み込みニューラルネットワーク（CNN）を組込み機器に展開することは、メモリと計算資源が限られているため困難です。特徴マップの冗長性は、それらの成功したCNNの重要な特性であるが、ニューラル・アーキテクチャ設計ではほとんど調査されていない。本論文では、安価な演算からより多くの特徴マップを生成する新しいGhostモジュールを提案する。固有の特徴マップのセットに基づいて、安価なコストで一連の線形変換を適用し、固有の特徴の根底にある情報を完全に明らかにすることができる多くのゴースト特徴マップを生成する。提案されたGhostモジュールは、既存の畳み込みニューラルネットワークをアップグレードするためのプラグアンドプレイのコンポーネントとして利用することができます。GhostのボトルネックはGhostモジュールを積み重ねるように設計されており，軽量なGhostNetを容易に構築することができる．ベンチマークを用いた実験では，提案したGhostモジュールがベースラインモデルの畳み込み層に代わる優れたモジュールであることを示しており，我々のGhostNetはImageNet ILSVRC-2012分類データセットにおいて，同程度の計算コストでMobileNetV3よりも高い認識性能（例：75.7% top-1 accuracy）を達成することができる．コードはこちらのhttpsのURLから入手できます。
識別的に学習されたニューラルネットワーク分類器は，配布されたサンプルに対してのみ信頼性の高い予測を行います．しかし、実際に使用する際には、配布されていないサンプル（OD）を検出することが重要です。OODが分布内という閉じた境界の外側にあると仮定すると、典型的なニューラル分類器は、推論中にOODを検出するためのこの境界の知識を含んでいません。最近では、分布内境界に近いOODサンプルを用いて分類器を明示的に学習することで、分類器にこの知識を植え付けるアプローチがあります。しかし、これらのサンプルでは、配布中の境界全体を効果的にカバーすることができず、結果的に最適ではないOOD検出器となってしまう。本論文では、このような「効果的な」OODサンプルを生成するための複雑さを調査することで、このようなアプローチの実現可能性を分析する。また、多様体学習ネットワーク（例：変分オートエンコーダー）を用いてそのようなサンプルを生成し、OD検出のためのn+1分類器を訓練する新しいアルゴリズムを提案します（n+1^{th}クラスは、ODサンプルを表します）。MNISTおよびFashion-MNISTデータセットを用いて、提案手法を最近の分類器ベースのOOD検出器と比較した。その結果、提案手法は一貫して他の手法よりも優れた性能を示した。
トランスフォーマーベースのNLPモデルは、何億、何十億ものパラメータを使ってトレーニングされるため、計算機に制約のある環境での適用には限界があります。パラメータの数は一般的に性能と相関しているが、下流のタスクにネットワーク全体が必要かどうかは明らかではない。本研究では，学習済みモデルの刈り込みと抽出に関する最近の研究に触発され，学習済みモデルのレイヤーを削除する戦略を検討し，下流のGLUEタスクに対する刈り込みの効果を観察した．その結果、BERT、RoBERTa、XLNetのモデルを、元の性能の98%まで維持しながら、最大40%まで刈り込むことができました。さらに、我々のプルーニングされたモデルは、サイズと性能の両方の点で、知識抽出を用いて構築されたモデルと同等であることを示しています。実験の結果、(i)下流のタスクの性能を維持するためには、下位の層が最も重要である、(ii)言い換え検出や文の類似性などのタスクは、層の削除に対してより頑健である、(iii)異なる目的関数を用いて学習されたモデルは、層の削除に対して異なる学習パターンを示す、などの興味深い結果が得られた。
我々はCURLを発表する。CURL: Contrastive Unsupervised Representations for Reinforcement Learning（強化学習のための対照的な教師なし表現）を発表します。CURLは、対照的な学習を用いて生のピクセルから高レベルの特徴を抽出し、抽出された特徴に基づいてオフポリシー制御を行います。CURLは、DeepMind Control SuiteおよびAtari Gamesの複雑なタスクにおいて、モデルベースおよびモデルフリーの両方のピクセルベースの先行手法を上回り、100K環境およびインタラクションステップのベンチマークでそれぞれ1.9倍および1.2倍の性能向上を示しました。DeepMind Control Suiteでは、CURLは、状態ベースの特徴を使用する手法のサンプル効率にほぼ匹敵する、初めての画像ベースのアルゴリズムです。我々のコードはオープンソースであり、このhttpsのURLから入手可能です。
テキスト生成はここ数年で大きく進歩しました。しかし、評価指標は遅れており、最も一般的な選択肢（BLEUやROUGEなど）は、人間の判断との相関性が低い場合があります。我々は、BLEURTを提案する。BLEURTは、数千の偏った可能性のある学習例で人間の判断をモデル化できる、BERTに基づく学習済み評価指標である。我々のアプローチの重要な点は、モデルの一般化を助けるために数百万の合成例を使用する新しい事前学習スキームである。BLEURTは、過去3年間のWMT Metrics shared taskおよびWebNLG Competitionデータセットにおいて、最先端の結果を提供しています。バニラBERTベースのアプローチとは対照的に、学習データが不足している場合や配布されていない場合でも、優れた結果をもたらします。
ほとんどのニューラル機械翻訳モデルは、構文情報が注意メカニズムによって自動的に学習されると仮定して、並列文のペアにのみ依存しています。本研究では、Transformerモデルに構文知識を組み込むための様々なアプローチを調査し、また、特に長文や低リソースのシナリオでの翻訳品質を向上させる、新しい、パラメータ不要の、依存関係を考慮した自己注意メカニズムを提案する。それぞれのアプローチの有効性を、WMTの英語-ドイツ語、英語-トルコ語、WATの英語-日本語の翻訳タスクで示した。
データプライバシーに対する注目度や法整備が進む中、処理に使用される個人データの保護を確保するための協調的機械学習（ML）アルゴリズムが開発されている。その中でも特に注目されているのが統合学習（Federated Learning: FL）で、中央のサーバーと個人情報を交換することなく、共有モデルの共同学習を促進することでプライバシー保護を実現しています。この方法では、データを抽象化した機械学習モデルの更新情報が送信されます。最近の研究では、このようなモデル更新によっても個人情報が漏れる可能性があることが示されており、より構造的なリスク評価が必要とされています。本論文では、FLの既存の脆弱性を分析し、続いて、プライバシー保護機能をターゲットとした可能性のある攻撃方法についての文献調査を行います。そして、これらの攻撃方法を基本的な分類法によって分類する。さらに、これらの攻撃を克服することを目的としたFLの最新の防御戦略とアルゴリズムについての文献調査を行う。これらの防御戦略は、それぞれの基本的な防御原理によって分類される。本稿では、単一の防御戦略を適用するだけでは、利用可能なすべての攻撃手法に対して十分な防御を提供することはできないと結論づけている。
バックドア攻撃は、ディープニューラルネットワーク（DNN）に隠れたバックドアを注入し、攻撃者が定義したトリガーによって隠れたバックドアが作動した場合に、感染したモデルの予測が悪意を持って変更されることを意図していますが、良性のサンプルに対しては十分な性能を発揮します。現在、既存のバックドア攻撃の多くは、トレーニング画像とテスト画像のトリガーが同じ外観で、同じ場所にあるという、 ˶˙º̬˙˶の設定を採用しています。本論文では，静的トリガの特徴を分析することで，この攻撃パラダイムを再検討しました。その結果，テスト画像のトリガがトレーニング画像のトリガと一致しない場合，このような攻撃パラダイムは脆弱であることがわかった。さらに、この特性をバックドア防衛に利用する方法を探り、既存の攻撃のこのような脆弱性を軽減する方法を議論します。
より実用的な画像生成に向けて、「顕著な物体配置からの高品質な画像合成」という新しい課題を提案する。この新しい課題では、ユーザは顕著なオブジェクトのレイアウト（すなわち、前景のバウンディングボックスとカテゴリー）のみを提供し、モデルには、発明された背景とそれに一致する前景を使って描画を完成させることができる。この新しい課題から、2つの大きな課題が生まれました。(1)セグメンテーションマップを入力せずに、細かいディテールやリアルなテクスチャを生成する方法、(2)背景を作成し、それを単体のオブジェクトにシームレスに織り込む方法です。背景幻覚生成Adversarial Network(BachGAN)は、まず背景検索モジュールを用いて膨大な候補プールから一連のセグメンテーションマップを選択し、次に背景融合モジュールを用いてこれらの候補レイアウトをエンコードして、与えられたオブジェクトに適した背景を幻覚化することを提案する。本モデルは、幻覚のような背景表現を動的に生成することで、フォトリアリスティックな前景と一体化した背景を持つ高解像度画像を合成することができます。CityscapesとADE20Kのデータセットを用いた実験では、生成された画像の視覚的な忠実度と、出力画像と入力レイアウトの間の視覚的な整合性の両方について測定し、既存の手法に対するBachGANの優位性を実証しました。
最近の研究では、深層学習システムが敵対的な事例の影響を受けやすいことが報告されていますが、そのような攻撃のほとんどは、分類器へのデジタル入力を直接操作するものです。また、物理的な敵対的攻撃を検討している研究もありますが、どのような場合でも、対象となる物体を操作することが必要です。例えば、物体に物理的なステッカーを貼って誤分類することや、誤分類されることを特に意図して物体を製造することなどが挙げられます。本研究では、カメラ自体を物理的に操作することで、特定の種類の物体をすべて認識する深層分類器を欺くことができるか、という別の問題を検討します。本研究では、カメラのレンズの上に注意深く作られた主に半透明のステッカーを置くことで、目立たないが、対象となるオブジェクトを異なる（ターゲットとなる）クラスに誤分類する普遍的な摂動を、観測された画像に作り出すことができることを示す。これを実現するために、攻撃摂動の更新（与えられた分類法に対して敵対的になるようにする）と、脅威モデル自体の更新（物理的に実現可能であるようにする）の両方を行う反復手順を提案します。例えば、物理的に実現可能な攻撃であれば、49.6%の確率でImageNet分類器を騙すことができることを示しています。これにより、物理的に実現可能な脅威モデルの新しいクラスが提示され、敵対的ロバストな機械学習の文脈で検討することができます。デモビデオは以下のURLからご覧になれます： https URL
クリーンラベルポイズニング攻撃は、無害そうな（そして「正しく」ラベル付けされた）ポイズン画像を学習データに注入し、このデータで学習したモデルが標的の画像を誤分類するように仕向けます。本研究では、被害者のネットワークの出力やアーキテクチャ、（場合によっては）学習データにアクセスすることなく成功する、転送可能なポイズニング攻撃について検討します。これを実現するために、ポイズン画像が特徴空間において標的画像を取り囲むように設計された、新しい「ポリトープ攻撃」を提案する。また、ポイズン作成時にDropoutを使用することで、この攻撃の移植性を高めることができることを実証しました。また、ポイズン作成時にDropoutを使用することで、攻撃の移植性を高めることができることを示しました。
機械学習モデルは、敵対的な例に対して脆弱です。ブラックボックス環境では、現在の代替攻撃は、敵対的な例を生成するために事前に訓練されたモデルを必要とします。しかし、事前に学習されたモデルは、現実のタスクでは入手が困難です。本論文では、実データを必要とせずに、敵対的なブラックボックス攻撃のための代替モデルを得るためのデータフリー代替学習法（DaST）を提案する。これを実現するために、DaSTは特別に設計された生成的敵対ネットワーク（GAN）を利用して代替モデルを学習する。特に、合成サンプルの不均等な分布に対処するために、生成モデルにマルチブランチ・アーキテクチャとラベルコントロール・ロスを設計する。そして，生成モデルで生成された合成サンプルを用いて代替モデルを学習し，攻撃モデルでラベル付けを行う．実験の結果，DaSTが生成した代替モデルは，攻撃を受けたモデルと同じ訓練セットで訓練されたベースラインモデルと比較して，競争力のある性能を達成できることがわかった．さらに，実世界のタスクにおける提案手法の実用性を評価するために，Microsoft Azureプラットフォーム上のオンライン機械学習モデルを攻撃した．このモデルは，本手法によって作成された敵対的な例のうち98.35%を誤分類した．我々の知る限り、実データなしで敵対的攻撃のための代替モデルを訓練したのは我々が初めてです。
最近の研究では、深層学習アプローチが顔検出タスクで顕著な結果を得ることが証明されました。その一方で、ディープ・コンボリューショナル・ニューラル・ネットワーク・モデルの安全性に関する新たな問題が発生し、DCNNsベースのアプリケーションの潜在的なリスクが明らかになりました。デジタル領域のわずかな入力変化でも、ネットワークが欺かれてしまう可能性があるからです。また、深層学習に基づく顔検出器は、デジタル領域だけでなく、実世界でも敵対的な攻撃を受けやすいことが示されました。本論文では、よく知られているカスケードCNN顔検出システムであるMTCNNの安全性を調査し、簡単に再現可能で堅牢な攻撃方法を紹介しています。白と黒のプリンターで印刷した異なる顔属性を、医療用フェイスマスクまたは顔に直接貼り付ける方法を提案します。我々のアプローチは、実世界のシナリオでMTCNN検出器を破ることができる。
サブワード・セグメンテーションは、機械翻訳におけるオープン・ボキャブラリーの問題を解決するために広く用いられている。サブワードのセグメンテーションには、バイトペアエンコーディング（BPE）という手法が主流で、最も頻度の高い単語はそのままに、まれな単語を複数のトークンに分割します。同じ語彙でも複数のセグメンテーションが可能ですが、BPEは単語をユニークなシーケンスに分割するため、モデルが単語の構成性をよりよく学習し、セグメンテーションエラーに強くなることを妨げる可能性があります。これまでは、このBPEの不完全性、つまり決定論的な性質を克服するには、別のサブワードセグメンテーションアルゴリズムを作るしかありませんでした（Kudo, 2018）。これに対し、我々はBPE自体が同じ単語の複数のセグメンテーションを生成する能力を組み込んでいることを示す。我々は、BPE-dropout - 従来のBPEに基づいており、互換性のあるシンプルで効果的なサブワード正則化法を紹介します。BPE-dropoutは、BPEのセグメンテーション手順を確率的に破壊することで、同じ固定されたBPEフレームワーク内で複数のセグメンテーションを生成することができます。学習時にBPE-dropoutを使用し、推論時に標準のBPEを使用することで、BPEと比較して最大3BLEU、従来のサブワード正則化と比較して最大0.9BLEUの翻訳品質の向上を実現しました。
人工知能（AI）は様々な領域で大きな成功を収めていますが、ゲームAIはAIの黎明期からその橋頭堡として広く知られています。近年、ゲームAIの研究は、比較的単純な環境（囲碁、チェス、将棋などの完全情報ゲームやヘッドアップテキサスホールデムなどの2人用不完全情報ゲームなど）から、より複雑な環境（マルチプレイヤーテキサスホールデムやStartCraft IIなどのマルチプレイヤー不完全情報ゲームなど）へと徐々に進化しています。麻雀は世界中で人気のあるマルチプレイヤー不完全情報ゲームですが、その複雑なプレイ/スコアリングルールと豊富な隠れた情報のため、AI研究にとって非常に困難です。我々は、深層強化学習をベースに、グローバル報酬予測、オラクルガイド、ランタイムポリシー適応などの新たな技術を加えた麻雀AIを設計し、Suphxと名付けました。Suphxは、安定したランクという点で、ほとんどのトップの人間のプレイヤーよりも強い性能を示し、Tenhouプラットフォームで公式にランク付けされたすべての人間のプレイヤーの99.99%以上の評価を得ています。これは、麻雀において、コンピュータプログラムがほとんどの人間のトッププレイヤーを凌駕した初めての例です。
機械学習の研究は、モデルの構造や学習方法など多面的に進んでいます。機械学習の研究は、モデルの構造や学習方法など様々な面で進歩しており、AutoMLと呼ばれる研究を自動化する取り組みも大きく進んでいます。しかし、この進歩は主にニューラルネットワークのアーキテクチャに焦点を当てたもので、専門家が設計した洗練された層を構成要素としたり、同様に制限された探索空間に依存していました。AutoMLは、基本的な数学的操作を構成要素として、完全な機械学習アルゴリズムを自動的に発見することができるのです。私たちは、一般的な検索空間を使って人間のバイアスを大幅に削減する新しいフレームワークを導入することで、これを実証します。広大な探索空間にもかかわらず、進化的探索はバックプロパゲーションによって学習された2層のニューラルネットワークを発見することができます。これらの単純なニューラルネットワークは、興味のあるタスク、例えばCIFAR-10の変形などに直接進化させることで、双線形相互作用、正規化勾配、重み平均化などの最新技術が上位のアルゴリズムに現れ、凌駕することができます。さらに、進化は、異なるタスクタイプにアルゴリズムを適応させます。例えば、データが少ない場合には、ドロップアウトのような手法が現れたりします。このように、機械学習アルゴリズムをゼロから発見することに成功したことは、この分野の新たな方向性を示していると考えている。
企業のメール検索では、同じ検索エンジンで、技術、教育、製造など様々な業界の複数の企業を検索することが多い。しかし、異なる企業間で同じグローバルランキングモデルを使用すると、コーパスの違いや異なる情報ニーズのために、最適な検索品質が得られない可能性があります。一方で、企業ごとに個別のランキングモデルをトレーニングすることは、特にデータが限られている小規模な機関にとっては、実行不可能な場合があります。この課題を解決するために、本稿では、グローバルモデルを個々の企業に合わせて微調整するドメイン適応アプローチを提案する。特に、情報検索における最大平均不一致（MMD）アプローチの新しい応用を提案し、グローバルなデータ分布と与えられた個々の企業のデータ分布の間のギャップを埋めることを試みる。大規模な電子メール検索エンジンで包括的な実験を行い、MMDアプローチは、グローバルランキングモデルや、敵対的学習法を含むいくつかの競合するドメイン適応ベースラインと比較して、複数の個別ドメインの検索品質を一貫して向上させることを実証しました。
データ補強は、ディープネットワークの性能を向上させる効果的な方法です。残念ながら、現在の手法はほとんどが高レベルのビジョンタスク（例：分類）のために開発されており、低レベルのビジョンタスク（例：画像復元）のために研究されているものはほとんどありません。本論文では、超解像タスクに適用されている既存の補強手法の包括的な分析を行った。その結果，画素や特徴を捨てたり操作したりする手法は，空間的な関係が非常に重要な画像復元を妨げることがわかった．そこで我々は、低解像度のパッチを切り取り、それを対応する高解像度の画像領域に貼り付けるCutBlurを提案する。CutBlurは、画像をどのように超解像するかということだけでなく、どこで超解像するかということもモデルに学習させることを目的としています。これにより、モデルはすべてのピクセルに超解像を適用するのではなく、「どの程度」適用するのかを理解することができます。我々の手法は、モデルサイズが大きく、実世界の環境下でデータを収集した場合に、様々なシナリオで一貫して大幅に性能を向上させます。また、本手法は、ノイズ除去や圧縮アーチファクトの除去など、他の低レベルのビジョンタスクを改善することも示している。
機械学習の多くのアプリケーションでは、学習時にタスク固有のラベルが少ない中で、学習時とは分布的に異なるテスト例に対してモデルが正確な事前予測を行うことが求められます。この課題に対する効果的なアプローチは、データが豊富な関連タスクでモデルを事前に学習し、その後、関心のある下流のタスクでモデルを微調整することです。事前学習は、多くの言語や視覚の分野で有効であるが、グラフのデータセットで事前学習を効果的に利用する方法はまだ未解決である。本論文では、グラフニューラルネットワーク（GNN）の事前学習のための新しい戦略と自己教師付きの手法を開発しました。我々の戦略の成功の鍵は、個々のノードやグラフ全体のレベルで表現力のあるGNNを事前学習し、GNNが有用なローカルおよびグローバルな表現を同時に学習できるようにすることである。私たちは、複数のグラフ分類データセットを用いて、事前学習を体系的に研究しました。その結果、グラフ全体または個々のノードレベルでGNNを事前学習するナイーブな戦略では、改善効果は限られており、多くの下流タスクで負の伝達を引き起こす可能性があることがわかりました。対照的に、我々の戦略は負の伝達を回避し、下流のタスクでの一般化を大幅に向上させ、事前学習していないモデルに比べてROC-AUCの絶対値を9.4%向上させ、分子特性予測とタンパク質機能予測において最先端の性能を達成しました。
単一画像ビュー合成では、1枚の入力画像からシーンの新しいビューを生成することができます。これは、1枚の画像から3Dシーンを包括的に理解する必要があるため、困難を伴います。そのため、現在の手法では、一般的に複数の画像を使用したり、グラウンドトゥルース深度でトレーニングを行ったり、合成データに限定したりしています。我々は、このタスクのための新しいエンド・ツー・エンドモデルを提案する。このモデルは、グランドトゥルースの3D情報を持たない実画像で学習される。この目的のために、我々は、潜在的な特徴の3D点群をターゲットビューに変換するために使用される新しい微分可能な点群レンダラーを導入します。投影された特徴は、我々の洗練されたネットワークによって復号され、欠落した領域を塗り潰し、現実的な出力画像を生成します。この生成モデルに含まれる3Dコンポーネントにより、テスト時に潜在的な特徴空間を解釈可能に操作することができます。また、先行研究とは異なり、高解像度の画像を生成し、他の解像度の入力にも対応することができます。また，Matterport，Replica，RealEstate10Kの各データセットにおいて，ベースラインや先行研究よりも優れた結果を得た．
事前に学習した表現がどの程度言語的特性を符号化しているかを測定するには，プローブの精度を用いるのが一般的である．すなわち，表現から特性を予測するように学習された分類器である．プローブは広く採用されていますが、その精度の違いは表現の違いを適切に反映していません。例えば、ランダムに初期化された表現よりも、事前に学習された表現の方が実質的に有利になることはありません。同様に、本物の言語ラベルを対象としたプローブと、ランダムな合成タスクを対象としたプローブでは、その精度は似通ったものになります。これまでの研究では、これらのランダムベースラインとの精度の違いを見るためには、プローブの学習データ量やモデルサイズのいずれかを制限する必要があった。本研究では、標準的なプロービングの代わりに、最小記述長（MDL）を用いた情報理論的プロービングを提案する。MDLプロービングでは、ラベルを予測するためにプローブを訓練することは、データを効果的に伝達するためにプローブを訓練することに置き換えられます。そのため、プローブの精度から、表現されたラベルの記述長へと関心の対象が変わります。記述長は、プローブの品質に加えて、品質を達成するために必要な「努力の量」を評価します。この努力の量は、(i)プローブモデルの大きさ、(ii)高品質を達成するために必要なデータ量のいずれかを特徴づける。本論文では，標準的なプロービングパイプライン上に容易に実装可能な2つのMDL推定法，すなわち，変分コーディングとオンラインコーディングを検討した．これらの手法は結果が一致しており、標準的なプロービングよりも情報量が多く、安定していることを示しています。
Atariゲームは、強化学習（RL）のコミュニティにおいて、過去10年間、長年のベンチマークとなっています。このベンチマークは、RLアルゴリズムの一般的な能力をテストするために提案されました。これまでの研究では、セットの多くのゲームで優れた成績を収め、平均的な性能を達成してきましたが、最も困難なゲームのいくつかでは非常に劣っていました。我々が提案するAgent57は、57種類のAtari社のゲーム全てにおいて、標準的な人間のベンチマークを上回る初の深層RLエージェントである。この結果を達成するために、我々は、探索的なものから搾取的なものまで、様々なポリシーをパラメータ化するニューラルネットワークを学習する。また、学習過程において、どの方針を優先するかを選択する適応的なメカニズムを提案する。さらに、より一貫性のある安定した学習を可能にするアーキテクチャの新しいパラメータ化を利用しています。
地球上には何千もの言語が話されていますが、視覚的な世界は一つしかありません。この視覚的な世界でのグラウンディングは、これらすべての言語間のギャップを埋める可能性があります。私たちの目標は、視覚的なグラウンディングを利用して、言語間の教師なしのワードマッピングを改善することです。キーとなるアイデアは、母国語でナレーションされたペアになっていない教育ビデオから埋め込みを学習することで、2つの言語間で共通の視覚表現を確立することである。この共有埋め込みを用いて、(i)2つの言語間の単語、特に「視覚的」な単語をマッピングできること、(ii)共有埋め込みは、既存の教師なしテキストベースの単語翻訳技術に良い初期化を提供し、我々が提案する視覚とテキストのハイブリッドマッピングアルゴリズム「MUVE」の基礎を形成すること、(iii)我々のアプローチは、テキストベースの手法の欠点を解決することで、よりロバストで、共通性の低いデータセットを扱い、低リソース言語にも適用できるという優れた性能を達成することを実証しました。これらの手法を、英語からフランス語、韓国語、日本語への翻訳に適用しました。これらの手法は、並列コーパスを使用せず、人々が何かをしながら話しているビデオをたくさん見るだけで、単語を翻訳することができました。
目に見えないローカルな文脈に適応する能力は、ソースコードのモデルを成功させるために克服しなければならない重要な課題です。このようなモデルを適応させるための最も一般的なアプローチの1つが動的評価です。動的評価では、見たことのないファイルに対してモデルを実行する際、そのファイルの各トークンを観測した直後にモデルが更新されます。本研究では，文脈適応の問題をメタ学習の問題として捉えることを提案する．我々の目的は、ファイル内の情報から最適な学習を行い、欠落したトークンの予測を改善することができるベースソースコードモデルを学習することです。動的評価とは異なり、この方法では、適応の対象となる情報（サポートトークン）を、ファイル内の対象となる穴の前と後の両方で選択することができます。我々は、IDEにおけるコードの自動補完という下流のタスクを反映して設計された、ラインレベルメンテナンスと呼ぶ評価設定を検討する。一次MAMLやReptileといった最近のメタ学習を活用し、大規模なJava GitHubコーパスを用いた実験では、動的評価を含む他の適応ベースラインと比較して性能が向上したことを実証した。さらに，非適応ベースラインと比較して，識別子で44%，リテラルで15%の性能向上が見られた．私たちの実装は，以下のURLに掲載されています： https URL
深層強化学習（RL）政策は，分類器に対する敵対的な例と同様に，観測結果に対する敵対的な摂動に対して脆弱であることが知られている．しかし、通常、攻撃者は他のエージェントの観測値を直接変更することはできません。では、マルチエージェント環境において、敵対的な政策を選択することで、RLエージェントを攻撃することは可能なのだろうか？本研究では、プロプリオセプティヴな観測データを持つシミュレートされたヒューマノイド・ロボットと、対戦相手に対してロバストになるように自己訓練された最先端の犠牲者との間で行われるゼロサムゲームにおいて、敵対的なポリシーの存在を実証する。敵対的な政策は、犠牲者に対して確実に勝利するが、一見ランダムで協調性のない行動を生み出す。これらの政策は高次元環境でより成功し、被害者の政策ネットワークにおいて、通常の相手と対戦した場合とは大きく異なる活性化を引き起こすことがわかりました。動画は https://adversarialpolicies.github.io/ でご覧いただけます。
好奇心とは、進化によって発見されたメカニズムであり、エージェントが生涯にわたって高い報酬を得ることができるような経験をさせるために、人生の早い段階で意味のある探索を促すものであるという仮説を立てています。外側のループは、エージェントの報酬信号を動的に適応させる好奇心メカニズムの空間を探索し、内側のループは、適応された報酬信号を用いて標準的な強化学習を行う。しかし、ニューラルネットワークの重みを転送することに基づく現在のメタ学習法は、非常に類似したタスク間でしか一般化されていない。一般化の幅を広げるために、私たちはアルゴリズムのメタ学習を提案しています。我々の豊富なプログラム言語は、ニューラルネットワークと、バッファ、最近傍モジュール、カスタム損失関数などの他の構成要素を組み合わせたものである。このアプローチの有効性を経験的に実証し、画像入力によるグリッドナビゲーション、アクロバット、月面着陸機、アリとホッパーなどの異なるドメインにおいて、人間が設計した発表済みの好奇心アルゴリズムと同等以上の性能を持つ2つの新しい好奇心アルゴリズムを発見した。
近年、機械学習モデルのNLPへの応用は、様々なタスクでモデルを評価するベンチマークによって進められてきました。しかし、これらのベンチマークはほとんどが英語に限定されており、多言語モデルへの関心が高まっているにもかかわらず、多様な言語とタスクでモデルを総合的に評価できるベンチマークはまだ存在しません。そこで本研究では、40の言語と9つのタスクで多言語表現の言語間汎用性を評価するマルチタスクベンチマークであるCross-lingual TRansfer Evaluation of Multilingual Encoders XTREMEベンチマークを紹介する。英語でテストされたモデルは多くのタスクで人間の性能に達していますが、言語間で移植されたモデルの性能には、特に構文や文の検索タスクにおいて、まだかなりのギャップがあることが分かりました。また、言語間で結果が大きく異なることもあります。私たちは、多様で代表的な言語とタスクで言語知識を伝達するクロスリンガル学習法の研究を奨励するために、このベンチマークを公開しました。
天気予報は、社会や経済に直接影響を与える長年の科学的課題です。このタスクは、継続的に収集される膨大な量のデータと、長期的な依存関係を示す豊かな空間的・時間的構造のため、深層ニューラルネットワークに適しています。我々はMetNetを紹介します。このニューラルネットワークは、1km2の高い空間解像度と2分の時間解像度で、数秒のレイテンシで8時間先までの降水量を予測します。MetNetは，レーダーや衛星のデータと予測リードタイムを入力として，確率的な降水量マップを作成します。このアーキテクチャは、軸方向の自己注意を用いて、100万平方キロメートルに相当する大きな入力パッチからグローバルなコンテキストを集約します。様々な降水量のしきい値でMetNetの性能を評価した結果、MetNetは、米国大陸の規模で7～8時間までの予測において、Numerical Weather Predictionを上回る性能を示しました。
過去4年間に発表されたディープ・メトリック・ラーニングの論文は、一貫して精度の大きな進歩を主張しており、しばしば10年前の手法の2倍以上の性能を示しています。この論文では、それが実際に正しいかどうかを確認するために、この分野を詳しく調査しました。私たちは、多くのメートル法学習論文の実験方法に欠陥があることを発見し、時間の経過に伴う実際の改善はせいぜいわずかなものであることを示した。
自動カリキュラム学習（ACL）は、近年の深層強化学習（DRL）の成功の礎となっています。これらの手法は、エージェントの能力に合わせたタスクに挑戦することで、エージェントの学習軌道を形成するものです。近年では、サンプル効率や漸近性能の向上、探索の整理、汎化の促進、疎な報酬問題の解決などに利用されています。本研究の目的は、1）自動カリキュラム学習に関する文献をコンパクトでわかりやすく紹介すること、2）ACLにおける技術の現状をより大きく描き、既存の概念の交配と新しいアイデアの出現を促すこと、の2点です。
私たちは、SEED（Scalable, Efficient Deep-RL）と呼ばれる最新のスケーラブルな強化学習エージェントを紹介します。最新のアクセラレータを効果的に活用することで、毎秒数百万フレームの学習が可能なだけでなく、現在の手法と比較して実験コストを下げることができることを示しています。SEEDは、推論の集中化と通信層の最適化を特徴とするシンプルなアーキテクチャでこれを実現しています。SEEDは、IMPALA/V-trace（policy gradients）とR2D2（Q-learning）という2つの最先端の分散アルゴリズムを採用しており、Atari-57、DeepMind Lab、Google Research Footballで評価されています。FootballではState of the artを改善し、Atari-57ではウォールタイムで3倍の速さでState of the artに到達することができました。考慮したシナリオでは、実験を行うためのコストを40%から80%削減することができました。実験と一緒に実装もオープンソース化しているので、結果の再現や新しいアイデアを試すことができます。
ニューラルネットワークの学習された重みは、しばしば精査可能な内部構造を持たないと考えられます。そこで、多層パーセプトロン（MLP）にモジュール性という測定可能な概念を導入し、小さな画像のデータセットで学習したMLPのモジュール性を調査した。モジュール」とは、内部接続性が強く、外部接続性が弱いニューロンの集合のことである。我々は、学習と重みの刈り込みを行ったMLPは、同じ分布の重みを持つランダムなネットワークよりも、しばしば有意にモジュール性が高いことを発見した。興味深いことに、ドロップアウトを用いて学習した場合、MLPはより一層モジュール化される。さらに、このモジュール性は、主に学習可能なデータセットで訓練されたネットワークで発生することがわかった。また、異なるモジュールの性能に対する重要性や、モジュールがどのように相互に依存しているかについての探索的な分析も行っています。ニューラルネットワークのモジュール構造を理解することで、その内部構造を技術者がより理解しやすくなることが期待されます。
本研究では、複雑なシーンの新しいビューを合成するために、入力ビューの疎なセットを用いて、基礎となる連続したボリュームのあるシーン関数を最適化することで、最先端の結果を達成する手法を紹介する。我々のアルゴリズムは、完全に接続された（非畳み込み）ディープネットワークを用いてシーンを表現する。その入力は、単一の連続した5次元座標（空間位置（x,y,z）と視線方向（\θ, phi））であり、その出力は、その空間位置における体積密度とビューに依存した放射輝度である。カメラの光線に沿った5次元座標を照会してビューを合成し、古典的なボリュームレンダリング技術を用いて、出力された色と密度を画像に投影します。ボリュームレンダリングは自然に微分可能であるため、我々の表現を最適化するために必要な唯一の入力は、既知のカメラのポーズを持つ画像のセットである。本論文では、複雑な形状と外観を持つシーンのフォトリアリスティックな新しいビューをレンダリングするために、ニューラル・ラジアンス・フィールドを効果的に最適化する方法を説明し、ニューラル・レンダリングとビュー合成に関する先行研究を上回る結果を示している。視点合成の結果は動画で見るのが一番わかりやすいので、ぜひ補足の動画を見て納得のいく比較をしていただきたいと思います。
斬新で適切な挑戦的な学習機会を自ら無限に生み出す、オープンエンドなアルゴリズムを作ることは、機械学習の自動化と進歩の加速に役立つでしょう。最近では、Paired Open-Ended Trailblazer（POET）というアルゴリズムが開発されました。このアルゴリズムは、自ら課題を生成して解決し、局所最適を避けるために課題間のゴールスイッチを可能にします。しかし、オリジナルのPOETは、アルゴリズム自体の限界や、問題空間の制限、普遍的な進捗指標の欠如などの外的な問題により、その創造性を十分に発揮することができませんでした。この2つの問題は、POETに限らず、オープンエンドを追求する上での障害となっています。ここでは、オリジナルのアルゴリズムに2つの新機軸を導入し、経験的に検証するとともに、その可能性を最大限に引き出すための2つの外部新機軸を導入しました。これら4つの工夫により，これまでで最もオープンエンドなアルゴリズムの実証が可能になりました．アルゴリズムの革新とは，(1) 新しい課題がどれだけ意味のある新規性を持つかを示す領域共通の尺度であり，システムが興味深い課題を無限に創造し解決することを可能にするものである．アルゴリズム以外では、オープンエンド性をより明確に示すために、(3)環境上の課題をコード化するための新しい柔軟な方法と、(4)システムがオープンエンド・イノベーションを継続する程度を示す一般的な尺度を導入しました。強化されたPOETは、他の手段では解決できないような幅広い環境課題を解決する、多様で洗練された行動を生み出します。
不注意による失明とは、目の前にあるものを見落としてしまう心理的な現象である。これは、私たちが世界の重要な部分に集中し、無関係な細部に気を取られないようにするための、知覚における選択的注意の結果です。本研究では、選択的注意に基づいて、自己注意のボトルネックを通して世界を知覚する人工エージェントの特性を研究します。視覚入力のごく一部へのアクセスを制限することで、エージェントの方針がピクセル空間で直接解釈可能であることを示している。神経進化は、視覚ベースの強化学習（RL）タスクのために自己注意アーキテクチャを訓練するのに理想的であり、エージェントに有用な離散的で非差別的な操作を含むモジュールを組み込むことができる。自己注意は、少数のキー・クエリー・パラメータから大きな暗黙の重み行列を生成するという意味で、間接的な符号化と同様の特性を持っていると主張しています。我々のエージェントは、タスクに重要な視覚的ヒントのみに注意を払うので、従来の方法が失敗する中で、タスクに関係のない要素が変更される環境にも一般化することができます。結果の動画とソースコードはこちらのhttps URLからご覧いただけます。
コンピュータビジョンでは，モデルの効率化がますます重要になっている．本論文では、物体検出のためのニューラルネットワークアーキテクチャ設計の選択を体系的に研究し、効率を向上させるためのいくつかの重要な最適化を提案します。第一に、マルチスケール特徴融合を容易かつ高速に行うことができる重み付き双方向特徴ピラミッドネットワーク（BiFPN）を提案する。第二に、バックボーン、特徴ネットワーク、ボックス／クラス予測ネットワークのすべてについて、解像度、深さ、幅を同時に均一にスケーリングする複合スケーリング法を提案する。これらの最適化と優れたバックボーンに基づいて、我々はEfficientDetと呼ばれる新しいオブジェクト検出器のファミリーを開発しました。これらのオブジェクト検出器は、幅広いリソース制約の中で一貫して先行技術よりもはるかに優れた効率を達成しています。特に、シングルモデル、シングルスケールの場合、当社のEfficientDet-D7は、COCO test-devにおいて、77Mのパラメータと410BのFLOPsを用いて、最先端の55.1APを達成しました。コードはこちらのhttpsのURLから入手できます。
AutoGluon-TabularはオープンソースのAutoMLフレームワークで、Pythonを1行書くだけで、CSVファイルのような未処理の表形式データセットに対して高精度の機械学習モデルを学習することができます。AutoGluon-Tabularは、モデル／ハイパーパラメータの選択に主眼を置いた既存のAutoMLフレームワークとは異なり、複数のモデルをアンサンブルし、複数のレイヤーに積み重ねることで成功しています。実験によると、多くのモデルを多層的に組み合わせることで、最適なモデルを探すよりも、割り当てられた学習時間を有効に使えることが明らかになりました。2つ目の貢献は、TPOT、H2O、AutoWEKA、auto-sklearn、AutoGluon、Google AutoML Tablesなどの公共および商用AutoMLプラットフォームの広範な評価です。また、KaggleやOpenML AutoML Benchmarkの50の分類・回帰タスクを用いたテストでは、AutoGluonがより高速で、よりロバストで、より正確であることが明らかになりました。また、AutoGluonは、後から見たときに、すべての競合他社の組み合わせよりも優れていることがわかっています。2つの人気のあるKaggleコンペティションにおいて、AutoGluonは、生データに対して4時間のトレーニングを行っただけで、参加したデータサイエンティストの99%を打ち負かしました。
自己言及は、最近、広範囲のシーケンスモデリング問題に採用されています。しかし、自己注釈は、その有効性にもかかわらず、配列の長さに対して二次的な計算とメモリの必要性があります。この複雑さを軽減するための成功したアプローチは、局所的なスライディングウィンドウや、コンテンツに依存しない小さな場所のセットに注目したものでした。本研究では、興味のある質問とは無関係のコンテンツに注目するために計算とメモリを割り当てることを避けるために、動的な疎な注目パターンを学習することを提案する。この研究は、コンテンツベースの疎な注意に関する先行研究のモデリングの柔軟性と、局所的・時間的な疎な注意に基づくアプローチの効率性を組み合わせたものである。我々のモデル「ルーティング・トランスフォーマー」は、オンラインk平均法に基づいたスパース・ルーティング・モジュールを自己注意に付与するとともに、注意の全体的な複雑さを、シーケンス長nおよび隠れ次元dの場合のO(n2d)からO(n1.5d)に低減している。我々のモデルは、Wikitext-103の言語モデリング（15.8 vs 18.3 perplexity）およびImageNet-64の画像生成（3.43 vs 3.44 bits/dim）において、より少ない自己注意層を用いながら、同等のスパース・アテンション・モデルを凌駕することを示した。さらに、新たに公開されたPG-19データセットでは、長さ8192の配列で学習した22層のルーティング・トランスフォーマー・モデルを用いて、テストのパープレキシティを33.2とし、新たな最先端技術を確立しました。
メッシュ上の畳み込みを定義する一般的なアプローチは、メッシュをグラフとして解釈し、グラフ畳み込みネットワーク（GCN）を適用することである。このようなGCNは、等方性カーネルを利用しているため、頂点の相対的な向きや、メッシュ全体の形状に影響されない。我々が提案するゲージ等変メッシュCNNは、GCNを一般化して異方性ゲージ等変カーネルを適用したものである。得られる特徴量には向きの情報が含まれているため、メッシュのエッジ上で特徴量を平行移動させることで定義される幾何学的なメッセージパッシングスキームを導入する。提案モデルは、従来のGCNや他の手法と比較して、表現力が大幅に向上することが実験で確認されています。
IRM（Invariant Risk Minimization）は、複数の学習分布にまたがる不変的な相関を推定するための学習パラダイムである。この目標を達成するために、IRMはデータ表現を学習し、そのデータ表現の上に立つ最適な分類器がすべての学習分布に対して一致するようにする。理論と実験により、IRMが学習する不変性が、データを支配する因果構造にどのように関連し、分布外の一般化を可能にするかを示します。
近年の自然言語表現の発展に伴い、膨大な量の一般的なテキストを自己教師付きの事前学習によって活用する、大規模で高価なモデルが登場しています。このようなモデルをダウンストリームタスクに適用するコストのために、事前学習された言語表現上のいくつかのモデル圧縮技術が提案されている（Sun et al.2019; Sanh, 2019）。しかし、意外にも、コンパクトなモデルを事前学習して微調整するだけのシンプルなベースラインは見過ごされてきた。本論文ではまず、より小さなアーキテクチャの文脈では事前学習が依然として重要であり、事前学習したコンパクトモデルを微調整することで、同時進行で提案されているより精巧な手法に対抗できることを示します。そして、事前に学習されたコンパクトなモデルを用いて、標準的な知識蒸留法を用いて、大規模な微調整モデルからタスク知識を転送することを検討します。その結果、シンプルでありながら効果的かつ一般的なアルゴリズムである「事前学習済み蒸留法」がさらに改良されました。さらに、これまであまり研究されてこなかった、モデルのサイズとラベルのないタスクデータの特性という2つの変数の下で、事前学習と蒸留の相互作用を広範な実験を通して調べました。驚くべきことに、同じデータに連続して適用しても、複合的な効果が得られることがわかりました。今後の研究を加速させるために、私たちは24個の事前学習済みミニチュアBERTモデルを公開します。
ニューラル機械翻訳（NMT）は、文レベルで訓練・評価された場合、間違いなく人間レベルの同等性を達成しています。文書レベルのニューラル機械翻訳は、あまり注目されておらず、文レベルの対応に遅れをとっています。提案されている文書レベルのアプローチの大半は、文書の文脈を把握するために、複数の原文またはターゲット文でモデルの条件付けを行う方法を研究しています。これらのアプローチでは、文書レベルの並列コーパスを用いて、特殊なNMTモデルを一から学習する必要がある。本研究では、文書レベルの並列コーパスに特化したモデルを学習する必要がなく、デコーディング時に学習済みの文レベルのNMTモデルに適用するアプローチを提案する。文書を左から右に複数回処理し、原文と生成された訳文のペアで文レベルのモデルを自己学習させる。この方法では、モデルが行った選択を強化することで、文書内の他の文でも同じ選択が行われる可能性を高めます。我々のアプローチを3つの文書レベルのデータセットで評価した。NIST中国語-英語，WMT'19中国語-英語，OpenSubtitles英語-ロシア語の3つの文書レベルのデータセットを用いて，我々のアプローチを評価した．その結果、我々のアプローチはベースラインよりも高いBLEUスコアと高い人間の嗜好性を持つことが実証された。また、我々のアプローチの定性分析では、モデルによる選択が文書全体で一貫していることを示しています。
タンパク質工学のための生成モデリングは、合成生物学、医学、および材料科学における基本的な問題を解決するための鍵となります。本研究では、タンパク質工学を教師なしの配列生成問題とみなし、コストのかかる構造注釈を持たないタンパク質が指数関数的に増加していることを利用しています。我々は、約2億8千万個のタンパク質配列に対して、1.2Bパラメータの言語モデルであるProGenを学習します。これにより、ProGenはこれまでにない進化的な配列の多様性を得ることができ、一次配列の類似性、二次構造の正確さ、コンフォメーションエネルギーに基づいた評価基準により、きめ細かな制御で生成することができます。
私たちは、ゼロショット協調の問題を考えます。これは、これまで見たことのない新しい相手（例えば人間）と協調できるAIエージェントを構築することです。一般的なマルチエージェント強化学習（MARL）の手法は、エージェントが自分自身とゲームを繰り返すことで戦略を構築する自己再生（SP）の設定に焦点を当てている。残念ながら、ゼロショット調整問題にSPを素朴に適用すると、エージェントは高度に専門化された慣習を確立し、訓練されていない新しいパートナーには引き継がれない。本研究では、他流試合（OP）と呼ばれる新しい学習アルゴリズムを導入する。OPは、問題の対称性の存在を利用して、より頑健な戦略を探すことにより、自流試合を強化する。OPは、理論的にも実験的にも特徴づけられる。協力型カードゲーム「HANABI」を研究し、OPエージェントは、独立して訓練されたエージェントとペアを組んだときに、より高いスコアを達成することを示す。予備的な結果として、我々のOPエージェントは、最先端のSPエージェントと比較して、人間のプレイヤーとペアを組んだときに高い平均スコアを得ることも示している。
CodeBERTは、プログラミング言語（PL）と自然言語（NL）のための二峰性の事前学習モデルです。CodeBERTは、自然言語コード検索、コード文書生成などのNL-PLアプリケーションの下流をサポートする汎用的な表現を学習します。CodeBERTは、Transformerベースのニューラル・アーキテクチャで開発されており、生成器からサンプリングされたもっともらしい代替品を検出するという、置き換えられたトークン検出の事前学習タスクを組み込んだハイブリッド目的関数で学習します。これにより、NL-PLペアの二峰性データと一峰性データの両方を利用することができ、前者はモデル学習のための入力トークンを提供し、後者はより良い生成器を学習するのに役立ちます。モデル・パラメータを微調整することにより、2つのNL-PLアプリケーションでCodeBERTを評価しました。結果は、CodeBERTが自然言語コード検索およびコード文書生成タスクの両方において、最先端の性能を達成したことを示しています。さらに、CodeBERTにおいてどのような種類の知識が学習されているかを調査するために、NL-PLプロービングのデータセットを構築し、事前に学習されたモデルのパラメータが固定されているゼロショット設定で評価を行った。結果は、NL-PLプロービングにおいて、CodeBERTが以前の事前学習モデルよりも優れた性能を発揮することを示しています。
事前に訓練された文脈上の単語埋め込みモデルを、教師付きの下流タスクに合わせて微調整することは、自然言語処理において一般的になっています。しかし，このプロセスは，同じハイパーパラメータ値であっても，ランダムシードが異なると結果が大きく異なるという脆さがある．この現象を理解するために、GLUEベンチマークの4つのデータセットを用いて、ランダムシードのみを変化させながらBERTを数百回にわたって微調整する実験を行いました。その結果、これまでに報告されている結果と比較して、大幅な性能向上が見られました。また、最適なモデルの性能が、微調整の試行回数の関数としてどのように変化するかを定量的に示しました。さらに，ランダムシードの選択によって影響を受ける2つの要素，すなわち，重みの初期化と学習データの順序を調べた．その結果，両者はサンプル外の性能の分散にほぼ同等の寄与をしており，また，ある種の重み初期化は調査したすべてのタスクで良好な性能を示すことがわかった．小規模なデータセットでは，多くの微調整試行がトレーニングの途中で発散することが観察され，有望でない試行のトレーニングを早期に中止するためのベストプラクティスを提供する．また，2,100回の試行におけるトレーニングと検証のスコアを含むすべての実験データを公開し，ファインチューニング中のトレーニングダイナミクスのさらなる分析を奨励している．
ハードウェアのリソースは限られているため、深層学習モデルをトレーニングする目的は、通常、トレーニングと推論の時間とメモリの制約のもとで、精度を最大化することです。本研究では、自己教師付き事前学習とハイリソース機械翻訳という計算量に制限のあるNLPタスクのためのTransformerモデルに焦点を当て、この設定におけるモデルサイズの影響を研究します。まず最初に、小さいTransformerモデルは反復ごとの実行速度が速いにもかかわらず、広くて深いモデルはかなり少ないステップで収束することを示します。さらに、この収束の加速は、通常、より大きなモデルを使用することによる追加の計算オーバーヘッドを上回ります。したがって、最も計算効率の高い学習戦略は、直感に反して非常に大きなモデルを学習し、少ない反復回数で停止することです。これにより、大きなTransformerモデルの学習効率と小さなTransformerモデルの推論効率の間に、明らかなトレードオフが生じます。しかし、大きなモデルは、小さなモデルよりも、量子化や刈り込みなどの圧縮技術に対してより頑健であることを示しています。その結果、重く圧縮された大きなモデルが、軽く圧縮された小さなモデルよりも高い精度を達成するという、両方の長所を得ることができる。
スタイル変換からマルチタスク学習まで、さまざまな深層学習技術が、特徴のアフィン変換の学習に依存している。これらの技術の中で最も顕著なのは、人気のある特徴の正規化技術であるBatchNormであり、これは活性化を正規化した後、学習したアフィン変換を適用するものである。本論文では、このような特徴量の変換に用いられるアフィンパラメータの役割と表現力を理解することを目的としています。そこで、BatchNormでこれらのパラメータのみを学習し、すべての重みをランダムな初期化で固定した場合の性能を調べました。この方法では、学習スタイルに大きな制限があるにもかかわらず、驚くほど高い性能が得られました。例えば、十分に深いResNetsは、この構成で82％（CIFAR-10）および32％（ImageNet, top-5）の精度を達成しており、ネットワーク内の他の場所で同数のランダムに選ばれたパラメータを学習した場合よりもはるかに高い精度を達成しています。BatchNormは，ランダムな特徴量の約3分の1を無効にするよう自然に学習することで，この性能を達成しています．これらの結果は、深層学習におけるアフィンパラメータの表現力を明らかにしただけでなく、より広い意味で、ランダムな特徴をシフトしたりリスケールしたりするだけで構築されるニューラルネットワークの表現力を特徴づけるものである。
lottery ticket hypothesis（Frankle and Carbin, 2018）は、ランダムに初期化されたネットワークには、分離して訓練された場合、元のネットワークの性能と競合できるような小さなサブネットワークが含まれているというものです。我々はさらに強い仮説（Ramanujan et al., 2019でも推測された）を証明し、すべての有界分布と有界重みを持つすべてのターゲットネットワークに対して、ランダムな重みを持つ十分にオーバーパラメータ化されたニューラルネットワークは、さらなるトレーニングを行わなくても、ターゲットネットワークとほぼ同じ精度を持つサブネットワークを含むことを示す。
ランダム化されたニューラルネットワークは、接続の大部分が確率的または決定論的に固定されたニューラルシステムの動作を探求します。このようなシステムの典型的な例は，隠れた層への接続が初期化後に学習されないままの多層ニューラルネットワークアーキテクチャである．学習アルゴリズムを制限して、削減された重みのセットで動作させることは、ランダム化ニューラルネットワークのクラスを本質的に特徴づけるものであり、多くの興味深い特徴があります。その中でも、学習プロセスの効率が非常に高いことは、完全に学習されたアーキテクチャと比較して、間違いなく顕著な利点です。さらに，単純化されているにもかかわらず，ランダム化されたニューラルシステムは，様々な分野で最先端の結果を達成しているという実践的な面と，ニューラルアーキテクチャの本質的な特性（例えば，隠れた層の接続を学習する前の状態）を分析できるという理論的な面の両方で，驚くべき特性を持っています。近年、ランダム化ニューラルネットワークの研究は、深層アーキテクチャに向けて拡張されており、ベクトル領域やより複雑なデータ領域において、効果的かつ非常に効率的な深層学習モデルを設計するための新たな研究の方向性を示しています。本章では、ランダム化ニューラルネットワークの設計と解析に関するすべての主要な側面と、その近似能力に関するいくつかの重要な結果を紹介します。まず、フィードフォワードネットワーク（Random Vector Functional Linkとそれに相当するモデル）と畳み込みフィルタの文脈でランダム化ニューラルモデルの基礎を紹介し、次にリカレントシステム（Reservoir Computingネットワーク）のケースを紹介します。いずれの場合も、特に深層ランダム化システムの領域における最近の成果と、（リカレントモデルの場合）構造化された領域への応用に焦点を当てています。
ロボット学習は、ロボットが新しいスキルを自動的に習得することを可能にする有望な結果を示しているが、学習ベースのシステムを展開する上での重要な課題は、ロボットが効果的に広範に一般化するために十分なデータを取得するというスケールである。特に模倣学習は、ロボット学習のための安定した強力なアプローチであり続けていますが、データ収集のために専門家の操作に大きく依存しています。本研究では、この課題を解決するために、自律的にデータを収集して継続的に改善できる模倣学習システムを構築すると同時に、強化学習を明示的に使用しないことで、教師付き模倣の安定性、簡便性、拡張性を維持することを目指しています。これを実現するために、我々は自律的な改善を伴う模倣の問題をマルチタスクの設定に落とし込む。マルチタスク環境では、あるタスクでの失敗が別のタスクでの成功を意味するという洞察を利用しています。これにより、ロボットが実際に挑戦したタスク以外のタスクについて、ロボット自身の試行をデモンストレーションとして活用することができる。マルチタスクのデモンストレーションデータの初期データセットを用いて、ロボットは自律的に試行を収集し、その試行が有用なタスクを達成したかどうかを示す2値のラベルをまばらに付けた。そして、この試行を、初期のデモンストレーションデータセットのみを用いて学習したタスクの潜在空間に埋め込み、様々な試行間の類似性を引き出すことで、ロボットが新しいタスクに一発で汎化できるようにする。また、強化学習アルゴリズムとは対照的に、タスクに依存しない報酬信号を効果的に改善することができます。
報酬の少ない環境での探索は、モデルフリー強化学習の重要な課題の一つである。最新の手法では、環境から得られる外発的な報酬だけに頼るのではなく、内発的な報酬を用いて探索を促すものが多い。しかし、既存の手法は、エージェントが1つの状態を2度以上訪れる可能性が低い手続き的に生成された環境では不十分であることを示す。そこで、学習した状態表現を大きく変化させるような行動をエージェントに促す、新しいタイプの内在的報酬を提案する。本手法を、MiniGrid上で手続き的に生成された複数の困難なタスクや、先行研究で用いられた高次元の観測タスクで評価した。実験の結果、この手法は既存の探索手法よりもサンプル効率が高く、特に手続き的に生成されたMiniGrid環境では効果的であることがわかった。さらに、エージェントが受け取る内発的な報酬だけでなく、学習された行動を分析します。これまでの手法とは異なり、我々の内在的報酬はトレーニング中に減少することはなく、エージェントがコントロールできるオブジェクトとインタラクトすることでより多くの報酬を得ることができます。
最近の研究では、ニューラルネットワークの学習の多くの重要な側面が、学習のごく初期の反復またはエポックで行われることがわかっています。例えば、スパースで学習可能なサブネットワークが出現し（Frankle et al., 2019）、勾配降下が小さな部分空間に移動し（Gur-Ari et al., 2018）、ネットワークが臨界期を迎える（Achille et al., 2019）。ここでは、ディープニューラルネットワークがトレーニングのこの初期段階で受ける変化を調べます。我々は、トレーニングのこれらの初期の反復の間にネットワークの状態の広範な測定を行い、Frankleら（2019）のフレームワークを活用して、重みの分布とデータセットの様々な側面への依存を定量的に調査します。このフレームワークの中で、ディープネットワークは符号を維持したままランダムな重みで再初期化してもロバストではなく、わずか数百回の反復でも重み分布は非常に非依存的であることがわかりました。このような挙動にもかかわらず、ぼかした入力や補助的な教師ありタスクを用いた事前学習により、教師ありネットワークの変化を近似的に表現することができる。このことは、ラベルがこのプロセスを大幅に加速させるにもかかわらず、これらの変化が本質的にラベルに依存しないことを示唆している。これらの結果は、学習の重要な初期段階で起こるネットワークの変化を解明するのに役立ちます。
このモデルは、将来の観測結果の潜在的なコードを予測することで、自然言語メッセージを解釈する言語条件付き生成モデルの一種である。これにより、メッセージの視覚的な根拠が得られます。これは、リスニングエージェントの視野の外にあるオブジェクトを含む世界の観察に似ています。この「観測」を永続的なメモリ状態に組み込み、リスニングエージェントのポリシーがそれを条件とすることを可能にします。これは、ワールドモデルにおけるメモリとコントローラの関係と同様です。これにより、2Dグリッドワールドでの話し手と聞き手のナビゲーションタスクにおいて、効果的なコミュニケーションとタスクの成功が改善されることを示した。さらに、積極的なシグナリングと積極的なリスニングを促進するために、モデルベースの処方に特化した2つの損失を開発しました。最後に、メッセージは生成モデルで解釈されるため、モデルの信念を可視化することで、コミュニケーションチャネルがどのように利用されているかを知ることができます。
強化学習アルゴリズムの多くは、価値関数を用いて、より良いポリシーの探索を導きます。これらの手法は、多くの状態を一般化しつつ、単一の政策の価値を推定する。本論文の中心的なアイデアは、この慣習を覆し、単一の状態セットに対して多くのポリシーの価値を推定することです。このアプローチは、新しいデータを見ることなく、政策空間で直接勾配上昇を行う可能性を開きます。このアプローチの主な課題は、学習と一般化を促進する複雑なポリシーを表現する方法を見つけることです。この問題を解決するために、我々は、簡潔な埋め込みで本質的なポリシー情報を保持する、スケーラブルで微分可能なフィンガープリンティングメカニズムを導入する。この3つの要素（学習済みポリシー評価ネットワーク、ポリシーフィンガープリント、勾配上昇法）を組み合わせることで、学習データを生成したものよりも優れたポリシーをゼロショットで生成できることを実証した。
バックトランスレーションは、ニューラル機械翻訳(NMT)においてモノリンガルコーパスを利用するためのシンプルかつ効果的なアプローチです。逆翻訳は、2つの異なるNMTモデルを、逆モデルによって生成された合成パラレルコーパスを交互に使用して共同で学習するという、反復的なバリエーションであり、教師なし機械翻訳において中心的な役割を果たしています。既存のアプローチでは、健全な翻訳を開始し、お互いに意味のあるトレーニング信号を提供するために、反復手順をウォームアップするための別の機械翻訳システムか、モデルの重みを初期化するための何らかの事前トレーニングに依存しています。本論文では、このような初期化が反復逆翻訳において果たす役割を分析します。最終的なシステムの振る舞いは、それに大きく依存しているのだろうか？また、反復バックトランスレーションは、どんな合理的な初期化を行っても同様の解に収束するのでしょうか？多様なウォームアップシステムを用いた一連の実証実験により、初期システムの品質は最終的な性能に影響を与えるものの、その影響は比較的小さいことが示されました。なぜなら、反復バックトランスレーションは類似の解に収束する傾向が強いからです。このように、初期化手法に残された改善の余地は狭く、今後の研究では、反復メカニズム自体の改善に焦点を当てるべきであることを示唆しています。
トランスフォーマーを用いたモデルは、NLPの多くの分野で最先端を行っていますが、その成功の背景にあるものについての理解はまだ限られています。本論文は、人気の高いBERTモデルに関する150以上の研究を初めて調査したものです。BERTがどのように動作するか、どのような情報を学習するか、どのように表現されるか、学習目的やアーキテクチャの一般的な変更、オーバーパラメータ化の問題、圧縮へのアプローチなどについて、現在の知識状況をレビューします。そして、今後の研究の方向性を示します。
マルチタスク強化学習（RL）は、多くのタスクを解決するための方針を同時に学習することを目的としている。先行研究では、過去の経験を異なる報酬関数で再ラベル化することで、サンプルの効率が向上することがわかっている。再ラベル化の方法は通常、「後から見て、自分の経験があるタスクに最適だったと仮定した場合、どのタスクに最適だったのか？本論文では、hindsight relabelingがinverse RLであることを示す。これは、inverse RLをRLアルゴリズムと併用することで、多くのタスクを効率的に解決できることを示唆している。このアイデアを用いて、先行研究のゴール・リラベリング技術を任意のクラスのタスクに一般化する。我々の実験では、逆RLを用いてデータを再ラベル化することで、ゴール到達、報酬の離散セットを持つドメイン、線形報酬関数を持つドメインなど、一般的なマルチタスクの設定で学習が加速されることを確認した。
ポリゴンメッシュは、3Dジオメトリを効率的に表現するものであり、コンピュータグラフィックス、ロボット工学、ゲーム開発において重要な役割を果たしている。既存の学習ベースのアプローチは、3Dメッシュを扱うという課題を避け、代わりに神経アーキテクチャや学習アプローチとの互換性が高い代替オブジェクト表現を使用しています。私たちは、メッシュを直接モデル化し、トランスフォーマーベースのアーキテクチャを用いて、メッシュの頂点と面を逐次予測するアプローチを提案します。このモデルは、オブジェクトクラス、ボクセル、画像などの様々な入力を条件とすることができ、また、このモデルは確率的であるため、曖昧なシナリオにおける不確実性を捉えるサンプルを生成することができる。このモデルが高品質で使用可能なメッシュを生成できることを示し、メッシュモデリングタスクの対数尤度ベンチマークを確立しました。また、条件付きモデルを用いた表面再構成の評価を、他の手法と比較して行ったところ、このタスクについて直接学習していないにもかかわらず、競争力のある性能を示すことができた。
継続的な生涯学習では、エージェントやモデルが、過去の知識を壊滅的に忘れることなく、多くの連続したタスクを学習する必要があります。機械学習モデルのデフォルトの傾向である致命的な忘却を防ぐために、多くの研究が行われていますが、そのような研究のほとんどは、手動で問題を解決するために設計されています。私たちは代わりに、破局的な忘却に対する解決策として、AIが継続的に学習することを可能にするメタ学習を提唱します。脳の神経調節プロセスにヒントを得て、我々は「神経調節されたメタ学習アルゴリズム（ANML）」を提案します。ANMLは、深層ニューラルネットワーク内で文脈に依存した選択的な活性化を可能にする活性化ゲート機能をメタ学習するために、逐次的な学習プロセスを経て分化します。具体的には、ニューロモジュレーション（NM）ニューラルネットワークが、予測学習ネットワーク（PLN）と呼ばれる別の（そうでなければ正常な）ニューラルネットワークのフォワードパスをゲートする。また、NMネットワークは、PLNの選択的可塑性（すなわち、バックワードパス）を間接的に制御します。ANMLは、破滅的な忘却を伴わない継続的な学習を大規模に行うことができます。600ものクラスを連続的に学習する（9,000回以上のSGD更新）という最先端の継続的な学習性能を実現しています。
マルチタスク条件付き言語生成のための生成モデルを提案します。我々が導き出した仮説は、多くの異なる言語生成タスクの根底には、共有された潜在的なスキルのセットがあり、これらのスキルをタスク埋め込み空間で明示的にモデル化することで、タスク間の積極的な移行と、新しいタスクへの効率的な適応の両方に役立つというものである。我々は、このタスク埋め込み空間を潜在変数 sequence-to-sequence モデルの潜在変数としてインスタンス化する。この仮説を評価するために、幅広いタスクとドメインをカバーする一連のモノリンガルのテキストからテキストへの言語生成データを用意し、マルチタスクと数ショットの両方のモデルの性能を比較した。その結果，マルチタスク環境では，潜在的タスク変数モデルが，他のsequence-to-sequenceベースラインよりも平均的に優れていることがわかった．また，見たことのないテストデータセット（新しいタスク）を用いた少数回の学習では，潜在タスク空間での推論に基づくモデル適応は，標準的な微調整に基づくパラメータ適応よりもロバスト性が高く，全体的な性能も同等であることを示した．最後に、我々のモデルによって学習された潜在的なタスク表現を検証し、それらが自然な方法でタスクをクラスタリングすることを示します。
Transformerベースのモデルは、ニューラル機械翻訳に急激な変化をもたらしました。Transformerアーキテクチャの主な特徴は、モデルが入力の異なる部分に同時に焦点を当てることができる、いわゆるマルチヘッドアテンションメカニズムです。しかし、最近の研究では、ほとんどの注目ヘッドが単純で、しばしば冗長な位置パターンを学習することが明らかになっています。本論文では、各エンコーダ層の1つを除くすべての注意ヘッドを、位置のみに基づいた、外部の知識を必要としない単純な固定の--学習不可能な--注意パターンに置き換えることを提案する。さまざまなデータサイズと複数の言語ペアを用いた実験では、学習時にTransformerのエンコーダ側のアテンションヘッドを固定しても翻訳品質に影響はなく、低リソースのシナリオではBLEUスコアが最大3ポイント上昇することも示された。
私たちは、難しい質問を、既存のQAシステムが回答可能な、より単純なサブ質問に分解することで、質問応答（QA）を改善することを目指しています。質問を分解してラベル付けするのは面倒なので、我々はサブ質問を生成するために教師なしのアプローチを取り、インターネットからの何百万もの質問を活用することも可能にします。具体的には、1つの難しいマルチホップの質問を、多くのより単純なシングルホップのサブ質問にマッピングすることを学習する、One-to-N Unsupervised Sequence transduction (ONUS)のアルゴリズムを提案しています。このアルゴリズムは、1つの難しいマルチホップの質問を、多くのより単純なシングルホップのサブ質問にマッピングすることを学習します。我々は、既製のQAモデルでサブ質問に回答し、その結果得られた回答を最終的な回答に結合する再構成モデルに与えます。HotpotQAでは、オリジナル、アウトオブドメイン、およびマルチホップの質問セットにおいて、強力なベースラインと比較して大幅な品質向上を示しています。ONUSは、さまざまな種類の質問を分解することを自動的に学習する一方で、QAに対する教師付き分解手法とヒューリスティックな分解手法の有用性を一致させ、流暢さではそれらの手法を上回っています。また、品質保証システムが予測を行う理由を明らかにするために、サブクエスチョンを使用することが有望であることがわかっています。
機械学習における多くの問題は、集合からグラフ、より一般的には超グラフへの学習関数、つまりSet2Graph関数として考えることができます。例えば、クラスタリング、グラフ上の頂点および辺の特徴の学習、コレクション内のトリプレットの特徴の学習などがあります。Set2Graphモデルを構築するための自然なアプローチは、すべての線形の等変量set-to-hypergraph層を特徴付け、非線形活性化でそれらをスタックすることである。これには2つの課題があります。すなわち、(i)これらのネットワークの表現力が十分に理解されていないこと、(ii)これらのモデルは、その次元が指数関数的に増加するため、計算やメモリの複雑性が高く、しばしば手に負えなくなることである。本論文では、Set2Graph関数を学習するためのニューラルネットワークモデルのファミリーを提唱する。このモデルは、実用的かつ最大の表現力（ユニバーサル）を備えており、コンパクトな集合上の任意の連続的なSet2Graph関数を近似することができる。これらのモデルを、素粒子物理学への応用を中心としたさまざまな機械学習タスクでテストしたところ、既存のベースラインよりも有利であることがわかりました。
私たちが直接、あるいは間接的に利用しているほぼすべてのコモディティイメージングシステムは、専用のハードウェアブロック、あるいはプログラマブルハードウェア上の独自のソフトウェアモジュールとして動作する、電力効率が高く、アプリケーションの調整が可能なブラックボックスハードウェア画像信号処理（ISP）ユニットを利用しています。このようなブラックボックス型のISPの設定パラメータは、出力画像と複雑な相互作用を持つことが多く、アプリケーション固有の品質や性能の指標に応じて、導入前に調整する必要があります。今日、この検索は、「金の目」の専門家や、ドメインの専門知識を活用したアルゴリズム開発者が手動で行うのが一般的です。我々は、ブラックボックス化されたハードウェアおよびソフトウェアの画像処理パイプラインのパラメータを、任意の（つまりアプリケーション固有の）指標に従って最適化する完全自動システムを提案します。構成空間と評価指標の間の微分可能なマッピングを活用し、画像処理ハードウェアのイン・ザ・ループを用いてエンド・ツー・エンドで学習させた畳み込みニューラルネットワークをパラメータとしています。従来の技術とは異なり、微分可能なプロキシは、低レベルの画像処理変換を明示的にモデル化することなく、確率的一次オプティマイザによる高次元のパラメータ探索を可能にしています。そのため、さまざまな画像処理アプリケーションのブラックボックス画像処理パイプラインを効率的に最適化することができ、アプリケーション固有の設定時間を数ヶ月から数時間に短縮することができます。この最適化手法は、ブラックボックスのハードウェアがあっても完全に自動化されています。本手法は、リアルタイムディスプレイアプリケーション、物体検出、極端な低照度イメージングの実験データで検証しました。提案されたアプローチは、テストされたすべてのドメイン固有のアプリケーションにおいて、質的にも量的にも手動検索よりも優れています。また、従来のノイズ除去装置に適用した場合、ハイパーパラメータを変更するだけで、最近のベンチマークにおいて、従来のアルゴリズムが最近の深層学習法を大幅に上回ることを実証した。
我々は、連続的な制御のための構造化されたポリシーの学習という問題に取り組んでいる。従来の強化学習では、エージェントのポリシーは、環境からのすべての観測値の連結を入力として行動を予測するMLPによって学習されます。本研究では、エージェントの構造を明示的にモデル化するために、NerveNetを提案しています。具体的には、エージェントのポリシーネットワークとして機能するNerveNetは、まずエージェントの構造上の情報を伝播し、次にエージェントの異なる部分の行動を予測します。実験では、まず、標準的なMuJoCo環境において、我々のNerveNetが最先端の手法に匹敵することを示します。さらに、我々のカスタマイズした強化学習環境を、2種類の構造移転学習タスク、すなわち、サイズ移転と障害移転のベンチマークに提案する。その結果、NerveNetが学習したポリシーは、他のモデルが学習したポリシーよりも有意に優れており、ゼロショットの環境でも伝達可能であることを実証しました。
タスク指向の報酬関数がない場合に能力を獲得することは、強化学習研究の最前線にあります。この問題は、オプション発見と情報理論を結びつけるエンパワーメントというレンズを通して研究されています。情報理論に基づくスキル発見法は、コミュニティから多くの関心を集めているが、その限界を理解するための研究はほとんど行われていない。理論的な分析と経験的な証拠により、既存のアルゴリズムには共通の限界があることを示している。そこで我々は、情報理論的なスキル発見の代替アプローチである「Explore, Discover and Learn」（EDL）を提案する。EDLは、エンパワーメントの文献から得られたのと同じ情報理論的な目的を最適化しますが、異なる方法で最適化問題に取り組みます。本研究では、制御された環境におけるスキル発見手法の広範な評価を行い、EDLが、カバレッジ問題の克服、学習されたスキルの初期状態への依存性の低減、どの行動を学習すべきかについてユーザが事前に定義できることなど、大きな利点を提供することを示した。コードはこのhttpsのURLで公開されています。
28の組織へのインタビューをもとに、業界の実務者は、機械学習（ML）システムへの攻撃を保護、検出、対応するための戦術的、戦略的なツールを備えていないことがわかりました。インタビューから得られた洞察を活用し、従来のソフトウェア・セキュリティ開発の文脈で見たときの、機械学習システムのセキュリティ確保に関する視点のギャップを列挙しています。私たちは、開発者/MLエンジニアと、MLシステムを設計・開発・展開する際に、MLシステムのセキュリティ確保を任務とするセキュリティインシデントレスポンダーという2つのペルソナの視点から本稿を執筆しました。本論文の目的は、敵対的なML時代における産業グレードのソフトウェアのためのセキュリティ開発ライフサイクルを改訂し、修正するよう研究者に働きかけることです。
本論文では、対にならない画像間翻訳の新たな領域として、児童書の挿絵を調査しました。現在の最新の画像間翻訳モデルは、スタイルとコンテンツのどちらか一方の翻訳には成功するが、両方を同時に翻訳することはできないことを示す。この問題を解決するために、新しい生成ネットワークを提案し、その結果、スタイルとコンテンツのバランスが良くなることを示します。対にならない画像間の翻訳については、明確に定義され、合意された評価指標はありません。これまでのところ、画像翻訳モデルの成功は、限られた数の画像における主観的で定性的な視覚的比較に基づいています。この問題を解決するために、我々は画像からイラストへの翻訳モデルを定量的に評価するための新しいフレームワークを提案します。この新しい評価フレームワークでは，イラストレーションのデータセットにおいて，我々の提案モデルが現在の最新モデルよりも優れた性能を示した．我々のコードと事前学習済みモデルは、このhttpsのURLで見ることができます。
深層学習の文脈で導入された知識蒸留は、あるアーキテクチャから別のアーキテクチャに知識を移すための手法です。特に、アーキテクチャが同一の場合は、自己蒸留と呼ばれます。訓練されたモデルの予測値を、再訓練のための新たな目標値として投入するというものだ（そして、このループをおそらく数回繰り返す）。自己蒸留されたモデルは、ホールドアウトされたデータに対して、より高い精度を達成することが多いことが経験的に観察されています。しかし、なぜこのようなことが起こるのかは謎でした。自己蒸留型のダイナミクスは、タスクに関する新しい情報を受け取ることなく、学習をループさせることによってのみ進化します。私たちの知る限り、この現象を厳密に理解した例はありません。本研究では、自己蒸留現象を初めて理論的に解析した。本研究では、非線形関数を訓練データに適合させることに着目し、モデル空間をヒルベルト空間とし、適合はこの関数空間においてℓ2正則化を受ける。自己蒸留の反復は、解を表現するために使用できる基底関数の数を徐々に制限することで正則化を修正することを示す。このことは（経験的にも検証しているが）、自己蒸留を数回行うことでオーバーフィッティングを減らすことができる一方で、それ以上行うとアンダーフィッティングになり、結果的に性能が低下することを意味している。
本論文では、SimCLR：視覚的表現の対照的な学習のためのシンプルなフレームワークを紹介する。このフレームワークは、最近提案された対比型の自己教師付き学習アルゴリズムを、専用のアーキテクチャやメモリバンクを必要とせずに単純化したものである。何が対照的な予測タスクが有用な表現を学習することを可能にするのかを理解するために、我々のフレームワークの主要なコンポーネントを体系的に研究する。その結果、(1)効果的な予測タスクを定義するためには、データ補強の構成が重要な役割を果たすこと、(2)表現と対比損失の間に学習可能な非線形変換を導入することで、学習された表現の質が大幅に向上すること、(3)対比学習は、教師付き学習と比較して、より大きなバッチサイズとより多くの学習ステップから利益を得ることができることを示した。これらの知見を組み合わせることで、ImageNetにおける自己教師付き学習および半教師付き学習の従来の手法を大幅に上回ることができました。SimCLRで学習した自己教師付き表現を用いて学習した線形分類器は、76.5%のトップ1精度を達成しました。これは、従来の最先端技術に比べて7%の相対的な改善であり、教師付きのResNet-50の性能に匹敵します。さらに、ラベルの1%のみを微調整した場合、85.8%のトップ5精度を達成し、100倍少ないラベルのAlexNetを上回りました。
言語モデルの事前学習は、質問応答などのNLPタスクに不可欠な世界知識を驚くほど多く取り込むことができることがわかっています。しかし、この知識はニューラルネットワークのパラメータに暗黙的に格納されているため、より多くの事実をカバーするためには、これまで以上に大きなネットワークが必要となります。知識をよりモジュール化された解釈可能な方法で獲得するために、我々は言語モデルの事前学習を潜在的な知識の検索機能で補強する。この機能により、モデルはWikipediaなどの大規模なコーパスから文書を検索し、事前学習、微調整、推論に使用することができる。本論文では、マスクド言語モデリングを学習信号として用い、数百万の文書を対象とした検索ステップでバックプロパゲーションを行うことで、このような知識検索エンジンを教師なしで事前学習する方法を初めて示す。我々は、Open-domain Question Answering (Open-QA)という困難なタスクで微調整を行うことで、Retrieval-Augmented Language Model pre-training (REALM)の有効性を実証した。本研究では、一般的なOpen-QAベンチマーク3種を用いて、明示的および暗黙的な知識蓄積を行う最先端のモデルと比較した結果、解釈可能性やモジュール性などの質的なメリットが得られると同時に、これまでの手法を大幅に上回る結果が得られました。
本研究では，教師なしの読解の領域適応（UDARC）に取り組んでいる．読解力（RC）は、テキストソースを用いた質問応答能力を学習するタスクである。最新の読解モデルは、一般的な言語的知能を持っていない。つまり、学習に使われていないアウトドメインのデータセットでは精度が低下する。我々は、この矛盾がアウトドメインの言語モデリング（LM）能力の欠如に起因すると仮定している。UDARCタスクでは、モデルはソースドメインでは教師付きのRCトレーニングデータを使用し、ターゲットドメインではラベルのないパッセージのみを使用することができる。UDARC問題を解決するために、我々は2つのドメイン適応モデルを提供する。1つ目のモデルは、アウトドメインのLMタスクとインドメインのRCタスクを逐次学習する。2つ目は、LMとRCのマルチタスク学習手法を用いる提案モデルである。このモデルは、ソースドメインの教師付きデータから取得したRC能力と、ターゲットドメインのラベルなしデータから取得したLM能力の両方を保持することができる。UDARCにおいて、異なるドメインの5つのデータセットを用いてモデルを評価した。その結果，提案モデルは，ドメイン適応を行わないモデルよりも優れた結果を得た．特に，提案モデルは，未見の生物医学ドメインにおけるEM/F1において，4.3/4.2ポイントの改善をもたらした．
本論文では，知識グラフ関係を介して，文書中の単語とそこに出現する実体との結合分布をパラメータ化する言語モデルの一種であるLatent Relation Language Models (LRLM)を提案する．このモデルは、言語モデルの性能を向上させるだけでなく、関係を介して与えられたテキストのエンティティスパンの事後確率をアノテーションすることができるなど、多くの魅力的な特性を持っている。実験では、単語ベースのベースライン言語モデルと、知識グラフ情報を組み込んだ従来のアプローチの両方に対して、経験的な改善が見られた。さらに、質的分析により、提案モデルが文脈の中で適切な関係を予測することを学習する能力があることを示した。
強化学習では、将来の観測結果と報酬のモデルを学習し、それを用いてエージェントの次の行動を計画することができる。しかし、将来の観測値を共同でモデル化することは、計算量が多く、観測値が高次元（画像など）である場合には、難航する可能性がある。このため、これまでの研究では、観測データの一部のみをモデル化する部分モデルが検討されてきた。本論文では、部分モデルが因果的に間違っている可能性があることを示す。つまり、部分モデルは、モデル化されていない観測結果と混同してしまい、その結果、誤ったプランニングにつながる可能性がある。この問題を解決するために、因果的に正しいことが証明されていながら、将来の観測を完全にモデル化する必要がないため、高速性を維持できる一般的な部分モデルのファミリーを紹介する。
BERT（Devlin et al., 2019）などの無向性神経シーケンスモデルは、質問応答や自然言語推論などの識別的な自然言語理解タスクで成功したことにより、再び関心を集めている。無向モデルからの生成は、有向シーケンスモデルにおける従来の単調な生成から大きく逸脱することもあり、これらのモデルから直接シーケンスを生成する問題は、比較的注目されていない。本研究では、有向モデルと無向モデルのデコーディングを統一する一般化されたシーケンス生成モデルを提案することで、この問題を検討する。提案されたフレームワークは、結果として得られるシーケンスではなく、生成のプロセスをモデル化するものであり、このフレームワークの下で、自己回帰モデル、半自己回帰モデル、および洗練に基づく非自己回帰モデルなど、様々な神経シーケンスモデルを特別なケースとして導き出すことができる。これにより、有向配列モデルで開発された復号化アルゴリズムを無向配列モデルに適用することができる。我々は、BERTのような機械翻訳モデル（Lample & Conneau, 2019）上で、様々な手作りおよび学習されたデコーディング戦略を評価することでこれを実証する。提案されたアプローチは、同じ無向シーケンスモデルからの線形時間の翻訳結果と同等の一定時間の翻訳結果を達成し、両方ともWMT'14英独翻訳での最先端と競争しています。
本論文では、ProphetNetと呼ばれる新しいシーケンス対シーケンスの事前学習モデルを紹介しています。このモデルでは、未来のn-gram予測と呼ばれる新しい自己教師付きの目的語と、提案されたn-streamの自己注意メカニズムを導入しています。従来のsequence-to-sequenceモデルでは1ステップ先の予測を最適化していましたが、ProphetNetでは、各時間ステップで前のコンテキストトークンに基づいて次のn個のトークンを同時に予測するnステップ先の予測によって最適化しています。将来のn-gram予測は、モデルが将来のトークンを計画することを明示的に促し、強い局所的な相関関係に過剰に適合することを防ぐ。基本規模のデータセット（16GB）と大規模データセット（160GB）をそれぞれ用いて、ProphetNetを事前学習する。そして、CNN/DailyMail、Gigaword、SQuAD 1.1の各ベンチマークを用いて、抽象的な要約と質問生成のタスクについて実験を行う。実験の結果、ProphetNetはこれらすべてのデータセットにおいて、同規模の事前学習コーパスを用いたモデルと比較して、新たに最先端の結果を達成した。
過去5年間、ベイジアン深層学習コミュニティは、深層ニューラルネットワークにおけるベイジアン推論を可能にする、ますます正確で効率的な近似的推論手順を開発してきました。しかし、このようなアルゴリズムの進歩や、不確実性の定量化とサンプル効率の向上が期待されているにもかかわらず、2020年初頭の時点で、ベイジアンニューラルネットワークを産業界で展開している事例は公表されていません。本研究では、一般的なディープニューラルネットワークにおけるベイズ事後予測に関する現在の理解に疑問を投げかけ、ベイズ事後予測によって誘発される事後予測が、SGDから得られる点推定値を含むより単純な方法と比較して、系統的に悪い予測をもたらすことを、慎重なMCMCサンプリングによって実証しました。さらに、証拠をオーバーカウントする「コールドポステリオ」を用いることで、予測性能が大幅に向上することを実証しました。このようなコールドポステリオは、ベイジアンパラダイムから大きく逸脱していますが、ベイジアン深層学習の論文ではヒューリスティックな手法としてよく用いられています。我々は、コールドポステリオルを説明しうるいくつかの仮説を提示し、実験を通して仮説を評価する。我々の研究は、ベイズ深層学習における正確な事後近似の目標に疑問を投げかけるものである。真のベイズ事後が貧弱であるならば、より正確な近似を行うことに何の意味があるのか？その代わりに、コールドポステリオの性能向上の起源を理解することに焦点を当てることがタイムリーであると主張しています。
Winograd Schema Challenge (WSC) (Levesque, Davis, and Morgenstern 2011)は、常識的な推論のベンチマークであり、273の専門家が作成した代名詞解決問題のセットで、元々は選択的選好や単語の関連付けに依存する統計モデルでは解決できないように設計されています。しかし、近年のニューラル言語モデルの進歩により、WSCの変形問題ではすでに90%程度の精度に達している。これは、これらのモデルが本当にロバストなコモンセンス能力を獲得したのか、あるいはデータセットのスプリアスなバイアスに依存して機械コモンセンスの真の能力を過大評価しているのか、という重要な問題を提起している。この問題を調査するために、我々はWSCのオリジナルデザインにヒントを得て、データセットの規模と硬さの両方を改善するために調整された、44k問題の大規模データセットであるWinoGrandeを紹介します。データセット構築の主なステップは、(1)慎重に設計されたクラウドソーシングの手順、(2)人間が検出可能な単語の関連付けを機械が検出可能な埋め込みの関連付けに一般化する新しいAfLiteアルゴリズムを用いた体系的なバイアスの削減、である。その結果、WinoGrandeにおける最先端の手法は59.4-79.1%を達成しましたが、これは許容される学習データの量にもよりますが、人間の性能である94.0%を15-35%下回っています。さらに、WSC (90.1%), DPR (93.1%), COPA (90.6%), KnowRef (85.6%), Winogender (97.1%)の5つの関連ベンチマークにおいても、新たに最先端の結果を得ることができました。これらの結果には2つの意味があります：一方では、WinoGrandeを伝達学習のリソースとして使用した場合の有効性を示しています。一方で、これらのベンチマークのすべてにおいて、機械的常識の真の能力を過大評価している可能性があるという懸念があります。我々は、このような過大評価を軽減するために、既存および将来のベンチマークにおけるアルゴリズムによるバイアス削減の重要性を強調する。
本論文では、ブラックボックス環境において、感情分析やテキスト分類モードに誤った予測をさせるような小さなテキスト摂動を効率的に生成する、新しいアルゴリズムFastWordBugを紹介します。単語の品詞属性を組み合わせることで、テキスト分類に影響を与える重要な単語を迅速に特定することができるスコアリング手法を提案する。FastWordBugを、3つの実世界のテキストデータセットと2つの最先端の機械学習モデルを用いて、ブラックボックス環境下で評価した。その結果、我々の手法は、モデルの精度を大幅に低下させることができ、同時に、モデルを可能な限り呼ばないようにすることができ、最高の攻撃効率が得られることがわかった。また、実世界で人気のある2つのNLPのクラウドサービスを攻撃し、その結果、我々の手法も同様に機能することが分かりました。
長短期記憶ネットワーク（LSTM）などのリカレントニューラルネットワーク（RNN）は、機械翻訳、言語モデリング、質問応答など、多くのシーケンス学習タスクの基本的な構成要素として機能しています。本論文では，単語レベルの言語モデリングという特殊な問題を検討し，LSTMベースのモデルを正則化および最適化するための戦略を検討する．本論文では、リカレント正則化の一形態として、隠れた部分の重みにDropConnectを用いるweight-droped LSTMを提案する。さらに、平均化確率的勾配法の一種であるNT-ASGDを導入し、ユーザーが調整するのではなく、非単調な条件で平均化トリガーを決定する。これらの正則化戦略やその他の正則化戦略を用いて、2つのデータセットで最先端の単語レベルのパープレキシティを達成しました：Penn Treebankでは57.3、WikiText-2では65.8です。また、ニューラルキャッシュと我々の提案するモデルを組み合わせた場合の有効性を検討した結果、Penn Treebankでは52.8、WikiText-2では52.0という、さらに低い最先端のパープレキシティを達成しました。
機械学習モデルのセキュリティは、不当に有利な判断を求める敵対的な攻撃に直面する可能性があるため、懸念されています。このテーマに関する研究は主に画像領域に焦点を当てていますが、多くの産業アプリケーション、特に金融では、標準的な表形式のデータに依存しています。本論文では、表形式の領域における敵対的事例の概念について議論する。本論文では、表形式領域における攻撃の不感帯性に基づいた形式化を提案し、不感帯性のある敵対的事例を生成するアプローチを提案する。実験によると、知覚できない敵対的な例を高い騙し率で生成できることがわかった。
本論文の目的は、希望する属性（テクスチャ、色、背景など）を記述したテキストに合わせて、画像の一部を意味的に編集し、テキストとは無関係な他のコンテンツを保存することである。これを実現するために、我々は、テキストと画像のアフィン結合モジュール（ACM）とディテール補正モジュール（DCM）という2つの重要なコンポーネントを含む、新しい生成的敵対ネットワーク（ManiGAN）を提案する。ACMは、与えられたテキストに関連する画像領域を選択し、その領域を対応する意味的な単語と相関させて、効果的な操作を行う。一方、ACMは、テキストに関連しないコンテンツを再構築するために、オリジナルの画像特徴をエンコードします。DCMは、不一致の属性を修正し、合成画像の欠落したコンテンツを補完する。最後に、新たな属性の生成とテキストに関係のないコンテンツの再構築という観点から、画像操作の結果を評価するための新しい指標を提案する。CUBおよびCOCOデータセットを用いた大規模な実験により，提案手法の優れた性能が実証された．コードはこちらのhttpsのURLから入手できます。
キーワード抽出は、文書コンテキストの分類、テキスト索引、文書分類などの多様なアプリケーションの発展につながる重要な研究テーマとして注目されている。本論文では、TF-IDFをベースにした新しいセマンティック手法であるSTF-IDFを提案し、コーパス内の非公式文書の単語重要度をスコアリングする。ヘルスケア系ソーシャルメディアから約400万件の文書を収集し、意味モデルの描画と単語の埋め込みを見つけるための学習を行った。次に，意味空間の特徴を利用して，反復解法により元のTF-IDFスコアを並べ替え，非公式文書に対する本アルゴリズムの適度な性能を向上させた．提案手法を無作為に選ばれた200の文書でテストした結果、本手法はTF-IDFの平均誤差を50%減少させることができ、元のTF-IDFの27.2%に対して13.7%の平均誤差に到達した。
Meenaは、パブリックドメインのソーシャルメディアでの会話からマイニングおよびフィルタリングされたデータを用いてエンドツーエンドで学習された、マルチターンのオープンドメインチャットボットです。この2.6Bパラメータのニューラルネットワークは、次のトークンのperplexityを最小化するように単純に学習されます。また、人間の評価指標である「Sensibleness and Specificity Average (SSA)」を提案しており、人間らしい複数回の会話の主要な要素を捉えています。実験の結果、パープレキシティとSSAには強い相関関係があることが分かりました。perplexityのエンドツーエンドの訓練を受けたMeenaがSSAで高いスコアを出した（マルチターン評価で72％）という事実は、perplexityをより最適化することができれば、人間レベルのSSAである86％に手が届く可能性があることを示唆している。さらに、Meenaのフルバージョン（フィルタリング機構と調整されたデコーディングを含む）は、79%のSSAスコアを獲得し、評価した既存のチャットボットよりも23%高い絶対的なSSAを実現しています。
本論文では、画像とテキストの共同埋め込みのための新しい視覚言語の事前学習モデル--ImageBERT--を紹介します。我々のモデルはTransformerベースのモデルであり、異なるモダリティを入力として受け取り、それらの間の関係をモデル化する。このモデルは、同時に4つのタスクで事前学習されています。このモデルは、マスクド・ランゲージ・モデリング（MLM）、マスクド・オブジェクト・クラシフィケーション（MOC）、マスクド・リージョン・フィーチャ・リグレッション（MRFR）、イメージ・テキスト・マッチング（ITM）の4つのタスクで同時に事前学習されます。事前学習の質をさらに高めるために、WebからLarge-scale weAk-supervised Image-Text (LAIT)データセットを収集しました。まず、このデータセットでモデルの事前学習を行い、次に概念的キャプションとSBUキャプションで第2段階の事前学習を行います。実験の結果、マルチステージの事前学習戦略は、シングルステージの事前学習よりも優れていることが分かりました。また、事前学習したImageBERTモデルを画像検索およびテキスト検索タスクで微調整および評価し、MSCOCOおよびFlickr30kの両データセットで最先端の結果を達成しました。
この研究は、低精度の重みと活性化を使用するネットワークである量子化ニューラルネットワーク（QNN）の自動化された最小エネルギー最適化を対象としています。これらのネットワークは、任意の固定点精度でゼロから学習されます。等精度の場合，より少ないビット数のQNNは，高精度の演算子を用いたネットワークに比べて，より深く，より広いネットワークアーキテクチャを必要としますが，一方で，複雑な演算や重みあたりのビット数は少なくて済みます．この基本的なトレードオフを分析・定量化することで、あらゆるベンチマークに対して最小エネルギーのQNNを見つけ、エネルギー効率を最適化します。この目的のために、一般的なハードウェアプラットフォームにおける推論のエネルギー消費をモデル化しました。これにより、さまざまなベンチマークについて、いくつかの結論を導き出すことができます。まず，エネルギー消費量は，QNNで使用されるビット数に応じて，等精度で桁違いに変化します．次に，一般的なシステムでは，BinaryNetsまたはint4の実装が，等精度においてint8ネットワークを最大2～10倍上回る，最小のエネルギーソリューションとなる．QNNの学習に使用したすべてのコードは、このhttpsのURLから入手できます。
我々は、物体やシーンの高品質な画像セグメンテーションを効率的に行うための新しい手法を紹介します。ピクセルラベリングタスクで直面するオーバーサンプリングとアンダーサンプリングの問題を、効率的なレンダリングのための古典的なコンピュータグラフィックスの方法になぞらえて、画像セグメンテーションをレンダリング問題として捉える独自の視点を開発しました。この観点から、ニューラルネットワークモジュールPointRend (Point-based Rendering)を発表します。これは、反復細分割アルゴリズムに基づいて、適応的に選択された位置でポイントベースのセグメンテーション予測を行うモジュールです。PointRendは、既存の最先端モデルをベースにすることで、インスタンスセグメンテーションとセマンティックセグメンテーションの両方のタスクに柔軟に適用することができます。一般的なアイデアの具体的な実装は数多く可能ですが、シンプルな設計でもすでに優れた結果が得られることを示しています。定性的には、PointRendは、従来の手法では過剰に平滑化された領域において、鮮明なオブジェクト境界を出力します。定量的には、インスタンスおよびセマンティックセグメンテーションの両方において、PointRendはCOCOおよびCityscapesに対して大きな利益をもたらしています。PointRendの効率性は、既存の手法ではメモリや計算量の点で実用的ではない出力解像度を可能にします。コードはこちらのhttps URLで公開されています。
本論文では、多言語ノイズ除去の事前トレーニングが、様々な機械翻訳（MT）タスクにおいて大幅な性能向上をもたらすことを実証しています。mBARTは、多言語のフルテキストをノイズ除去することで、完全なsequence-to-sequenceモデルを事前学習する最初の方法の1つです。一方、これまでのアプローチは、エンコーダ、デコーダ、またはテキストの一部の再構築にのみ焦点を当てていました。完全なモデルを事前に学習することで、教師あり（文レベルおよび文書レベル）および教師なしの機械翻訳のために、タスク固有の修正をすることなく、直接モデルを微調整することができます。mBARTの初期化を追加することで、低リソースの機械翻訳で最大12BLEUポイント、多くの文書レベルおよび教師なしモデルで5BLEUポイントなど、最高リソースの設定を除くすべての設定でパフォーマンスが向上することを実証しました。また、バイテキストがない言語ペアや事前学習用コーパスに含まれていない言語ペアに対しても、新しいタイプの移植が可能であることを示し、効果的な事前学習にどのような要因が最も貢献しているかについて、広範な分析を行っています。
半教師付き学習（SSL）は，ラベルのないデータを活用してモデルの性能を向上させる効果的な手段である．本論文では，2つの一般的なSSL手法である一貫性正則化と疑似ラベリングを単純に組み合わせることで，その効果を実証しています．我々のアルゴリズムであるFixMatchは，まず，弱くタグ付けされたラベルなしの画像に対するモデルの予測値を用いて擬似ラベルを生成する．ある画像に対して、モデルが高い信頼性の予測を行った場合にのみ、擬似ラベルが保持されます。そして、モデルは、同じ画像の強いタグ付けされたバージョンを与えられたときに、擬似ラベルを予測するように訓練されます。FixMatchは、そのシンプルさにもかかわらず、様々な標準的な半教師付き学習のベンチマークにおいて、最先端の性能を達成していることを示している。FixMatchは、既存のSSL手法と多くの類似点がありますが、性能は劣っているため、FixMatchの成功に最も重要な実験的要因を明らかにするために、大規模なアブレーション研究を行っています。我々のコードはこのhttpsのURLで公開されています。
Q-learningを高次元行動空間や連続行動空間に適用することは、可能な行動のセットに対する最大化が必要なため、困難です。償却型推論の技術に触発され、我々は全ての行動に対する高価な最大化を、学習された提案分布からサンプリングされた可能な行動の小さなサブセットに対する最大化に置き換える。その結果、AQL（Amortized Q-learning）と名付けられたアプローチは、Q-learningの利点を維持しながら、離散的、連続的、またはハイブリッドな行動空間を扱うことができる。最大21次元のアクションを持つ連続的な制御タスクに関する我々の実験は、AQLがD3PG（Barth-Maron et al, 2018）およびQT-Opt（Kalashnikov et al, 2018）を上回ることを示している。また、構造化された離散行動空間での実験では、AQLが数千の離散行動を持つ空間で良い政策を効率的に学習できることを示しています。
この論文では、地理的に多様なデータセットを対象に、一般に入手可能な物体認識システムの精度を分析しています。このデータセットは、家庭用品を含んでおり、物体認識で一般的に使用される画像データセットよりも、より代表的な地理的範囲を持つように設計されている。その結果、世帯収入の低い国でよく見られる家庭用品では、システムの性能が相対的に低下することがわかりました。定性的な分析によると、パフォーマンスの低下は、主にオブジェクトクラス内での外観の違い（例：食器用洗剤）と、異なるコンテキストで現れるアイテム（例：バスルーム以外で現れる歯ブラシ）に起因すると考えられる。今回の研究結果は、国や所得水準の異なる人々が同じように物体認識システムを使えるようにするためには、さらなる研究が必要であることを示唆している。
RGBの入力からシーンの奥行きを予測する学習は、屋内および屋外のロボットナビゲーションにとって困難な課題です。本研究では、シーンの奥行きとロボットの自我運動を教師なしで学習する方法を提案する。これまでに行われた教師なしの画像から奥行きへの学習では、この分野における強力なベースラインが確立されている。本研究では、より高品質な結果を得ることができ、移動する物体をモデル化することができ、また、屋外から屋内のシーンなど、データ領域を超えて移行することができる新しいアプローチを提案する。主なアイデアは、シーンと個々のオブジェクトをモデル化することで、学習プロセスに幾何学的な構造を導入することです。さらに、学習を未知の領域に適応させるために、オンライン改良法を導入しています。提案されたアプローチは、学習されたフローなどで動きを処理するアプローチを含め、すべての最先端のアプローチを凌駕しています。我々の結果は、ステレオをスーパービジョンとして使用したものと同等の品質であり、物体の動きを多く含むシーンやデータセットでの深度予測を大幅に改善した。このアプローチは、都市部でのロボットのナビゲーションのために収集されたデータでトレーニングされたモデルを、屋内のナビゲーションの設定に移すことで、環境間の移行を可能にするため、実用的なものとなっています。本論文に関連するコードは、こちらのhttps URLでご覧いただけます。
点群は、3次元メートル空間で定義された点の集合です。点群は、3D表現のための最も重要なデータフォーマットの1つとなっています。点群は、LiDARなどの取得装置の普及や、ロボット工学、自律走行、拡張現実、仮想現実などの分野での応用の増加により、人気が高まっています。深層学習は、コンピュータビジョンにおけるデータ処理の最も強力なツールであり、分類、セグメンテーション、検出などのタスクで最も好まれる技術となっています。深層学習の技術は主に構造化されたグリッドを持つデータに適用されますが、一方で点群は非構造化されています。点群は構造化されていないため、点群の処理に直接ディープラーニングを使用することは非常に困難です。これまでのアプローチでは、点群を構造化されたグリッド形式に前処理することでこの課題を克服してきたが、計算コストの増加や深さ情報の損失を余儀なくされてきた。しかし最近では、点群を直接処理する最先端の深層学習技術が数多く開発されている。本稿では、主に点群データに焦点を当てた最近の最先端の深層学習技術のサーベイを行う。まず、点群データに直接深層学習を適用する際に直面する主要な課題について簡単に説明し、点群データを構造化されたグリッドに前処理することで課題を克服した以前のアプローチについても簡単に説明した。次に、構造化されていない点群を直接処理する様々な最新の深層学習アプローチのレビューを行います。また、一般的な3D点群ベンチマークデータセットを紹介しました。さらに、分類、セグメンテーション、検出などの一般的な3Dビジョンタスクにおける深層学習の応用についても説明しました。
ビデオモデルを学習するための近似バックプロパゲーション法であるSidewaysを提案します。標準的なバックプロパゲーションでは、モデルの各計算ステップにおける勾配とアクティベーションが時間的に同期しています。しかし、この方法では、後方パスが実行されるまで前方の活性化を保存しておく必要があり、層間（深度）の並列化ができません。しかし、動画のような滑らかで冗長な入力ストリームを活用して、より効率的な学習スキームを開発することはできないだろうか。ここでは、バックプロパゲーションの代わりに、ネットワークの活性化が新しいフレームから得られるたびに上書きする方法を検討します。このように、両方のパスからの情報をより緩やかに蓄積することで、勾配と活性化の間の正確な対応関係が崩れ、理論的にはよりノイズの多い重み更新になります。直感に反して、我々は、深い畳み込みビデオネットワークの横向きトレーニングは、収束するだけでなく、標準的な同期バックプロパゲーションと比較して、より良い一般化を示す可能性があることを示します。
自然言語処理における多くの進歩は、入力とそれが発生する文脈との相互作用をより表現力豊かに表すモデルに基づいています。これまで成功を収めてきたリカレントネットワークは、言語をモデル化するために必要な汎化性と系統性を欠いています。本研究では、現在の入力と以前の出力を相互に調整するという形で、古くからある長短期記憶の拡張を提案する。このメカニズムは、入力とその文脈の間のより豊かな相互作用の空間をモデル化することを可能にする。同様に、我々のモデルは、LSTMによって与えられる遷移関数を文脈依存にしていると見ることができます。実験では、Penn TreebankとWikitext-2では3〜4パープレキシティポイント、4つの文字ベースのデータセットでは0.01〜0.05bpcの範囲で、言語モデリングの一般化が著しく向上したことを実証しました。LSTMモデルとTransformerモデルの間の大きなギャップを解消したEnwik8を除き、すべてのデータセットで新たな技術水準を確立しました。
オーディオのほとんどの生成モデルは、時間または周波数の2つのドメインのいずれかでサンプルを直接生成します。これらの表現は、あらゆる信号を表現するには十分ですが、音がどのように生成され、知覚されるかについての既存の知識を利用していないため、非効率的です。第3のアプローチ（ボコーダ／シンセサイザー）は、信号処理と知覚に関する強力なドメイン知識をうまく取り入れることができるが、表現力が限られており、最新の自動微分法に基づく機械学習手法との統合が難しいため、あまり活発に研究されていない。本論文では、古典的な信号処理要素と深層学習手法との直接的な統合を可能にするDifferentiable Digital Signal Processing (DDSP)ライブラリを紹介します。DDSPは、ニューラルネットワークの表現力を損なうことなく、強い帰納的バイアスを利用できることを示しています。さらに、解釈可能なモジュールを組み合わせることで、個別のモデルコンポーネントを操作することができ、ピッチとラウドネスの独立した制御、トレーニング中に見られなかったピッチへの現実的な外挿、室内音響のブラインド残響除去、抽出された室内音響の新しい環境への転送、異なるソース間の音色の変換などの応用が可能であることを示しています。つまり、DDSPは、深層学習の利点を犠牲にすることなく、解釈可能でモジュール化された生成モデリングのアプローチを可能にします。このライブラリは https://github.com/magenta/ddsp で公開されており、コミュニティや分野の専門家からのさらなる貢献を期待しています。
畳み込みニューラルネットワーク（CNN）は、完全に連結されたネットワークとは対照的に、有限の空間的広がりを持つローカルフィルターに関連した重みを学習することで効率性を実現します。このことは、フィルターが何を見ているかは知っていても、画像のどこに位置しているかは知らないということを意味している。絶対的な位置に関する情報は本質的に有用であり、もしそうする手段があれば、ディープCNNはこの情報を暗黙的にエンコードすることを学ぶと考えるのが妥当である。本論文では、この仮説を検証し、一般的に使用されているニューラルネットワークでは、驚くほど多くの絶対位置情報がエンコードされていることを明らかにした。一連の包括的な実験により、この仮説の妥当性が示され、この情報がどこでどのように表現されているのかに光が当てられ、ディープCNNにおいて位置情報がどこから得られるのかを知る手がかりが得られた。
視覚に注意メカニズムを取り入れるという最近の傾向から、研究者たちは主要な構成要素としての畳み込み層の優位性を再考している。CNNが長距離の依存性を処理するのに役立つだけでなく、Ramachandranら（2019）は、注意が畳み込みを完全に置き換え、視覚タスクで最先端の性能を達成できることを示した。このことから、学習した注目層は、畳み込み層と同様に動作するのかという疑問が生じます。本研究では、注意層が畳み込みを実行することができ、実際に、練習中にしばしばそうすることを学習するという証拠を提供します。具体的には、十分な数のヘッドを持つマルチヘッド自己注意層が、少なくとも畳み込み層と同等の表現力を持つことを証明します。さらに、自己注意層がピクセルグリッドパターンをCNN層と同様に処理することを数値実験で示し、我々の分析結果を裏付けました。このコードは公開されています。
強化学習において、新しい環境に一般化できるポリシーを得ることは困難です。本研究では、読解方針学習器を用いた言語理解が、新しい環境に一般化するための有望な手段であることを示します。この問題では、エージェントは、言語ゴール、文書に記述された関連するダイナミクス、および環境の観測結果を共同で推論しなければならない。エージェントは、特定の情報を記憶するのではなく、新しい環境のダイナミクスを理解するために読まなければならないように、環境のダイナミクスとそのダイナミクスに対応する言語記述を手続き的に生成する。さらに、ゴール、ドキュメント、観測結果の間の3方向のインタラクションを表現するモデル、txt2\piを提案する。RTFMにおいて、txt2\piは、学習時には見られなかったダイナミクスを持つ新しい環境に、読書によって一般化する。さらに、我々のモデルは、FiLMや言語調整されたCNNなどのベースラインをRTFM上で凌駕している。txt2\piは、カリキュラム学習により、複数の推論や共参照のステップを必要とする複雑なRTFMタスクに優れたポリシーを生成する。
異なる画像のスタイルとコンテンツを合成して、視覚的に一貫した画像を形成する能力は、スタイルペイント、デザインプロトタイピング、画像編集、拡張現実などの様々な用途で大きな期待が寄せられています。しかし、画像のスタイルを別の画像の全体に転送することに焦点を当てた研究が大半で、別の画像のインスタンスにスタイルを転送する方法を実験した研究はごく少数しかありません。任意の形状のインスタンスにスタイルを転写することの難しさを回避する方法が研究者によって提案されています。本論文では、この問題に取り組むために、トポロジーにインスパイアされたForward Stretchingと呼ばれるアルゴリズムを提案する。インスタンスをテンソル表現に変換することで、このインスタンス自体に直接スタイルを移すことができるようになる。Forward Stretchingは、ピクセルを特定の位置にマッピングし、ピクセル間の値を補間することで、インスタンスをテンソルに変換する。このアルゴリズムにより、任意の形状のインスタンスに任意のスタイルを転写する手法を導入することができます。本論文では、我々の手法の結果を紹介しています。
本研究では、アーキテクチャやデータセットに関わらず、実画像とCNNで生成された画像を見分けるための「ユニバーサル」な検出器を作ることができるかどうかを問う。これを検証するために、11種類のCNNベースの画像生成モデルによって生成された偽の画像からなるデータセットを収集しました。このモデルは、現在一般的に使用されているアーキテクチャ（ProGAN、StyleGAN、BigGAN、CycleGAN、StarGAN、GauGAN、DeepFakes、カスケード・リファインメント・ネットワーク、暗黙の最尤推定、2次注意の超解像、暗視）の範囲内で選ばれています。我々は、慎重な前後処理とデータ増強により、特定のCNNジェネレータ（ProGAN）のみで訓練された標準的な画像分類器が、（リリースされたばかりのStyleGAN2を含む）見たことのないアーキテクチャ、データセット、および訓練方法に驚くほどよく一般化できることを実証した。今回の発見は、今日のCNN生成画像には共通のシステム的欠陥があり、現実的な画像合成の実現を妨げているという興味深い可能性を示唆している。コードと事前学習済みのネットワークは、このhttpsのURLから入手できます。
本論文では、AIエージェントの迅速な学習を支援するために、学習データ、学習環境、カリキュラムを自動的に生成する学習アルゴリズムを作成できないかという興味深い問題を検討しています。これは、理論的には教師付き学習、教師なし学習、強化学習に適用可能な一般的なアプローチであるが、我々の実験は教師付き学習の場合にのみ焦点を当てている。GTNは、学習者（例えば、初期化されたばかりのニューラルネットワーク）がターゲットタスクでテストされる前に、数回のSGDステップで学習するデータや学習環境を生成するディープニューラルネットワークです。そして、学習プロセス全体をメタグラデーションによって微分し、GTNのパラメータを更新することで、ターゲットタスクのパフォーマンスを向上させます。GTNは、理論的にあらゆる種類のデータや学習環境を生成できるという有益な特性を持っており、その潜在的な影響力は大きい。本論文では、GTNを紹介し、その可能性について議論し、GTNが学習を大幅に高速化できることを紹介する。また、GTNの実用的でエキサイティングな応用例として、ニューラル・アーキテクチャ・サーチ（NAS）の候補アーキテクチャの評価を高速化することで、NASの大幅な高速化を実現します。GTN-NASは、NASの現状を改善し、探索提案メカニズムを制御することで、より高性能なアーキテクチャを見つけることができます。GTN-NASはまた、典型的なNAS手法よりも数桁少ない計算量で最高の性能を達成する、全体的な最新手法に対しても競争力がある。今後、GTNは、自ら学習データを生成するアルゴリズムという野心的な目標に向けた第一歩となる可能性があり、そうすることで、様々な興味深い新しい研究課題や方向性を開くことになるだろう。
これまでの単眼深さ推定法は、単一のビューを取得し、期待される結果を直接回帰していました。最近では、学習時に幾何学的にインスパイアされた損失関数を適用することで進歩していますが、推論手順では幾何学的な制約を明示的に課すことはありません。そのため、これらのモデルは、データの質と学習の有効性に純粋に依存しています。このため、最適な結果が得られないか、妥当な結果を得るためには膨大な量の高価なグランドトゥルース・ラベル付きデータを必要とすることになる。本論文では、単眼深度推定問題が、2つのサブ問題、すなわち、ビュー合成とステレオマッチングの2つのサブ問題として再定式化できることを初めて示した。この2つのサブ問題には、i) 推論時に幾何学的制約を明示的に課すことができる、ii) ラベル付き深度データへの要求を大幅に軽減できる、という興味深い特性がある。我々は、パイプライン全体をエンド・ツー・エンドで学習できることを示し、この新しい定式化が性能向上に重要な役割を果たすことを示した。得られたモデルは、少数の実データを用いただけで、難易度の高いKITTIデータセットにおいて、これまでの単眼深度推定法やステレオブロックマッチング法を上回る性能を示しました。また、このモデルは、他の単眼深度推定ベンチマークにも十分に一般化できる。また，ステレオ法を用いて単眼の奥行き推定を解決することの意味や利点についても議論する。
本研究では、高忠実度でオクルージョンを考慮した顔交換のために、FaceShifterと呼ばれる新しい2段階のフレームワークを提案します。既存の多くの顔交換手法は、交換後の顔を合成する際に対象画像からの限られた情報しか利用しないが、我々のフレームワークでは、その第一段階において、対象画像の属性を徹底的に利用し、適応的に統合することで、高忠実度の交換後の顔を生成する。本フレームワークでは、複数のレベルの顔属性を抽出するための新しい属性エンコーダーと、顔合成のためにアイデンティティと属性を適応的に統合するために注意深く設計されたAdaptive Attentional Denormalization (AAD)レイヤーを持つ新しいジェネレータを提案します。さらに、困難な顔のオクルージョンに対応するために、新しいヒューリスティック・エラー・アクノレッジング・リファインメント・ネットワーク（HEAR-Net）で構成される第2ステージを追加しました。HEAR-Netは、手動でアノテーションを行わなくても、自己教師的に異常領域を回復するように訓練されています。野生の顔を用いた大規模な実験により、我々の顔交換の結果は、他の最先端の手法と比較して、知覚的に魅力的であるだけでなく、同一性の保持にも優れていることが実証されました。
過剰パラメータ化されたニューラルネットワークは、i.i.d.テストセットでは平均的に高精度であるが、データの非典型的なグループでは一貫して失敗することがある（例えば、平均的には成立するが、そのようなグループでは成立しない偽の相関を学習することによって）。分布的ロバスト最適化（DRO）は、あらかじめ定義されたグループのセットにおいて、最悪のトレーニング損失を最小化するモデルを学習することができます。しかし、オーバーパラメータ化されたニューラルネットワークに単純にグループDROを適用しても失敗することがわかりました。これらのモデルは学習データに完全にフィットし、平均学習損失が消滅するモデルは、すでに最悪ケースの学習損失も消滅しています。そうではなく、最悪のケースでのパフォーマンスの低さは、いくつかのグループでの一般化の低さから生じています。グループDROモデルに正則化（通常のL2正則化よりも強い正則化や早期停止）を組み合わせることで、高い平均精度を維持しつつ、自然言語推論タスクと2つの画像タスクで10-40ポイントの改善を行い、大幅に高いワーストグループ精度を達成した。この結果は、平均的な汎化には必要なくても、オーバーパラメター化された領域での最悪グループの汎化には正則化が重要であることを示唆している。最後に、グループDROの設定のための確率的最適化アルゴリズムを紹介し、新しいアルゴリズムの収束保証を提供します。
深層強化学習アプローチは、様々な異なるドメインで印象的な結果を示していますが、世界モデルのようなより複雑な異種アーキテクチャでは、異なる神経コンポーネントをエンドツーエンドではなく個別に学習する必要があります。最近、単純な遺伝的アルゴリズムがエンド・ツー・エンドの学習が可能であることを示しましたが、より複雑な3Dタスクを解決することはできませんでした。本論文では、このような環境のために複雑な異種ニューラルネットワークモデルをエンド・ツー・エンドでトレーニングする際のクレジット割り当て問題に対処するDeep Innovation Protection (DIP)と呼ばれる手法を紹介します。この手法の背後にある主なアイデアは、多目的最適化を採用して、多成分ネットワークの特定のコンポーネントに対する選択圧力を一時的に減らし、他のコンポーネントが適応できるようにすることである。本研究では、これらの進化したネットワークの創発的な表現を調査する。これらのネットワークは、特定の前方予測損失を必要とせずに、エージェントの生存に重要な特性を予測することを学習する。
BERTのようなマスクド・ランゲージ・モデリング（MLM）事前学習法は、いくつかのトークンを[MASK]に置き換えることで入力を破損し、元のトークンを再構築するためにモデルを学習します。これらの手法は、下流のNLPタスクに移行した際には良い結果をもたらしますが、一般的には効果を発揮するために大量の計算を必要とします。これに代わるものとして，我々は，置換されたトークンの検出と呼ばれる，よりサンプル効率の良い事前学習タスクを提案する．このアプローチでは，入力をマスキングする代わりに，いくつかのトークンを小さなジェネレータネットワークからサンプリングしたもっともらしい代替品に置き換えることで，入力を破損します．そして、破壊されたトークンの元のアイデンティティを予測するモデルを学習する代わりに、破壊された入力の各トークンがジェネレータサンプルで置き換えられたかどうかを予測する識別モデルを学習する。この新しい事前学習タスクは、マスクアウトされた小さなサブセットだけではなく、すべての入力トークンに対して定義されているため、MLMよりも効率的であることが、徹底した実験により明らかになりました。その結果、同じモデルサイズ、データ、計算量であれば、我々のアプローチによって学習された文脈表現は、BERTによって学習されたものを大幅に上回りました。例えば、1つのGPUで4日間モデルを学習したところ、GLUE自然言語理解ベンチマークにおいて、30倍の計算量で学習したGPTを上回る結果となりました。また、我々のアプローチは、スケールアップした際にも有効で、RoBERTaやXLNetの1/4以下の計算量で同等の性能を発揮し、同じ計算量であればそれらを上回る性能を発揮します。
NN-LMは、事前に学習されたニューラル言語モデル（LM）を、最近接モデル（NN）で線形補間することで拡張します。直近の隣人は、事前に学習されたLMの埋め込み空間における距離に応じて計算され、元のLMの学習データを含むあらゆるテキストコレクションから抽出することができます。この変換をWikitext-103という強力なLMに適用したところ、NN-LMは15.79という最新のperplexityを達成しました。これは、追加の学習を行うことなく、2.9ポイントの改善となります。また，この手法は，より大きな学習セットへの効率的な拡張を可能にし，最近傍データストアを変更するだけで，効果的なドメイン適応が可能になることも示した．質的には、このモデルは、事実上の知識のようなまれなパターンを予測するのに特に役立つ。これらの結果は、テキストのシーケンス間の類似性を学習することは、次の単語を予測することよりも簡単であること、また、ロングテールにおける言語モデリングには、最近傍探索が効果的であることを強く示唆しています。
大規模な公共データベースへの自由なアクセスと、ディープラーニング技術、特にGenerative Adversarial Networksの急速な進歩により、非常にリアルなフェイクコンテンツが生成されるようになり、フェイクニュースの時代における社会への影響が懸念されています。本調査では、DeepFake法を含む顔画像の操作技術と、その検出方法について徹底的に検証しています。具体的には、i)顔全体の合成、ii)アイデンティティの入れ替え（DeepFakes）、iii)属性の入れ替え、iv)表情の入れ替え、の4種類の顔操作についてレビューします。それぞれの操作グループについて、操作技術の詳細、既存の公開データベース、偽物検出手法の技術評価のための主要なベンチマーク、およびそれらの評価結果の概要を示します。今回の調査では、特に最新世代のDeepFakesに注目し、その改善点と偽物検出の課題を明らかにしました。また、調査内容に加えて、この分野を発展させるために考慮すべき未解決の課題や今後の動向についても言及しています。
グラフニューラルネットワーク（グラフNN）は、グラフ構造を持つデータを分析するための有望な深層学習アプローチです。しかし、多くの層を積み上げ、非線形性を加えても予測性能が向上しない（時には悪化する）ことが知られている。この問題を解決するために、我々は、層のサイズが無限に近づくにつれての漸近挙動を介して、グラフNNの表現力を調査する。我々の戦略は、一般的なグラフNNであるGraph Convolutional Network (GCN)の前進伝搬を、特定の力学系として一般化することである。GCNの場合、その重みが（拡張）正規化ラプラシアンのスペクトルによって決定される条件を満たすとき、その出力は指数関数的に、ノードを区別するためだけに連結成分とノード度の情報を伝える信号のセットに近づくことを示す。我々の理論は、GCNの表現力を、グラフ・スペクトルに内在する基礎的なグラフのトポロジー情報と関連付けることを可能にする。このことを実証するために、Erd\H{o}s -- R\'{e}nyi graph上でのGCNの漸近的な振る舞いを特徴づける。その結果、Erd\H{o}s -- R\'{e}nyi graphが十分に密で大きい場合、このグラフ上の幅広いGCNは、無限層の極限において、高い確率で「情報損失」に陥ることがわかった。本研究では，この理論に基づいて，グラフNNの重み正規化のための原理的な指針を提供する．提案された重みスケーリングにより、実データにおけるGCNの予測性能が向上することを実験的に確認した。コードは、https://github.com/delta2323/gnn-asymptotics。
会話中の感情認識(ERC)は、ヘルスケア、教育、人材などの多様な分野で広く応用される可能性があるため、最近、研究者から注目されている。本論文では、対話グラフ畳み込みネットワーク(Dialogue Graph Convolutional Network, DialogueGCN)を用いたERCのアプローチを紹介します。対話者の自己依存性と話者間依存性を利用して、感情認識のための会話文脈をモデル化します。グラフニューラルネットワークを用いて、ダイアログGCNは現在のRNNベースの手法に見られる文脈伝播の問題を解決します。我々は、この手法がこのような問題を軽減し、多くのベンチマークとなる感情分類データセットにおいて現在の技術を上回ることを実証的に示します。
画像分類用に構築された畳み込みニューラルネットワーク（CNN）アーキテクチャのための、エンドツーエンドで学習可能な注目モジュールを提案する。このモジュールは、CNNパイプラインのさまざまな段階で入力画像の中間表現を形成する2次元特徴ベクトルマップを入力とし、各マップのスコアの2次元行列を出力する。標準的なCNNアーキテクチャは、このモジュールを組み込むことで変更され、スコア行列によってパラメータ化された中間の2D特徴ベクトルの凸型結合が分類に使用されなければならないという制約のもとで訓練される。関連性のあるものを増幅し、無関係なものや誤解を招くようなものを抑制するように動機づけられているため、スコアは注意値の役割を果たしていると言えます。我々の実験結果は、この効果を明確に証明している。学習されたアテンションマップは、背景の乱雑さを抑えながら、関心領域をきれいに強調している。その結果、提案された関数は、画像分類のタスクのために標準的なCNNアーキテクチャをブートストラップすることができ、6つの未見のベンチマークデータセットで優れた一般化を示した。二値化した場合、我々のアテンションマップは、他のCNNベースのアテンションマップ、従来の顕在マップ、およびObject Discoveryデータセットで実証された弱い教師付きセグメンテーションのためのトップオブジェクトプロポーザルを上回る。また、敵対的攻撃である高速勾配標識法に対する堅牢性も向上している。
本論文では、Cauchy/Lorentzian、Geman-McClure、Welsch/Leclerc、generalized Charbonnier、Charbonnier/pseudo-Huber/L1-L2、L2損失関数の一般化を提案している。ロバスト性を連続的なパラメータとして導入することで、我々の損失関数は、ロバストな損失最小化に基づいて構築されたアルゴリズムを一般化することができ、レジストレーションやクラスタリングなどの基本的なビジョンタスクのパフォーマンスを向上させます。損失関数を一変量密度の負対数として解釈すると，正規分布とコーシー分布を特別なケースとして含む一般的な確率分布が得られる．この確率的な解釈により、損失のロバスト性が学習中に自動的に適応するニューラルネットワークの学習が可能になり、生成的画像合成や教師なしの単眼深度推定などの学習ベースのタスクにおいて、手動でのパラメータ調整を必要とせずにパフォーマンスを向上させることができます。
大規模なTransformerモデルは、多くのタスクで最先端の結果を日常的に達成していますが、これらのモデルの学習は、特に長いシーケンスでは、法外なコストがかかります。本研究では、Transformerの効率を向上させるための2つの技術を紹介する。1つは、ドット・プロッド・アテンションをロカリティ・センシティブ・ハッシュを用いたものに置き換えることで、その複雑さをO( L 2 ) からO( L log L ) に変更することである。さらに，標準的な残差の代わりに可逆的な残差層を使用することで，学習プロセスにおいて活性化をN回（Nは層の数）ではなく1回だけ記憶することができる．結果として得られたモデル「Reformer」は、Transformerモデルと同等の性能を発揮する一方で、メモリ効率が格段に向上し、長いシーケンスでも高速に処理できるようになった。
1枚の入力画像から様々な種類の歪みを持つ文書画像を補正する、新しい学習手法を提案する。従来の学習ベースの手法とは異なり、本手法では、まず、画像全体ではなく、入力画像のパッチに対する歪みの流れを学習する。そして、勾配領域で処理することにより、パッチの結果を修正されたドキュメントにスティッチするロバストな手法を提案する。さらに、不均一な照明を補正するための2つ目のネットワークを提案し、読みやすさとOCR精度をさらに向上させます。小さな画像パッチにはそれほど複雑な歪みが存在しないため、パッチベースのアプローチに続いてスティッチングと照明補正を行うことで、合成データセットと実データセットの両方で全体的な精度を大幅に向上させることができる。
自動微分法のフレームワークは、ミニバッチの平均グラデーションを計算するという、まさに1つのことに最適化されています。しかし、ミニバッチグラデーションの分散やヘシアンの多くの近似値などの他の量は、理論的には、グラデーションと同時に効率的に計算することができます。これらの量は研究者や実務者にとって非常に興味深いものですが、現在の深層学習ソフトウェアはそれらの自動計算をサポートしていません。手動で実装するのは負担が大きく、素朴に行うと非効率的であり、結果として得られるコードが共有されることはほとんどありません。このことは、深層学習の進歩を妨げ、不必要に研究を勾配降下法とその変形に焦点を絞ることになります。また、これらの量を必要とする再現研究や新しく開発された手法間の比較を不可能なほど複雑にします。この問題を解決するために、我々はBackPACKを紹介します。これはPyTorchの上に構築された効率的なフレームワークで、バックプロパゲーションアルゴリズムを拡張し、1次および2次の導関数から追加の情報を抽出します。このフレームワークは、バックプロパゲーションアルゴリズムを拡張し、1次、2次の微分から追加情報を抽出するものです。このフレームワークの機能は、ディープニューラルネットワークの追加量を計算するベンチマークレポートと、最適化のための最近の曲率近似をテストするアプリケーション例で説明されます。
新しい超電導体の探索は、いまだに専門家の経験と勘に頼っており、実験的な試行錯誤のプロセスが主となっています。ある研究では、候補となった材料のうち3％しか超伝導を示すことができませんでした。ここでは、新しい超電導体を見つけるための初めての深層学習モデルを報告します。学習データの外にある新規超伝導体を発見する目的で、ディープラーニングに周期表の読み方を学習させ、元素の法則を学習させる「周期表を読む」と名付けた手法を導入しました。ディープラーニングでは、学習データの外にあるものを予測することは難しいと認識しています。我々は材料の化学組成のみを情報としたが、超電導体のデータベースに含まれる材料のTcを予測した結果、R2値は0.92となった。また、存在しない非超電導体の合成データを作成する「ガベージ・イン」という手法を導入しました。非超伝導体は報告されていませんが、ディープラーニングが超伝導体と非超伝導体を区別するために必要なデータであるはずです。私たちは3つの注目すべき結果を得ました。1つは、ある物質の超伝導を62％の精度で予測できたこと、もう1つは、最近発見された超伝導体CaBi2と、超伝導体データベースにはないHf0.5Nb0.2V2Zr0.3を発見したこと、もう1つは、2008年以前の学習データからFe系高温超伝導体（2008年発見）を発見したことです。これらの結果は、新たな高温超伝導体ファミリーの発見への道を開くものです。候補物質のリスト、データ、方法などは、このhttps URLのリンクからオープンになっています。
最新のGANは、超リアルな画像を生成するという素晴らしい性能を持っていますが、GAN識別装置は、生成された個々のサンプルの品質を評価することが困難です。これは、生成された画像の品質を評価するというタスクが、画像が本物か偽物かを判断することとは異なるためです。生成された画像は、1つの領域を除いて完璧であっても、偽物として検出される可能性がある。そこで私たちは、生成された画像のどこにエラーがあるのかを検出する新しいアプローチを提案します。実際の画像と生成された画像をコラージュすることで、各ピクセルが実際の分布と生成された分布のどちらに属しているかを計算します。さらに、注意を利用して長距離依存性をモデル化することで、局所的には妥当だが全体的には妥当でないエラーを検出することができる。評価としては、FIDやISとは異なり、我々のエラー検出が個々の画像の品質指標として機能することを示しています。Improved Wasserstein、BigGAN、StyleGANを活用して、我々の指標に基づくランキングがFIDスコアと見事に相関していることを示す。私たちの研究は、GANのより良い理解と、GANモデルから最良のサンプルを選択する能力への扉を開きます。
最近の研究では、最先端の深層学習モデルが、入力の小さな変化に対して一般化できないことがあるという驚くべき発見がありました。敵対的学習は、この問題を克服するための効果的なアプローチであることが示されています。しかし、その応用は、ℓpノルム有界摂動のような解析的に定義された変換に対する不変性を強制する場合に限られていました。このような摂動は、入力のセマンティクスを保持する現実世界のもっともらしい変動（例えば、照明条件の変化など）を必ずしもカバーしていない。本論文では、このような実世界における入力の変化に対する頑健性を表現し、公式化するための新しいアプローチを提案する。本論文では、(1)入力の分離された表現を利用して、様々な変化の要因を定義する、(2)異なる画像の表現を敵対的に合成して新しい入力画像を生成する、という2つの重要なアイデアを提案している。このフレームワークの有効性を実証するために、StyleGANモデルを使用します。具体的には、StyleGANモデルによって計算された潜在表現の分散を利用して、現実世界の変動に似た画像の摂動（メイクアップの追加や人物の肌色の変更など）を生成し、これらの摂動に対して不変的なモデルを学習します。大規模な実験の結果、本手法は一般化を向上させ、スプリアスな相関の影響を低減させることがわかった（例えば、「笑顔」検出器のエラー率を21％低減させた）。
我々は、p(y|x)の標準的な識別的分類器を、結合分布p(x, y)のエネルギーベースのモデルとして再解釈することを提案する。この設定では、p(x)とp(x|y)の非正規化された値と同様に、標準的なクラス確率を容易に計算することができる。このフレームワークでは、標準的な識別アーキテクチャを使用することができ、ラベルのないデータでモデルを学習することもできます。我々は、結合分布のエネルギーベースの学習により、キャリブレーション、ロバスト性、分布外の検出が改善されることを示し、また、我々のモデルが最近のGANアプローチに匹敵する品質のサンプルを生成できることを示した。最近提案されたエネルギーベースモデルの学習を拡大する技術を改良し、標準的な分類学習に比べてオーバーヘッドがほとんどないアプローチを提示しました。我々のアプローチは、生成学習と識別学習の両方において、1つのハイブリッドモデルで最先端に匹敵する性能を達成した初めてのものです。
人工ニューラルネットワークは、複数のタスクを連続して学習すると、壊滅的な忘却に悩まされます。この問題を解決するために、タスク条件付きハイパーネットワーク（タスクの同一性に基づいてターゲットモデルの重みを生成するネットワーク）に基づいた新しいアプローチを提案します。タスク条件付きハイパーネットワークは、以前に見たすべてのデータの入出力関係を思い出す代わりに、タスク固有の重みの実現をリハーサルするだけでよく、簡単な正則化を用いてメモリに維持することができる。標準的なCLベンチマークで最先端の性能を達成しただけでなく、長時間のタスクシーケンスを用いた追加実験により、タスク条件付きハイパーネットワークスは以前の記憶を保持する能力が非常に高いことが明らかになった。注目すべきは、このような長い記憶寿命は、学習可能なハイパーネットワークの重みの数がターゲットネットワークサイズと同等かそれ以下の圧縮領域で達成されることである。また、低次元のタスク埋め込み空間（ハイパーネットワークの入力空間）の構造を明らかにし、タスク条件付きハイパーネットワークが転移学習を行うことを示した。最後に、CIFAR-10/100画像データセットに基づいた難易度の高いCLベンチマークでの実証結果により、前方への情報伝達がさらに裏付けられた。
シングルセルのトランスクリプトミクスやサイトメトリーにおいて最も一般的な解析ツールの1つに，t-SNE（t-Distributed stochastic neighbor embedding）[1]があります．最近では、uniform manifold approximation and projection (UMAP) [2]と呼ばれる関連アルゴリズムが、シングルセル・コミュニティで大きな注目を集めている。Bechtら[3]はNature Biotechnology誌において、UMAPはt-SNEよりもデータの大域的な構造をよりよく保持し、実行時の一貫性が高いため、好ましいと主張しています。このUMAPの優位性は、Bechtらが使用した実装における初期化の選択の違いに起因することを示しています。t-SNEの実装ではデフォルトでランダムな初期化が使用されているのに対し、UMAPの実装ではLaplacian eigenmaps [4]と呼ばれる技術を使用して埋め込みを初期化していました。我々は、ランダムな初期化を行ったUMAPは、ランダムな初期化を行ったt-SNEと同様に大域的な構造を保持しないことを示しています。一方、情報的な初期化を行ったt-SNEは、情報的な初期化を行ったUMAPと同等の性能を示しています。したがって、Bechtらの主張に反して、彼らの実験はUMAPアルゴリズム自体の優位性を示すものではなく、むしろランダムな初期化の使用に対して警告を発しています。
機械システムにおける原因と結果を理解することは、物理的世界での推論に不可欠な要素です。本研究では、視覚的な入力から物体の力学を反事実的に学習するという新しい問題を提起しています。本研究では、CoPhyベンチマークを開発し、3次元合成環境における因果関係に基づく物理的推論のための最先端モデルの能力を評価するとともに、反事実的な設定で物理的ダイナミクスを学習するモデルを提案する。落下するブロック、跳ねるボール、衝突する物体などを含む機械的な実験を観察した後、シーン内の物体の1つを移動させるなど、初期条件に任意の介入を行った場合に、その結果がどのように影響を受けるかを予測することを学びます。過去の変化と、モデルが学習した交絡因子の潜在的な表現をもとに、代替となる未来を予測します（監督なし）。フィードフォワードビデオ予測のベースラインと比較して、代替的な経験を観察することで、ネットワークが環境の潜在的な物理的特性を捉えることができ、その結果、超人的なパフォーマンスのレベルで著しく正確な予測が可能になることを示しています。
メタ学習は、タスクの分布から集められたデータを用いて、新しいタスク内で効率的に学習するための有望な戦略です。しかし、これまでのメタ学習に関する文献は、タスクを分割した設定に焦点を当てており、トレーニング時にはオフラインデータが基礎となるタスクに応じて分割されていると仮定し、テスト時には単一のタスクで学習するようにアルゴリズムを最適化している。本研究では、時間的に変化するタスクを用いた継続的なオンライン学習のように、タスクの分割ができない環境でも、汎用的なメタ学習アルゴリズムを適用できるようにする。本研究では、微分可能なベイズ型変化点検出法を用いてメタ学習アルゴリズムを拡張するアプローチである、オンライン変化点分析によるメタ学習（MOCA）を提案する。このフレームワークでは、時系列データを個別のタスクに分割することなく、直接トレーニングとテストを行うことができます。このアプローチの有用性を、非線形メタ回帰ベンチマークと2つのメタ画像分類ベンチマークで実証した。
本論文では、多言語言語モデルを大規模に事前学習することで、様々なクロスリンガル・トランスファー・タスクのパフォーマンスが大幅に向上することを示す。2テラバイト以上のフィルタリングされたCommonCrawlデータを用いて、Transformerベースのマスク付き言語モデルを100の言語で学習しました。XLM-Rと名付けられた我々のモデルは、XNLIでの平均精度+14.6%、MLQAでの平均F1スコア+13%、NERでのF1スコア+2.4%など、様々なクロスリンガルベンチマークにおいて、多言語BERT（mBERT）を大幅に上回った。XLM-Rは特に低リソース言語において優れた性能を発揮し、スワヒリ語のXNLIの精度を15.7％、ウルドゥー語の精度を11.4％向上させることに成功した。また、これらの向上を実現するために必要な要素として、(1)積極的な転送と容量の希釈、(2)高リソース言語と低リソース言語の規模に応じた性能のトレードオフなど、詳細な実証分析を行いました。最後に、言語ごとの性能を犠牲にすることなく、多言語モデリングの可能性を初めて示しました。XLM-Rは、GLUEおよびXNLIベンチマークにおいて、強力な単一言語モデルと非常に高い競争力を持っています。XLM-Rは、コード、データ、モデルを公開しています。
係り受け木は、関係性抽出モデルが単語間の長距離関係を捉えるのに役立ちます。しかし、既存の依存関係に基づくモデルでは、依存関係木を積極的に刈り込むことで重要な情報（否定など）を無視してしまったり、異なる木構造に対して並列化することが困難なために計算効率が悪かったりする。本研究では、関係性抽出に適したグラフ畳み込みネットワークの拡張を提案する。これは、任意の依存関係構造上の情報を並列に効率よくプールする。さらに、関連性のある情報を取り込みつつ、無関係なコンテンツを最大限に除去するために、関係が成立する可能性のある2つのエンティティ間の最短パスの周辺にある単語を残すという、新しい刈り込み戦略を入力木に適用する。このモデルは、大規模なTACREDデータセットにおいて、既存のシーケンスモデルや依存関係ベースのニューラルモデルを上回る最先端の性能を達成した。また、詳細な分析により、このモデルがシーケンスモデルと相補的な強みを持っており、これらを組み合わせることで、さらに技術水準が向上することを示している。
テキストに対して複数のステップで推論を行う必要がある構成的な質問に答えることは、特に離散的で記号的な操作を伴う場合には困難です。ニューラルモジュールネットワーク（NMN）は、このような質問を、学習可能なモジュールで構成された実行可能なプログラムとして解析することを学習し、合成された視覚的なQAドメインで優れた性能を発揮します。しかし、モデルが自然言語の多様性に対応し、より広範な推論を行う必要があるオープンドメインのテキスト上の非合成質問に対して、これらのモデルを学習することは困難であることがわかった。我々は以下の方法でNMNを拡張します。(a)テキストの段落を対象とした推論を行うモジュールを導入し、確率的かつ微分可能な方法で数字や日付を対象とした記号的な推論（算術、ソート、カウントなど）を実行する。さらに、ヒューリスティックに得られた限られた量の質問プログラムと中間モジュールの出力監視によって、正確な学習のための十分な帰納的バイアスが得られることを示しています。我々の提案モデルは、我々のモジュールがカバーする様々な推論の課題を提起するDROPデータセットのサブセットにおいて、最先端のモデルを大幅に凌駕する。
ニューラルネットワークの学習は、重みの値を学習することと同義である。一方、ランダムに重み付けされたニューラルネットワークには、重みの値を学習することなく優れた性能を発揮するサブネットワークが存在することを示しています。ランダムに重み付けされたWide ResNet-50の中に、ImageNetで学習したResNet-34よりも小さいが、それに匹敵する性能を持つサブネットワーク（ランダムな重みを持つ）が存在することを示しています。このような「学習されていないサブネットワーク」は存在するだけでなく、それを効果的に見つけるためのアルゴリズムを提供します。経験的に、固定の重みでランダムに重み付けされたニューラルネットワークがより広く、より深くなると、「未学習のサブネットワーク」は学習された重みを持つネットワークに精度が近づくことを示しています。私たちのコードと学習済みモデルは、このhttpsのURLから入手できます。
マルチタスク学習は、コンピュータビジョンの分野では未解決の難問です。深層ニューラルネットワークを用いてマルチタスク学習を行う典型的な方法は、すべての初期層を共有し、アドホックなポイントで分岐する手作りのスキームか、追加の特徴共有/融合メカニズムを備えた個別のタスク固有のネットワークのいずれかである。既存の手法とは異なり、我々はAdaShareと呼ばれる適応的な共有アプローチを提案します。これは、リソース効率を考慮しながら、最高の認識精度を達成するために、どのタスクで何を共有するかを決定するものです。具体的には、マルチタスクネットワーク内の与えられたタスクに対してどのレイヤーを実行するかを選択するタスク固有のポリシーを通じて共有パターンを学習することを主なアイデアとしています。我々は、標準的なバックプロパゲーションを用いて、タスク固有のポリシーをネットワークの重みと合わせて効率的に最適化する。本研究では、タスクの数が変化する挑戦的で多様なベンチマークデータセットを用いた実験により、本研究のアプローチが最先端の手法よりも有効であることを実証した。プロジェクトページ：このhttpsのURL。
マルチクラス・ニューラルネットワークの一般化と学習速度は、ハードターゲットとラベルの一様分布の加重平均であるソフトターゲットを用いることで、大幅に改善することができます。このようにラベルを平滑化することで、ネットワークが過信するのを防ぐことができます。ラベル平滑化は、画像分類、言語翻訳、音声認識など、多くの最新モデルで使用されています。ラベルスムージングは、広く使われているにもかかわらず、まだあまり理解されていない。ここでは、一般化の改善に加えて、ラベルスムージングがモデルのキャリブレーションを改善し、ビームサーチを大幅に改善できることを経験的に示す。しかし、教師ネットワークがラベルスムージングを用いて学習された場合、生徒ネットワークへの知識の蒸留は非常に効果的ではないことも観察された。これらの観察結果を説明するために、ラベルスムージングがネットワークの最下層で学習される表現をどのように変化させるかを視覚化した。ラベルスムージングを行うと、同じクラスの学習例の表現が緊密なクラスターにまとめられることがわかります。この結果、蒸留に必要な異なるクラスのインスタンス間の類似性に関するロジットの情報が失われますが、モデルの予測の一般化やキャリブレーションに支障はありません。
深層ニューラル言語モデルが大幅に進歩したにもかかわらず、これらのモデルをテキスト生成機としてテストした場合、ニューラルテキストの変性という謎が残っています。反直感的な経験的観察によると、学習目的として尤度を使用すると、幅広い言語理解タスクに対して高品質のモデルが得られるにもかかわらず、デコーディング目的として尤度を使用すると、当たり障りのない奇妙な繰り返しのあるテキストが得られる。本論文では、人間のテキストと機械のテキストの間にある驚くべき分布の違いを明らかにした。さらに、全く同じ神経言語モデルから生成されたテキストであっても、デコーディングストラテジーだけでマシンテキストの品質が劇的に変わることを発見しました。これらの発見は、神経言語モデルから最良の結果を引き出すためのシンプルかつ効果的な方法である「核サンプリング」の動機となりました。確率分布のダイナミックな核からテキストをサンプリングすることで、多様性を確保しつつ、信頼性の低い分布の末尾を効果的に切り詰めることができ、結果として、流暢さや一貫性を犠牲にすることなく多様性を高めた人間のテキストの品質をよりよく示すことができます。
本研究では，シンプルな完全畳み込みモデルを用いたリアルタイム（30fps以上）のインスタンス・セグメンテーションを提案し，Titan Xp1台で評価したMS COCOで競争力のある結果を得ることができました．さらに，1台のGPUで学習するだけで，この結果を得ることができました．これを実現するために，インスタンス分割を2つの並列サブタスクに分割しました．(1)プロトタイプマスクの生成と、(2)インスタンスごとのマスク係数の予測です。次に、プロトタイプとマスク係数を線形結合してインスタンスマスクを生成します。このプロセスは再プールに依存しないため、このアプローチは非常に高品質なマスクを生成し、無料で時間的安定性を示すことがわかりました。さらに、我々のプロトタイプの創発的な動作を分析し、完全畳み込み型であるにもかかわらず、翻訳変異型の方法でインスタンスのローカライズを学習することを示した。また、標準的なNMSの代わりに、わずかな性能低下で12msの高速化が可能なFast NMSを提案します。最後に、変形可能な畳み込みをバックボーンネットワークに組み込み、予測ヘッドをより良いアンカースケールとアスペクト比で最適化し、新規の高速マスク再スコアリングブランチを追加することで、我々のYOLACT++モデルは、MS COCO上で34.1mAPを33.5fpsで達成することができ、これはリアルタイムで動作しながらも、最先端のアプローチにかなり近いものです。
2019年4月13日、OpenAI Fiveは、esportsのゲームで世界チャンピオンを破った初のAIシステムとなりました。Dota 2というゲームは、長い時間軸、不完全な情報、複雑で連続的な状態作用空間など、AIシステムに新たな課題を提示しており、これらの課題はすべて、より能力の高いAIシステムにとってますます中心的な課題となるでしょう。OpenAI Fiveは、既存の強化学習技術を活用し、2秒ごとに約200万フレームのバッチから学習するようにスケールアップしました。私たちは、分散型の学習システムと継続的な学習のためのツールを開発し、OpenAI Fiveを10カ月間にわたって学習させました。OpenAI Fiveは、Dota 2の世界チャンピオン（チームOG）を破ることで、自己再生型強化学習が困難な課題に対して超人的なパフォーマンスを達成できることを実証しました。
私たちは、未知のダイナミクス、未知の報酬関数、未知の安全でない状態を持つ強化学習の設定において、エージェントの行動をユーザーの目的に合わせることを目指しています。ユーザは報酬と安全でない状態を知っていますが、ユーザへの問い合わせはコストがかかります。この課題を解決するために、我々はユーザの報酬関数のモデルを安全かつインタラクティブに学習するアルゴリズムを提案する。まず、初期状態の生成モデルと、オフポリシーデータで学習したフォワード・ダイナミクス・モデルを用いる。この手法では，これらのモデルを用いて仮想的な行動を合成し，ユーザにその行動に報酬のラベルを付けてもらい，ニューラルネットワークを学習して報酬を予測する．重要なアイデアは、環境と相互作用することなく、情報の価値のための扱いやすい代数を最大化することによって、仮想的な行動をゼロから能動的に合成することである。この手法を「軌道最適化による報酬クエリ合成（ReQueST）」と呼ぶ。本研究では、状態ベースの2Dナビゲーションタスクおよび画像ベースのCar Racingビデオゲームにおいて、模擬ユーザを用いてReQueSTを評価した。その結果、ReQueSTは、異なる初期状態分布を持つ新しい環境に移行する報酬モデルの学習において、先行する手法を大幅に上回ることがわかった。さらに、ReQueSTは報酬モデルを安全に学習して安全でない状態を検出し、エージェントを展開する前に報酬のハッキングを修正します。
現在、ブラックボックス化した機械学習モデルは、社会全体のハイステークな意思決定に使用されており、医療や刑事司法などの領域で問題を引き起こしています。しかし、ブラックボックスモデルを説明する方法があれば、問題は解決すると期待されています。しかし、ブラックボックスモデルを説明しようとしても、そもそも解釈可能なモデルを作ることができないため、悪しき慣習が蔓延し、社会に壊滅的な損害を与える可能性があります。それは、本質的に解釈可能なモデルを設計することです。本論文では、ブラックボックスの説明と本質的に解釈可能なモデルの使用との間にある溝を明らかにし、重大な意思決定において説明可能なブラックボックスを避けるべき理由をいくつか示し、解釈可能な機械学習の課題を明らかにし、解釈可能なモデルがブラックボックスモデルに取って代わる可能性のある、刑事司法、医療、コンピュータビジョンなどのいくつかのアプリケーション例を示しています。
医療や刑事裁判などの分野で機械学習のブラックボックス化が進む中、これらのブラックボックスを解釈可能な方法で説明するためのツールや技術の構築が重要視されています。このような説明は、ブラックボックスの体系的なエラーや根本的なバイアスを診断するために、ドメインエキスパートによって活用されています。本論文では、LIMEやSHAPのような入力摂動に依存した事後的な説明技術は信頼性が低いことを実証します。具体的には、敵対的なエンティティが任意の望ましい説明を作ることができるようにすることで、任意の分類器のバイアスを効果的に隠すことができる新しいスカフォールド技術を提案します。我々の手法は、入力データの分布に対する予測が偏ったままになるように、偏った分類器を足場にすることができるが、足場にされた分類器の事後説明は無害なものに見える。複数の実世界データセット（COMPASを含む）を用いた大規模な評価により、我々のフレームワークによって作られた極端に偏った（人種差別的な）分類器が、LIMEやSHAPなどの一般的な説明技術を簡単に騙し、根本的な偏りを反映していない無害な説明を生成することを実証している。
画像からの自己教師付き学習の目的は、大規模なトレーニングセットの画像の意味的なアノテーションを必要としない口実タスクを介して、意味的に意味のある画像表現を構築することです。多くのプリテキストタスクは，画像変換に共変する表現を導く．我々は、意味表現はそのような変換の下では不変であるべきだと主張する。具体的には、プレテキストタスクに基づいて不変な表現を学習するプレテキスト不変表現学習（PIRL、発音は「パール」）を開発する。PIRLは、ジグソーパズルを解くという一般的に使われているプレテキストタスクを用いている。その結果、PIRLは、学習した画像表現の意味的品質を大幅に向上させることがわかった。PIRLのアプローチは、画像からの自己教師付き学習において、いくつかの一般的な自己教師付き学習のベンチマークにおいて、新たな最先端を示した。また、PIRLは、教師なしにもかかわらず、物体検出のための画像表現の学習において、教師ありの事前学習よりも優れている。これらの結果は、良好な不変性を持つ画像表現の自己教師付き学習の可能性を示すものである。
近年、様々な言語理解タスクにおいて、事前学習されたモデルが最先端の結果を達成しており、大規模なコーパスを用いた事前学習が自然言語処理において重要な役割を果たしていることが示されている。現在の事前学習では、単語や文章の共起を把握するために、いくつかの簡単なタスクを用いてモデルを学習するのが一般的である。しかし、訓練コーパスには、共起以外にも、名前付き実体、意味的な近さ、談話関係など、価値のある語彙、構文、意味的な情報が存在する。我々は、訓練コーパスから字句、構文、意味情報を最大限に引き出すために、ERNIE 2.0と名付けた継続的な事前学習フレームワークを提案している。ERNIE 2.0は、GLUEベンチマークの英語タスクや中国語の一般的なタスクを含む16のタスクにおいて、BERTやXLNetよりも優れた性能を発揮することが実験的に示されています。ソースコードと学習済みモデルは、このhttpsのURLで公開されています。
少量のデータで新しい概念を学習する能力は、知能の重要な側面ですが、深層学習手法にとっては難しいことが分かっています。メタ学習は、過去のタスクから得たデータを活用して、新しいタスクを効率的に学習するための有望な手法として登場しました。しかし、ほとんどのメタ学習アルゴリズムは、メタ学習のタスクが相互に排他的であることを暗黙のうちに要求しており、単一のモデルではすべてのタスクを一度に解決できないようになっています。例えば、数ショットの画像分類のタスクを作成する場合、先行研究では、画像クラスをNウェイ分類ラベルにタスクごとにランダムに割り当てる方法が用いられています。これを行わないと、メタ学習者はタスクの学習データを無視して、ゼロショットですべてのメタ学習タスクを実行する単一のモデルを学習することができますが、新しい画像クラスには効果的に適応できません。このような場合、ユーザはタスクの設計に細心の注意を払う必要があります。例えば、ラベルをシャッフルしたり、タスクを識別する情報を入力から削除したりします。ドメインによっては、メタ学習が全く適用できない場合もあります。本論文では、この課題を解決するために、情報理論を用いて、データ駆動型の適応を優先するメタ規則化目的を設計する。これにより、メタ学習者は、タスクトレーニングデータから何を学習すべきか、タスクテスト入力から何を推論すべきかを決定する。このようにして、我々のアルゴリズムは、相互に排他的ではないタスクのデータをうまく利用して、新しいタスクに効率的に適応することができる。我々は、コンテクストベースと勾配ベースの両方のメタ学習アルゴリズムへの適用性を実証し、標準的なメタ学習の適用が困難であった実用的な設定に適用している。その結果、標準的なメタ学習アルゴリズムを大幅に上回る結果が得られました。
軽量の畳み込みニューラルネットワーク（CNN）では、計算量が少ないためにCNNの深さ（畳み込み層の数）と幅（チャンネル数）が制限され、表現能力が限られてしまうため、性能が低下してしまいます。この問題を解決するために、我々は、ネットワークの深さや幅を増やすことなくモデルの複雑さを向上させる新しいデザインであるDynamic Convolutionを提案します。ダイナミックコンボリューションは、レイヤーごとに単一のコンボリューションカーネルを使用するのではなく、複数の並列コンボリューションカーネルを、入力に依存する注目度に基づいて動的に集約する。複数のカーネルを集合させることは、カーネルサイズが小さいために計算効率が良いだけでなく、これらのカーネルがアテンションによって非線形に集合されるため、より大きな表現力を持つことになります。最先端のアーキテクチャであるMobileNetV3-Smallにダイナミックコンボリューションを使用するだけで、わずか4%の追加FLOPsでImageNet分類のトップ1精度が2.9%向上し、COCOキーポイント検出では2.9APの向上が達成されました。
教師付き学習技術だけで行動を学習する手法であるUpside-Down Reinforcement Learning（UDRL）を開発しました。UDRLは従来のアルゴリズムと異なり、報酬予測や最適なポリシーの探索を行いません。UDRLは、従来のアルゴリズムとは異なり、報酬の予測や最適な政策の探索を行わず、"これだけの時間でこれだけの総報酬を得る "といった命令に従うようにエージェントを学習させる。本論文の目的は、実用的な学習アルゴリズムを開発し、この概念的に単純なエージェント訓練の観点が、複数のエピソード環境において様々な報酬を得る行動を生み出すことができることを示すことである。実験によると、いくつかのタスクにおいて、UDRLのパフォーマンスは、数十年の研究を経て開発された伝統的なベースライン・アルゴリズムと驚くほど競合し、さらにはそれを上回ることがわかった。これらの結果から、期待報酬の最大化に代わるアプローチは、有用な自律的エージェントを訓練する上で重要な役割を果たすことが示唆される。
マーケットメイカーは、自分が売買したい価格を継続的に提示し、在庫リスクを管理することで、市場に流動性を提供する重要な役割を担っている。本論文では、ディーラー市場のマルチエージェント・シミュレーションを構築し、強化学習（RL）ベースのマーケット・メーカー・エージェントの行動を理解するために使用できることを示す。我々はこのシミュレータを用いて、異なる競争シナリオ、報酬体系、市場価格の傾向（ドリフト）を持つRLベースのマーケットメーカーエージェントを訓練する。また、強化学習エージェントは、買い側と売り側で非対称な価格を賢く選択し（スキューイング）、市場価格のドリフトが正（または負）であるかどうかに応じて正（または負）の在庫を維持することで、在庫管理を学習することができることを示します。最後に、リスクを回避するRLベースのマーケットメーカー・エージェントを作るための報酬定式化を提案し、検証する。
意味領域適応型正規化(SEAN)を提案する。これは、望ましい出力画像の意味領域を記述するセグメンテーションマスクを条件とした、生成アドバーサリアルネットワークのためのシンプルかつ効果的な構成要素である。SEAN正規化を用いることで、各意味領域のスタイルを個別に制御できるネットワーク・アーキテクチャを構築することができます。SEANは、再構成品質、変動性、視覚的品質の点で、以前の最良の手法よりも、スタイルの符号化、転送、合成に適している。複数のデータセットでSEANを評価し、現在の技術水準よりも優れた定量的指標（FID、PSNRなど）を報告しています。また、SEANは、インタラクティブな画像編集のフロンティアを開拓しています。セグメンテーションマスクや任意の領域のスタイルを変更することで、画像をインタラクティブに編集することができます。また、領域ごとに2つの参照画像からスタイルを補うこともできます。
多くの深層学習モデルは敵対的攻撃に対して脆弱である。すなわち、入力に対して知覚できないが意図的に設計された摂動が、ネットワークの誤った出力を引き起こす可能性がある。本論文では、情報幾何学を用いて、深層学習モデルの脆弱性を合理的に説明している。データ空間を、ニューラルネットワークから誘導されたフィッシャー情報メトリックを持つ非線形空間と考えることで、まず、ワンステップ・スペクトル・アタック（OSSA）と呼ばれる敵対的攻撃アルゴリズムを提案する。この手法は、フィッシャー情報行列の制約された二次形式で記述され、最適な敵対的摂動は第一固有ベクトルで与えられ、モデルの脆弱性は固有値で反映される。固有値が大きいほど、対応する固有ベクトルによる攻撃に対してモデルの脆弱性が高くなります。この性質を利用して、固有値を特徴とした敵対的な検出方法も提案しています。攻撃アルゴリズムと検出アルゴリズムは，いずれも大規模なデータセットで効率的に動作するように数値的に最適化されている．評価の結果、他の手法と比較して優れた性能を示し、フィッシャー情報が敵対的な攻撃や防御を調査するための有望なアプローチであることを示唆している。
多くのアプリケーションでは、スペースや推論時間の制限から、スパースなニューラルネットワークが必要とされます。密なネットワークを学習して、推論用の疎なネットワークを得る方法は数多くありますが、これでは学習可能な最大の疎なモデルのサイズが、学習可能な最大の密なモデルのサイズに制限されてしまいます。本論文では、既存の密から疎への学習方法に比べて精度を犠牲にすることなく、固定のパラメータ数と学習中の固定の計算コストで疎なニューラルネットワークを学習する方法を紹介する。本手法は、パラメータの大きさと頻度の低い勾配計算を用いて、学習中に疎なネットワークのトポロジーを更新する。この手法では，従来の手法と比較して，所定の精度を達成するために必要な浮動小数点演算（FLOPs）が少なくて済むことを示している．また，ResNet-50，Imagenet-2012のMobileNets，WikiText-103のRNNなど，さまざまなネットワークやデータセットを用いて，最先端のスパーストレーニングの結果を示した．最後に，最適化の際にトポロジーを変化させることで，トポロジーが固定されている場合に発生する局所的な最小値を克服できる理由について考察します．本研究で使用されたコードは、このhttpのURLにあります。
学習はデータの文脈の中で行われますが、信頼性の概念は通常、ラベルの品質ではなく、モデルの予測に焦点を当てています。信頼性の高い学習（Confident Learning: CL）は、ノイズの多いデータの刈り込み、ノイズを推定するための確率的しきい値によるカウント、信頼性の高い学習を行うための例のランク付けといった原則に基づいて、データセットのラベルエラーを特徴づけ、識別することで、ラベルの品質に焦点を当てる代替アプローチである。これまで多くの研究がこれらの原理を独自に発展させてきましたが、ここでは、ノイズの多い（与えられた）ラベルと破壊されていない（未知の）ラベルの間の共同分布を直接推定するクラス条件付きノイズプロセスの仮定に基づいて、これらを組み合わせます。これにより、証明可能な一貫性と実験的な性能を持つ一般化されたCLが得られる。本論文では、CLがラベルの誤りを正確に発見するための十分条件を提示し、CIFARデータセットにおいて、ノイズの多いラベルを用いた学習において、CLの性能が最近の7つの競合手法を上回ることを示す。ユニークなのは、CLフレームワークが特定のデータモダリティやモデルに結合されていないことである（例えば、我々はCLを使って、エラーがないと思われるMNISTデータセットからいくつかのラベルエラーを見つけ、Amazonレビューのテキストデータのセンチメント分類を改善する）。また、ImageNetにおいては、CLを用いてオントロジー的なクラスの重複を定量化し（例：645枚の "missile "画像が親クラスである "projectile "に誤ってラベル付けされていると推定）、学習前にデータをクリーニングすることでモデルの精度を適度に向上させました（例：ResNet）。これらの結果は，オープンソースの cleanlab を用いて再現することができます．
近年のゲームにおける超人的な結果は、囲碁やポーカーなど、エージェントが他者と競争しなければならないゼロサムの環境で達成されたものがほとんどです。しかし、人間と同じように、現実のAIシステムも、部分的に観測可能な協力的な環境において、他のエージェントと協調し、コミュニケーションを取らなければなりません。このような環境では、参加者は他者の行動を解釈することと、解釈されたときに有益な行動をとることの両方を要求されます。このような能力は、一般的に心の理論としてまとめられ、社会的相互作用に不可欠であると考えられる。本論文では、部分的に観測可能な協力ゲームにおいて、任意の合意された方針を改善するために適用可能な2つの異なる探索技術を提案する。1つ目の手法であるシングルエージェント探索では、1つのエージェントを除いたすべてのエージェントが合意された方針に基づいてプレイすることで、問題をシングルエージェントの設定に効果的に変換する。一方、マルチエージェント探索では、すべてのエージェントが同じ共通認識を持つ探索手順を実行し、それが計算上可能な場合には、合意された方針に従ってプレイすることに戻る。これらの探索手順は、少なくとも合意された方針の元の性能を維持することが理論的に保証されていることを証明した（制限付きの近似誤差まで）。Hanabiのベンチマークチャレンジ問題において、我々の探索手法は、我々がテストした全てのエージェントの性能を大幅に向上させ、RLを用いて学習したポリシーに適用した場合には、ゲームにおいて24.61 / 25という新しい最先端のスコアを達成した。
正規化フローは、表現力豊かな確率分布を定義するための一般的なメカニズムを提供します。必要なのは、（通常は単純な）基本分布と一連の双方向変換の指定だけです。正規化フローについては、表現力の向上や応用範囲の拡大など、最近多くの研究が行われています。我々は、この分野が成熟し、統一された視点を必要としていると考えている。このレビューでは、確率的モデリングと推論のレンズを通してフローを記述することで、そのような視点を提供することを試みます。特に、フローデザインの基本原理に重点を置き、表現力や計算のトレードオフといった基礎的なトピックについて議論します。また、フローをより一般的な確率変換と関連付けることで、フローの概念的な枠組みを広げます。最後に、生成モデリング、近似推論、教師付き学習などのタスクにおけるフローの利用についてまとめています。
転移学習は、自然言語処理(NLP)研究の状況を根本的に変えました。既存の最先端モデルの多くは、まず大規模なテキストコーパスで事前学習され、その後、下流のタスクで微調整されます。しかし、下流のタスクのデータリソースが限られていることや、事前に学習したモデルの容量が非常に大きいことから、積極的な微調整を行うと、適応したモデルが下流のタスクのデータに過剰に適合し、事前に学習したモデルの知識を忘れてしまうことがよくあります。本研究では、上記の問題を解決するために、学習済みの言語モデルをロバストかつ効率的に微調整するための新しい計算フレームワークを提案する。具体的には、我々の提案するフレームワークには2つの重要な要素が含まれる。1. 1.モデルの容量を効果的に管理する平滑性誘導正則化、2.知識の忘却を防止する信頼領域法の一種であるブレグマン近位点最適化である。実験の結果、提案した手法は複数のNLPベンチマークにおいて最先端の性能を達成した。
最新のディープニューラルネットワークは、訓練分布とテスト分布が同一分布である場合に高い精度を達成することができますが、実際にはこの仮定は頻繁に破られます。訓練分布とテスト分布が不一致になると、精度が急激に低下することがあります。現在のところ，展開時に発生する予期せぬデータシフトに対するロバスト性を向上させる技術はほとんどない．本研究では，画像分類器の頑健性と不確実性の推定を改善する技術を提案する．本研究では，実装が簡単で計算オーバーヘッドが少なく，不測の破損にもモデルが耐えられるようにするデータ処理技術「AugMix」を提案する．AugMixは、難易度の高い画像分類ベンチマークにおいて、頑健性と不確実性の評価を大幅に改善し、従来の手法と最良の性能との差を半分以上に縮めたケースもあります。
我々は、現代の様々な深層学習タスクが、モデルサイズを大きくすると、性能が最初に悪くなり、次に良くなるという「二重降下」現象を示すことを示します。さらに、二重降下は、モデルサイズの関数としてだけでなく、学習エポック数の関数としても発生することを示します。これらの現象を統一するために、有効なモデルの複雑さと呼ぶ新しい複雑さの尺度を定義し、この尺度に関して一般化された二重降下を推測した。さらに、我々のモデル複雑度の概念により、訓練サンプルの数を増やす（4倍にする）ことでテストの性能が低下する特定の領域を特定することができる。
生成的敵対ネットワークの学習には、デリケートな敵対ダイナミクスのバランスをとることが必要です。慎重にチューニングを行っても、トレーニングが発散したり、モードを落として悪い平衡状態になってしまうことがあります。本研究では、CS-GANを自然な勾配ベースの潜在的最適化で改良し、識別器と生成器の間の相互作用を強化することで、敵対的なダイナミクスを改善することを示します。我々の実験では、潜在的な最適化がGANの学習を大幅に改善し、ImageNet (128×128)データセットで最先端の性能を得ることができた。我々のモデルは、同じアーキテクチャとパラメータ数を持つベースラインのBigGAN-deepモデルと比較して、Inception Score (IS) 148、Fréchet Inception Distance (FID) 3.4を達成し、ISとFIDでそれぞれ17%と32%の改善を実現した。
我々は、点のバッチとモデルパラメータの間の相互情報に対する扱いやすい近似であるBatchBALDを開発し、ディープベイズ能動学習のタスクのために、複数の情報量の多い点を共同で選択するための獲得関数として使用する。BatchBALDは、動的計画法と効率的なキャッシングが可能な、貪欲な線形時間1-1e近似アルゴリズムである。BatchBALDと一般的に使われているバッチデータ取得方法を比較したところ、現在の方法では類似した冗長な点を取得し、時にはランダムにデータを取得するよりも性能が悪いことがわかった。最後に、BatchBALDを使用して取得バッチ内の依存関係を考慮することで、標準的なベンチマークにおいて最先端の性能を達成し、バッチ取得におけるデータ効率の大幅な向上を実現したことを示します。
与えられた証拠に基づいてテキストの仮説が成り立つかどうかを検証する問題は、事実検証としても知られており、自然言語理解や意味表現の研究において重要な役割を果たしています。しかし，既存の研究は，主に非構造化証拠（自然言語文や文書，ニュースなど）を扱うものに限られており，表やグラフ，データベースなどの構造化証拠の下での検証は，まだ十分に検討されていないのが現状である。本論文では，半構造化データを証拠とした事実検証の研究を目的とする．この目的のために、我々はTabFactと呼ばれる大規模なデータセットを構築し、16kのWikipediaテーブルを118kの人間が注釈をつけた自然言語文の証拠として使用し、それらの文にはENTAILEDまたはREFUTEDのラベルが付けられている。TabFactは、ソフトな言語的推論とハードな記号的推論の両方を必要とするため、チャレンジングです。これらの推論の課題に対処するために、2つの異なるモデルを設計しました。Table-BERTとLatent Program Algorithm (LPA)です。Table-BERTは、最先端の事前学習済み言語モデルを活用して、線形化された表と文を検証用の連続ベクターにエンコードします。LPAは、ステートメントをプログラムに解析し、それをテーブルに対して実行して、検証用のバイナリ値を返します。どちらの手法も同程度の精度を達成していますが，人間のパフォーマンスには遠く及ばないことがわかります．また、将来の大きな可能性を示すために、包括的な分析を行っています。データセットのデータとコードは、 ˶ˆ꒳ˆ˵ ) にあります。
宝くじの初期化の成功（Frankle and Carbin, 2019）は、ネットワークが適切に初期化されている限り、小さくてスパース化されたネットワークを訓練できることを示唆しています。残念ながら、これらの「当たりくじ」の初期化を見つけることは、計算量が多い。1つの潜在的な解決策は、様々なデータセットやオプティマイザーで同じウィニングチケットを再利用することです。しかし、ウィニングチケットの初期化の一般性はまだ不明である。ここでは、あるトレーニング構成（オプティマイザとデータセット）のウィニングチケットを生成し、別の構成でその性能を評価することで、この疑問に答えようとしています。驚くべきことに、自然画像領域において、ウィニングチケットの初期化は、Fashion MNIST、SVHN、CIFAR-10/100、ImageNet、Places365などの様々なデータセットで一般化し、しばしば同じデータセットで生成されたウィニングチケットに近い性能を達成することがわかりました。さらに，大規模なデータセットを用いて生成されたウィニング・チケットは，小規模なデータセットを用いて生成されたウィニング・チケットよりも一貫して転送性能が高かった．また，ウィニングチケットの初期化は，高い性能を持つオプティマイザに共通していることがわかりました．これらの結果は、十分に大きなデータセットを用いて生成されたウィニングチケットの初期化には、ニューラルネットワーク全般に共通する帰納的バイアスが含まれていることを示唆しており、これにより多くの設定で学習が改善され、より優れた初期化手法の開発に期待が持てる。
UDifyは、75の言語にわたる124のUniversal Dependenciesツリーバンクすべてについて、普遍的な品詞、形態素、語幹、および依存関係ツリーを同時に正確に予測することができる多言語マルチタスクモデルです。104言語で事前学習された多言語BERT自己注意モデルを活用し、すべてのデータセットで微調整を行い、各UDタスクのシンプルなソフトマックス分類器と組み合わせることで、リカレントコンポーネントや言語固有のコンポーネントを必要とせずに、最先端のUPOS、UFeats、Lemmas、（特に）UAS、LASのスコアを満たす、または上回ることができることを発見しました。UDifyを多言語学習用に評価した結果、リソースの少ない言語は言語間アノテーションから最も恩恵を受けることがわかった。また、ゼロショット学習についても評価し、UDifyもBERTも学習したことのない言語であっても、多言語学習によって強力なUD予測が得られることを示唆する結果を得た。
オブジェクト、関係、および階層の観点から世界を構造的に理解することは、人間の認知の重要な要素です。しかし、このような構造化された世界モデルを生の感覚データから学習することは、依然として課題となっています。私たちは、その一歩として、対照的に学習された構造化世界モデル（C-SWM）を紹介します。C-SWMは、構成的な構造を持つ環境での表現学習に対照的なアプローチを利用しています。C-SWMでは、各状態の埋め込みを、グラフニューラルネットワークでモデル化されたオブジェクト表現とその関係のセットとして構成します。これにより、学習プロセスの一部として直接監督することなく、生のピクセル観測からオブジェクトを発見することができます。C-SWMは、エージェントが独立して操作できる複数の相互作用するオブジェクトを含む合成環境、シンプルなアタリゲーム、およびマルチオブジェクト物理シミュレーションで評価しました。実験の結果、C-SWMは、ピクセル再構成に基づくモデルの限界を克服し、高度に構造化された環境において、解釈可能なオブジェクトベースの表現を学習しながら、このモデルクラスの典型的な代表的なモデルよりも優れた性能を発揮することが実証されました。
ウェブスケールでマルチホップ推論を必要とする質問に答えるためには、複数の証拠文書を検索する必要があるが、そのうちの1つは質問との語彙的または意味的な関係がほとんどないことが多い。本論文では、マルチホップのオープンドメインの質問に答えるために、Wikipediaグラフ上の推論パスを検索することを学習する、新しいグラフベースのリカレント検索アプローチを紹介する。我々の検索モデルはリカレントニューラルネットワークを学習し、以前に検索された文書を条件として、推論パス内の証拠段落を順次検索するように学習する。リーダーモデルは、推論パスをランク付けし、最適な推論パスに含まれる回答スパンを抽出する。実験結果は、3つのオープンドメインQAデータセットにおいて最先端の結果を示し、本手法の有効性と頑健性を示した。特に，HotpotQAにおいて，我々の手法は，以前のベストモデルを14ポイント以上上回る大幅な改善を達成した．
敵対的な例は、一般的にConvNetsの脅威とみなされている。ここでは逆の視点を提示する。つまり、適切な方法で利用すれば、敵対的な例は画像認識モデルの改善に利用できる。我々はAdvPropという強化された敵対的学習スキームを提案する。これは敵対的な例を追加の例として扱い、オーバーフィッティングを防ぐ。我々の手法の鍵となるのは、通常の例とは異なる基本的な分布を持っているため、敵対的な例に対して別の補助バッチノルムを使用することです。我々は AdvProp が様々な画像認識タスクにおいて幅広いモデルを改善し，モデルが大きい時にはより良い性能を発揮することを示します．例えば、ImageNet 上の最新の EfficientNet-B7 [28] に AdvProp を適用することで、ImageNet (+0.7%), ImageNet-C (+6.5%), ImageNet-A (+7.0%), Stylized-ImageNet (+4.8%) で大幅な改善が得られました。強化されたEfficientNet-B8を用いた本手法は、追加データなしで最先端の85.5%のImageNet top-1精度を達成しました。この結果は、3.5BのInstagram画像（ImageNetの約3000倍）と約9.4倍のパラメータを用いて学習された[20]のベストモデルをも上回っています。モデルはこのhttpsのURLから入手可能です。
BERTやRoBERTaなど、事前に学習された変換言語モデルにおける個々の注目点が、どの程度まで暗黙的に統語的な依存関係を捉えているかを調査します。本研究では、最大アテンション・ウェイトを取る方法と、最大スパニング・ツリーを計算する方法の2つを用いて、各層・各ヘッドのアテンション・ウェイトから暗黙的な依存関係を抽出し、それらをグランドトゥルースのUniversal Dependency (UD)ツリーと比較した。我々は、いくつかのUD関係タイプについて、構文解析された英語テキスト上でベースラインよりも有意に優れた依存関係タイプを回復できるヘッドが存在することを示し、いくつかの自己注目ヘッドが構文構造のプロキシとして機能することを示唆している。また，構文指向のCoLAと意味指向のMNLIという2つのデータセットで微調整したBERTを解析し，微調整が自己注釈のパターンに影響を与えるかどうかを調べたが，我々の手法を用いて抽出された依存関係全体に大きな違いは見られなかったという。この結果は、これらのモデルは、個々の依存関係のタイプを追跡するいくつかの専門的な注意ヘッドを持っているが、些細なベースラインよりも有意に全体的な解析を行うジェネラリストヘッドは持っていないこと、また、注意の重みを直接分析しても、BERTスタイルのモデルが学習することが知られている統語的知識の多くを明らかにしない可能性があることを示唆している。
シーケンス学習において、自己注意メカニズムは非常に効果的であることが証明され、多くのタスクで大幅な改善を達成しています。しかし、自己注意メカニズムには、欠点がないわけではありません。自己注意は非常に長い依存関係をモデル化することができますが、深層の注意は単一のトークンに過度に集中する傾向があり、局所的な情報を十分に利用できず、長いシーケンスを表現することが困難になります。本研究では、長距離と短距離の両方の言語構造を捉えるために、シーケンスデータを対象とした並列マルチスケール表現学習を検討する。この目的のために、我々は並列マルチスケール表現学習（MUSE）とMUSE-simpleを提案する。MUSE-simpleは、並列マルチスケール配列表現学習の基本的なアイデアを含んでおり、自己注意、およびポイントワイズ変換の助けを借りて、異なるスケールの観点から並列に配列をエンコードする。MUSEはMUSE-simpleの上に構築されており、より異なるスケールからシーケンス表現を学習するために、畳み込みと自己注意を組み合わせることを検討している。我々は機械翻訳に焦点を当て、提案されたアプローチは、特に長いシーケンスにおいてTransformerよりも大幅な性能向上を達成した。さらに重要なことは、概念的には単純であるが、実際には複雑な検討が必要であり、マルチスケールの注意は統一されたセマンティック空間の上に構築されなければならないということである。一般的な環境下では、提案モデルは、3つの主要な機械翻訳タスクにおいて実質的な性能を達成し、以前のすべてのモデルよりも優れている。また、MUSEは並列性を持っているため、推論を高速化できる可能性がある。コードはこのhttpsのURLで公開されます。
最近の物体検出器は、様々な認識段階で物体を表現するために、アンカー、プロポーザル、最終予測などの長方形のバウンディングボックスに大きく依存しています。バウンディングボックスは便利ではあるが、オブジェクトの粗いローカライズしかできず、それに応じてオブジェクトの特徴の粗い抽出につながる。本論文では，新たなフィンガーポイントである ˶˙º̬˙˶ (representative points) を提案する．これは，定位と認識の両方に有用なサンプルポイントのセットとして，オブジェクトをより細かく表現するものである．学習のために定位と認識のターゲットが与えられると、RepPointsは、オブジェクトの空間的範囲を制限し、意味的に重要な局所領域を示す方法で、自動的に自己を配置することを学習する。さらに、RepPointsは、バウンディングボックスの空間をサンプリングするためにアンカーを使用する必要がありません。RepPointsに基づいたアンカーフリーのオブジェクト検出器は、最新のアンカーベースの検出手法と同等の効果があることを示し、ResNet-101モデルを用いたCOCO test-dev検出ベンチマークにおいて、AP46.5とAP67.4{50}を記録しました。コードはこのhttpsのURLで公開されています。
ニュースや百科事典、一部のソーシャルメディアなどのテキストは、客観性を追求しています。しかし、不適切な主観という形でのバイアスは、フレーミングによる態度の導入、真実を前提とすること、疑いをかけることなど、どこにでも存在しています。このようなバイアスは、私たちの集団的信頼を損ない、社会的対立を助長します。この問題を解決するために、本研究では、不適切な主観的テキストを自動的に中立的な視点に持っていく（偏ったテキストを「中立化」する）という、自然言語生成のための新しいテストベッドを紹介します。また、初の偏った言語のパラレルコーパスを提供します。このコーパスは180,000文対を含み、偏った文章から様々なフレーミング、前提、態度を削除したWikipediaの編集に由来する。最後に、このタスクのための2つの強力なエンコーダ/デコーダベースラインを提案する。分かりやすいが不透明なCONCURRENTシステムは、生成プロセスの一部として主観的な単語を識別するためにBERTエンコーダを使用しています。解釈可能で制御可能なMODULARアルゴリズムは、（1）問題のある単語を識別するためのBERTベースの分類器と、（2）分類器がエンコーダの隠れた状態を編集することができる新しい結合埋め込みを用いて、これらのステップを分離する。4つのドメイン（百科事典、ニュースの見出し、書籍、政治演説）を対象とした大規模な人間による評価によると、これらのアルゴリズムは、バイアスを自動的に識別して削減するための第一歩であることが示唆されている。
継続的学習は，現代の学習システムが非定常分布を扱う能力を向上させることを目的としており，典型的には一連のタスクを連続的に学習しようとするものである．この分野の先行技術は、主に教師付き学習や強化学習のタスクを対象としており、タスクのラベルや境界の完全な知識を前提としていることが多い。本研究では、より一般的な問題に取り組むためのアプローチ(CURL)を提案します。タスクの識別に関する知識がなくても表現を学習することに焦点を当て、タスク間の急激な変化、あるタスクから別のタスクへのスムーズな移行、さらにはデータがシャッフルされた場合のシナリオを検討する。提案されたアプローチは、モデル内で直接タスクの推論を行い、その有効期間中に新しい概念を取り込むために動的に拡張することができ、破滅的な忘却に対処するためにリハーサルベースの技術を追加で組み込んでいる。CURLの有効性を、MNISTとOmniglotを用いた教師なし学習の設定で実証した。さらに、i.i.d.環境や、この技術をインクリメンタル・クラス・ラーニングなどの教師付きタスクに適用した場合にも、先行技術と比較して高い性能を示すことができます。
計画法は、単純な行動を組み合わせることで、時間的に拡張された逐次的な意思決定問題を解決することができる。しかし、計画法では、状態と遷移を適切に抽象化する必要があり、通常は手作業で設計する必要があります。一方、モデルフリーの強化学習（RL）は、低レベルの入力から直接行動を獲得することができるが、時間的に拡張された課題では苦戦することが多い。では、強化学習を利用して、プランニングに必要な抽象度を自動的に形成することで、両者の長所を活かすことができるのだろうか？我々は、RLで学習したゴール条件付きのポリシーをプランニングに組み込むことで、プランナーはどの状態に到達するかではなく、どの状態に到達するかに焦点を当てることができることを示す。しかし、画像のような複雑な状態観測では、すべての入力が有効な状態を表すとは限りません。そこで、プランナーにとって有効な状態のセットをコンパクトに表現するために、潜在変数モデルを用いることも提案する。これにより、ポリシーは行動の抽象化を提供し、潜在変数モデルは状態の抽象化を提供する。我々の手法を、プランニングベースの手法やモデルフリーの手法と比較した結果、貪欲ではない多段階の行動を必要とする画像ベースのロボットのナビゲーションやマニピュレーションのタスクにおいて、我々の手法が先行研究を大幅に上回ることがわかりました。
エッジにおけるビジュアルインテリジェンスは、低遅延アプリケーションやリアルタイムの判断が不可欠な状況において、必要性が高まっています。ビジュアルデータ解析の第一歩である物体検出は、畳み込みニューラルネットワーク（CNN）やディープラーニングの登場により、最先端の精度が大幅に向上しました。しかし、このような複雑なパラダイムは、計算需要が増大するため、リソースに制約のあるデバイスへの展開を妨げています。本研究では、高解像度ビデオフレーム内の物体を検出するための階層的なフレームワークを提案します。このフレームワークでは、最先端のCNNベースの物体検出器の精度を維持しつつ、インテリジェントなデータ削減メカニズムを用いて低消費電力の組み込みプロセッサをターゲットにした場合、処理速度の点で既存の作品を上回ることができます。さらに、無人実車（UAV）からの歩行者検出のユースケースを提示し、異なるプラットフォームに実装した場合に、提案されたアプローチが感度、平均処理時間、消費電力に与える影響を示しています。提案された選択プロセスを用いることで、我々のフレームワークは処理データを100分の1に減らすことができ、様々なエッジデバイスでの消費電力を4W以下に抑えることができました。
プランニング機能を持つエージェントの構築は、長い間、人工知能の追求における主要な課題の一つでした。木に基づく計画法は、チェスや囲碁のように完全なシミュレータが利用可能な難しい領域では大きな成功を収めています。しかし、現実の問題では、環境を支配する力学は複雑で未知であることが多い。本研究では、MuZeroアルゴリズムを発表する。MuZeroアルゴリズムは、ツリーベースの探索と学習したモデルを組み合わせることで、様々な挑戦的で視覚的に複雑な領域において、その根底にあるダイナミクスの知識がなくても、超人的なパフォーマンスを達成する。MuZeroはモデルを学習し、反復的に適用することで、プランニングに最も直接的に関連する量である報酬、行動選択方針、価値関数を予測します。モデルベースの計画手法が苦手とするAI技術を試すための代表的なビデオゲーム環境であるAtari社の57種類のゲームで評価したところ、MuZeroの新しいアルゴリズムは新たな技術水準を達成しました。また、囲碁、チェス、将棋について、ゲームのルールを知らずに評価したところ、MuZeroは、ゲームのルールとともに提供されたAlphaZeroアルゴリズムの超人的なパフォーマンスに匹敵しました。
ビデオ認識のためのSlowFastネットワークを発表します。我々のモデルは、(i)低フレームレートで動作し、空間的なセマンティクスをキャプチャするSlow経路と、(ii)高フレームレートで動作し、細かい時間解像度で動きをキャプチャするFast経路を含む。高速経路は、チャネル容量を小さくすることで非常に軽量化できるが、映像認識に有用な時間情報を学習することができる。我々のモデルは、ビデオ内のアクションの分類と検出の両方で強力な性能を達成し、大きな改善は我々のSlowFastコンセプトによる貢献であると特定されている。Kinetics、Charades、AVAといった主要なビデオ認識ベンチマークにおいて、最先端の精度を報告する。コードは以下のURLで公開されています：このhttpsのURL
最近の研究では、データの増強が深層学習モデルの一般化を大幅に改善する可能性があることが示されています。最近では、自動化されたオーグメンテーション戦略が、画像分類や物体検出における最先端の結果をもたらしています。これらの戦略は、検証精度を向上させるために最適化されていますが、半教師付き学習においても最先端の結果をもたらし、画像の一般的な破損に対するロバスト性を向上させました。これらの手法を大規模に採用する際の障害は、学習の複雑さを増大させ、計算コストを大幅に増加させる可能性のある別個の探索フェーズです。さらに、探索段階が独立しているため、これらの手法は、モデルやデータセットのサイズに応じて正則化の強さを調整することができません。自動化された正則化ポリシーは、小さなデータセットで小さなモデルをトレーニングすることで発見され、その後大きなモデルのトレーニングに適用されることが多い。本研究では、これらの障害の両方を取り除きます。RandAugmentは探索空間が大幅に削減されているため、別のプロキシタスクを必要とせず、ターゲットタスクでトレーニングすることができる。さらに、パラメータ化されているため、正則化の強さをモデルやデータセットのサイズに合わせて調整することができます。RandAugmentは、様々なタスクやデータセットで一様に使用することができ、CIFAR-10/100、SVHN、ImageNetにおいて、これまでの自動化されたオーグメンテーションアプローチと一致、もしくはそれを上回る結果を得ることができた。ImageNetデータセットでは、85.0%の精度を達成しました。これは、これまでの最新技術に比べて0.6%の向上であり、ベースラインオーグメンテーションに比べて1.0%の向上です。また、物体検出において、RandAugmentはベースラインオーグメンテーションよりも1.0-1.3%向上し、COCOにおいてはAutoAugmentよりも0.3%mAP以内に収まっている。最後に、RandAugmentは解釈可能なハイパーパラメータを持つため、モデルやデータセットのサイズを変えてデータ補強の役割を調べるために使用することができます。コードはオンラインで入手可能です。
近年、大規模な少数ショット学習（FSL）が話題になっています。すなわち、集約されたソースクラスを用いて深い特徴埋め込みモデルを学習し、ターゲットクラスに対して学習された特徴を用いて最近傍探索（NN）を行うというものである。最先端の大規模FSL手法はこのベースラインに勝てず、スケーラビリティに本質的な限界があることを示している。この課題を克服するために、我々は、ソースクラスとターゲットクラスの間の意味的関係を符号化したクラス階層を用いて、伝達可能な視覚的特徴を学習することにより、新しい大規模FSLモデルを提案する。大規模な実験の結果、提案モデルは、NNベースラインだけでなく、最先端の代替モデルをも大幅に上回ることがわかった。さらに、提案モデルは、大規模なゼロショット学習（ZSL）問題にも容易に拡張でき、最先端の結果を得ることができることを示す。
教師なし視覚表現学習のためのMomentum Contrast (MoCo)を発表します。辞書引きとしてのコントラスト学習の観点から、待ち行列と移動平均型エンコーダを用いて動的な辞書を構築する。これにより、大規模で一貫性のある辞書をオンザフライで構築することができ、対照的な教師なし学習を促進します。MoCoは、ImageNetの分類において、一般的な線形プロトコルの下で競争力のある結果を提供します。さらに重要なのは、MoCoによって学習された表現は、下流のタスクにうまく移行することです。MoCoは、PASCAL VOC、COCO、およびその他のデータセットにおける7つの検出/セグメンテーションタスクにおいて、教師ありの事前学習を上回ることができ、時には大差で上回ることもある。これは、多くの視覚タスクにおいて、教師なしの表現学習と教師ありの表現学習の間のギャップがほぼ解消されたことを示唆している。
変分オートエンコーダは，再構成損失（歪み）とKL項（レート）を組み合わせた目的を最適化します．レートは相互情報量の上限値であり、圧縮の度合いを制御する正則化と解釈されることが多い。ここでは、レートを含めることが、一般化を向上させる帰納的なバイアスとしても機能するかどうかを検討する。レート項の強さ、ネットワーク容量、汎化問題の難易度を制御したレート・ディストーション分析を行った。レートの強さを下げると逆説的にほとんどの設定で汎化が改善され、相互情報量を減らすと典型的にはアンダーフィッティングになる。さらに、相互情報量が飽和した後も汎化が改善されることを示し、境界上のギャップ（推論マージンに対するKLダイバージェンス）が汎化に影響することを示した。このことは、標準的なガウス事前分布は、一般的に汎化を助ける帰納的バイアスではないことを示唆しており、VAEにおける汎化を向上させる事前分布の選択を理解するための研究を促している。
予測のための複雑な機械学習モデルを学習するには、必ずしも容易に入手できない大量のデータが必要になることが多い。そのため、データが少ない環境下で優れた予測モデルを構築するためには、関連するが異なるソースからの外部データセットを活用することが重要な課題となる。本論文では、この問題に対する新しいアプローチを提案する。あるデータセットから別のデータセットへの変換を学習するために、複数のGANアーキテクチャを使用することで、対象となるデータセットを効果的に拡大することができ、その結果、単に対象となるデータセットを使用する場合よりも優れた予測モデルを学習することができる。我々は、このようなアプローチの有用性を示し、我々の手法が、ターゲットデータセットだけを使用する場合よりも、ターゲットドメインでの予測性能を向上させることを実証し、また、我々のフレームワークが、実世界の医療データセットのコレクションにおいて、他のいくつかのベンチマークを上回ることを示した。
ラベル付きデータが豊富な場合にも有効な半教師付き学習手法である「Noisy Student Training」を発表しました。Noisy Student Trainingは，ImageNetにおいて88.4%のトップ1精度を達成した．これは，3.5Bの弱いラベル付きInstagram画像を必要とする最先端モデルよりも2.0%優れている．また，ロバスト性テストセットでは，ImageNet-Aのトップ1精度を61.0%から83.7%に向上させ，ImageNet-Cの平均破損エラーを45.7から28.3に低減し，ImageNet-Pの平均フリップレートを27.8から12.2に低減しました．Noisy Student Trainingは、自己学習と蒸留のアイデアを、等身大の学生モデルと学習中に学生に加えられるノイズを用いて拡張したものです。ImageNetでは、まずラベル付き画像でEfficientNetモデルを学習し、それを教師として3億枚のラベルなし画像の疑似ラベルを生成します。次に、ラベル付き画像と擬似ラベル付き画像の組み合わせに対して、より大きなEfficientNetを生徒モデルとして学習します。このプロセスは、生徒を教師に戻して繰り返し行われます。生徒の学習中に、ドロップアウト、ストキャスティック・デプス、RandAugmentによるデータ増強などのノイズを生徒に注入し、生徒が教師よりもよく一般化するようにします。モデルはこのhttpsのURLから入手可能です。コードはこちらのhttpsのURLから入手できます。
多言語文の埋め込みを意味的に強化するシステムであるEmuを紹介します。我々のフレームワークは、意味的分類器と言語識別器の2つの主要なコンポーネントを使用して、事前に訓練された多言語文の埋め込みを微調整します。意味分類器は、関連する文の意味的な類似性を向上させ、言語識別器は、多言語の敵対的な学習によって埋め込みの多言語性を向上させる。いくつかの言語ペアを用いた実験の結果、我々の特殊化された埋め込みは、単言語のラベル付きデータのみを用いたクロスリンガルの意図分類のタスクにおいて、最先端の多言語文埋め込みモデルを上回ることが示された。
機械翻訳は、学習データの大きさと質に大きく影響されるため、大規模な並列コーパスの収集とフィルタリングへの関心が高まっている。本論文では、この課題に対して、多言語文の埋め込みに基づく新しい手法を提案する。従来の手法では、コサイン類似度のハードスレッショルドを用いた最近傍検索に依存していたが、本提案手法では、コサイン類似度のスケール不整合を考慮し、代わりに与えられた文ペアとその最も近い候補とのマージンを考慮する。実験の結果，既存の手法に比べて大きな改善が見られた．BUCCマイニングタスクとUNリコンストラクションタスクにおいて、公表されている最良の結果を、それぞれ10F1ポイント、30精度ポイント以上上回りました。英独ParaCrawlコーパスを我々の手法でフィルタリングした結果、newstest2014で31.2BLEUポイントを獲得し、公式フィルタリングされたベストバージョンよりも1ポイント以上改善しました。
最先端の物体検出フレームワークに対する敵対的な攻撃について、体系的な研究を行いました。標準的な検出データセットを用いて，一般的に使用されているさまざまな検出器や検出器のアンサンブルが生成するオブジェクトネススコアを抑制するパターンを学習します．大規模な実験により，敵対的に学習されたパッチの有効性をホワイトボックスとブラックボックスの両方の設定で評価し，データセット，オブジェクトクラス，検出器モデル間での攻撃の伝達性を定量化した．最後に、印刷されたポスターや着用可能な衣服を用いた物理的な世界への攻撃について詳細な研究を行い、様々な指標を用いてこれらの攻撃のパフォーマンスを厳密に定量化します。
畳み込みニューラルネットワーク（CNN）、特にUnetは、医用画像のセグメンテーションのための強力な手法です。これまでUnetは、多くの複雑な医用画像のセグメンテーションタスクにおいて、特にトレーニングデータとテストデータが同じ分布を持つ（つまり、同じソースドメインから来ている）条件下で、最先端の性能を示してきました。しかし、実際の臨床現場では、医用画像は異なるベンダーやセンターから取得されます。あるソースドメインで学習されたU-Netが、異なるターゲットドメイン（例：異なるベンダー、取得パラメータ）に移された場合、その性能は予想外に低下する可能性があります。U-Netを再学習するために、それぞれの新しいドメインから大量のアノテーションを収集することは、費用がかかり、面倒であり、実際には不可能である。本研究では、この問題に対処するために、(1)ベンダー適応のための不対生成敵対ネットワーク(GAN)と、(2)オブジェクトセグメンテーションのためのUnetからなる汎用フレームワークを提案した。提案されたUnet-GANアーキテクチャでは、GANはセグメンテーションに特化した特徴レベルでUnetから学習します。例として、心臓シネMRIを用い、3つの主要ベンダー（Philips、Siemens、GE）を3つのドメインとしたが、この手法は医療画像のセグメンテーション全般に拡張可能である。提案手法は、ベンダー間でセグメンテーション結果の大幅な改善を示した。提案されたUnet-GANは、ベンダー横断的な医用画像セグメンテーション問題に対するアノテーションフリーのソリューションを提供し、訓練された深層学習モデルを実際の臨床シナリオにおける多施設・多ベンダーでの使用に拡張できる可能性がある。
Transformerのニューラルシーケンスモデルで使用されているマルチヘッドアテンションレイヤーは、シーケンス間で情報を移動させるためのRNNの強力な代替手段です。これらの層の学習は、シーケンスの長さを超えた並列化が可能であるため、一般的に高速かつシンプルですが、（そのような並列化が不可能な場合）インクリメンタルな推論は、大きな「キー」と「値」のテンソルを繰り返し読み込むためのメモリ・バンド幅のコストが原因で、しばしば遅くなります。本研究では、「マルチクエリー・アテンション」と呼ばれる手法を提案しています。この手法では、キーと値を異なるアテンション「ヘッド」のすべてで共有し、テンソルのサイズを大幅に縮小することで、インクリメンタルなデコーディングに必要なメモリ帯域幅を削減します。このようにして得られたモデルは、実際にデコードが大幅に高速化され、ベースラインからわずかな品質劣化しか生じないことを実験的に検証しました。
しばしば、表現上の知識をあるニューラルネットワークから別のニューラルネットワークに移したいと思うことがあります。例えば、大きなネットワークをより小さなネットワークに分割したり、ある感覚モダリティから別のモダリティに知識を移したり、モデルのコレクションを単一の推定器にアンサンブルしたりすることがあります。これらの問題に対する標準的なアプローチである知識の蒸留は、教師と生徒のネットワークの確率的な出力間のKL乖離を最小化する。我々は、この目的が教師ネットワークの重要な構造的知識を無視していることを示す。このことから、教師がデータを表現する際に、より多くの情報を取り込むように生徒を訓練するという別の目的が生まれました。我々はこの目的を対比学習と名付けた。実験によると、この新しい目的は、単一モデルの圧縮、アンサンブル蒸留、クロスモーダル転送などの様々な知識転送タスクにおいて、知識蒸留や他の最先端の蒸留器よりも優れていることが実証された。私たちの手法は、多くの転送タスクにおいて新しい最先端の技術を設定し、知識蒸留と組み合わせた場合には、教師ネットワークを上回ることもあります。Code: this http URL.
最先端のNLPモデルは、主にディープニューラルネットワークに基づいていますが、どのようにして予測を行うのかという点では、不透明です。この制限により、モデル出力の背後にある「理由」を明らかにする、より解釈可能なNLP用の深層モデルを設計することへの関心が高まっています。しかし、この方向性の研究は、様々なデータセットやタスクで行われており、それに応じて固有の目的や評価基準があるため、進捗状況を把握することが困難になっています。私たちは、NLPにおける解釈可能なモデルの研究を進めるために、Evaluating Rationales And Simple English Reasoning (ERASER) ベンチマークを提案します。このベンチマークは、複数のデータセットとタスクで構成されており、「根拠」（裏付けとなる証拠）の人間によるアノテーションが収集されています。私たちは、モデルが提供する根拠が人間の根拠とどの程度一致しているか、また、これらの根拠がどの程度忠実であるか（提供された根拠が対応する予測にどの程度影響を与えたか）を把握することを目的としたいくつかの指標を提案しています。このベンチマークを公開することで、より解釈しやすいNLPシステムの設計が進むことを期待しています。ベンチマーク、コード、ドキュメントはこちらのhttpsのURLから入手できます。
神経抽象的要約モデルは、人間の文献とのオーバーラップが高い要約を生成することができます。しかし、既存のモデルは、実世界のアプリケーションで重要な指標である事実の正しさには最適化されていない。本研究では、情報抽出モジュールを用いて要約の事実確認を行うことで、生成された要約の事実上の正しさを評価する一般的なフレームワークを開発する。さらに、強化学習によって事実の正しさを報酬とするニューラル要約モデルを最適化する学習戦略を提案する。提案手法を，事実の正確さが重要な要件である放射線報告書の要約に適用した．病院から収集した2つのデータセットを用いて、自動評価と人間による評価の両方を行い、提案手法が、競合するニューラル要約システムに比べて、事実の正しさと出力の全体的な品質を大幅に改善し、人間が作成したものに近い品質の放射線科サマリーを作成することを示した。
実際の低リソース言語では，利用可能なすべてのデータを学習に利用する方が効果的な場合が多いため，開発セットを入手することは現実的ではありません．しかし、開発セットは、低リソースの自然言語処理（NLP）を扱っているとされる研究論文では広く使用されています。ここでは、以下の質問に答えることを目的としています。低リソース環境で早期停止のために開発セットを使用することは、開発言語で学習エポック数を調整するという、より現実的な選択肢と比較して、結果に影響を与えるか？また、それは性能の過大評価や過小評価につながるのか？我々は、低リソースNLPのためのニューラルモデルに関する最近の研究から複数の実験を繰り返し、開発セットを用いたトレーニングと用いないトレーニングによって得られたモデルの結果を比較しました。言語間の平均では、絶対的な精度の差は最大で1.4%です。しかし、いくつかの言語やタスクでは、18.0%もの精度の差がありました。この結果は、低リソースのNLP研究成果を発表する際に、現実的な実験セットアップの重要性を強調しています。
クロスドメインの汎用データベース（DB）クエリ対話システムを構築するためのコーパス「CoSQL」を発表します。このコーパスは、138のドメインにまたがる200の複雑なDBに問い合わせを行う3つの対話を集めたWizard-of-Oz（Wizard-of-Oz）コレクションから得られた、30k以上の対話と10k以上の注釈付きSQLクエリで構成されています。各対話では、クラウドワーカーがDBを探索するユーザーとなり、SQLエキスパートがSQLで回答を取得したり、曖昧な質問を明確にしたり、回答不可能な質問を通知したりすることで、実世界のDB問い合わせシナリオをシミュレートしています。ユーザーの質問がSQLで回答可能な場合、エキスパートはSQLと実行結果をユーザーに説明し、自然なインタラクションフローを維持しています。CoSQLは、既存のタスク指向の対話データセットと比較して、次のような新たな課題を導入している。（1）対話状態は、ドメイン固有のスロットと値のペアではなく、ドメインに依存しない実行可能な表現であるSQLに基づいていること、（2）テストは見たことのないデータベースで行われるため、成功には新しいドメインへの一般化が必要であること。CoSQLには3つのタスクがあります。CoSQLには、SQLに基づいた対話状態の追跡、問い合わせ結果からの応答生成、ユーザーの対話行為の予測という3つのタスクが含まれています。各タスクの強力なベースラインを評価し、CoSQLが今後の研究にとって重要な課題であることを示す。データセット、ベースライン、リーダーボードはこの https URL で公開されます。
既存のイベント抽出（EE）手法の多くは、単に文の範囲内でイベントの引数を抽出するだけです。しかし、このような文レベルのEE手法では、金融、法律、健康などの新しいアプリケーションからの膨大な量の文書を処理するのに苦労する。イベントの議論は常に異なる文に散らばっており、さらにそのようなイベントの言及が同じ文書に複数存在することも多い。これらの課題を解決するために、本研究では、文書レベルEE（DEE）を効果的に実現するために、エンティティベースの有向非環状グラフを生成することができる新しいエンド・ツー・エンドモデルDoc2EDAGを提案します。さらに、文書レベルのイベントラベリングを容易にするために、トリガーワードを使用しないデザインでDEEタスクを再構成します。Doc2EDAGの有効性を実証するために、上述の課題を持つ中国の金融発表からなる大規模な実世界データセットを構築しました。大規模な実験と包括的な分析により、Doc2EDAGが最先端の手法よりも優れていることを示しています。データとコードはこちらのhttpsのURLにあります。
本論文は、確率的勾配降下法のハイパーパラメータが、ニューラルネットワークの最終的な学習損失とテスト精度にどのように影響するかを理解するために、2つの貢献をしています。まず、確率的勾配降下法には、バッチサイズが小さいか中程度の場合に典型的に発生するノイズ支配型のレジームと、バッチサイズが大きい場合に典型的に発生する曲率支配型のレジームという、異なる挙動を持つ2つのレジームがあることを主張する。ノイズ支配領域では、バッチサイズが大きくなるにつれて最適な学習率が増加し、一定のエポックバジェットの下では、トレーニング損失とテスト精度はバッチサイズに依存しません。曲率支配領域では、最適な学習率はバッチサイズに依存せず、バッチサイズが大きくなるとトレーニング損失とテスト精度が低下することがわかった。これらの主張を、ResNets、LSTM、オートエンコーダーなどの様々なアーキテクチャを用いた実験で裏付ける。我々は、すべてのバッチサイズにおいて、学習率のグリッドサーチを常に行っている。次に、テストセットでは、両方のモデルが同じステップ数で学習され、同じような学習損失に達した場合でも、小さいまたは中程度の大きさのバッチサイズが、非常に大きなバッチサイズよりも引き続き優れていることを実証します。さらに，CIFAR-10上でWide-ResNetsを64バッチサイズで学習した場合，テスト精度を最大化するための最適学習率は，エポックバジェットを128倍にしても2倍にしか減少せず，学習損失を最小化するための最適学習率は16倍にしか減少しなかった．これらの結果は、確率的勾配のノイズが、有益な暗黙の正則化をもたらすことを確認している。
文章を上手に読むためには、その文章から得た知識を新しい状況に適用する能力が重要な要素となる。このような読解の上達を促すために、「状況における段落効果の推論」をテーマにした読解のチャレンジングなベンチマーク「ROPES」を紹介します。ROPESでは、原因と結果を説明する説明的な言葉（例：「動物の受粉媒介者は花の受精効率を高める」）が、新しい状況に明確な影響を与えることを対象としています。システムには，これらの関係のうち少なくとも1つを含む背景文，この背景文を用いた新しい状況，背景文の関係の効果を状況に応じて推論する問題が提示される．我々は、科学の教科書やウィキペディアからこのような現象を含む背景の文章を収集し、クラウドワーカーに状況、質問、回答の作成を依頼し、14,322の質問データセットを得た。このタスクの課題を分析し、最新の読解モデルの性能を評価した。最も優れたモデルの性能は、正しいタイプの答えをランダムに推測するよりもわずかに優れており、F1は61.6%で、人間の性能である89.0%を大きく下回っていた。
本研究では、機械翻訳の生成順序に関する実証的な研究を行っている。本研究では、挿入ベースのモデリングの最近の進歩に基づき、任意のオラクル生成ポリシーに従うようにモデルを訓練することを可能にする、ソフトな順序-報酬フレームワークをまず導入する。次に、このフレームワークを利用して、情報なしの命令、場所ベースの命令、頻度ベースの命令、コンテンツベースの命令、モデルベースの命令など、さまざまな生成命令を調査します。不思議なことに、WMT'14の英語→ドイツ語翻訳タスクでは、アルファベット順や最短順などの直感的ではない順序が、標準的なTransformerの性能と一致し、順序が出力品質に大きな影響を与えないことがわかりました。これは、高い性能を得るためには、伝統的な左から右への生成は厳密には必要ではないことを示しています。一方、WMT'18の英語→中国語タスクでは、結果のばらつきが大きい傾向にあり、あまり整合性のない言語ペアの翻訳は、生成順序に敏感である可能性が示唆されています。
自然画像の生成モデルは、スケールをうまく利用することで、忠実度の高いサンプルを得ることができるようになりました。我々は、複雑なKinetics-600データセットで訓練された大規模なGenerative Adversarial Networksが、これまでの研究よりも大幅に高い複雑性と忠実性を持つビデオサンプルを生成できることを示すことで、この成功をビデオモデリングの分野に持ち込もうとしている。我々が提案するモデル、Dual Video Discriminator GAN (DVD-GAN)は、識別器の計算効率の高い分解を利用することで、より長く、より高い解像度のビデオに対応する。ビデオ合成とビデオ予測の関連タスクで評価した結果、Kinetics-600の予測では最先端のフレシェ・インセプション距離を達成し、UCF-101データセットの合成では最先端のインセプション・スコアを達成し、Kinetics-600の合成では強力なベースラインを確立した。
Generative Adversarial Networks (GAN)は、多大な研究努力にもかかわらず、学習が難しいことが知られている。学習を安定させるためのいくつかの正則化技術が提案されているが、これらは自明ではない計算上のオーバーヘッドをもたらし、スペクトル正規化のような既存の技術との相互作用が不十分である。本研究では、半教師付き学習の分野で一般的な手法である一貫性正則化の概念に基づいた、シンプルで効果的な学習安定化手法を提案する。具体的には、GAN識別器に渡すデータを増強し、これらの増強に対する識別器の感度にペナルティを課す。一連の実験を行い、整合性正則化がスペクトル正規化や様々なGANアーキテクチャ、損失関数、オプティマイザーの設定と効果的に連動することを実証した。我々の手法は、CIFAR-10とCelebAにおいて、他の正則化手法と比較して、無条件の画像生成において最高のFIDスコアを達成した。さらに、我々の整合性正則化GAN（CR-GAN）は、条件付き生成のための最先端のFIDスコアを、CIFAR-10では14.73から11.48に、ImageNet-2012では8.73から6.66に改善した。
Generative Adversarial Network（GAN）は、教師なし学習の強力なアプローチです。GANは、画像領域において最先端の性能を達成しています。しかし、GANには2つの点で限界があります。また、確率密度の存在が保証されていないため、予測対数尤度を用いた汎化評価が不可能である。本論文では、これらの欠点を解決するために、所定のGAN(PresGAN)を開発する。PresGANは、密度ネットワークの出力にノイズを加え、エントロピー正則化された逆問題損失を最適化する。追加されたノイズは、予測対数尤度の扱いやすい近似値を与え、学習手順を安定させる。エントロピー正則化は、PresGANがデータ分布のすべてのモードを捕捉することを促す。PresGANsのフィッティングには、エントロピー正則化項の難解な勾配を計算する必要があるが、PresGANsは不偏の確率的推定値を用いてこの難解さを回避する。我々は、いくつかのデータセットでPresGANを評価し、モード崩壊を緩和し、高い知覚品質のサンプルを生成することがわかった。さらに、PresGANは、従来のGANと変分オートエンコーダー（VAE）の間の予測対数尤度の性能の差を縮めることがわかった。
本論文では、AIにおける重要な課題である、見たことのない環境を効率的に探索する問題を考察する。我々は、環境の分布から方針を学習する「探索学習」の枠組みを提案する。これは、環境の分布から方針を学習し、テスト時に同じ分布から未見の環境が提示されたときに、限られたステップ数で最大数のユニークな状態を訪れるように探索戦略を一般化することを目的とする。ここでは、ソフトウェアテストや地図の作成など、多くの重要な実世界のアプリケーションで遭遇する、グラフ構造の状態空間を持つ環境に特に注目する。我々はこの課題を強化学習問題として定式化し、「探索」エージェントが以前に見たことのない環境の状態に移行することで報酬を得て、エージェントの過去の軌跡を符号化するためにグラフ構造のメモリを採用する。実験結果によると、我々の手法は空間マップの探索に非常に有効であり、ドメイン固有のプログラムや実世界のモバイルアプリケーションのカバーガイド付きソフトウェアテストという困難な問題に適用した場合、人間の専門家が手作業で設計した手法よりも優れた結果を得ることができた。
Generative Adversarial Network (GAN) は、教師なし学習の強力なアプローチです。GANは，教師なし学習の強力なアプローチであり，画像領域において最先端の性能を達成している．しかし，GANには2つの問題点がある．また、確率密度の存在が保証されていないため、予測対数尤度を用いた汎化評価が不可能である。本論文では、これらの欠点を解決するために、所定のGAN（PresGAN）を開発する。PresGANは、密度ネットワークの出力にノイズを加え、エントロピー正則化された逆問題損失を最適化する。追加されたノイズは、予測対数尤度の扱いやすい近似値を与え、学習手順を安定させる。エントロピー正則化は、PresGANがデータ分布のすべてのモードを捕捉することを促す。PresGANsのフィッティングには、エントロピー正則化項の難解な勾配を計算する必要があるが、PresGANsは不偏の確率的推定値を用いてこの難解さを回避する。我々は、いくつかのデータセットでPresGANを評価し、モード崩壊を緩和し、高い知覚品質のサンプルを生成することがわかった。さらに、PresGANは、従来のGANと変分オートエンコーダー（VAE）の間の予測対数尤度の性能の差を縮めることがわかった。
さらに、大規模なNLIベンチマークデータセットを導入しました。このデータセットは、人間とモデルによる反復的なin-the-loop手順によって収集されたものです。この新しいデータセットでモデルを学習すると、様々な一般的なNLIベンチマークで最先端の性能が得られる一方、新しいテストセットではより困難な課題が発生することを示した。我々の分析は、現在の最新モデルの欠点に光を当て、専門家ではないアノテーターがその弱点を見つけることに成功したことを示している。このデータ収集方法は、すぐに飽和してしまうような静的なベンチマークではなく、NLUの移動するターゲットとなり、終わりのない学習シナリオに適用することができます。
グラフの深層生成モデルは、ドラッグデザインの分野で大きな期待が寄せられていますが、これまでのところ、グラフ構造を持つ分子を生成する以外の用途はほとんど見つかっていません。本研究では、画像データから道路ネットワークを抽出するという困難な課題に対する概念実証を行った。この課題は、画像を条件としたグラフ生成とみなすことができ、そのために、画像の条件付けとグラフの再帰的生成のための注意メカニズムを利用した深層自己回帰モデルであるGenerative Graph Transformer (GGT)を開発した。GGTのベンチマークとして、セマンティックセグメンテーションデータからの道路ネットワーク抽出を行った。そのために、実際に公開されているデータに基づいたToulouse Road Networkデータセットを導入する。さらに、道路ネットワーク生成の品質を効果的に評価するために、Sinkhorn距離に基づいた指標であるStreetMover距離を提案します。このコードとデータセットは公開されています。
モデルベース強化学習の多くは、エージェントの世界のモデルを学習し、このモデルを活用してタスクをより効率的に実行できるようにエージェントを訓練することである。このようなモデルはエージェントにとって有用であることは明らかですが、私たちが認識している世界の自然発生モデル（例えば脳）は、生存のための競合する進化圧力の副産物として生じたものであり、勾配降下法による教師付き順予測損失の最小化ではありません。進化の面倒で遅い最適化プロセスから有用なモデルが生まれるということは、適切な状況下では、最適化の副作用として順予測モデリングが生まれることを示唆している。重要なのは、この最適化プロセスは、明示的にフォワード・プレディクティブ・ロスである必要はないということです。本研究では、従来の強化学習を修正し、「観測的ドロップアウト」と呼ぶ手法を導入しています。そうすることで、強化学習中の観測のギャップを埋めるために、エージェントに世界モデルを学習させることができる。このようにして生成された世界モデルは、未来を予測するようには明示的に学習されていませんが、エージェントが環境でうまく機能するために必要な主要なスキルを学習するのに役立つことを示しています。結果の動画はこちらのhttpsのURLからご覧いただけます。
モデル不可知論的なメタ学習器は、類似したタスクからメタ学習されたパラメータを獲得し、少ない勾配更新で同じ分布から新しいタスクに適応することを目的としています。モデルを柔軟に選択できることから、これらのフレームワークは、数ショットの画像分類や強化学習など、様々な領域で魅力的な性能を発揮している。しかし、これらのフレームワークは、タスク分布全体に共通の初期化を求めるため、学習可能なタスク分布の多様性が大幅に制限されるという重要な限界がある。本論文では、MAMLに、マルチモーダルなタスク分布からサンプリングされたタスクのモードを識別し、勾配更新によって迅速に適応する機能を追加する。具体的には、マルチモーダルMAML（MMAML）フレームワークを提案する。MMAMLは、識別されたモードに応じてメタ学習された事前パラメータを調整することができ、より効率的な高速適応を可能にする。提案モデルを、回帰、画像分類、強化学習など、多様な数ショットの学習タスクで評価した。その結果、タスクの特性に応じてメタ学習された事前パラメータを調整する本モデルの有効性が示されただけでなく、マルチモーダルな分布に基づいて学習することで、単一モーダルな学習よりも改善されることが示された。
ディープニューラルネットワーク（DNN）は、多くの自然言語生成（NLG）タスクにおいて、事実上の標準的なモデリング手法となりつつあります。このようなモデルが真に有用であるためには、テスト時に新規の意味表現（MR）の発話を正しく生成できなければならない。実際には、様々な形で意味制御を行う高度なDNNであっても、入力された意味表現に忠実な発話を生成できないことが多い。本論文では、アーキテクチャに依存しない自己学習法を提案し、新しいMRとテキストの発話ペアをサンプリングして、元の学習データを補強する。驚くべきことに、増強されたデータで学習すると、欲張りなデコーディングを行う単純なエンコーダ・デコーダモデルであっても、意味的に正しい発話を生成することができ、自動評価と人間による品質評価の両方において、最先端の出力と同等の品質を得ることができる。
密集した規則的なグリッド上でバウンディングボックスオブジェクトの予測を生成するスライディングウィンドウオブジェクト検出器は、急速に進歩し、人気を博している。一方、最近のインスタンスセグメンテーションアプローチでは、マスクR-CNNに代表されるように、まずオブジェクトのバウンディングボックスを検出し、その領域を切り取ってセグメンテーションする手法が主流となっています。本研究では、密なスライディング・ウィンドウによるインスタンス・セグメンテーションのパラダイムを研究しています。このタスクは、セマンティックセグメンテーションやバウンディングボックスオブジェクト検出などの他の密な予測タスクとは根本的に異なるというのが我々の中心的な観察である。なぜなら、すべての空間的位置での出力は、それ自体が独自の空間的次元を持つ幾何学的構造だからである。このことを公式化するために、我々は高密度インスタンスセグメンテーションを4次元テンソル上の予測タスクとして扱い、この幾何学的構造を明示的に捉え、4次元テンソル上の新しい演算子を可能にするTensorMaskと呼ばれる一般的なフレームワークを提示する。このテンソルビューは、この構造を無視したベースラインよりも大きな利益をもたらし、Mask R-CNNに匹敵する結果をもたらすことを実証した。これらの有望な結果は、TensorMaskが、高密度のマスク予測における新しい進歩と、タスクのより完全な理解のための基盤として役立つことを示唆している。コードは公開される予定です。
要約アルゴリズムを評価するために現在使用されているメトリクスは、要約がソース文書と事実上一致しているかどうかを考慮していない。我々は、事実の一貫性を検証し、ソース文書と生成された要約の間の矛盾を識別するための、弱い教師付きのモデルベースのアプローチを提案する。学習データは、ソース文書の文に一連のルールベースの変換を適用することで生成される。そして、事実の一貫性モデルは、3つのタスクのために共同で学習される。1) 変換後も文章が事実上一貫しているかどうかを識別する、2) 一貫性の予測をサポートするためにソース文書内のスパンを抽出する、3) 要約文に一貫性のないスパンが存在する場合、それを抽出する。このモデルを、いくつかの最新モデルによって生成された要約に適用したところ、この拡張性の高いアプローチは、自然言語推論や事実確認のための標準的なデータセットを用いて強力な監視下で学習されたモデルを含め、従来のモデルを大幅に上回る結果となった。さらに、人間による評価では、補助的なスパン抽出タスクが、事実の一貫性を検証するプロセスにおいて有用な支援となることが示されました。
訓練された機械学習モデルは、法執行機関、医療、教育、雇用などの分野で、影響力の大きいタスクを実行するために使用されることが多くなっています。機械学習モデルの使用目的を明確にし，適していない文脈での使用を最小限にするために，リリースされたモデルには，その性能特性を詳細に示す文書を添付することを推奨する．本論文では、このような透明性のあるモデル報告を促すために、モデルカードと呼ぶフレームワークを提案する。モデルカードとは、学習した機械学習モデルに付随する短い文書であり、意図した応用領域に関連する異なる文化的、人口統計学的、表現型のグループ（例：人種、地理的位置、性別、フィッツパトリック・スキンタイプ）や、交差するグループ（例：年齢と人種、性別とフィッツパトリック・スキンタイプ）など、様々な条件でのベンチマーク評価を提供するものである。また、モデルカードには、モデルの使用目的、性能評価手順の詳細、その他の関連情報が記載されています。ここでは、コンピュータビジョンや自然言語処理などの応用分野における人間中心の機械学習モデルに焦点を当てていますが、このフレームワークは、訓練されたあらゆる機械学習モデルの文書化に利用できます。この概念を明確にするために、2つの教師付きモデルのカードを提供しています。1つは画像中の笑顔を検出するために学習されたもの、もう1つはテキスト中の毒々しいコメントを検出するために学習されたものです。モデルカードは、機械学習や関連するAI技術を責任を持って民主化するための一歩として提案しており、AI技術がどれだけうまく機能しているかの透明性を高めます。この研究により、学習済みの機械学習モデルをリリースする人たちが、モデルのリリース時に同様の詳細な評価数値やその他の関連文書を添付するようになることを期待しています。
把持を成功させるためには、グリッパーの形状やキネマティクスなどの属性が、物体の形状と同様に重要な役割を果たします。これまでの研究では、新奇な物体形状に一般化しつつも、特定のロボットハンドに特化した把持方法の開発が中心でした。我々は、物体の形状とグリッパーの属性の両方を入力として考慮する、効率的なデータ駆動型の把持合成手法であるUniGraspを提案する。UniGraspは、物体の入力点群から接触点のセットを選択する、新しいディープニューラルネットワークアーキテクチャに基づいている。提案されたモデルは、大規模なデータセットで学習され、フォースクロージャーにあり、ロボットハンドが到達可能な接触点を生成します。接触点を出力として使用することで、多様なマルチフィンガーロボットハンドのセット間で転送することができる。我々のモデルは、様々な既知の2本指および3本指のグリッパーに対して、シミュレーションにおけるTop10予測では90%以上の有効な接触点を生成し、実世界の実験では90%以上の把持を成功させた。また、未知の2本指のグリッパーや2本の多指の擬人化ロボットハンドに対しても、93％、83％、90％の把持成功率を達成しています。
Video-to-Video Synthesis (vid2vid)は、人間のポーズやセグメンテーション・マスクのビデオなどの入力セマンティック・ビデオを、出力フォトリアリスティック・ビデオに変換することを目的としている。vid2vidの最新技術は大きく進歩していますが、既存のアプローチには2つの大きな限界があります。まず、データを大量に消費します。学習には、対象となる人間やシーンの画像が多数必要となります。第二に、学習したモデルの一般化能力に限界があります。pose-to-human vid2vid モデルは、トレーニングセットに含まれる1人の人物のポーズしか合成できません。トレーニングセットに含まれていない他の人間には一般化できません。この限界を解決するために、我々は、テスト時にターゲットの少数の例示画像を利用して、以前に見たことのない被写体やシーンのビデオを合成することを学習する、数ショットvid2vidフレームワークを提案する。このモデルは、注目メカニズムを利用した新しいネットワーク重み生成モジュールによって、数ショットの汎用性を実現している。我々は、人間のダンス映像、話し相手の映像、街並みの映像など、複数の大規模な映像データセットを用いて、強力なベースラインとの比較を含む広範な実験的検証を行った。実験結果は、既存のvid2vidアプローチの2つの限界を解決するための提案フレームワークの有効性を検証しています。
ロボット学習は、実世界の複雑さと多様性を飼いならすための有望なツールとして浮上している。ディープネットワークなどの大容量モデルに基づく手法は、オープンワールドの幅広い環境に対して効果的な一般化を提供することが期待されています。しかし、これらの手法は、効果的に一般化するために、大量の多様な学習データを必要とします。一方、ほとんどのロボット学習実験は、小規模、単一ドメイン、単一ロボットで行われています。これは、ロボット学習において頻繁に起こる問題である。つまり、個別の実験ごとに非実用的なほど大量のデータを収集することなく、一般化可能なロボット制御装置を学習するにはどうすればよいかということである。本論文では、ロボットの経験を共有するためのオープンなデータベースであるRoboNetを提案し、7つの異なるロボットプラットフォームからの1500万のビデオフレームの初期プールを提供し、ビジョンベースのロボット操作のための一般化可能なモデルの学習にどのように使用できるかを研究します。本研究では，このデータセットに，映像の前方予測モデルを用いた「視覚的先見性」と，教師付きの「逆モデル」という2種類の学習アルゴリズムを組み合わせる．実験では、学習したアルゴリズムが、新しい物体、新しいタスク、新しいシーン、新しいカメラの視点、新しいグリッパー、さらにはまったく新しいロボットにも対応できるかどうかを検証した。最後の実験では、RoboNetで事前にトレーニングを行い、FrankaやKukaロボットのデータを使って微調整を行うことで、4倍から20倍のデータを使用するロボット固有のトレーニングアプローチのパフォーマンスを上回ることができました。動画やデータについては、プロジェクトのウェブページ（https://www.robonet.wiki/）をご覧ください。
ニューラル機械翻訳における言語アノテーションの有用性は、過去の論文で確立されていたようです。しかし、これらの実験は、再帰的な配列-配列間のアーキテクチャと、比較的小さなデータ設定に限られていました。我々は、最先端のTransformerモデルに焦点を当て、比較的大きなコーパスを使用する。具体的には、単純なデータ操作または専用のモデルコンポーネントによって、マルチタスク学習を用いてソース側の構文の知識を促進することを試みています。特に、Transformerのアテンションヘッドの1つを、ソース側の依存関係ツリーを生成するように訓練します。今回の結果は、言語情報を用いたマルチタスク学習の有用性に疑問を投げかけるものであった。以前の研究で推奨されていたデータ操作技術は、大規模なデータ設定では効果がないことが分かった。自己言及を依存関係として扱うことで、翻訳に役立ち、Transformerモデルが非常に簡単に構文構造を把握できることが明らかになりました。しかし、重要かつ不思議なことに、真の依存関係の代わりに些細な「線形木」を使用しても、同じ利益が得られるという結果が出ています。この結果は、言語的知識の追加によるものではなく、自己注意行列に誘発されたより単純な正則化効果によるものである可能性があります。
転移学習とは、データ量の多いタスクでモデルを学習した後、下流のタスクでモデルを微調整するもので、自然言語処理（NLP）の強力な手法として注目されています。転移学習の有効性は、多様なアプローチ、方法論、実践を生み出しました。本稿では、テキストベースのすべての言語問題をテキスト間フォーマットに変換する統一的なフレームワークを導入することで、NLPのための転移学習技術のランドスケープを探ります。我々の体系的な研究では、数十の言語理解タスクについて、事前学習の目的、アーキテクチャ、ラベルのないデータセット、転送アプローチ、およびその他の要因を比較しています。その結果、要約、質問応答、テキスト分類などの多くのベンチマークにおいて、最先端の結果を得ることができました。NLPのための伝達学習に関する将来の研究を促進するために、我々はデータセット、事前に学習されたモデル、およびコードを公開します。
慇懃無礼な言葉遣いは、対話を終了させたり、コミュニティを分断したりする苛烈なものです。そのため、慇懃無礼な言葉を検出するシステムは、大きなプラスの影響を与える可能性があります。ここでの課題は、慇懃無礼は、談話や社会的文脈に依存するため、単独の発話からは検出できないことが多いことです。この問題を解決するために、我々は、文脈の中で見下した言語行為の新しいラベル付きデータセットであるTalkDownを発表する。言語のみのモデルを談話の表現で拡張することで、パフォーマンスが向上することを示し、慇懃無礼の割合が全体的に低いことに対処するための技術を提案する。また、我々のモデルを用いて、様々なオンラインコミュニティにおける慇懃無礼の割合を推定し、その違いをコミュニティの規範の違いと関連付ける。
パーサーは大量の学習データを必要とするため、世界のほんの一握りの言語でしか利用できません。しかし、少量の学習データでどこまでできるのでしょうか？本研究では、リソースの少ないパーサーを改善するためのシンプルな戦略を系統的に比較しています。これまでにテストされたことのない「データ増強」、「クロスリンガルトレーニング」、「音訳」です。北サーミ語、ガリシア語、カザ語という類型的に異なる3つの低リソース言語で実験を行った結果、（1）低リソースツリーバンクのみが利用可能な場合、データ補強が非常に有効であること、（2）関連する高リソースツリーバンクが利用可能な場合、異言語トレーニングが有効であり、データ補強を補完すること、（3）高リソースツリーバンクが異なる文字体系を使用している場合、共通の正書法空間に音訳することも非常に有効であることがわかった。
事前に学習された言語モデルは、ラベルのないデータを必要とするため、特に低リソース言語に対して有望です。しかし、既存のモデルの学習には膨大な計算量が必要であり、また、事前に学習された多言語モデルは、リソースの少ない言語では性能が劣ることが多い。本論文では、実務家が自国語で効率的に言語モデルを学習し、微調整できるようにするために、多言語言語モデル微調整（MultiFiT）を提案する。さらに、事前に学習された既存のクロス言語モデルを用いたゼロショット法を提案する。我々の手法を、広く利用されている2つの言語横断的な分類データセットで評価したところ、事前に学習させたモデルよりも数桁多いデータと計算量で優れた結果が得られました。我々は全てのモデルとコードを公開します。
我々は人間と協調できるエージェントを望んでいるが、セルフプレイや集団ベースのトレーニングなどの現在のアルゴリズムでは、自分自身と協調できるエージェントを作り出すことができる。パートナーが最適である、あるいは自分と似ていると仮定しているエージェントは、人間を理解できず、また人間に理解されない調整プロトコルに収束する可能性があります。これを実証するために、人気ゲーム「Overcooked」をベースにした、難易度の高い調整を必要とする簡単な環境を導入し、人間のプレイを模倣した単純なモデルを学習する。自己学習と集団学習によって学習されたエージェントの性能を評価します。これらのエージェントは、自分自身とペアを組んだときには非常に良い性能を発揮するが、我々の人間モデルとペアを組んだときには、人間モデルと一緒にプレイするように設計されたエージェントに比べて著しく劣る。プランニングアルゴリズムを用いた実験でも、同じ結論が得られました。ただし、人間を意識したプランナーに、一緒にプレイする正確な人間モデルが与えられた場合に限ります。実際の人間を使ったユーザー調査でも、それほど強くはありませんが、同様のパターンが見られます。質的には、エージェントを人間のゲームプレイに適応させることで利益が得られることがわかりました。この結果を受けて、我々は、人間との協調性を高めるために人間について学ぶエージェントを設計するためのいくつかのアプローチを提案する。コードはこちらのhttpsのURLから入手できます。
本論文は、大規模な畳み込みネットワークを用いた半教師付き学習の研究を紹介する。我々は、教師と生徒のパラダイムに基づいて、ラベルのない画像の大規模なコレクション（最大10億枚）を活用するパイプラインを提案する。我々の主な目標は、ResNet-50やResNextのような、与えられたターゲットアーキテクチャの性能を向上させることです。我々のアプローチの成功要因を徹底的に分析し、半教師付き学習による画像分類の高精度モデルを作成するためのいくつかの推奨事項を提示しています。その結果、我々のアプローチは、画像、ビデオ、および細かい分類のための標準的なアーキテクチャに重要な利益をもたらします。例えば、10億枚のラベルなし画像を利用して、我々の学習したバニラResNet-50は、ImageNetベンチマークで81.2%のトップ1精度を達成しました。
本論文では、WMT19 Metrics Shared Taskの結果を紹介しています。参加者は、WMT19のニュース翻訳タスクに参加している翻訳システムの出力を、自動メトリクスで採点するよう求められました。13の研究グループが24のメトリクスを提出しましたが、そのうち10は参照のない「メトリクス」であり、WMT19品質推定タスクとの共同タスク「メトリクスとしてのQE」への提出物を構成しています。さらに、11のベースラインメトリクスを計算し、8つの一般的に適用されているベースライン（BLEU、SentBLEU、NIST、WER、PER、TER、CDER、chrF）と、3つの再実装（chrF+、sacreBLEU-BLEU、sacreBLEU-chrF）を用意した。メトリクスの評価は、システムレベルでは、あるメトリクスがWMT19の公式マニュアルランキングとどの程度相関しているか、セグメントレベルでは、そのメトリクスが人間によるセグメント品質の判断とどの程度相関しているかを評価した。今年は、唯一の手動評価方法として、直接評価（DA）を採用しました。
現在のワンステップの検索・読み取り方式の質問応答システムでは、「『Armada』の著者が書いたどの小説が、Steven Spielbergによって長編映画として映画化されるか」のような質問に答えることは困難である。このような質問に答えるには、さらに推論を進めるために、失われたエンティティ（または事実）に関する情報を収集しなければならないマルチホップ推論が必要になります。GoldEn (Gold Entity) Retrieverは、オープンドメインのマルチホップ質問に答えるために、文脈を読むことと、より多くのサポート文書を検索することを繰り返す。GoldEn Retrieverは、不透明で計算コストの高いニューラル検索モデルを使用する代わりに、質問と利用可能なコンテキストを考慮して自然言語の検索クエリを生成し、市販の情報検索システムを活用して不足しているエンティティを検索します。これにより、GoldEn Retrieverは解釈可能性を維持しつつ、オープンドメインのマルチホップ推論のために効率的にスケールアップすることができます。最近提案されたオープンドメイン・マルチホップQAデータセット「HotpotQA」でGoldEn Retrieverを評価したところ、BERTなどの事前学習済み言語モデルを使用していないにもかかわらず、過去に発表された最良のモデルよりも性能が高いことが実証されました。
Generative adversarial networks（GAN）の性能向上のための一般的なヒューリスティックは、識別器に何らかの勾配ペナルティを使用することです。この勾配ペナルティは、もともとWasserstein距離の定式化が動機となっている。しかし、他のGANの定式化における勾配ペナルティの使用は、十分に動機付けられていない。我々は、期待マージン最大化の統一的なフレームワークを提示し、このフレームワークから広範囲の勾配ペナルティ付きGAN（例えば、Wasserstein、Standard、Least-Squares、Hinge GAN）を導き出すことができることを示す。我々の結果は、勾配ペナルティを採用することで、大マージン分類器（したがって、GANにおける大マージン識別器）を誘導することを意味する。また、期待マージン最大化が、GANにおける既知の問題である偽（生成）サンプルでの勾配消失をどのように軽減するかを説明する。このフレームワークから、Hinge lossを用いた新しいL^\infty gradient norm penaltyを導出する。このペナルティは、L^2ノルムペナルティ（Fréchet Inception Distanceに基づく）と比較して、一般的にGANにおいて同等の（あるいはより良い）生成出力を得ることができる。
我々は、シミュレーションのみで訓練されたモデルを使って、実際のロボットの前例のない複雑な操作問題を解決できることを実証する。これを可能にしたのは、ADR（Automatic Domain Randomization）と呼ばれる新しいアルゴリズムと、機械学習用のロボットプラットフォームという2つの重要な要素である。ADRは、難易度の高いランダム化された環境の分布を自動的に生成します。ADRを用いて学習された制御ポリシーと視覚状態推定器は、シミュレーション2現実的な伝達を大幅に改善した。制御ポリシーについては、ADRで生成された環境の分布で訓練されたメモリ・アウグメンテッド・モデルが、テスト時にメタ学習の出現を明確に示しています。ADRと当社のカスタムロボットプラットフォームを組み合わせることで、制御と状態推定の両方の問題を含むルービックキューブを人型ロボットの手で解くことができました。結果をまとめた動画はこちらのhttpsのURLからご覧いただけます。
現在、機械学習コミュニティには、データセットを文書化するための標準化されたプロセスがありません。このことは、重要度の高い領域では深刻な結果につながる可能性があります。このギャップを解決するために、我々はデータセットのためのデータシートを提案します。電子機器業界では、単純なものから複雑なものまで、すべての部品にデータシートが添付されており、そこには動作特性、テスト結果、推奨される用途などが記載されています。それと同じように、すべてのデータセットにも、その動機、構成、収集プロセス、推奨される使用方法などを記したデータシートを添付することを提案します。データセットのためのデータシートは、データセットの作成者とデータセットの消費者の間のより良いコミュニケーションを促進し、機械学習コミュニティが透明性と説明責任を優先することを奨励する。
ニューラルシーケンスの生成は、通常、トークンごとに、左から右へと行われます。トークンが生成されるたびに、以前に生成されたトークンのみが考慮されます。対照的に、シーケンス分類のような問題では、過去と未来のトークンの両方を考慮する双方向性の注目が、はるかに優れた性能を発揮することが示されています。我々は、特別なプレースホルダートークンを採用することで、シーケンス生成プロセスを双方向にすることを提案する。プレースホルダートークンは、完全連結グラフのノードとして扱われ、実際の出力トークンを生成する際に、過去と未来のトークンを考慮することができます。提案手法の有効性を，2つの会話タスクで実験的に検証したところ，提案された双方向モデルは，競合するベースラインを大差で上回る結果となった．
Weka，R（caretパッケージあり，なし），C，Matlabで実装された17種類の分類器（判別分析，ベイジアン，ニューラルネットワーク，サポートベクターマシン，決定木，ルールベース分類器，ブースティング，バギング，スタッキング，ランダムフォレストなどのアンサンブル，一般化線形モデル，最近傍，部分最小二乗，主成分回帰，ロジスティック回帰，多項回帰，多重適応回帰スプラインなど）からなる179個の分類器を評価しました．分類器の動作について、データセットの収集に依存しない重要な結論を得るために、UCIの全データベース（大規模な問題を除く）と他の独自の実問題を表す121のデータセットを使用しています。最も優秀と思われる分類器は，ランダムフォレスト（RF）バージョンで，その中でも最も優れたもの（Rで実装され，caretでアクセス）は，84.3%のデータセットで90%を超える94.1%の最大精度を達成しています．しかし，2番目に優れている LibSVM を用いて C で実装されたガウスカーネル付き SVM では，最大精度 92.3% を達成しており，その差は統計的に有意ではありませんでした．ランダムフォレスト、ガウスカーネルと多項式カーネルを持つSVM、ガウスカーネルを持つ極限学習マシン、C5.0、avNNet（caretパッケージを用いてRで実装された多層パーセプトロンの委員会）など、いくつかのモデルが残りのモデルよりも明らかに優れています。ランダムフォレストは明らかに最高の分類器ファミリーであり（ベスト5のうち3つがRF），次いでSVM（トップ10に4つの分類器が入っている），ニューラルネットワークとブースティングアンサンブル（トップ20にそれぞれ5つと3つのメンバーが入っている）となっています．
本研究では，方言の違いに鈍感なアノテーターが，ヘイトスピーチの自動検出モデルに人種的な偏りをもたらし，マイノリティの人々に対する被害を拡大させる可能性があることを調査した．まず、広く使われているヘイトスピーチのデータセットにおいて、アフリカ系アメリカ人の英語（AAE）の表面的な特徴と、毒性の評価との間に予期せぬ相関関係があることを発見しました。次に、これらのコーパスで訓練されたモデルがこれらのバイアスを獲得し、伝播することを示します。その結果、AAEのツイートや自称アフリカ系アメリカ人のツイートは、他のツイートに比べて攻撃的とラベル付けされる可能性が最大で2倍高くなります。最後に、アノテーションにおける人種的バイアスを軽減する方法として、*dialect*と*race priming*を提案し、AAEのツイートの方言をアノテーターに明示的に認識させた場合、そのツイートを攻撃的とラベル付けする可能性が大幅に減少することを示した。
本論文では、深層ネットワークを学習するためのSGD（stochastic gradient descent）法を改善するための新しい手法を提案しています。提案するPowerSGD法は、反復の間に確率的勾配をあるパワーに上げるだけであり、追加のパラメータはパワー指数のみである（PowerSGDがSGDに還元されるとき）。さらに、PowerSGD with momentum（PowerSGDM）を提案し、PowerSGDとPowerSGDMの収束率分析を行います。実験は、一般的な深層学習モデルとベンチマークデータセットで行われます。実証実験の結果、提案されたPowerSGDとPowerSGDMは、適応勾配法よりも速い初期学習速度、SGDと同等の一般化能力、ハイパーパラメータ選択や消失勾配に対するロバスト性の向上を得ることができました。PowerSGDは本質的に、非線形変換による勾配修正です。そのため、勾配ベースの最適化を高速化する他の手法とは直交し、補完関係にあります。
深層学習や強化学習において「メタ学習」と自認するアプローチの多くは（すべてではありませんが）、入れ子になった最適化問題の解を近似するという共通のパターンに当てはまります。本論文では、GIMLIと呼ぶこの共通パターンの形式化を行い、その一般的な要件を証明し、同様のアプローチを実装するための汎用アルゴリズムを導出する。この分析とアルゴリズムに基づいて、我々が設計したライブラリ「higher」について説明する。このライブラリは、これらの種類のメタ学習アプローチに関する将来の研究を支援し、可能にするためにコミュニティと共有している。最後に、このフレームワークとライブラリの実用的な応用例として、実験とアブレーションの研究を例示して本稿を締めくくります。
本論文では、強化学習（RL）を用いて都市の地下鉄ネットワーク拡張問題を解決する手法を紹介する。この手法では、地下鉄の拡張を、駅を順次選択するプロセスとして定式化し、選択された駅の順序に基づいて、地下鉄路線の合理的な接続パターンを確保するための実現可能性ルールを設計する。この定式化に続いて、次の地下鉄路線を設計するために、アクター批判モデルを訓練する。アクターはseq2seqネットワークで、実現可能な駅の確率分布であるパラメータ化されたポリシーを生成する注目メカニズムを持つ。評論家は、学習の分散を減らすために、学習中にアクターによって生成された出力駅シーケンスによって決定される期待報酬を推定するために使用されます。学習手順では報酬の計算のみが必要となるため、我々の一般的な手法は多因子の場合にも容易に拡張することができる。Origin-Destination(OD)トリップと社会的公平性を考慮し、中国の西安市において、24,770,715人の携帯電話ユーザーの実際の移動情報に基づいて、現在の地下鉄ネットワークを拡張した。その結果，我々の手法の有効性が示された．
可変パラメータ化された機械学習モデルのサンプル外予測精度を定性的に表現するために、「二重降下」リスクカーブを提案した。本稿では、最小二乗/最小ノルム予測子を用いた2つの単純なデータモデルにおけるこの曲線の形状について、正確な数学的分析を行っています。具体的には、特徴量の数pがサンプルサイズnに近いときにリスクがピークに達するが、pがnを超えて増加するにつれてリスクが最小になることが示されている。この挙動は、特徴量を事前に最適な順序で選択する「予知的」モデルと対照的である。
本論文では、標準的な教師付き学習法をサブルーチンとして使用する、シンプルでスケーラブルな強化学習アルゴリズムを開発することを目的としています。我々の目標は、シンプルで収束性の高い最尤損失関数のみを利用し、かつオフポリシーデータを活用できるアルゴリズムである。我々が提案する手法は、advantage-weighted regression（AWR）と呼ばれ、2つの標準的な教師付き学習のステップで構成されています。1つは価値関数の目標値に回帰するステップで、もう1つはポリシーの重み付けされた目標行動に回帰するステップです。この手法は単純かつ一般的であり、連続的および離散的な行動を扱うことができ、標準的な教師付き学習手法の上にわずか数行のコードで実装することができる。AWRの理論的な動機付けを行い、経験の再生からオフポリシーのデータを組み込んだ場合の特性を分析する。AWRをOpenAI Gymの標準的なベンチマークタスク群で評価し、AWRが多くの確立された最先端のRLアルゴリズムと比較して競争力のある性能を達成することを示した。また、AWRは、環境との相互作用がない純粋に静的なデータセットから学習した場合、多くのオフポリシーアルゴリズムよりも効果的なポリシーを獲得することができる。さらに、非常に複雑なシミュレーションキャラクターを用いた難しい連続制御タスクにおいて、本アルゴリズムを実証した。
ニューラル機械翻訳モデルは高い翻訳品質を達成したが、自己回帰的な性質のため、推論の並列化が難しく、翻訳の待ち時間が長くなってしまう。本研究では、最近の洗練されたアプローチにヒントを得て、連続的な潜在変数と決定論的な推論手順を持つ、潜在変数型の非自動回帰モデルであるLaNMTを提案する。既存のアプローチとは対照的に、我々は決定論的推論アルゴリズムを用いて、log-probabilityの下界を最大化するターゲット配列を見つける。推論の際、翻訳の長さは自動的に適応される。我々の実験では、推論アルゴリズムを実行することで下限値を大幅に増加させることができ、その結果、翻訳品質が大幅に向上することがわかった。提案モデルは、ASPEC Ja-Enデータセットにおいて、非自動回帰アプローチと自動回帰アプローチの性能差を縮め、8.6倍の高速デコーディングを実現しました。WMT'14 En-Deデータセットにおいて、我々のモデルは12.5倍の速度で自動回帰ベースラインとの差を2.0BLEUポイントまで縮めた。さらに、複数の初期潜在変数を並行してデコードし、教師モデルを用いて再スコアリングすることで、WMT'14 En-Deタスクにおいて、提案モデルは6.8倍の速度で1.0BLEUポイントまで差を縮めることができた。
ELMoやBERTのような文脈に基づいた単語表現は、様々な意味的・構造的（構文的）タスクで優れた性能を発揮することが示されています。本研究では、神経言語表現における意味と構造を教師なしで分離するという課題に取り組んでいます。この目的のために、構造的には似ているが意味的には異なる文のグループを自動的に生成し、メトリック学習法を用いて、ベクトルに符号化された構造的要素を強調する変換を学習します。この変換は、語彙的な意味ではなく、構造的な特性によって空間内のベクトルをクラスター化することを実証した。最後に、我々の抽出した表現の有用性を、数ショットの構文解析の設定において、元の文脈に基づく表現よりも優れていることを示す。
本研究では、自己注意メカニズムが対話ターンのシーケンス上で動作する、トランスフォーマー・アーキテクチャに基づく対話ポリシーを紹介する。最近の研究では、階層型リカレントニューラルネットワークを用いて、対話文脈における複数の発話を符号化していますが、純粋な自己注意メカニズムの方が適していることを主張します。デフォルトでは、RNNは一連の会話の中の全ての項目が、その会話全体の符号化に関連していると仮定するが、1つの会話は、話者が複数のトピックを織り交ぜることで、複数のオーバーラップする談話セグメントで構成されることがある。Transformerは、現在の対話状態のエンコーディングにどの順番を含めるかを選択し、対話履歴を選択的に無視したり、注意したりするのに適しています。我々は、Transformer Embedding Dialogue (TED)ポリシーの性能を、LSTMや、RNNのこの限界を克服するために特別に設計されたREDPと比較する。
Generative Adversarial Networks (GAN) は生成モデルの一種であり、複雑な実世界のデータをモデル化できるという点で注目されています。しかし、GANの学習には、非収束、勾配の消失や爆発、モード崩壊などの不安定性の問題があり、近年の成功にもかかわらず、依然として困難な状況が続いています。近年、GANの学習手順を安定化させることに焦点を当てた様々なアプローチが提案されている。本調査の目的は、文献に見られるGAN学習の安定化手法の包括的な概要を提供することである。各アプローチの長所と短所を議論し、比較してまとめ、最後に未解決の問題を議論する。
強化学習（RL）は、過去数年間で大きな進歩を遂げてきました。しかし、RLのコミュニティでは、現在使用されているモデルフリーの手法は、その利点にもかかわらず、極端なデータの非効率性に悩まされているという点で一致しています。この問題を回避するために、新しいモデルベースの手法が導入され、モデルフリーの手法よりもはるかに効率的であると主張されることが多い。しかし、本論文では、最先端のモデルフリーRainbow DQNアルゴリズムが、一般に報告されているよりもはるかに少ないサンプル数で学習できることを実証しました。このアルゴリズムでは、ネットワークの更新をより頻繁に行うことで、既存のモデルベースの手法と同等以上の結果を、わずかな複雑さと計算コストで達成することができます。さらに、本研究の成果に基づいて、本論文で紹介されている修正Rainbow DQNに似たエージェントは、深層強化学習のサンプル効率を改善することを目的とした今後の研究のベースラインとして使用されるべきであると主張しています。
自然言語処理（NLP）では、事前に学習した大規模なモデルからの転送学習が普及していますが、これらの大規模なモデルをオンザエッジで運用したり、学習や推論の予算が制限されている場合には、依然として困難が伴います。本研究では、DistilBERTと呼ばれる小型の汎用言語表現モデルを事前学習する方法を提案しています。ほとんどの先行研究では、タスクに特化したモデルを構築するために蒸留を使用することが研究されていますが、我々は事前学習段階で知識の蒸留を活用し、BERTモデルのサイズを40％削減することが可能であることを示しています。大型モデルが事前学習中に学習した帰納的バイアスを活用するために、言語モデリング、蒸留、コサイン距離の損失を組み合わせた三重損失を導入しました。本研究で開発した小型・高速・軽量のモデルは、事前学習にかかる費用が少なく、また、概念実証実験とデバイス上での比較研究により、デバイス上での計算に適していることを実証しました。
ニューラルテキスト生成は、自然言語アプリケーションにおける重要なツールですが、その中核には大きな問題があることがよく知られています。特に、標準的な尤度トレーニングとデコーディングでは、退屈で反復的な出力になってしまいます。その場しのぎの対処法として、top-kサンプリングやnucleusサンプリングなどが提案されているが、モデルによって予測されるトークンレベルの確率が低いという事実には対処していない。本論文では、尤度の目的自体に問題があり、その結果、人間の学習分布とは異なり、繰り返しや頻出の単語を含む配列に過剰な確率を割り当てるモデルになっていることを示す。本論文では、新しい目的である「非尤度学習」を提案する。これは、可能性の低い世代がモデルによって低い確率を割り当てられるようにするものである。トークンレベルとシーケンスレベルの非尤度学習により、繰り返しの少ない、退屈なテキストが得られることを示し、同時に、標準的な貪欲探索やビーム探索を用いた場合よりも優れた世代を与える。人間の評価によると、標準的なビーム探索を用いた我々のアプローチは、核サンプリングやビームブロッキングといった現在よく使われているデコーディング手法よりも優れており、既存の技術に代わる強力な選択肢を提供している。
過去の記憶を圧縮して長距離のシーケンスを学習する気配りのあるシーケンスモデル「Compressive Transformer」を発表した。Compressive Transformerは、WikiText-103およびEnwik8ベンチマークにおいて、それぞれ17.1 pplおよび0.97bpcという最先端の言語モデリング結果を得ることができました。また、高周波数の音声を効果的にモデル化することができ、RLの記憶メカニズムとして使用できることをオブジェクトマッチングタスクで実証した。長距離シーケンス学習の領域を促進するために、我々は書籍に由来する新しいオープンボキャブラリー言語モデリングベンチマーク、PG-19を提案する。
本論文では、これまでの最大のデータセットよりも桁違いに大きい、400億以上の対訳文ペアのデータセットを用いて、ニューラル機械翻訳（NMT）システムを学習する問題を調査する。このような状況では、データに含まれる深刻なノイズや、法外に長い学習時間など、これまでのNMT研究に比べて前例のない課題が発生します。我々は、これらの問題を解決するための実用的なソリューションを提案し、大規模な前処理によってNMTの性能が大幅に向上することを実証しました。その結果、WMT17中国語-英語データセットのBLEUスコアを32.3に押し上げることができ、既存の最先端の結果に比べて+3.2の大幅な性能向上を実現しました。
最近の学習型計画法は、観測空間から直接計画を立てることに有望な結果を示しています。しかし、これらの手法は、予測モデルの精度によって、長期的なタスクの計画を立てる能力が制限されています。一方、古典的なシンボリックプランナーは、長周期タスクの解決に顕著な能力を示すが、事前に定義されたシンボリックルールとシンボリックステートを必要とするため、実世界での適用が制限される。本研究では、これら2つのパラダイムの利点を組み合わせ、高次元観測を条件とした長期的なシンボリックプランを直接生成することができるlearning-to-plan手法を提案する。本研究では、古典的な計画学の文献から回帰（バックワード）計画のアイデアを借用し、回帰計画ネットワーク（RPN）を導入する。RPNは、タスクゴールから逆算して計画を立て、現在の観測値に到達する中間ゴールのシーケンスを生成するニューラルネットワークアーキテクチャである。我々のモデルは、以前に見たことのないタスクを解決する能力など、記号的計画から多くの好ましい特徴を受け継ぐだけでなく、視覚的入力からエンド・ツー・エンドで学習できることを示す。RPNは、複雑なビジュアルシーンと長いタスクホライズンを特徴とするグリッドワールド環境と3Dキッチンのシミュレーション環境でその能力を評価し、全く新しいタスクインスタンスにおいて最適に近い性能を達成することを示した。
潜在木学習（Latent Tree Learning: LTL）は、下流のタスクからの間接的な監視だけで文章の解析を学習する手法です。最近の潜在木学習の進歩により、言語モデリングや自動エンコーディングを目的とした学習により、中程度の品質の木構造を回復することが可能になった。本研究では、機械翻訳におけるデコーディングは、条件付きの言語モデリングタスクとして、言語モデリングと同様の学習信号を提供するが、より多くの意味的な信号を提供するため、より良い木構造を生成するだろうという仮説を探る。そこで、PRPNとON-LSTMという2つの既存の潜在木構造言語モデルを翻訳用に改良しました。WSJテストセットにおいて、これらのモデルは、翻訳の品質を維持しながら、言語モデリングで見られたものよりもF1スコアで優れた木を回復することがわかった。これは、機械翻訳を目的とした潜在木学習が初めて成功したことを意味する。さらに、翻訳は言語モデリングよりも木を誘導するのに適した信号を提供するが、翻訳モデルは潜在木構造を利用しなくても十分な性能を発揮することが示唆された。
データ増強は、特にディープニューラルネットワークを学習する際に、一般化を向上させるための効果的な手法として広く適用されています。最近、研究者たちはいくつかの集中的なデータ増強技術を提案し、実際に精度を向上させたが、これらの方法でデータを増強すると、クリーンなデータと増強されたデータの間にかなりのギャップが生じることに気がついた。本論文では、分析的観点からこの問題を再検討し、経験的リスクと一般化誤差という2つの用語を用いて、期待されるリスクの上界を推定する。また、データ増強を正則化として理解し、その主な特徴を明らかにした。その結果、データ増強は一般化誤差を大幅に減少させるが、一方で経験的リスクをわずかに増加させることになる。データ補強はモデルがより良い領域に収束するのに役立つと仮定すると、モデルは単純な方法で達成される低い経験的リスクから恩恵を受けることができる。すなわち、完全に補強されたデータで訓練されたモデルを改良するために、より少ない補強データを使用する。我々のアプローチは、いくつかの標準的な画像分類ベンチマークにおいて一貫した精度向上を達成しており、この向上は物体検出にも適用される。
空間的、時間的に変化するデータは、多くのアプリケーションで注目されています。この課題は、複雑な空間依存性、長距離の時間依存性、データの非定常性、およびデータの不均一性のために困難である。これらの課題を解決するために、我々はグラフトランスフォーマーのアーキテクチャであるForecasterを提案する。具体的には、まず、異なる場所にあるデータ間の空間依存性を解析的に表すグラフの構造を学習します。グラフのトポロジーに基づいて、空間依存性の強さ、長距離の時間依存性、データの非定常性、データの不均一性を考慮してTransformerをスパース化する。本研究では、タクシーのライド需要を予測する問題でForecasterを評価し、本提案のアーキテクチャが最先端のベースラインを大幅に上回ることを示した。
ニュースコメントの自動生成は、自然言語生成技術の新しいテストベッドである。本論文では、ニュースコメント生成のための "read-attend-comment "手順を提案し、読み上げネットワークと生成ネットワークを用いてこの手順を形式化する。読み上げネットワークは、ニュース記事を理解し、そこから重要なポイントを抽出し、生成ネットワークは、抽出された個別のポイントとニュースタイトルに注意してコメントを作成する。モデルの最適化は、バックプロパゲーションアルゴリズムを用いて、真の目的の変分下界を最大化することにより、エンド・ツー・エンドで行います。2つのデータセットを用いた実験の結果，我々のモデルは，自動評価と人間の判断の両方において，既存の手法を大幅に凌駕できることがわかった．
本論文では、非常に深いニューラルネットワークの自動チャネルプルーニングのための新しいメタ学習アプローチを提案する。まず、メタネットワークの一種であるPruningNetを学習する。このPruningNetは、対象となるネットワークが与えられたときに、任意の刈り込み構造に対する重みパラメータを生成することができる。刈り込みネットの学習には、単純な確率構造サンプリング法を用います。 次に、進化的手法を用いて、良好な性能の刈り込みネットワークを探索します。重みは学習されたPruningNetによって直接生成され、探索時に微調整を必要としないため、この探索は非常に効率的です。対象となるネットワークのために学習された単一のPruningNetを用いて、異なる制約の下で様々なPruned Networkを検索することができ、人間はほとんど関与しません。MobileNet V1/V2およびResNetにおいて、最先端のプルーニング手法と比較して、優れた性能を実証しています。コードはこのhttpsのURLから入手できます。
我々は、記録されたロボットの経験の大規模なデータセットを利用し、学習された報酬関数を用いて複数のタスクに対応するデータ駆動型ロボットのフレームワークを提示します。このフレームワークは、ロボットの経験を記録した大規模なデータセットを利用し、学習された報酬関数を用いて複数のタスクに対応するものです。タスクのデモンストレーションとタスクに依存しない記録された経験が与えられた場合、報酬関数を学習するために監督として特別な形の人間のアノテーションを使用する。これにより、報酬信号を直接取得できない実世界のタスクに対処することができる。学習された報酬は、異なるタスクからの経験の大規模なデータセットと組み合わせて使用され、バッチRLを使用してオフラインでロボットポリシーを学習する。この手法を用いて、剛体の積み重ねや布の取り扱いなど、様々な困難な操作タスクを実行するエージェントを育成できることを示している。
生成的敵対ネットワークは、近年急速に発展しており、画像の生成的モデリングに著しい改善をもたらしています。しかし、音声領域への応用はあまり注目されておらず、人間の音声などの音声信号の生成モデルは、WaveNetなどの自己回帰モデルが主流となっています。この問題を解決するために、我々はGAN-TTS（Generative Adversarial Network for Text-to-Speech）を開発しました。GAN-TTSのアーキテクチャは、生の音声を生成する条件付きフィードフォワードジェネレータと、異なるサイズのランダムウィンドウで動作する識別器のアンサンブルで構成されています。識別器は、音声の一般的なリアリズムと、音声が発音すべき音声にどれだけ対応しているかの両方の観点から音声を分析します。GAN-TTSの性能を測定するために、主観的な人間の評価（MOS - Mean Opinion Score）と、新しい定量的な指標（Fréchet DeepSpeech DistanceとKernel DeepSpeech Distance）の両方を採用しました。GAN-TTSは、最先端のモデルに匹敵する自然さで高忠実度の音声を生成することができ、自己回帰モデルとは異なり、効率的なフィードフォワード生成器のおかげで高度な並列化が可能であることを示しています。GAN-TTSがこのアブストラクトを読んでいる様子は、こちらのhttpsのURLで聞くことができます。
自然言語処理では、大規模なラベルなしコーパスで事前学習した大規模言語モデルを微調整することで、一般化を大幅に改善できることが近年観察されています。しかし，事前に学習させた大規模な言語モデルを下流のタスクで微調整することは，利用可能な学習インスタンスが少ない場合には性能が低下しやすい．本論文では、ドロップアウトを利用した新しい正則化手法（ミックスアウト）を紹介する。mixoutは、2つのモデルのパラメータを確率的に混合する。我々のミックスアウト技術は、2つのモデルのうちの1つからの偏差を最小化するように学習を正則化し、正則化の強さは最適化の軌道に沿って適応することを示す。本研究では，事前に学習した言語モデルを下流のタスクで微調整する際に，提案したミックスアウトとその変形を実証的に評価した．具体的には、GLUEの下流タスクにおけるBERTの微調整を正則化するために提案した手法を用いると、微調整の安定性と平均精度が大きく向上することを実証した。
自然言語表現の前処理を行う際にモデルサイズを大きくすると、下流のタスクでのパフォーマンスが向上することが多い。しかし、GPU/TPUのメモリの制限やトレーニング時間の長さのために、ある時点でさらなるモデルの増加が困難になります。これらの問題に対処するために、我々はBERTのメモリ消費量を減らし、トレーニング速度を向上させるための2つのパラメータ削減技術を提示します。包括的な経験的証拠は、我々の提案した方法が、オリジナルのBERTと比較してはるかに優れたスケールのモデルにつながることを示している。また、文間コヒーレンスのモデル化に焦点を当てた自己教師付き損失を使用し、それが複数文の入力を持つ下流のタスクに一貫して役立つことを示しています。その結果、BERT-large と比較してパラメータ数が少ないにもかかわらず、GLUE、RACE、および squad の各ベンチマークにおいて、我々の最高モデルが新たに最先端の結果を確立しました。コードおよび事前学習されたモデルは、https://github.com/google-research/ALBERT。
機械学習における重要な研究の方向性は、少数ショットの学習に取り組むためのメタ学習アルゴリズムの開発にあります。このアルゴリズムは、2つの最適化ループから構成されており、外側のループがメタ初期化を見つけ、そこから内側のループが新しいタスクを効率的に学習するというものです。MAMLは人気がありますが、基本的な未解決問題が残っています。MAMLの有効性は、メタ初期化が迅速な学習（表現の大規模かつ効率的な変更）のために準備されていることによるものなのか、それともメタ初期化がすでに高品質な特徴を含んでいることによる特徴の再利用によるものなのか？この疑問について、アブレーション研究と潜在的な表現の分析によって調べたところ、特徴の再利用が主な要因であることがわかりました。これは、MAMLを簡略化したANIL（Almost No Inner Loop）アルゴリズムであり、MAMLで学習されたネットワークの（タスク固有の）頭部以外のすべてについて、内部ループを削除するものである。ANILは、ベンチマークである数ショットの画像分類とRLにおいてMAMLと同等の性能を発揮し、MAMLよりも計算量が向上した。さらに、ネットワークの頭部と胴体部の正確な貢献を研究し、テストタスクでのパフォーマンスは学習した特徴の質によって完全に決定され、ネットワークの頭部さえも取り除くことができることを示した（NILアルゴリズム）。最後に、メタ学習アルゴリズムの迅速な学習と特徴の再利用の問題を、より広く議論して終わります。
最近の一連の論文では、Shenら（2018）による構文解析アルゴリズムを用いて、"syntactic depth "のプロキシに基づいてフレーズ構造ツリーを回復している。これらのプロキシの深さは、自然言語文に潜在する階層構造の（教師なしの）発見を促すメカニズムで補強されたリカレント言語モデルが学習する表現から得られる。同じパーサーを用いて、従来のLSTM言語モデルから得られたプロキシは、これまでの研究で用いられてきた特殊なアーキテクチャと同等の木を生成することを示した。しかし、解析アルゴリズムの詳細な分析を行い、(1)不完全であること、つまり可能な木の一部しか復元できないこと、(2)右分岐構造に顕著な偏りがあり、英語のような右分岐言語では性能が高くなることを示しました。このように、偏った構文解析アルゴリズムで評価すると、言語モデルの見かけ上の構造的な能力が高くなってしまうことが分かります。
人々の行動や相互作用を理解するには、通常、彼らを見ることが必要です。視覚データから行動を認識するプロセスを自動化することは、コンピュータビジョンのコミュニティで多くの研究テーマとなっています。しかし、暗すぎたり、人物が隠れていたり、壁の後ろにいたりした場合はどうすればよいのでしょうか。本論文では、壁やオクルージョンを通り抜け、照明条件が悪い場合でも、人間の行動を検出できるニューラルネットワークモデルを紹介します。このモデルは、無線周波数（RF）信号を入力とし、中間表現として3Dの人物スケルトンを生成し、複数の人物の行動やインタラクションを時系列で認識します。入力を骨格ベースの中間表現に変換することで，我々のモデルは，視覚ベースとRFベースの両方のデータセットから学習することができ，2つのタスクがお互いに助け合うことができる．我々のモデルは、人が見える場面ではビジョンベースの行動認識システムに匹敵する精度を達成し、人が見えない場面でも引き続き正確に動作することを示し、今日のビジョンベースの行動認識の限界を超えたシナリオに対応する。
ある服を着たときに、どのような小さな変更を加えれば、その服のファッション性が最も高まるか？この問いは、新しいビジョンの課題を提示しています。我々はFashion++を紹介します。これは、ファッション性に最大の影響を与えるような、全身の服に対する最小限の調整を提案するアプローチです。我々のモデルは、衣服ごとに学習されたエンコーディングに基づいて衣服を合成することを学習する、深層画像生成ニューラルネットワークで構成されています。潜在的なエンコーディングは、形状と質感に応じて明示的に因数分解されており、それによってフィット感/表現力と色/パターン/素材の両方をそれぞれ直接編集することができる。本論文では，Web写真をブートストラップしてファッション性モデルを自動的に学習する方法を示し，入力画像をよりファッショナブルなものに変換する活性化最大化スタイルのアプローチを開発した．入力された画像をよりファッショナブルなものに変換するために、活性化最大化スタイルのアプローチを開発した。提案される編集は、新しい衣服の交換から、色、着方（例：袖をまくる）、フィット感（例：ズボンを太くする）の微調整まで多岐にわたる。実験では、Fashion++が自動化された指標と人間の意見の両方に基づいて、成功する編集を提供することを実証しています。
政策勾配法は、大きな状態空間や行動空間を持つ強化学習問題に挑戦する際に、最も効果的な手法の一つである。しかし、政策勾配法の最も基本的な理論的収束特性についてはほとんど知られていません。例えば、大域的に最適な解に収束するかどうか、どの程度の速さで収束するか、限定されたパラメトリック政策のクラスを使用することによる近似誤差にどのように対処するかなどです。本研究では、割引マルコフ決定過程(MDP)の文脈において、政策勾配法の計算、近似、サンプルサイズの特性を証明可能な形で示す。本研究では、以下の両方に焦点を当てます。「また、パラメトリック政策クラス（対数線形政策クラスとニューラル政策クラスの両方を考慮）では、最適な政策が含まれていない可能性があり、不可知論的な学習結果を提供する。本研究の中心的な貢献の1つは、分布シフト下の教師付き学習に正式に接続することで、平均ケース（状態空間のサイズに対する明示的な最悪ケースの依存性を回避する）の近似保証を提供することです。この特徴は、推定誤差、近似誤差、および探索（正確に定義された条件数によって特徴付けられる）の間の重要な相互作用を示している。
本研究では，クラスの不均衡が畳み込みニューラルネットワーク（CNN）の分類性能に与える影響を系統的に調査し，この問題に対処するためによく用いられる手法を比較した．クラスの不均衡は、古典的な機械学習において包括的に研究されてきた一般的な問題であるが、深層学習の文脈では非常に限られた系統的な研究しか行われていない。本研究では、MNIST、CIFAR-10、ImageNetという複雑さを増す3つのベンチマークデータを用いて、分類におけるインバランスの影響を調査し、この問題に対処するためのいくつかの手法（オーバーサンプリング、アンダーサンプリング、2段階の学習、事前のクラス確率を補正する閾値）を徹底的に比較します。主な評価指標は、受信者動作特性曲線下の面積（ROC AUC）で、マルチクラスのタスクに合わせて調整しています。これは、全体的な精度指標は、不均衡なデータの文脈では顕著な困難を伴うためです。実験結果に基づき、以下の結論を得た。(i) クラスの不均衡が分類性能に与える影響は有害である。(iii) オーバーサンプリングは不均衡を完全に解消するレベルまで適用すべきだが、最適なアンダーサンプリング比率は不均衡の程度に依存する。 (iv) 古典的な機械学習モデルとは対照的に、オーバーサンプリングはCNNのオーバーフィッティングを引き起こさない。
報酬学習は、報酬が人間の判断によって定義されるタスクに強化学習（RL）を適用するもので、人間に質問することで報酬のモデルを構築する。報酬学習に関する研究の多くはシミュレーション環境を用いていますが、価値に関する複雑な情報は自然言語で表現されることが多く、言語に対する報酬学習はRLを現実世界のタスクで実用的かつ安全なものにするための鍵になると考えています。本論文では、言語モデルの生成的な事前学習の進歩を利用して、報酬学習を4つの自然言語タスクに適用した。すなわち、肯定的な感情を持つテキストの継続、物理的に説明的な言語、TL;DRデータセットとCNN/Daily Mailデータセットの要約タスクである。文体の継続では、人間が評価したわずか5,000回の比較で良好な結果を得ることができました。要約の場合、60,000回の比較で学習したモデルは、入力から文全体をコピーしますが、無関係な前文はスキップします。これにより、妥当なROUGEスコアが得られ、人間のラベラーによると非常に良い結果が得られますが、ラベラーが単純なヒューリスティックに依存していることを利用している可能性があります。
知的システムの中核となる能力は，過去の経験を利用して新しいタスクを素早く学習する能力である．勾配（または最適化）を利用したメタ学習は、数回の学習を行うための効果的なアプローチとして最近登場した。この手法では、外側のループでメタパラメータを学習し、内側のループでタスク固有のモデルを、現在のタスクからの少量のデータのみを使用して学習します。これらのアプローチを拡張する上での重要な課題は、インナーループの学習プロセスで微分する必要があることで、これはかなりの計算量とメモリの負担になります。暗黙の区別を利用して、暗黙のMAMLアルゴリズムを開発しました。このアルゴリズムは、内部レベルの最適化の解のみに依存し、内部ループオプティマイザが取る経路には依存しません。これにより、メタグラジエントの計算を内ループオプティマイザの選択から効果的に切り離すことができます。その結果、我々のアプローチは内部ループオプティマイザの選択にとらわれず、消失勾配やメモリ制約のない多くの勾配ステップを優雅に扱うことができる。理論的には、暗黙的MAMLは、小さな定数までは、単一の内ループ勾配を計算するのに必要なメモリフットプリントと変わらないメモリフットプリントで、正確なメタグラジェントを計算することができ、全体的な計算コストは増加しないことを証明します。実験的には、暗黙的MAMLのこれらの利点が、数ショットの画像認識ベンチマークにおける経験的な利益につながることを示している。
マルチエージェントの競争、かくれんぼという単純な目的、標準的な強化学習アルゴリズムを大規模に実行することで、エージェントが自己監視型の自己カリキュラムを作成し、高度な道具の使用や調整を必要とする複数の異なるラウンドの創発的戦略を誘発することを発見した。例えば、エージェントは移動可能な箱を使って複数の物体のためのシェルターを作ることを学び、その結果、エージェントはスロープを使って障害物を乗り越えることができることを発見する。さらに、マルチエージェントの競争は、環境の複雑さが増すにつれてスケールアップする可能性があり、内発的動機付けなどの他の自己監視型強化学習手法よりも、はるかに人間に関連するスキルを中心とした行動につながるという証拠を示しています。最後に、目標とする能力を定量的に評価する方法として、伝達と微調整を提案し、ドメインに特化した一連の知能テストにおいて、かくれんぼエージェントを内在的動機とランダムな初期化ベースラインの両方と比較します。
また、学習目的が異なる深層ニューラルネットワークにおいて、個々のトークンの表現と学習された特徴空間の構造が層間でどのように変化するかを理解することを目指しています。トランスフォーマーは、機械翻訳（MT）、標準的な左から右への言語モデル（LM）、マスクド・ランゲージ・モデリング（MLM）など、さまざまなタスクで有効性が示されているため、今回の分析ではトランスフォーマーに焦点を当てます。これまでの研究では、ブラックボックスのプロービングタスクを用いて、Transformerによって学習される表現が目的によって大きく異なることを示しました。本研究では、正準相関分析と相互情報推定量を用いて、Transformerの層間で情報がどのように流れるか、またこのプロセスが学習目的の選択にどのように依存するかを研究している。例えば、下の層から上の層に行くにつれて、左から右への言語モデルでは、過去に関する情報が消えていき、未来に関する予測が形成されていく。一方、MLMでは、表現は最初にトークン周辺の文脈に関する情報を獲得し、トークンのアイデンティティを部分的に忘れて、より一般的なトークン表現を生成します。その後、トークンのアイデンティティは、MLMの最上層で再現される。
深層学習モデルは、スケルトンベースの人間の行動認識において素晴らしい性能を発揮する。しかし、これらのモデルは、複雑な時空間的性質を持ち、疎で離散的なスケルトンの関節を表現しなければならないため、敵対的攻撃に対するロバスト性については、ほとんど調査されていない。本研究では、グラフ畳み込みネットワークを用いたスケルトンベースの行動認識に対する初めての敵対的攻撃を提案する。提案された攻撃方法は、Constrainted Iterative Attack for Skeleton Actions (CIASA)と呼ばれ、アクションシーケンスの関節位置を変化させ、結果として得られる敵対的シーケンスがスケルトンの時間的な一貫性、空間的な整合性、擬人化された妥当性を維持するようにします。CIASAは、複数の物理的制約を満たし、摂動された骨格に空間的な骨格再調整を行い、生成ネットワークを用いて敵対的な骨格を正則化することで、この偉業を達成している。また、CIASAを用いて、意味的に感知できない局所的な攻撃の可能性を探り、最新のスケルトンアクション認識モデルを高い信頼性で騙すことに成功した。CIASAの摂動は、ブラックボックス攻撃に対して高い移植性を示す。また、コンピュータグラフィックスで作成されたRGBビデオにおいても、摂動を受けたスケルトンシーケンスが敵対的な行動を引き起こすことができることを示している。NTUデータとKineticsデータを用いた包括的な評価により、グラフベースのスケルトンアクション認識におけるCIASAの有効性を確認するとともに、時空間深層学習タスク全般に対する差し迫った脅威を明らかにする。
本研究では、質問に対する回答の裏付けとなる最も強力な証拠を見つけるシステムを提案する。エビデンスエージェントは、事前に訓練されたQAモデルに、与えられた答えを最も納得させる文章を選択するように訓練されている。エージェントが選んだ証拠は、他のQAモデルや人間が判断して、支持された答えの信憑性を高める。エージェントが選択した証拠は、他のQAモデルや人間が判断して、支持された答えの信憑性を高めます。エージェントが選択した証拠を用いることで、(i)人間は文章全体の20%程度しか使っていない質問に正しく答えることができ、(ii)QAモデルはより長い文章や難しい質問に一般化することができます。
深層学習技術は、推薦システムのアルゴリズム的な側面を研究している研究者が選択する手法となっています。機械学習全般への関心が高まっている中で、例えばtop-n推薦タスクなど、現時点での最先端を把握することが難しくなっています。同時に、最近のいくつかの論文では、結果の再現性や新しいモデルを提案する際のベースラインの選択など、今日の応用機械学習の研究手法の問題点が指摘されています。本研究では、top-n推薦タスクに対するアルゴリズム提案を系統的に分析した結果を報告する。具体的には、過去数年間にトップレベルの研究会で発表された18のアルゴリズムを検討した。そのうち、合理的な努力で再現できたのは7つだけであった。しかし、これらの手法のうち6つは、最近傍探索やグラフベースの手法など、比較的に単純なヒューリスティック手法で凌駕できることが判明した。残りの1つは、明らかにベースラインを上回っていましたが、よく調整された非ニューラルの線形ランキング法を一貫して上回ることはできませんでした。本研究は、今日の機械学習の研究における多くの潜在的な問題に光を当て、この分野における科学的実践の改善を求めるものである。我々の実験のソースコードと全結果は、以下のhttpsのURLから入手できます。
ニューラルネットワークを理解するための最近の研究では、トップダウンでモデルを探りますが、事前に分かっているモデルの傾向しか識別できません。我々は、事前に何の制約も課さずにモデルの好みを明らかにする新しい抽象化手法であるSusceptibility Identification through Fine-Tuning (SIFT)を提案する。固定された分類器からの勾配を用いてオートエンコーダーを微調整することで、異なる種類の分類器を特徴づける傾向をボトムアップ的に抽出することができる。さらに、SIFTアーキテクチャを利用して、グランドトゥルースラベルの反対側のクラスを予測するために文章を言い換えることで、固定分類モデルに含まれる潜在的なアーティファクトを明らかにすることができる。この手法を、4種類のモデルを用いた3つの多様なタスクで評価した。本手法は、4種類のモデルを用いて3つの多様なタスクで評価し、各モデルの傾向を対比させるとともに、文献で報告されているアーティファクトを再現した。
機械学習（ML）手法は、時系列予測のための統計的手法に代わるものとして、学術論文で提案されている。しかし，精度や計算量の点での相対的な性能については，ほとんど証拠がない。本論文の目的は，M3大会で使用された1045の月次時系列の大規模なサブセットを用いて，複数の予測水平軸にわたってその性能を評価することです。ポピュラーなML手法のサンプル後の精度を，8つの伝統的な統計手法の精度と比較した結果，使用した両方の精度指標において，また調べたすべての予測水平線において，前者が優勢であることがわかりました。さらに、ML法の計算量は統計的手法に比べてかなり多いことがわかりました。本論文では、これらの結果を考察し、MLモデルの精度が統計的モデルの精度を下回る理由を説明し、今後の可能な方法を提案します。我々の研究で得られた経験的な結果は、予測手法の性能をテストするための客観的で偏りのない方法の必要性を強調しています。これは、意味のある比較と明確な結論を可能にする、大規模でオープンなコンペティションによって達成することができます。
近年、大規模なテキストコーパスを用いて言語モデルを事前に学習する技術が進歩し、下流のNLPタスクの改善が急速に進んでいます。言語モデルは、言語的な知識を学習する一方で、学習データに含まれる関係的な知識を蓄積している可能性があり、「穴埋め式」の暗号文として構成されたクエリに答えることができるかもしれません。言語モデルは、構造化された知識ベースに比べて多くの利点があります。スキーマエンジニアリングを必要とせず、オープンクラスの関係をクエリすることができ、より多くのデータに拡張することが容易で、人間の監視なしにトレーニングすることができます。本論文では，事前に学習された最新の言語モデルにすでに含まれている関係知識（微調整なし）の詳細な分析を行った．その結果、（1）BERTは、微調整を行わずに、神託知識にある程度アクセスできる従来のNLP手法と競合する関係知識を含んでいること、（2）BERTは、監視下のベースラインに対してオープンドメインの質問応答でも非常に優れた結果を示していること、（3）特定の種類の事実的知識は、標準的な言語モデルの事前学習アプローチによって他のものよりもはるかに容易に学習されることがわかりました。これらのモデルは、微調整なしで事実上の知識を呼び出すことができ、教師なしのオープンドメインQAシステムとしての可能性を示しています。我々の分析結果を再現するコードは、このhttpsのURLから入手できます。
大規模な言語モデルを用いたテキスト生成機能は有望ですが、生成されたテキストの特定の部分をユーザが簡単に制御することはできません。CTRLは16億3000万パラメータの条件変換言語モデルで、スタイル、コンテンツ、タスク固有の動作を制御する制御コードを条件として学習されています。制御コードは、生のテキストに自然に共起する構造から派生したもので、教師なし学習の利点を維持しつつ、テキスト生成をより明確に制御することができます。また、これらのコードにより、CTRLは学習データのどの部分に配列が与えられれば最も可能性が高いかを予測することができる。これにより、モデルベースのソースアトリビューションによって大量のデータを分析する方法の可能性が広がります。CTRLの複数のフルサイズのプリトレーニング版は、こちらのhttpsのURLで公開しています。
ニューラルネットワークは、現代の多くのNLPシステムに搭載されていますが、その経験的な成功は、敵対的な攻撃に対する脆弱性という代償を伴います。これまでの研究では、このような脆弱性を部分的に緩和するために、敵対的なトレーニングやデータ増強を用いてきましたが、離散的なテキスト摂動から生じる探索空間の複雑さのために、最悪のケースの敵を見つけることはできませんでした。本研究では、この問題を逆の方向からアプローチする。すなわち、事前に定義した敵対的攻撃のクラスに対するシステムの頑健性を正式に検証する。本研究では、同義語の置き換えや文字の反転などの摂動下でのテキスト分類を研究する。我々は、これらの入力摂動をシンプレックスとしてモデル化し、形式的なモデル検証方法であるInterval Bound Propagationを使用することを提案します。従来の対数尤度の学習目的を修正して、効率的に検証できるモデルを学習するが、これは指数関数的な探索の複雑さを伴う。その結果、名目上の精度にはほとんど差がないものの、摂動下での検証精度が大幅に向上し、最悪のケースの敵に対して効率的に計算可能な形式的保証が得られました。
既存の機械翻訳モデルのほとんどは、文字、サブワード、またはワードといった文字ベースの語彙の上に構築されています。しかし、日本語や中国語のように文字数の多い言語や、ノイズの多いテキストに含まれる希少な文字は、不必要に語彙のスロットを占有し、そのコンパクト性を制限してしまいます。この問題を解決するには、テキストをバイト単位で表現し、256バイトのセットを語彙として使用する方法があります。しかし、計算コストが高いため、広く普及していないのが現状である。本論文では、バイトレベルのサブワード、特にバイトレベルBPE（BBPE）について検討する。バイトレベルBPEは、文字語彙よりもコンパクトで、語彙外のトークンがないが、純粋なバイトのみを使用するよりも効率的である。我々は、BBPE埋め込みの文脈化が必要であると主張し、これは畳み込み層やリカレント層で実装できる。我々の実験によると、BBPEはBPEと同等の性能を持ちながら、そのサイズはBPEの1/8しかない。多言語環境では、BBPEは多くの言語間の語彙共有を最大化し、より良い翻訳品質を達成する。さらに、BBPEは、文字セットが重複しない言語間でモデルを転送できることを示す。
我々は、画像コレクションの中から新しいオブジェクトカテゴリを発見する問題を考える。これらの画像はラベル付けされていませんが、関連するが異なる画像クラスの事前知識も仮定します。このような事前知識を用いて、クラスタリングの曖昧さを軽減し、新たに発見されたクラスの品質を向上させます。我々の貢献は2つあります。1つ目の貢献は、Deep Embedded Clusteringを伝達学習の設定に拡張することであり、表現のボトルネック、時間的なアンサンブル、一貫性を導入することでアルゴリズムを改善している。2つ目の貢献は、ラベルのないデータに含まれるクラスの数を推定する方法です。これは、既知のクラスから知識を移し、ラベルのないサブセットにおけるクラス数の異なる選択を診断するためのプローブとして使用します。我々の手法を徹底的に評価し、ImageNet、OmniGlot、CIFAR-100、CIFAR-10、SVHNなどの多数のベンチマークにおいて、最先端の手法を大幅に上回る結果を得た。
近年、自然言語理解（NLU）システムの成功は、これらのモデルが体系的かつ頑健な方法で一般化できないことを強調する結果によって悩まされてきた。本研究では、NLUシステムのロバスト性とシステマティック性に関するいくつかの重要な問題を明らかにするために、CLUTRRと名付けられた診断ベンチマーク・スイートを紹介します。CLUTRRは、古典的な帰納論理プログラミングの研究に基づいており、NLUシステムが短編小説の登場人物間の親族関係を推論することを要求しています。このタスクを成功させるためには、エンティティ間の関係を抽出するだけでなく、これらの関係を支配する論理的なルールを推論する必要があります。CLUTRRは、論理ルールの組み合わせを評価することで、モデルの系統的な一般化能力を正確に測定することができ、また、キュレートされたノイズファクトを追加することで、モデルのロバスト性を評価することができます。その結果、最新のNLUモデル（BERTやMACなど）と、記号的な入力を直接扱うグラフニューラルネットワークモデルとの間には、かなりの性能差があることが明らかになりました。
本論文では、ニューラルアブストラクティブサマリーを用いて、数千語を超える長文の要約を生成する手法を紹介する。要約を生成する前に簡単な抽出ステップを行い、これを用いて変換言語モデルに関連情報を与えてから要約の生成を行う。この抽出ステップにより、要約の結果が大幅に改善されることを示す。また、このアプローチは、コピーメカニズムを採用した先行研究と比較して、より抽象的な要約を生成する一方で、より高いルージュスコアを達成することを示す。注：上記の要約は著者が書いたものではなく、本稿で紹介するモデルの1つによって生成されたものです。
本論文では、スペルミスに強い単語埋め込みを学習する手法を紹介する。既存の単語埋め込みは、無視できない量の語彙外の単語を含む不正なテキストへの適用が限られている。本研究では、FastTextとサブワードを組み合わせ、スペルミスのパターンを学習する教師付きタスクを組み合わせた手法を提案する。本手法では、各単語のスペルミスを、その正しいバリエーションの近くに埋め込む。これらの埋め込みを、我々が公開している新しいデータセットで学習します。最後に、公開されているテストセットを用いて、内在的および外在的なNLPタスクにおいて、この手法の利点を実験的に示す。
強化学習において割引率が最適化プロセスに与える様々な影響をよりよく理解するために、私たちはそれぞれの影響を個別に研究するための一連の実験を計画しました。分析の結果、割引率が低い場合のパフォーマンスの低さは、アクションギャップが（小さすぎる）ことが原因であるという一般的な認識には修正が必要であることがわかった。我々は、状態空間におけるアクションギャップの大きさの違いが主な原因であるという代替仮説を提案する。また、アクションギャップの値を対数空間にマッピングすることで、より均質なアクションギャップを実現する新しい手法を紹介する。この方法は、標準的な仮定の下で収束を証明し、近似強化学習法の割引係数を下げることができることを経験的に示した。これにより、従来の手法では解くことが困難であった一連の強化学習問題に取り組むことが可能となる。
ほとんどのsequence-to-sequence（seq2seq）モデルは自己回帰的で、以前に生成されたトークンを条件として各トークンを生成します。一方，非自己回帰型seq2seqモデルは，すべてのトークンを1回で生成するため，GPUなどのハードウェアで並列処理することで効率化を図ることができる．しかし，すべてのトークンの結合分布を同時に直接モデル化することは困難であり，モデル構造が複雑になっても精度は自己回帰モデルに大きく遅れてしまう．本論文では、潜在変数モデルを用いた非自己回帰シーケンス生成のための、シンプルで効率的かつ効果的なモデルを提案する。具体的には、ニューラルネットワークを用いて複雑な分布をモデル化するエレガントな手法である生成フローに着目し、連続する潜在変数の条件付き密度をモデル化するために調整されたフローの複数の層を設計する。このモデルを3つのニューラル機械翻訳（NMT）ベンチマークデータセットで評価したところ、最先端の非自己回帰型NMTモデルと同等の性能を達成し、シーケンスの長さに対してデコーディング時間がほぼ一定になった。
本論文では、ビデオ内の自然文を弱教師付きで時空間的にグラウンディングするという新しいタスクに取り組む。具体的には、自然文とビデオが与えられた場合、学習時に時空間アノテーションに依存することなく、与えられた文に意味的に対応するビデオ内の時空間チューブをローカライズする。まず、ビデオから時空間チューブのセット（インスタンスと呼ばれる）を抽出します。次に、これらのインスタンスと文を、我々が提案する気配りのあるインタラクターを用いて符号化する。このインタラクターは、インスタンスと文の細かい関係を利用して、それらのマッチング行動を特徴付けることができる。本論文では，ランキング損失に加えて，新たにダイバーシティ損失を導入し，信頼性の高いインスタンスと文のペアのマッチング行動を強化し，信頼性の低いペアにはペナルティを与えることで，提案する気配りインタラクタを学習する．さらに、ImageNetのビデオオブジェクト検出データセットに基づいたVID-sentenceというデータセットを用いて、我々のタスクのベンチマークとする。広範な実験結果から、我々のモデルがベースライン・アプローチよりも優れていることが実証された。
学習と表現の進歩により、言語と他のモダリティを結びつける研究が再活性化されています。その中でも特に注目されているのが「視覚言語ナビゲーション（VLN）」で、エージェントが自然言語による指示や視覚的なシーンを解釈して、環境を移動したり目標を達成したりするものです。しかし、最近の研究では、この課題において言語理解がどの程度の役割を果たしているのかが明らかになっていない。特に、一般的な評価指標は、指示に対応する一連の動作ではなく、ゴールの完了に焦点を当てているためである。ここでは、Room-to-Roomデータセット(Anderson et al.,2018b)に対する現在の評価指標の欠点を明らかにし、新しい評価指標であるCoverage weighted by Length Score(CLS)を提案する。また、データセット内の既存のパスは、直接ゴールに向かう最短パスであるため、命令フォローの評価には理想的ではないことを示します。そこで、既存の短い経路を結合して、より困難な拡張経路を形成し、新しいデータセット「Room-for-Room（R4R）」を作成しました。R4RとCLSを用いて、指示の忠実さに応じて報酬を受け取るエージェントが、目標達成に焦点を当てたエージェントよりも優れていることを示す。
VG-NSL（Visually Grounded Neural Syntax Learner）は、明示的な監督なしに構文表現や構造を学習するアプローチである。このモデルは、自然な画像を見て、ペアのキャプションを読むことで学習する。VG-NSLは、テキストの構成要素の構文木を生成し、構成要素の表現を再帰的に合成し、画像と照合する。構成要素の具体性を画像とのマッチングスコアで定義し、それをテキストの構文解析の指針とする。MSCOCO データセットを用いた実験では，VG-NSL は，ゴールド解析木に対する F1 スコアにおいて，ビジュアルグラウンディングを使用しない様々な教師なし解析アプローチよりも優れていることが示された．また，VG-NSL は，ランダムな初期化の選択や学習データ量に対して，より安定していることがわかった．また、VG-NSL が獲得した具体性は、言語学者が定義した同様の指標とよく相関していることがわかった。最後に、VG-NSL を Multi30K データセットの複数の言語に適用し、我々のモデルが先行する教師なしのアプロー チよりも一貫して優れていることを示す。
我々は、訓練データの選択と内部のNMT表現の学習を同時に行うために、創発的なNMTシステムを使用するシンプルな新しい方法を提示する。この方法は、並列データを使用せずに、学習中に両方のタスクがお互いに強化されるような方法で、自己教師付きで行われます。この手法は、言語に依存せず、追加のハイパーパラメータを導入せず、英語とフランス語のWikipediaデータを用いたnewstest2014において、BLEUスコア29.21（en2fr）、27.36（fr2en）を達成しました。
音声からのエンド・ツー・エンド翻訳に関するこれまでの研究では、音声表現として主にフレームレベルの特徴を使用しており、テキストよりも長くて粗いシーケンスを作成していました。本研究では、圧縮された音素のような音声表現を生成する素朴な方法が、従来のフレームレベルの音声特徴よりもはるかに効果的かつ効率的な翻訳を可能にすることを示します。具体的には、音声フレームに音素ラベルを生成し、同じラベルを持つ連続したフレームを平均化することで、翻訳のためのより短い高レベルのソースシーケンスを作成します。この結果、リソースの多い言語ペアと少ない言語ペアの両方で、最大5BLEUの改善が見られ、学習時間も60%削減されました。この改善効果は、複数のデータサイズと2つの言語ペアに渡って維持されています。
注意メカニズムは、NLPではどこにでもあるものになっています。Transformerをはじめとする最近のアーキテクチャでは、層状のマルチヘッドアテンションにより、強力な文脈認識型の単語表現を学習します。複数のヘッドは、様々なタイプの単語関係を学習します。しかし、標準的なソフトマックスアテンションでは、すべてのアテンションヘッドは密であり、すべての文脈の単語にゼロではない重みを割り当てます。本研究では、適応的に疎なTransformerを導入し、注意ヘッドが文脈に依存した柔軟な疎性パターンを持つようにしています。このスパース化は、softmaxを\alpha-entmaxに置き換えることで達成されます。softmaxの微分可能な一般化であり、低スコアの単語が正確にゼロの重みを受け取ることができます。さらに、このパラメータは\alpha-entmaxの形状とスパース性を制御するものであり、これにより注意を集中させるか分散させるかを選択することができます。また、機械翻訳のデータセットにおいて、ソフトマックストランスフォーマーと比較して、適応的なスパーストランスフォーマーは、解釈性と頭部の多様性を向上させることができました。我々のアプローチの定量的・定性的分析の結果、異なる層のヘッドは異なるスパースの好みを学習し、ソフトマックストランスフォーマーよりも注意分布が多様になる傾向があることが分かった。さらに、注目ヘッドのスパース性は、精度を犠牲にすることなく、異なるヘッドの専門性を明らかにするのに役立ちます。
標準的なベンチマークではニューラル機械翻訳（NMT）が実証的に成功していますが、限られた並列データしかないため、多くの言語ペアにNMTモデルを適用することができません。逆翻訳のようなデータ増強法は、これらの問題を軽減するために単言語データを使用することを可能にしますが、逆翻訳自体は、特に統語的に分岐した言語の場合、極端にリソースの少ないシナリオでは失敗します。本論文では，ターゲット言語の文をソース言語の順序に合わせて並べ替え，トレーニング時の監視の追加ソースとして使用するという，シンプルかつ効果的な解決策を提案する．本論文では、リソースの少ない日英間のシミュレーションや、リソースの少ないウイグル語から英語へのシナリオを用いた実験により、他の半教師を用いた手法に比べて大幅な改善が見られた。
マルチコア・プロセッサとアクセラレータの進歩により、機械学習技術を様々なアプリケーションに応用することが可能になりました。これらの進歩は、ムーアの法則をはじめとするいくつかのトレンドの崩壊とともに、さらに高い計算能力と機械学習能力を約束するプロセッサーとアクセラレーターの爆発的な増加を促しました。これらのプロセッサやアクセラレータは、CPUやGPU、ASIC、FPGA、データフロー・アクセラレータなど、さまざまな形態で登場しています。本稿では、性能や消費電力の数値が公表されているこれらのプロセッサやアクセラレータの現状を調査しました。性能と消費電力の数値は散布図にプロットされ、このプロット上の傾向からいくつかの次元と観察が議論され、分析されます。例えば、消費電力、数値精度、推論と学習に関する興味深い傾向がプロットされています。次に、市販されている2つの低サイズ・重量・電力（SWaP）アクセラレータを選択し、ベンチマークを実施しました。これらのプロセッサは、DoD（米国防総省）やその他のSWaPに制約のあるユーザーに最も適した、組み込み型およびモバイル型の機械学習推論アプリケーションにとって最も興味深いものです。本研究では、実世界の画像やニューラルネットワークモデルを用いて実際にどのような性能を発揮するのかを明らかにし、それらの結果を報告されている性能や消費電力の値と比較し、一部の組み込みアプリケーションで使用されているインテルのCPUと比較評価します。
画像をテキストで記述することは、視覚言語研究の基本的な問題です。この分野の現在の研究は、ほとんどが単一の画像キャプションに焦点を当てています。しかし、実際の様々なアプリケーション（例：画像編集、差分解釈、検索）においては、2つの画像に対して関係性のあるキャプションを生成することも非常に有用である。この重要な問題は、データセットや効果的なモデルが不足しているため、これまであまり検討されていませんでした。そこで本研究では、言語誘導型画像編集のためのデータセットを開発した。このデータセットには、多数の実画像とそれに対応する編集指示が含まれている。次に、静的関係性注意とシーケンシャルマルチヘッド注意を備えたエンコーダ-デコーダアーキテクチャに基づいた、新しい関係性話者モデルを提案する。さらに、このモデルを動的関係注意に拡張し、デコーディング中に視覚的な位置合わせを計算する。これらのモデルは、我々が新たに収集したデータセットと、関係性の文章が注釈された画像ペアからなる2つの公開データセットで評価した。自動評価と人間評価の両方に基づいた実験結果は、すべてのデータセットにおいて、我々のモデルがすべてのベースラインと既存の手法よりも優れていることを示している。
機械翻訳システムのユーザは、異なる方法で翻訳された複数の候補を得たいと思うことがある。本研究では、文生成の条件として文コードを用いることで、多様な翻訳を得ることを試みる。文章コードを抽出する方法として、構文情報を用いる方法と用いない方法の2種類がある。多様な翻訳を得るためには、複数の候補文をサンプリングし、それぞれの候補文に固有のコードを条件とする。実験によると、合理的な文のコードを用いた場合、サンプルされた翻訳ははるかに高い多様性スコアを示し、コードによる強い制約がある場合でも、翻訳品質はベースラインと同等であることがわかった。定性的な分析では，本手法が大幅に異なる構造を持つパラフレーズ翻訳を生成できることを示した．提案手法は、モデルの変更を必要としないため、既存の翻訳システムに容易に導入することができます。
NAS（Neural Architecture Search）は、新しいタスクのためのディープネットワークの設計を容易にすることを目的としています。既存の技術は、アーキテクチャ空間の探索と、最適なアーキテクチャの検証という2つの段階に依存しています。現在、NASアルゴリズムは、下流のタスクでの結果のみに基づいて比較されています。これは直感的ではあるが、探索戦略の有効性を明示的に評価することができない。本論文では、NASの探索フェーズを評価することを提案する。この目的のために、我々はNASの探索方針によって得られたソリューションの品質を、ランダムなアーキテクチャ選択の品質と比較する。我々は以下のことを発見した。(i)平均して、最先端のNASアルゴリズムは、ランダム・ポリシーと同様の性能を発揮する。(ii)広く使われている重み付け戦略は、NAS候補のランキングを劣化させ、真の性能を反映しないため、探索プロセスの有効性が低下する。我々の評価フレームワークは、ランダムなアーキテクチャよりも優れたアーキテクチャを一貫して発見するNAS戦略を設計するための鍵となると確信しています。
我々は、教師なしの画像間翻訳のための新しい手法を提案する。この手法は、新しい注目モジュールと新しい学習可能な正規化関数をエンド・ツー・エンドで組み込む。注目モジュールは、補助分類器によって得られた注目マップに基づいて、ソースドメインとターゲットドメインを区別する、より重要な領域に焦点を当てるように我々のモデルを導く。ドメイン間の幾何学的変化を扱うことができない従来の注意ベースの手法とは異なり、我々のモデルは全体的な変化を必要とする画像と大きな形状変化を必要とする画像の両方を翻訳することができます。さらに，新しいAdaLIN（Adaptive Layer-Instance Normalization）機能を用いることで，注意誘導モデルは，データセットに応じて学習したパラメータにより，形状やテクスチャの変化量を柔軟に制御することができます．実験結果は，ネットワークアーキテクチャとハイパーパラメータを固定した既存の最先端モデルと比較して，提案手法の優位性を示している．我々のコードとデータセットは、このhttpsのURLまたはこのhttpsのURLから入手可能です。
視覚と言語の推論には、視覚的な概念、言語のセマンティクス、そして最も重要なこととして、これら2つのモダリティ間の整合性と関係性の理解が必要です。そこで我々は、このような視覚と言語の関連性を学習するために、LXMERT（Learning Cross-Modality Encoder Representations from Transformers）フレームワークを提案する。LXMERTでは、物体関係エンコーダー、言語エンコーダー、クロスモダリティエンコーダーの3つのエンコーダーから構成される大規模なTransformerモデルを構築します。次に、我々のモデルに視覚と言語のセマンティクスを結びつける能力を与えるために、マスクされた言語モデリング、マスクされたオブジェクト予測（特徴回帰とラベル分類）、クロスモダリティマッチング、画像質問応答という5つの多様な代表的な事前トレーニングタスクを介して、大量の画像と文のペアでモデルを事前トレーニングします。これらのタスクは、イントラ・モダリティとクロス・モダリティの両方の関係を学習するのに役立ちます。我々のモデルは、事前に学習したパラメータを微調整した後、2つの視覚的質問応答データセット（VQAおよびGQA）において、最先端の結果を達成した。また、事前に学習したクロスモダリティモデルを、難易度の高い視覚的推論タスクであるNLVR2に適応することで、その汎用性を示し、従来の最良の結果を22%(54%→76%)改善しました。最後に、私たちの新しいモデルコンポーネントと事前学習戦略の両方が、この強力な結果に大きく貢献していることを証明するために、詳細なアブレーション研究を示し、異なるエンコーダに対するいくつかの注意喚起の視覚化も紹介します。コードと事前学習済みモデルは以下のURLで公開されています。
本論文では、視覚的な分類タスクのベクトル表現を提供し、それらのタスクの性質や関係性を推論するために用いる手法を紹介する。本研究では，基底ラベルとそのラベルに対して定義された損失関数を持つデータセットが与えられたとき，「プローブネットワーク」を介して画像を処理し，プローブネットワークのパラメータに関連するフィッシャー情報行列の推定値に基づいて埋め込みを計算する．これにより、クラスの数などの詳細に依存せず、クラスラベルのセマンティクスを理解する必要のない、固定次元のタスクの埋め込みが可能となる。本研究では、この埋め込みにより、異なる視覚タスク間の意味的・分類的関係に関する直感に合致するタスクの類似性を予測できることを示す（例：異なる種類の植物を分類するタスクは類似している）。また、新しいタスクに対して事前に学習された特徴抽出器を選択するというメタタスクに対して、このフレームワークの実用的な価値を示す。どの特徴抽出器が良い性能を発揮するかを予測することができる、埋め込みに関する指標を学習するための簡単なメタ学習フレームワークを紹介する。タスクを埋め込んだ特徴抽出器を選択することで、利用可能な最良の特徴抽出器に近い性能を得ることができるが、利用可能なすべての特徴抽出器を網羅的に学習・評価するよりもコストが大幅に削減される。
リカレントニューラルネットワーク（RNN）は，連続したデータの長期的な依存関係をモデル化するのに適しているが，時間的に逆伝播した誤差が消滅するか，指数関数的に爆発するため，学習が難しいことで知られている．多くの研究では、ゲート付きリカレントユニット、選択されたパラメトリック制約、スキップ結合などによってこの効果を緩和しようとしているが、我々は常微分方程式（ODE）の平衡多様体上で隠れた状態を進化させようとする新しい視点を開発した。本研究では、常微分方程式（ODE）の平衡多様体上で隠れた状態を進化させるという新しい視点を導入し、新しいRNNファミリーである ERNNs を提案する。(本研究では、勾配減衰や爆発の影響を克服し、平衡多様体上で進化するリカレントモデルを実現する新しいRNNファミリー、すなわちERNNsを提案する。我々は、平衡点が安定しており、離散化されたODEの固定点への収束が速いことを示す。さらに、ERNNは長期的な依存性を考慮しており、遠い過去のデータの有益な側面を効率的に呼び出すことができる。我々は、ERNNが、多くの困難なデータセットにおいて、3-10倍のスピードアップ、1.5-3倍のモデルサイズの縮小、そしてバニラRNNと同等の予測コストで、最先端の精度を達成することを示した。
現在の最新の画像セグメンテーション手法では、ディープCNN内で色、形、テクスチャの情報をまとめて処理することで、高密度な画像表現を行っています。しかし、これらの情報は、認識に関連する非常に異なるタイプの情報を含んでいるため、これは理想的ではないかもしれません。ここでは、セマンティックセグメンテーションのための新しい2ストリームCNNアーキテクチャを提案する。このアーキテクチャでは、形状情報を別の処理ブランチ、すなわち形状ストリームとして明示的に配線し、古典的ストリームと並行して情報を処理する。このアーキテクチャの鍵となるのは、2つのストリームの中間層を接続する新しいタイプのゲートである。具体的には、古典ストリームの高レベルの活性化を利用して、形状ストリームの低レベルの活性化をゲートすることで、ノイズを効果的に除去し、形状ストリームが関連する境界関連情報の処理のみに集中できるようにしている。これにより、画像レベルの解像度で動作する形状ストリームに、非常に浅いアーキテクチャを使用することができます。実験によると、このアーキテクチャは非常に効果的で、物体の境界付近をよりシャープに予測することができ、薄くて小さい物体に対する性能を大幅に向上させることができました。我々の手法は，Cityscapesベンチマークにおいて，マスク（mIoU）と境界（F-score）の両方の品質において最先端の性能を達成し，強力なベースラインに比べて2%と4%の向上を実現した．
メトリック学習は、学習タスクに最適な距離メトリックを使用しながら、サンプル間の類似性を測定することを目的としています。一般的に線形投影を使用するメトリック学習法は、非線形特性を示す実世界の問題を解決するには限界があります。この問題を解決するために、メトリック学習ではカーネルアプローチが利用されています。近年では、活性化関数を用いて非線形データに対するより良い解決策を提供するディープメトリック学習が、様々な分野の研究者の注目を集めている。本稿では，最近の研究を踏まえて，ディープ・メトリック学習の重要性とこの分野で扱われている問題を明らかにすることを目的とする。この分野で行われている研究に関して言えば、シャムネットワークやトリプレットネットワークにインスパイアされた既存の研究のほとんどは、ディープメトリック学習で共有重みを使用しながらサンプル間の相関を取るために一般的に使用されている。これらのネットワークの成功は、サンプル間の類似性の関係を理解する能力に基づいています。さらに、サンプリング戦略、適切な距離メトリック、およびネットワークの構造は、ネットワークモデルの性能を向上させるために研究者にとって挑戦的な要素です。本論文は、これらの要素を全体として体系的に分析・評価し、手法の定量的な結果を比較することで裏付けをとった初めての包括的な研究であり、重要であると考えられます。
機械学習の多くの応用分野では，学習時にタスク固有のラベルが少ない中で，学習時とは分布的に異なるテスト例に対してモデルが正確な事前予測を行うことが求められます．この課題に対する効果的なアプローチは、データが豊富な関連タスクでモデルを事前に学習し、その後、関心のある下流のタスクでモデルを微調整することです。事前学習は、多くの言語や視覚の分野で有効であるが、グラフのデータセットで事前学習を効果的に利用する方法はまだ未解決である。本論文では、グラフニューラルネットワーク（GNN）の事前学習のための新しい戦略と自己教師付きの手法を開発しました。我々の戦略の成功の鍵は、個々のノードやグラフ全体のレベルで表現力のあるGNNを事前学習し、GNNが有用なローカルおよびグローバルな表現を同時に学習できるようにすることである。私たちは、複数のグラフ分類データセットを用いて、事前学習を体系的に研究しました。その結果、グラフ全体または個々のノードレベルでGNNを事前学習するナイーブな戦略では、改善効果は限られており、多くの下流タスクで負の伝達を引き起こす可能性があることがわかりました。対照的に、我々の戦略では、負の伝達を回避し、下流のタスクでの一般化を大幅に改善し、ROC-AUCの絶対値を事前学習していないモデルよりも9.4%向上させ、分子特性予測とタンパク質機能予測で最先端の性能を達成しました。
因果推論は、構造解析に理論と予備知識を必要とするため、通常は予測モデリングの応用分野とは考えられません。しかし、現代の因果推論手法は、反実例や潜在的な結果へのアプローチを前提としており、最終的な推定ステップの前に処理ステップを含むことが多い。本論文の目的は (i)現代の因果推論法に有用な視点として、現代の因果推論法における予測の裏付けとなるステップの最近の出現を概観すること、(ii)因果推論における（「最良の予測」への1つのアプローチとしての）機械学習の役割を探求することである。因果推論の手法としては、傾向スコア、治療重みの逆確率（IPTW）、G計算、標的型最尤推定（TMLE）などを取り上げています。傾向スコアやTMLEには機械学習が多く使われていますが、G計算やIPTWの推定には利用が拡大する可能性があります。
指数関数に温度を導入し、ニューラルネットのソフトマックス出力層を高温の一般化に置き換えます。同様に、学習に使用する対数損失の対数を、低温の対数に置き換えます。2つの温度を調整することで、単層の場合にはすでに非凸である損失関数を作成します。ニューラルネットの最後の層を、ロジスティック損失の2つの温度による一般化で置き換えると、学習はノイズに対してよりロバストになります。簡単な設定で2つの温度を調整する効果を視覚化し、大規模なデータセットで本手法の有効性を示します。我々の手法はブレグマン発散に基づいており、Tsallis発散を用いた関連する2温度法よりも優れている。
変圧器ネットワークは、言語モデリングや機械翻訳において重要な進歩をもたらした。これらのモデルは、フィードフォワード層と自己注意層の2つの連続したモジュールを含んでいます。後者は、ネットワークが長期的な依存関係を捉えることを可能にし、Transformerの成功の鍵となる要素であると考えられています。この直観に基づいて、我々は注意層のみで構成される新しいモデルを提案する。より正確には、自己注意層を、フィードフォワード層と同様の役割を果たす永続的な記憶のベクトルで補強します。このベクターのおかげで、トランスフォーマーの性能を低下させることなく、フィードフォワード層を取り除くことができます。評価では、標準的な文字および単語レベルの言語モデリングベンチマークにおいて、我々のモデルがもたらす利点を示しています。
我々は、最適なアテンションスパンを学習することができる新しい自己注意メカニズムを提案する。これにより、Transformerで使用される最大コンテキストサイズを大幅に拡張しつつ、メモリフットプリントと計算時間の制御を維持することができます。本研究では、文字レベルの言語モデリングという課題において、8k文字の最大コンテキストを用いてtext8とenwiki8で最先端の性能を達成し、本アプローチの有効性を示した。
機械学習の飛躍的な進歩は、科学や社会を急速に変化させていますが、この技術の基本的な理解ははるかに遅れています。実際、この分野の中心的な考え方の一つである「偏りと分散のトレードオフ」は、現代の機械学習の現場で使用されている手法の観察された挙動とは相反するもののように見えます。偏りと分散のトレードオフは、モデルがアンダーフィッティングとオーバーフィッティングのバランスをとることを意味しています。しかし、現代では、ニューラルネットワークのような非常にリッチなモデルが、データに正確にフィットするように（つまり、補間するように）学習されています。古典的には、このようなモデルはフィットしすぎていると考えられますが、テストデータでは高い精度が得られることが多いのです。この明らかな矛盾は、機械学習の数学的基礎と実務者への関連性について疑問を投げかけている。この論文では、古典的な理解と現代的な実践を、統一された性能曲線の中で両立させている。この「二重降下」曲線は、補間点を超えてモデルの容量を増加させると性能が向上することを示すことで、教科書的なU字型のバイアス・分散トレードオフ曲線を包含する。私たちは、幅広い種類のモデルとデータセットにおいて、二重降下の存在と偏在性を示す証拠を示し、その出現のメカニズムを明らかにしました。このような機械学習モデルの性能と構造の関係は、古典的な分析の限界を明確にし、機械学習の理論と実践の両方に影響を与えます。
オープンドメインの会話エージェントを構築することは、困難な問題です。現在の評価方法は、ほとんどが静的な会話の事後判定であり、現実的な対話文脈での会話品質を捉えることができない。本論文では、人間によるインタラクティブな評価を調査し、その必要性を証明する。そして、モデルに依存せず、データセットにも依存しない新しい評価方法を紹介する。具体的には、対話システムが自分自身に話しかけるセルフプレイのシナリオを提案し、会話の軌跡に対して感情や意味的な一貫性などの指標の組み合わせを計算する。この指標は、これまでに知られている自動化された指標よりも、人間が評価したダイアログモデルの品質をよりよく捉えることができることを示し、有意なピアソン相関（r>.7, p<.05）を達成した。この新しい指標と対話評価の強みを、最先端の指標や静的な会話の人間評価と比較するために、一連のモデルを用いた拡張実験を行いました。その中には、最近の階層的な対話生成アーキテクチャを、発話レベルでの感情や意味的な知識の抽出によって新たに改善したモデルも含まれています。最後に、研究者が効率的にダイアログモデルを展開・評価できるように、我々が構築したインタラクティブな評価プラットフォームと収集したデータセットをオープンソース化した。
既存の敵対的防御のほとんどは、L_P敵対的攻撃に対する堅牢性を測定するだけです。しかし、敵対者がL_p個の小さな摂動のみを作り出す可能性は低いだけでなく、敵対者が固定されたままでいる可能性も低いのです。そのため、敵対的防衛手段は、予期しない幅広い攻撃に対して堅牢でなければなりません。私たちは、ImageNet-UAと呼ばれる新しい評価フレームワークを提案することで、研究と現実の間のこの矛盾を解決します。このフレームワークにより、研究コミュニティは、ImageNetモデルの頑健性を、学習時に遭遇しなかった攻撃に対してテストすることができます。ImageNet-UAでは、多様な攻撃方法を実現するために、合計4つの新しい攻撃方法を導入しました。また、従来のL_infによる頑健性評価は、ImageNet-UAと比較して、モデルの頑健性を狭く評価していることを示しています。ImageNet-UAを用いて現在の防御方法を評価したところ、予想外の攻撃に対する堅牢性が低いことが分かりました。ImageNet-UAの多様性と現実性により、訓練中に見られた攻撃を超えて一般化できる、より強固な防御策を開発できることを期待しています。
本論文では、Facebook FAIRのWMT19共有ニュース翻訳タスクへの参加について説明します。私たちは、英語<->ドイツ語、英語<->ロシア語の2つの言語ペアと4つの言語方向に参加しています。昨年に引き続き、我々のベースラインシステムは、サンプリングされたバックトランスレーションに依存するFairseqシーケンスモデリングツールキットでトレーニングされた大規模なBPEベースのトランスフォーマモデルです。本年度は、様々なビットテキストデータのフィルタリングスキームと、フィルタリングされた逆翻訳データの追加を試みました。また、ドメイン固有のデータを用いてモデルをアンサンブルして微調整し、ノイズの多いチャネルモデルのリランキングを用いてデコードしました。我々のシステムは、人間による評価キャンペーンの4つの方向すべてにおいて1位を獲得しました。En->Deでは、我々のシステムは、他のシステムや人間の翻訳を大幅に上回りました。また、WMT'18では4.5BLEUポイントの改善が見られました。
近年、機械学習(ML)の産業応用が盛んになり、関心が高まっています。そのため、MLエンジニアの需要は業界全体で高まっていますが、MLエンジニアの効率化は依然として基本的な課題です。機械学習の自動化（AutoML）は、データの前処理、特徴量のエンジニアリング、モデルの選択、ハイパーパラメータの最適化、予測結果の分析など、MLパイプラインにおける反復的な作業にかかる時間と労力を節約する方法として登場しました。本論文では、これらの作業を自動化することを目的としたAutoMLツールの現状を調査した。異なるデータセグメントの多くのデータセットでツールの様々な評価を行い、その性能を検証し、異なるテストケースでの長所と短所を比較する。
学習率ウォームアップヒューリスティックは、RMSpropやAdamなどの適応型確率最適化アルゴリズムにおいて、学習の安定化、収束の促進、汎化の向上に顕著な成果を上げている。ここでは、そのメカニズムを詳細に検討します。ウォームアップの理論を追求し、適応学習率の問題点(初期段階で問題となる大きな分散を持つこと)を特定し、ウォームアップが分散低減技術として機能することを提案し、仮説を検証するための経験的、理論的な証拠を提供します。さらに、適応学習率の分散を是正する項を導入することで、Adamの新しい変形版であるRAdamを提案します。画像分類、言語モデリング、ニューラル機械翻訳に関する広範な実験結果により、我々の直観を検証し、提案手法の有効性と頑健性を実証します。すべての実装は、このhttpsのURLから入手可能である。
本論文では，一般的な機械学習モデルであるジェネレーティブ・シーケンス・モデルにおいて，稀少またはユニークな学習データ・シーケンスが意図せずに記憶されてしまうリスクを定量的に評価するためのテスト手法について述べている．このようなモデルは、センシティブなデータ（例えば、ユーザーのプライベートメッセージのテキスト）に対して学習されることがあるため、この方法論は、深層学習の実践者がこのような記憶を最小限にする学習方法を選択できるようにすることで、プライバシーに貢献することができる。実験では、意図しない記憶は、深刻な結果をもたらす可能性のある、避けるのが困難な問題であることを示しています。具体的には、記憶を考慮せずに学習したモデルに対して、クレジットカード番号などのユニークな秘密の配列を抽出することができる、新しい効率的な手順を説明します。例えば、GoogleのSmart Composeは、数百万人のユーザーの電子メールメッセージを使って学習された商用のテキスト補完ニューラルネットワークですが、このニューラルネットワークのデータ露出を定量的に制限するために、本テスト戦略が実用的で使いやすい第一の防御策であることを示しています。 
深層強化学習（DRL）の一貫した再現性のある評価は簡単ではありません。アーケード学習環境（ALE）では、確率や最大許容プレイ時間などの環境パラメータを少し変更するだけで、パフォーマンスが大きく変わってしまいます。本研究では、ALEで学習した異なるエージェントを比較することの難しさについて議論する。再現性のある比較可能なDRLに向けて一歩前進するために、一般的な強化学習アルゴリズムのためのStandardized Atari BEnchmarkであるSABERを導入する。SABERの手法は、これまでの推奨手法を拡張したものであり、環境パラメータやトレーニング、テストの手順を完全に網羅しています。そして、SABERを用いて、現在の技術水準であるRainbowの評価を行います。さらに、人間の世界記録のベースラインを導入し、DRLの専門家や超人的なパフォーマンスに関するこれまでの主張は正確ではない可能性があることを主張します。最後に、RainbowをImplicit Quantile Networks (IQN)で拡張したRainbow-IQNを提案し、新たな最先端の性能を得ることができました。再現性を高めるためにソースコードを公開しています。
本論文では、Behaviour Suite for Reinforcement Learning（強化学習のための行動スイート）、略してbsuiteを紹介します。bsuiteは、強化学習（RL）エージェントの中核的な能力を調査するために慎重に設計された実験のコレクションであり、2つの目的があります。第一に、一般的で効率的な学習アルゴリズムを設計する上で重要な問題を捉えた、明確で有益かつスケーラブルな問題を収集すること。第二に、これらの共有ベンチマーク上でのエージェントのパフォーマンスを通じて、エージェントの動作を研究することです。この取り組みを補完するために、bsuite上の任意のエージェントの評価と分析を自動化するこのhttpのURLをオープンソースにしています。このライブラリは、RLの核心的な問題について再現性のあるアクセス可能な研究を促進し、最終的に優れた学習アルゴリズムの設計を可能にします。コードはPythonを使用しており、既存のプロジェクトで簡単に使用することができます。OpenAIのBaselinesやDopamineを使った例や、新しいリファレンスの実装も含まれています。将来的には、研究コミュニティからより多くの優れた実験を取り入れ、著名な研究者からなる委員会によるbsuiteの定期的なレビューを約束したいと考えています。
新しいタスクや新しいデータセットが次々と登場することで、興味深い方向性に向けたコミュニティの活発な研究が促進されますが、異なるデータセットで異なる分野の研究活動が活発に行われていることを把握することは、今後ますます困難になっていくと思われます。このような場合、科学的成果をリーダーボードのような形でまとめられる自動システムがあれば、コミュニティは大きな恩恵を受けることができる。本論文では、2つのデータセットを構築し、NLP論文からタスク、データセット、メトリック、スコアを自動的に抽出するフレームワーク（TDMS-IE）を開発し、リーダーボードの自動構築を目指す。実験の結果、我々のモデルはいくつかのベースラインを大差で凌駕することがわかった。我々のモデルは、例えばNLP領域において、リーダーボードを自動的に構築するための第一歩となる。
物質の発見は、エネルギー、環境、医療など様々な分野の緊急課題に取り組む上で決定的な意味を持ちます。化学分野では、従来の革新的な方法論は、分子構造から特性を最適化する高価で漸進的な戦略に依存しています。一方、逆アプローチは、特性と構造を対応させることで、新規の有用な化合物の設計を促進します。本章では、現在の深層生成モデルが逆化学的発見のパラダイムにどのように対応しているかを検証します。まず、初期の逆設計アルゴリズムを再検討します。次に、分子システムの生成モデルを紹介し、そのアーキテクチャと分子表現に基づいて分類します。この分類を用いて、文献で報告されている重要な分子生成スキームの進化と性能をレビューします。最後に、物質探索の最先端ツールとしての生成モデルの展望と課題を明らかにして結論とする。
物体検出の進歩は、研究コミュニティが未解決の課題に注目するデータセットによって可能になります。このプロセスは、単純な画像から複雑なシーンへ、そしてバウンディングボックスからセグメンテーションマスクへと我々を導いた。本研究では、LVIS（発音は「エルビス」）：Large Vocabulary Instance Segmentationのための新しいデータセットを紹介する。164k枚の画像から、1000以上のエントリーレベルのオブジェクトカテゴリの高品質なインスタンス・セグメンテーション・マスクを200万枚集める予定である。自然画像におけるカテゴリーのZipfian分布により、LVISは当然ながら、トレーニングサンプルが少ないカテゴリーのロングテールを持っています。最先端の深層学習法である物体検出法は、サンプル数が少ない領域では性能が低いことから、我々のデータセットは重要でエキサイティングな新しい科学的課題を提起していると考えています。LVISは、こちらのhttpのURLから入手できます。
機械が自然言語による命令に適切に応答できるようになれば、機械が役に立つ人の数を大幅に増やすことができます。最近では、ニューラルネットワークで学習した単語埋め込みの進歩により、体を持たないテキスト処理アルゴリズムが強化されており、体を持つ機械にも同様の有用性があることが示唆されている。ここでは、意味的に類似したword2vec符号化されたコマンドに類似した動作をするようにロボットを訓練することで、これを実現する方法を紹介する。これにより、ロボットは訓練後に、以前に聞いたことのない命令に対して適切に行動できるようになることを示す。最後に、このような運動と言語の類似性の調整は、ロボットの機械的構造によって促進されたり、妨げられたりすることを示します。これは、行動、言語、ロボットの構造の間の関係を見つけて利用する、将来の大規模な手法を示唆しています。
手動でオブジェクトの境界をトレースしてラベリングするのは手間のかかる作業です。Polygon-RNN++では、ポリゴンアノテーションをCNN-RNNアーキテクチャを用いてリカレントに生成し、人間によるインタラクティブな修正を可能にするPolygon-RNNを提案している。本研究では、グラフ畳み込みネットワーク（GCN）を用いてすべての頂点を同時に予測することで、Polygon-RNNの逐次的な性質を緩和する新しいフレームワークを提案する。このモデルはエンドツーエンドで学習されます。このモデルは、ポリゴンまたはスプラインによるオブジェクトのアノテーションをサポートしており、ラインベースのオブジェクトとカーブしたオブジェクトの両方のラベリングを効率的に行うことができます。Curve-GCNは、自動モードでは、強力なPSP-DeepLabを含む既存のすべてのアプローチを上回り、対話モードでは、Polygon-RNN++よりもはるかに効率的であることを示しています。我々のモデルは、自動モードでは29.3ms、インタラクティブモードでは2.6msで動作し、Polygon-RNN++の10倍、100倍の速度を実現しています。
近年，ポーズ推定が大きく進歩し，ポーズトラッキングへの関心が高まっています．その一方で，アルゴリズムやシステム全体の複雑さも増しており，アルゴリズムの分析や比較が難しくなっています．本研究では，シンプルで効果的なベースライン手法を提供しています．これらは、この分野の新しいアイデアを刺激し、評価するのに役立ちます。挑戦的なベンチマークで最先端の結果が得られます。コードはこのhttpsのURLで公開されます。
提示バイアスは、検索エンジンの暗黙のフィードバックから学習する際の重要な課題の一つであり、関連性シグナルを混乱させます。最近、反実仮想的なLTR（Learning-to-Rank）アプローチが、観察の傾向が分かっている場合に、提示バイアスを証明的に克服できることが示されたが、これらの傾向を効果的に推定する方法を示す必要がある。本論文では、手動での関連性判断、破壊的な介入、制限的な関連性モデルの仮定なしに、一貫した傾向推定値を生成する最初の方法を提案する。まず、複数の異なるランキング関数の歴史的なフィードバックログから特定のタイプの介入データを採取する方法を示し、このデータが位置ベースモデルにおける一貫した傾向性の推定に十分であることを示す。第二に、このデータを効果的に利用する新しい極値推定法を提案する。実証的な評価では，Arxiv Full-text SearchとGoogle Drive Searchという2つの実世界のシステムにおいて，この新しい推定量が優れた傾向推定値を提供することがわかった．また，シミュレーション研究においても，この手法は様々な設定に対して頑健であることがわかった．
収穫量予測，精密農業，自動収穫などの農業アプリケーションには，低コストのセンシングデバイスから作物の状態を推論できるシステムが必要です．手頃な価格のカメラとコンピュータビジョンを組み合わせた近距離センシングは、有望な代替手段と考えられており、自然画像における困難なパターン認識問題の代替手段として、畳み込みニューラルネットワーク（CNN）が登場した後に強化されました。果実栽培の監視と自動化を考えると、基本的な問題は、果樹園での個々の果実の検出、セグメンテーション、カウントです。ここでは、形、色、大きさ、密集度に大きなばらつきがあるワイン用ブドウについて、最新のCNNを使ってブドウの房を検出し、分割し、追跡できることを示します。トレリスシステムを用いたブドウ園で撮影された408個のブドウの房を含むテストセットにおいて、インスタンスセグメンテーションのF1-スコアは0.91に達しました。また、果樹園の列を記録したビデオシーケンスに沿ってクラスターを識別し、追跡できることを示しました。さらに、300枚の画像に適切にアノテーションされたブドウの房を含む公開データセットと、自然画像中の複雑なオブジェクトをセグメンテーションするための新しいアノテーション手法を紹介します。画像中の農業パターンのアノテーション、学習、評価、追跡のためのパイプラインは、さまざまな作物や生産システムに適用することができます。このパイプラインは、様々な作物や生産システムに適用することができ、農業や環境に関する様々なアプリケーションのためのセンシングコンポーネントの開発に利用することができます。
データが技術的・経済的成長の原動力となる中、アルゴリズムによる予測や意思決定におけるデータの価値をいかに定量化するかが根本的な課題となっています。例えば、ヘルスケアや消費者市場では、個人が生成したデータに対して報酬を支払うべきだと提案されていますが、個人のデータに対する公平な評価は明確ではありません。本研究では、教師付き機械学習の文脈でデータ評価に取り組むための原理的なフレームワークを開発する。予測値を生成するためにn個のデータポイントで学習された学習アルゴリズムが与えられたとき、予測値の性能に対する各学習データの価値を定量化するための指標として、データシェイプリを提案する。データシャプレー値は、データ評価を公平に行うためのいくつかの自然な特性を一意に満たす。我々は、ニューラルネットワークを含む複雑な学習アルゴリズムが大規模なデータセットで学習される実用的な環境において、データ・シャプレー値を効率的に推定するために、モンテカルロ法と勾配ベースの手法を開発した。公平であることに加えて、生物医学、画像、合成データを対象とした広範な実験により、データ・シャプレーには他にもいくつかの利点があることが実証された。1) 与えられた学習課題に対して、どのデータがより価値があるかを洞察する上で、一般的なリーブオンアウトやレバレッジスコアよりも強力である。2) 低いシャプレー値のデータは、外れ値や破損を効果的に捉えることができる。
本研究では、ブラックボックス環境で敵対的な画像を構築するための非常にシンプルな方法を提案する。ホワイトボックスのシナリオとは対照的に、ブラックボックスの敵対的な画像を構築するには、クエリの予算という追加的な制約があり、効率的な攻撃は現在も未解決の問題です。本研究では，信頼度が連続的に変化するという穏やかな仮定のもと，次のような単純な反復原理を用いて，非常に効率的なアルゴリズムを開発した．すなわち，あらかじめ定義された正規基底からランダムにベクトルをサンプリングし，それを対象画像に加減するというものである．そのシンプルさにもかかわらず，提案された手法はターゲットを絞らない攻撃にもターゲットを絞る攻撃にも使用することができ，どちらの設定においてもこれまでにない問い合わせ効率を実現している．我々は、Google Cloud Vision APIを含むいくつかの実世界の設定で、我々のアルゴリズムの有効性と効率性を実証した。特に、本アルゴリズムは非常に高速であり、実装に必要なPyTorchコードは20行以下であることから、今後のブラックボックス攻撃の強力なベースラインとなるべきであると主張しています。
配列のソートは、機械学習における基本的なルーチンであり、ランクベースの統計、累積分布関数（CDF）、クオンタイルを計算したり、最も近い隣人やラベルを選択したりするのに使用されます。しかし、ソート機能は断片的に一定であるため（ベクトルのエントリが無限に変化しても、ベクトルのソート順列は変化しない）、バックプロパゲートするための勾配情報を持たない。我々は、アルゴリズム的に微分可能な要素のソートのフレームワークを提案する。ソートは、入力値から事前に定義されたソートされた値の配列（例：入力配列がn個の要素を持つ場合、1,2,n）への最適輸送（OT）問題の特定のインスタンスとして見ることができるという事実を利用している。このリンクを基に，対象となる事前にソートされた配列のサイズと重みを変化させることで，一般化されたCDFと分位点演算子を提案する．これは、OTのいわゆるKantorovich定式化を使用することになるので、これらの量をK-sorts、K-CDFs、K-quantilesと呼ぶ。我々は、OT問題にエントロピー正則化を加えることで微分可能なアルゴリズムを復元し、いくつかのSinkhorn反復を用いて近似する。これらの演算子をS-sorts, S-CDFs, S-quantilesと呼び、様々な学習環境で使用する。最近提案されたneuralsort [Grover et al. 2019]に対するベンチマークを行い、分位点回帰への応用を提案し、最先端の性能を発揮するtop-k精度の微分可能な定式化を紹介する。
依存木は、テキスト内のエンティティ間の関係を抽出するのに有用であることが証明されている豊富な構造情報を伝える。しかし、依存性ツリーから無関係な情報を無視して、関連する情報を効果的に利用する方法は、依然として困難な研究課題である。関連する部分依存関係構造を選択するためにルールベースのハードプルーニング戦略を採用している既存のアプローチは、必ずしも最適な結果を得られるとは限らない。本研究では、完全な依存関係ツリーを直接入力とする新しいモデル、Attention Guided Graph Convolutional Networks (AGGCNs)を提案する。このモデルは、関係性抽出タスクに有用な関連サブ構造に選択的にアテンションする方法を自動的に学習するソフトプルーニングアプローチとして理解することができる。本研究では、文横断的なN-ary関係の抽出や、大規模な文レベルの関係抽出など、様々なタスクにおける広範な結果から、本モデルが完全依存木の構造情報をより有効に活用でき、従来のアプローチよりも大幅に良い結果が得られることを示した。
ドメインオントロジーへの過度の依存と、ドメイン間での知識共有の欠如は、対話状態の追跡における2つの現実的な問題であり、まだあまり研究されていない。既存のアプローチでは、推論時に未知のスロット値を追跡することができず、新しいドメインへの適応が困難な場合が多い。本論文では、コピーメカニズムを用いて発話から対話状態を生成し、学習時に遭遇しなかった(ドメイン、スロット、値)のトリプレットを予測する際に、知識の伝達を容易にするTransferable Dialogue State Generator (TRADE)を提案する。このモデルは、発話エンコーダー、スロットゲート、状態生成器から構成されており、ドメイン間で共有されている。実証実験の結果，TRADEは，人間と人間の対話データセットであるMultiWOZの5つのドメインにおいて，48.62%という最先端のジョイントゴール精度を達成した．さらに、未見のドメインに対するゼロショットおよび数ショットの対話状態の追跡をシミュレーションすることで、その転送能力を示した。TRADEは、ゼロショットのうちの1つのドメインで60.58%の共同目標精度を達成し、既に訓練されたドメインを忘れることなく、数ショットのケースに適応することができる。
言語モデルの事前学習は大幅な性能向上をもたらしたが、異なるアプローチ間での慎重な比較は困難である。学習は計算量が多く、サイズの異なるプライベートなデータセットで行われることが多く、また、これから示すように、ハイパーパラメータの選択が最終的な結果に大きな影響を与える。我々は、多くの主要なハイパーパラメータとトレーニングデータサイズの影響を慎重に測定したBERT事前トレーニング（Devlin et al.、2019）の複製研究を発表する。我々は、BERTが大幅にアンダートレーニングされており、その後に発表されたすべてのモデルの性能と一致またはそれを上回ることができることを発見しました。我々の最高のモデルは、GLUE、RACE、SQuADにおいて最先端の結果を達成しました。これらの結果は、これまで見過ごされてきた設計上の選択の重要性を浮き彫りにするとともに、最近報告された改善点の原因について疑問を投げかけています。私たちはモデルとコードを公開しました。
バッチ正規化を用いたディープネットワークの学習は、ベイジアンモデルにおける近似的な推論と同等であることを示しました。さらに、この発見により、ネットワークや学習手順に変更を加えることなく、従来のアーキテクチャを用いてモデルの不確実性を意味のある形で推定できることを示します。我々のアプローチは、様々なタスクに関する一連の実証実験において、不確実性の質を測定することで徹底的に検証されている。その結果、ベースラインを統計的に有意に上回り、最近のベイジアンアプローチに匹敵する性能を示しました。
深層学習の研究に必要な計算量は、数カ月ごとに倍増しており、結果として2012年から2018年にかけて30万倍になったと推定されています[2]。これらの計算は、驚くほど大きなカーボンフットプリントをもたらしている[38]。皮肉なことに，深層学習は，エネルギー効率が著しく高い人間の脳から着想を得たものである．さらに，計算にかかる経済的コストのために，大学や学生，研究者，特に新興国の人々が深層学習の研究に取り組むことが難しくなっています．本ポジションペーパーでは、効率性を精度や関連する指標と並んで研究の評価基準とすることで、現実的な解決策を提唱しています。さらに、モデルの開発、学習、実行にかかる金銭的なコスト、つまり「プライスタグ」を報告することで、より効率的な手法を検討するためのベースラインを提供することを提案します。私たちの目標は、AIをより環境に優しく、より包括的なものにすることであり、ノートパソコンを持っている優秀な学部生なら誰でも高品質な研究論文を書けるようにすることです。グリーンAIは、アレン・インスティテュートの新たな取り組みです。
生成モデルの飛躍的な進歩により、人工的にレンダリングされた顔や動物などの自然界の物体は、写真に近い品質になりました。しかし、このような進歩にもかかわらず、視覚や画像をより高度に理解するには、対象物を徹底的にモデル化するのではなく、対象物の側面を最もよく要約する高レベルの属性を特定する必要があります。本研究では、ベクターグラフィックスの逐次生成モデルを構築することで、フォントの描画プロセスをモデル化することを試みる。このモデルは、潜在的な表現を体系的に操作し、スタイル伝搬を行うことができる画像のスケール不変な表現を提供するという利点がある。我々は、フォントの大規模なデータセットでこれらの結果を実証し、このようなモデルがいかにこのデータセットの統計的依存性と豊かさを捉えているかを強調する。我々のモデルは、グラフィックデザイナーがフォントデザインを容易にするためのツールとして利用できることを想定しています。
Argument Reasoning Comprehension TaskにおけるBERTのピーク性能77%が、訓練を受けていない人間の平均的なベースラインよりもわずか3ポイント低いことに驚きました。しかし、この結果は、データセット内の偽の統計的な手掛かりを利用することで完全に説明できることを示しています。この手がかりの性質を分析し、さまざまなモデルがこの手がかりを利用していることを示しました。この分析は、すべてのモデルがランダムな精度を得ることができる敵対的なデータセットの構築に役立ちます。このデータセットは、議論の理解度をより強固に評価することができ、今後の研究の基準として採用されるべきものである。
本論文では、SGNS（Skip-gram Model with Negative Sampling）のインクリメンタル・トレーニング戦略を、経験と理論の両面から検討する。SGNSを含む既存のニューラルワードエンベディングの手法は、マルチパスアルゴリズムであるため、インクリメンタルなモデル更新を行うことができない。この問題を解決するために、我々はSGNSのシンプルなインクリメンタル拡張を提示し、その有効性を実証するために徹底した理論的分析を行う。実証実験により、理論的分析の正しさと、インクリメンタルアルゴリズムの実用的な有用性を示した。
本論文では、対象物を正しく参照するだけでなく、人間が対象物を素早く見つけることができる参照表現の生成を扱う。対象が相対的に目立たなくなると、参照される対象を特定すること自体が困難になる。しかし、これまでの研究では、人間が理解しやすいかどうかを無視して、対象物を正しく参照する文章はすべて等しく優秀であると考えられてきました。対象が顕著でない場合、人間は対象の周囲にある顕著な文脈との関係を利用して、聞き手が対象をよりよく理解できるようにします。このように人間のアノテーションから情報を引き出すために、我々のモデルはターゲットと環境から情報を抽出するように設計されています。また、理解しやすい文章とは、人間が正しくかつ素早く理解できる文章であると考えています。これを、人間が参照した対象物の位置を特定するのに要した時間とその精度を用いて最適化しました。本システムを評価するために，Grand Theft Auto V (GTA V)から画像を取得し，対象を人物に限定した新たな参照表現データセットを作成した．実験結果は，我々のアプローチの有効性を示している．我々のコードとデータセットは、こちらのhttps URLで公開されています。
グラフ表現学習の目的は，グラフの各頂点を低次元のベクトル空間に埋め込むことである．既存のグラフ表現学習法は、グラフの基本的な接続性分布を学習する生成モデルと、頂点のペア間のエッジの存在確率を予測する識別モデルの2つに分類される。本稿では、生成モデルと識別モデルがゲーム理論的なミニマックスゲームを行うという、上記2つのクラスの手法を統合した革新的なグラフ表現学習フレームワークであるGraphGANを提案する。具体的には、与えられた頂点に対して、生成モデルは、他のすべての頂点に対する真の接続性分布を適合させようとし、識別モデルを欺くために「偽の」サンプルを生成する。一方、識別モデルは、サンプルされた頂点がグランドトゥルースからのものか、生成モデルによって生成されたものかを検出しようとする。この2つのモデルの競合により、どちらも交互に繰り返し性能を上げることができます。さらに、生成モデルの実装を考えると、従来のソフトマックス関数の限界を克服するために、新しいグラフソフトマックスを提案する。このソフトマックスは、正規化、グラフ構造の認識、および計算効率という望ましい特性を満たすことが証明されている。実世界のデータセットを用いた広範な実験により、GraphGANは、リンク予測、ノード分類、推薦などの様々なアプリケーションにおいて、最先端のベースラインを上回る実質的な利益を達成することを実証しています。
深層学習における重要な目標は、入力データの汎用的で高レベルな特徴表現を学習することです。しかし、標準的なネットワークの表現には欠点があり、この目標を完全に実現することができないようです。本研究では、ロバストな最適化が、ディープニューラルネットワークが学習する特徴にプライアを強制するためのツールとして再構成できることを示しています。その結果、ロバストモデルによって学習された表現は、前述の欠点を解決し、入力のハイレベルなエンコーディングの学習に向けて大きく前進することがわかりました。特に、これらの表現は近似的に反転可能であり、顕著な入力特徴を直接視覚化して操作することができる。さらに、この結果は、学習した表現を改善するための有望な手段として、敵対的頑健性を示している。これらの結果を再現するための我々のコードとモデルは、このhttpsのURLから入手できます。
反転可能な正規化フローベースの分子グラフ生成モデルであるGraphNVPを提案しています。グラフの生成を、(i)隣接テンソルの生成と(ii)ノード属性の生成の2つのステップに分解します。この分解により、グラフ構造のデータに対する正確な尤度最大化と、2つの新しい可逆フローが得られる。我々のモデルは、重複する分子がほとんどない有効な分子グラフを効率的に生成することを経験的に示した。さらに、学習した潜在空間を利用して、望ましい化学的特性を持つ分子を生成できることを確認しました。
2D画像のピクセルを、対応する3Dオブジェクトのグローバルコンテキストに局所的に合わせる、非常に効果的な暗黙的表現であるPixel-aligned Implicit Function (PIFu)を紹介する。PIFuを用いて、1枚の画像、あるいはオプションで複数の入力画像から3D表面とテクスチャの両方を推測することができる、非常に詳細な衣服を着た人間をデジタル化するためのエンド・ツー・エンドの深層学習手法を提案します。髪型や衣服などの非常に複雑な形状や、それらのバリエーションや変形を統一的にデジタル化することができます。PIFuは、3D深層学習に用いられる既存の表現と比較して、人物の後ろ姿など、ほとんど見えていない領域を含む高解像度の面を生成することができます。特に、ボクセル表現とは異なりメモリ効率が良く、任意のトポロジーを扱うことができ、得られるサーフェイスは入力画像と空間的に整列しています。さらに、これまでの技術は単一の画像または複数のビューを処理するように設計されていたが、PIFuは任意の数のビューに自然に拡張することができる。我々は、DeepFashionデータセットから得られた実世界の画像を用いて、高解像度でロバストな再構成を実証した。このデータセットには、様々な種類の難しい服が含まれている。我々の手法は、一般的なベンチマークで最先端の性能を達成し、1枚の画像から服を着た人間をデジタル化する先行研究よりも優れています。
リカレント・ニューラル・ネットワークは、長年にわたりシーケンス・モデリングの有力な選択肢となっています。しかし、リカレントニューラルネットワークは、非常に長期的な依存関係を捉えることができないことと、逐次的な計算手順を並列化することができないという2つの問題を抱えています。そのため、最近では、畳み込みや注目操作を利用した非リカレントシーケンスモデルが数多く提案されている。特に、Transformerに代表される複数ヘッドの注目を用いたモデルは、様々なシーケンスモデリングタスクにおいて、長期的な依存関係を捉えることに極めて有効であることが実証されている。しかし、これらのモデルは、シーケンスの局所的な構造をモデル化するために必要なコンポーネントが不足しており、効果が限定的な位置埋め込みに大きく依存しているため、設計に多大な労力を要していた。本論文では、RNNとマルチヘッドアテンションメカニズムの両方の利点を享受しながら、それぞれの欠点を回避するR-Transformerを提案する。提案モデルは，位置埋め込みを用いずに，シーケンスの局所的な構造とグローバルな長期依存性の両方を効果的に捉えることができる．R-Transformerを評価するために、様々な分野のデータを用いた広範な実験を行い、その結果、R-Transformerはほとんどのタスクにおいて最先端の手法を大差で上回ることがわかった。その結果、R-Transformerはほとんどのタスクにおいて最先端の手法を大幅に凌駕していることが分かりました。このコードはウェブサイトで公開されています。
異なるレイアウトは，同じグラフの異なる側面を特徴づけることができます．そのため，グラフの「良い」レイアウトを見つけることは，グラフの可視化にとって重要な課題です．実際には、ユーザーは、目的に合ったレイアウトを見つけるまで、さまざまな手法を用いたり、パラメータ設定を変えたりして、複数のレイアウトでグラフを可視化することが多い。しかし、このような試行錯誤は、往々にして時間のかかる作業です。そこで、本研究では、深層生成モデルを用いて、グラフを多様なレイアウトで体系的に可視化する手法を提案する。我々は、レイアウト例のコレクションからモデルを学習するために、エンコーダ-デコーダアーキテクチャを設計した。特に，ユーザーが簡単に探索してさまざまなレイアウトを生成できるように，2次元の潜在空間を構築するようにモデルを学習している．本研究では，生成されたレイアウトの定量的および定性的な評価を通じて，本アプローチを実証する．その結果，本研究で開発したモデルは，単に学習例を記憶するだけでなく，グラフレイアウトの抽象的な概念を学習し，一般化することができることがわかった．本論文は、機械学習モデルが、手動で定義されたヒューリスティックスを使わずに、例題からグラフの可視化を学習するという、グラフの可視化に対する根本的に新しいアプローチを提示しています。
本論文では、ニューラルネットワークに簡単に組み込むことができる構造化メモリを導入しています。このメモリは設計上非常に大きく、わずかな計算オーバーヘッドで最大10億個のパラメータを格納することができ、アーキテクチャの容量を大幅に向上させることができます。その設計とアクセスパターンはプロダクトキーに基づいており、高速かつ正確な最近傍探索が可能です。同じ計算量を維持しながらパラメータ数を増やすことができるため、システム全体として、トレーニング時とテスト時の両方で、予測精度と計算効率の間でより良いトレードオフを実現することができます。このメモリ層のおかげで、非常に大規模な言語モデリングのタスクに取り組むことができます。実験では、最大300億語のデータセットを対象とし、メモリ層を最新のトランスフォーマーベースのアーキテクチャに接続しました。特に、わずか12層のメモリ拡張モデルは、24層のベースライン・トランスフォーマー・モデルよりも性能が高く、推論時には2倍の速度を示すことが分かりました。再現性を高めるために、コードを公開しています。
これは、密な性能レベルを達成しながら、学習中に疎な重みを維持する深層ニューラルネットワークの学習を加速するものです。スパース・モメンタムは、指数関数的に平滑化された勾配（モメンタム）を用いて、誤差を効率的に低減する層と重みを特定するアルゴリズムである。疎な運動量は、各層の平均運動量の大きさに従って、刈り込まれた重みを層間で再分配します。また，層内では，ゼロ値の重みの運動量の大きさに応じて，重みを増やしていく．本研究では，MNIST，CIFAR-10，ImageNetにおいて最先端のスパース性能を実証し，他のスパースアルゴリズムと比較して，平均誤差を相対的に8%，15%，6%減少させた．さらに、スパースモーメンタムは、高密度のパフォーマンスレベルを確実に再現する一方で、最大で5.61倍の高速なトレーニングを提供することを示した。今回の分析では、ネットワークの深さや大きさに応じて、運動量の再配分と成長のメリットが大きくなることをアブレーションで示しました。さらに、スパース・モメンタムはハイパーパラメータの選択に影響されないことがわかり、スパース・モメンタムがロバストで使いやすいことを示唆しています。
我々は、スパース学習と呼んでいるものの可能性を示している。つまり、密な性能レベルを達成しながら、学習中にスパースな重みを維持するディープニューラルネットワークのトレーニングを加速することができる。スパースモメンタムは、指数関数的に平滑化された勾配（モメンタム）を用いて、誤差を効率的に低減する層や重みを特定するアルゴリズムで、これを開発しました。疎な運動量は、各層の平均運動量の大きさに従って、刈り込まれた重みを層間で再分配します。また，層内では，ゼロ値の重みの運動量の大きさに応じて，重みを増やしていく．本研究では，MNIST，CIFAR-10，ImageNetにおいて最先端のスパース性能を実証し，他のスパースアルゴリズムと比較して，平均誤差を相対的に8%，15%，6%減少させた．さらに、スパースモーメンタムは、高密度のパフォーマンスレベルを確実に再現する一方で、最大で5.61倍の高速なトレーニングを提供することを示した。今回の分析では、ネットワークの深さや大きさに応じて、運動量の再配分と成長のメリットが大きくなることをアブレーションで示しました。さらに、スパース・モメンタムはハイパーパラメータの選択に影響されないことがわかり、スパース・モメンタムがロバストで使いやすいことを示唆しています。
マルチタスクのニューラルネットワークを、シングルタスクのニューラルネットワークよりも優れた性能を持つように訓練することは困難な場合があります。この問題を解決するために、シングルタスクモデルがマルチタスクモデルを教える知識蒸留法を提案しています。この学習を教師アニーリングで強化する。教師アニーリングは、モデルを蒸留から教師付き学習へと徐々に移行させる新しい手法であり、マルチタスクモデルがシングルタスクの教師を凌駕するのに役立つ。GLUEベンチマークでBERTをマルチタスクで微調整することで、本手法を評価しました。私たちの手法は、標準的なシングルタスクおよびマルチタスクの学習よりも一貫して向上しています。
最近の研究で示されているように、深層ニューラルネットワークは、ランダムにラベル付けされたデータに完全に適合することができますが、ホールドアウトされたデータでは非常に低い精度となります。この現象は、クロス・エントロピーなどの損失関数が、一般化の信頼できる指標ではないことを示しています。このことから、学習データとネットワークのパラメータから、どのようにして汎化ギャップを予測すべきかという重要な問題が生じる。本論文では，そのような尺度を提案し，それがどの程度まで汎化ギャップを予測できるかについて広範な実証研究を行った．我々の尺度は，決定境界に対する訓練点の距離であるマージン分布の概念に基づいている．その結果、深層ネットワークの複数の層でマージン分布を使用する必要があることがわかった。CIFAR-10およびCIFAR-100データセットにおいて，我々の提案した指標は，一般化ギャップと非常に強い相関があることがわかった．さらに、次の他の要因も重要であることがわかった：スケール独立性のためにマージン値を正規化すること、マージン（決定境界への最も近い距離）だけではなくマージン分布の特徴を使用すること、線形空間ではなく対数空間で作業すること（和ではなくマージンの積を効果的に使用する）。この手法は、どのようなアーキテクチャのフィードフォワード・ディープネットワークにも簡単に適用することができ、より優れた汎化を可能にする新たな学習損失関数を示す可能性があります。
逆方向に学習された生成モデル（GAN）は、最近、画像合成の分野で目覚ましい成果を上げている。しかし、教師なしの表現学習にGANを使用することで初期の成功を収めたにもかかわらず、自己教師法に基づくアプローチに取って代わられてしまった。本研究では、画像生成品質の向上が、表現学習性能の大幅な向上につながることを示しています。我々のアプローチであるBigBiGANは、最先端のBigGANモデルをベースに、エンコーダを追加し、識別器を変更することで表現学習を拡張している。我々は、これらのBigBiGANモデルの表現学習および生成能力を広範囲に評価し、これらの生成ベースのモデルが、ImageNet上の教師なし表現学習および無条件画像生成において最先端を達成していることを示した。画像生成器とエンコーダーを含む、事前にトレーニングされたBigBiGANモデルは、TensorFlow Hub（https://tfhub.dev/s?publisher=deepmind&q=bigbigan）で入手可能です。
ハースストーンのような複雑性の高い戦略的なゲームが増え続けると、そのバランスを取るのは複雑な作業になります。戦略を多様化し、カスタマイズできるようにするという目標が、結果的に繊細な複雑なシステムを生み出しています。2000枚以上のカードを調整して、既存の環境を壊すことなく望ましい結果を生み出すことは、手間のかかる課題です。この論文では、ハースストーンにおいて、既存のカードの変更が戦略に与える影響について考察します。異なる戦略でプレイされる様々なデッキの対戦における勝率を分析することで、異なるカードの改善や悪化のために変更が加えられる前と後のパフォーマンスを比較することを提案します。そして、進化論的アルゴリズムを用いて、デッキの勝率を50％と同等に近づけるためのカード属性の変更の組み合わせを探索します。次に、進化的アルゴリズムを多目的ソリューションに拡張し、既存のカードへの変更とその結果としての混乱を最小限に抑えながら、この結果を求めます。最後に、バランス変更の対象となるカードを決定するためのヒューリスティックな指標を提案し、評価します。
リージョナル・ドロップアウト戦略は、畳み込みニューラルネットワーク分類器の性能を向上させるために提案されてきました。リージョナル・ドロップアウト戦略は、物体の識別性の低い部分（例えば、人物の頭部ではなく脚部）に注目するようにモデルを誘導することで、ネットワークの汎化能力や物体の定位能力を向上させるのに有効であることが証明されています。一方、リージョナル・ドロップアウトの現在の手法では、黒のピクセルやランダムなノイズのパッチを重ねることで、トレーニング画像の情報量の多いピクセルを削除しています。このような除去は、情報の損失や学習時の非効率性につながるため、望ましくない。そこで我々は，カットミックス法を提案する．パッチを切り取って訓練画像に貼り付け，そのパッチの面積に比例して，グランドトゥルースラベルを混ぜるのである．CutMixは、CIFARやImageNetの分類タスクや、ImageNetの弱い教師付きローカリゼーションタスクにおいて、学習ピクセルを効率的に利用し、Regional Dropoutによる正則化効果を維持することで、最先端の拡張戦略を一貫して凌駕している。さらに、これまでの拡張手法とは異なり、CutMixで学習したImageNet分類器を事前学習モデルとして使用した場合、Pascal検出およびMS-COCO画像キャプション・ベンチマークにおいて一貫した性能向上が得られます。また，CutMixは，入力の破損に対するモデルのロバスト性と，配信外の検出性能を向上させることを示している．ソースコードと学習済みモデルは，この https URL から入手できます．
条件付密度推定は，経験的な観測データが与えられたときに，条件変数\mathbf{x}と従属変数\mathbf{y}の間の統計的な関係を，それらの条件付き確率p(\mathbf{y}|\mathbf{x})をモデル化することで捉えることを目的としています．本論文では、ニューラルネットワークを用いた金融アプリケーションのための条件付き密度推定のベストプラクティスを、数学的な洞察と経験的な評価に基づいて開発しています。特に、ノイズの正則化とデータの正規化のスキームを導入することで、オーバーフィッティング、初期化、超パラメータ感度の問題を緩和する。提案手法を一般的なセミパラメトリックおよびノンパラメトリックの密度推定量と比較し、シミュレーションデータおよびEuro Stoxx 50データを用いた様々なベンチマークでその有効性を確認し、優れた性能を示した。我々の方法論は、高次モーメント、クオンタイル、非線形リターン変換の統計的期待値の高品質な推定量を、リターン・ダイナミックに関する仮定をほとんど用いずに得ることができる。
AI技術は、障害者（PWD）の生活に劇的な影響を与える可能性があります。実際、聴覚障害者のためにビデオに字幕を付けることができる自動音声認識ツールや、言語障害者や認知障害者のためにコミュニケーションを拡張することができる言語予測アルゴリズムなど、最先端のAIシステムの多くは、PWDの生活を向上させることが動機となっています。しかし、広く普及しているAIシステムは、PWDに対して適切に機能しない場合や、最悪の場合、PWDを積極的に差別する場合があります。このようなPWD向けAIの公平性に関する考察は、これまでほとんど注目されていませんでした。このポジションペーパーでは、いくつかのAI技術カテゴリーについて、その設計、開発、テストに注意を払わなければ、特定の障害者にどのような影響を与えるかについて、潜在的な懸念事項を明らかにします。様々なクラスのAIが様々なクラスの障害者とどのように相互作用するかについてのこのリスク評価は、データを収集し、これらの仮説を検証し、よりインクルーシブなアルゴリズムを構築するために必要な将来の研究のロードマップを提供することを意図しています。
合成ビジュアルデータは、プライバシーやバイアスなどの倫理的な問題を回避しつつ、実質的に無限の多様性と豊富なラベルを提供することができます。しかし、多くのタスクにおいて、合成データでトレーニングされた現在のモデルは、実データへの一般化が不十分である。人間の3Dポーズ推定のタスクは、このsim2real問題の特に興味深い例である。なぜなら、学習ベースのアプローチは、実際のトレーニングデータがあれば、それなりの性能を発揮するが、ラベル付きの3Dポーズを得ることは非常に難しく、スケーラビリティに限界があるからである。本論文では、合成RGB画像で学習した場合には性能が低い標準的なニューラルネットワーク手法でも、データを前処理して人物の動きに関する手がかり（特にオプティカルフローや2Dキーポイントの動き）を抽出すると、性能が向上することを示している。したがって、我々の結果は、ビデオが利用可能な場合には、モーションは、sim2realのギャップを埋めるための簡単な方法であることを示唆している。本研究では，3Dポーズ推定の最新のベンチマークである「3D Poses in the Wild」データセットを用いて評価を行った．このデータセットでは，SURREALデータセットの合成人物のみを用いて学習を行ったにもかかわらず，実際の3Dシーケンスを用いて学習した最先端の手法と同等の3Dメッシュを完全に復元することができた．
従来、モデルベース強化学習（MBRL）は、環境のダイナミクスに関するグローバルモデルを学習することを目的としています。優れたモデルがあれば、計画アルゴリズムが多種多様な行動を生成し、多様なタスクを解決できる可能性があります。しかし、複雑な力学系の正確なモデルを学習することは難しく、また、モデルが学習された状態の分布以外ではうまく一般化できない可能性がある。本研究では、モデルベースの学習と、モデルベースのプランニングを容易にするプリミティブのモデルフリー学習を組み合わせる。この目的のために、我々は「結果を予測しやすいスキルをどのようにして発見できるか」という質問に答えることを目指している。我々は、予測可能な行動の発見とそのダイナミクスの学習を同時に行う教師なし学習アルゴリズム、Dynamics-Aware Discovery of Skills (DADS)を提案する。この手法は、理論的には連続的なスキル空間を利用することができ、高次元の状態空間であっても無限に多くの行動を学習することができる。学習された潜在空間でのゼロショットプランニングは、標準的なMBRLやモデルフリーのゴール条件付きRLを大幅に上回り、疎な報酬のタスクを扱うことができ、教師なしのスキル発見のための先行的な階層的RL手法を大幅に改善することを実証した。
3D点群が複数のビジョンやグラフィックアプリケーションで選択される表現になるにつれ、高解像度で高忠実度の点群を合成または再構築する能力が重要になっています。近年、点群の識別タスクにおいて深層学習モデルが成功しているが、点群の生成は依然として困難である。本論文では、3D点群を分布の分布としてモデル化することで、3D点群を生成する原理的な確率論的フレームワークを提案する。具体的には、分布の2レベルの階層を学習し、第1レベルは形状の分布、第2レベルは形状を与えられた点の分布とする。この定式化により、形状のサンプリングと、形状からの任意の数の点のサンプリングの両方が可能になります。PointFlowと名付けられた我々の生成モデルは、分布の各レベルを連続的な正規化フローで学習する。正規化フローの反転可能性により、学習中に尤度を計算することができ、変分推論の枠組みでモデルを学習することができます。実証的には、PointFlowが点群生成において最先端の性能を達成することを示しています。さらに、我々のモデルは点群を忠実に再構成し、教師なしで有用な表現を学習できることを示しています。コードはこのhttpsのURLで公開されます。
モデルベース強化学習（MBRL）は、モデルフリーRLに比べてサンプル効率が大幅に向上する可能性があると広く考えられています。しかし、モデルベースRLの研究はあまり標準化されていません。著者が自分で設計した環境で実験することはかなり一般的であり、いくつかの独立した研究ラインがあり、それらは時にクローズドソースであったり、再現性がなかったりします。従って、これらの様々な既存のMBRLアルゴリズムが互いにどのように機能するかは未解決の問題です。本論文では、MBRLの研究を促進するために、様々なMBRLアルゴリズムを収集し、MBRLのために特別に設計された18以上のベンチマーク環境を提案する。これらのアルゴリズムを、ノイズの多い環境を含む統一された問題設定でベンチマークします。また，性能だけではなく，MBRLアルゴリズム間の根本的なアルゴリズムの違いについても調査し，統一している．また，今後のMBRL研究の課題として，ダイナミクスのボトルネック，計画地平線のジレンマ，早期終了のジレンマの3つを挙げた．最後に、今後のMBRL研究を最大限に促進するために、我々のベンチマークをこのhttpのURLでオープンソース化する。
コンピュータビジョンにおける物体表現の研究は、主に画像分類、物体検出、セマンティックセグメンテーションなどの下流タスクに有用な表現の開発に焦点を当てています。本研究では、制御や強化学習(RL)に有用なオブジェクト表現を学習することを目的とする。この目的のために、キーポイントや画像空間座標の観点から簡潔な幾何学的オブジェクト表現を発見するためのニューラルネットワークアーキテクチャであるTransporterを紹介します。我々の手法は，完全に教師なしの方法で生のビデオフレームから学習し，キーポイントのボトルネックを用いてビデオフレーム間で学習した画像特徴を転送します．発見されたキーポイントは，最近の類似した手法に比べて，長い時間軸にわたって物体や物体の一部を正確に追跡します．さらに、一貫した長期追跡により、制御領域における2つの注目すべき結果が得られました。（1）キーポイントの座標と対応する画像特徴を入力として使用することで、サンプル効率の高い強化学習が可能になります。
AIシステムの安全性を向上させるためには、AIシステムの予測の不確実性を見積もることが重要です。予測の不確実性には、モデルパラメータの不確実性、還元できないデータの不確実性、テストデータとトレーニングデータの分布の不一致による不確実性があります。不確実性の原因に応じて異なるアクションが取られる可能性があるため、それらを区別できることが重要です。近年、ベースラインとなるタスクやメトリクスが定義され、不確実性を推定するための実用的な手法がいくつか開発されています。しかし、これらの手法は、分布の不一致による不確実性を、モデルの不確実性によって暗黙的に、あるいはデータの不確実性としてモデル化しようとしている。本研究では、分布の不確実性を明示的にモデル化するプライアネットワーク（PN）という予測不確実性をモデル化するための新しいフレームワークを提案する。PNは、予測分布に対する事前分布をパラメータ化することでこれを行う。本研究では、分類の不確実性に焦点を当て、MNISTデータセットにおける分布外（OOD）サンプルの識別と誤分類の検出のタスクでPNを評価したところ、従来の手法よりも優れていることがわかった。合成データとMNISTおよびCIFAR-10データを用いた実験では、これまでの非ベイズ法とは異なり、PNはデータと分布の不確実性を区別することができる。
本論文では、失われた言語の自動解読のための新しいニューラルアプローチを提案する。強力な監視信号の欠如を補うために、我々のモデルデザインは、歴史的言語学で記録された言語変化のパターンに基づいている。このモデルは、同族間の文字レベルの対応関係を捉えるために、表現力豊かな配列対配列モデルを利用している。このモデルを教師なしで効果的に学習するために、学習手順を最小コストフロー問題として形式化することで革新的な方法を採用した。このモデルをウガリット語の解読に適用したところ、最先端の結果に比べて5.5%の絶対値の改善を達成しました。また、古代ギリシャ語に関連した音節言語であるLinear Bの解読において、我々のモデルが67.3%の同義語を正しく翻訳したという初めての自動結果を報告する。
BERTのような事前に学習された大規模なニューラルネットワークは、近年、NLPにおいて大きな成功を収めており、ラベルのないデータから言語のどのような側面を学習することができるかを調査する研究が増えています。最近のほとんどの分析は、モデルの出力（例：言語モデルの驚き）または内部ベクトル表現（例：分類器のプローブ）に焦点を当てています。これらの研究を補完するために、我々は、事前に訓練されたモデルの注意メカニズムを分析する方法を提案し、BERTに適用しています。BERTの注目ヘッドは、区切りトークンへの注目、特定の位置のオフセットへの注目、文全体への幅広い注目などのパターンを示し、同じ層のヘッドはしばしば同様の行動を示すことがわかった。さらに、ある種のアテンションヘッドは、言語学的な構文や共参照の概念によく対応していることを示しています。例えば、動詞の直接目的語、名詞の決定詞、前置詞の目的語、共参照の言及などを、非常に高い精度で注意するヘッドを発見した。最後に、注意に基づくプロービング分類法を提案し、それを用いてBERTの注意に実質的な構文情報が取り込まれていることをさらに実証する。
従来のニューラルアーキテクチャ探索（NAS）アプローチは、強化学習や進化的戦略に基づいており、CIFAR-10上で良いモデルを見つけるためには、3000GPU時間以上かかります。我々は、勾配降下法による探索を学習する効率的なNASアプローチを提案します。このアプローチでは、探索空間を有向非環状グラフ（DAG）として表現します。このDAGには何十億ものサブグラフが含まれており、それぞれのサブグラフはある種の神経アーキテクチャを示しています。サブグラフのすべての可能性を横断することを避けるために、DAG上で微分可能なサンプラーを開発しました。このサンプラーは学習可能で、サンプルされたアーキテクチャをトレーニングした後の検証損失によって最適化される。このようにして、我々のアプローチは、勾配降下法によってエンド・ツー・エンドで学習することができ、Gradient-based search using Differentiable Architecture Sampler (GDAS)と名付けられました。実験では、CIFAR-10において、1回の探索手順を4時間のGPU時間で終了させることができ、発見されたモデルは、わずか2.5M個のパラメータでテストエラー2.82%を得ることができ、これは最先端の技術と同程度です。コードはGitHubで公開されています：このhttpsのURL。
早期行動予測の目的は、行動の実行が不完全な状態で部分的に観測された映像から行動を認識することであり、行動認識とは全く異なります。部分的に観測された動画には、認識に必要な十分なアクション情報が含まれていないため、初期のアクションを予測することは非常に困難である。本論文では、教師と生徒の新しい学習フレームワークを提案することで、初期行動の予測を改善することを目的としている。我々のフレームワークには、動画全体から行動を認識するための教師モデル、部分的な動画から初期行動を予測するための学生モデル、そして教師から学生への進歩的な知識を抽出するための教師-学生学習ブロックが含まれ、異なるタスクを横断する。3つのパブリックアクションデータセットを用いた広範な実験により、提案されたプログレッシブな教師-生徒学習フレームワークは、早期行動予測モデルの性能を一貫して向上させることができることを示した。また、これらすべてのセットにおいて、早期行動予測の最先端の性能を報告しています。
最近では、深層学習に基づく顔のランドマーク検出が大きな成功を収めている。しかし、その一方で、意味的な曖昧さが検出性能を大きく低下させていることに気づきました。意味的な曖昧さとは、顔の輪郭に沿って均等に配置されたランドマークなどが、明確かつ正確な定義を持たず、アノテーターによる一貫性のないアノテーションを引き起こすことを意味します。このような矛盾したアノテーションは、通常、公共のデータベースから提供され、ネットワークの学習を監視するためのグランドトゥルースとして使用され、精度の低下につながります。我々の知る限り、この問題を調査した研究はほとんどない。本論文では、潜在変数、すなわち意味的に一貫性のある「本当の」グランドトゥルースを導入して最適化する、新しい確率モデルを提案する。このフレームワークは、(1)ランドマーク検出CNNの学習と、(2)本当のグランドトゥルースの探索の2つの部分から構成されている。この2つの部分は交互に最適化される。すなわち、検索された「本物」のグランドトゥルースがCNNの学習を監督し、学習されたCNNが「本物」のグランドトゥルースの検索を支援するのである。さらに、オクルージョンや低品質のために自信なく予測されたランドマークを回復するために、グローバルな顔の形状を制約条件として考慮し、外れ値を修正するグローバルヒートマップ補正ユニット（GHCU）を提案する。画像ベース（300WおよびAFRW）とビデオベース（300-VW）のデータベースを用いた広範な実験により、本手法がランドマーク検出精度を効果的に向上させ、最先端の性能を達成することが実証された。
深層学習を用いた検出器は，効率化のために1つの入力画像から複数のスケールの顔を検出する傾向がある．FPNやSSDのような最近の作品では、一般的に空間解像度の異なる複数の層からの特徴マップを使用して、小さな物体には高解像度の特徴マップを使用するなど、異なるスケールの物体を検出します。しかし、このような多層予測は必要ないことがわかりました。すべてのスケールの顔は、ネットワークの単一の層からの特徴で十分に検出することができる。本論文では，広範囲のスケールでの顔検出に影響を与える要因を慎重に検討し，異なるスケールでのポジティブなものとネガティブなものの両方を含むトレーニングサンプルのバランスが鍵となると結論づけている。そこで，スケールに応じてアンカーをいくつかのグループに分け，学習時に各グループのサンプル数が同じになるようにするグループサンプリング法を提案する．FPNの最後の層のみを特徴量として使用する我々のアプローチは、技術を進歩させることができる。提案手法の有効性を示すために，包括的な分析と広範な実験が行われた．FDDBおよびWIDER FACEデータセットを含む顔検出ベンチマークで評価された我々のアプローチは、ベルとホイッスルなしで最先端の結果を達成した。
単語ベクトルの意外な特性として、単語の類推がベクトル演算で解決できることが多いことが挙げられます。しかし、なぜ算術演算子がskip-gram with negative sampling (SGNS)のような非線形埋め込みモデルに対応するのかは不明です。我々は、この現象を、過去の理論がベクトル空間や単語の分布について行ってきた強い仮定をせずに、正式に説明する。我々の理論はいくつかの意味を持っている。過去の研究では、関係が比として表現できることから、ベクトル空間には線形部分構造が存在すると推測されていたが、我々はこれがSGNSでも成り立つことを証明する。また、SGNSの単語ベクトルを追加する際に、重み付けスキームがアドホックに行うように、より頻度の高い単語に自動的に重み付けを下げることを示すことで、新たな正当性を示す。最後に、ベクトル空間におけるユークリッド距離を情報理論的に解釈し、単語の非類似性を把握するために使用することを正当化する。
Deep Convolutional Neural Network (CNN)の意思決定を視覚的に理解することは可能ですが、性能向上に貢献するには十分ではありません。本論文では、画像認識において重要な領域として、高い応答値を示す視覚的説明のためのアテンションマップに注目した。この領域は、画像中の特定の領域に注目するアテンションメカニズムを導入することで、CNNの性能を大幅に向上させることができる。本研究では、注意メカニズムを持つブランチ構造を導入することで、トップダウン型の視覚的説明モデルを拡張するAttention Branch Network (ABN)を提案する。ABNは、注意メカニズムのための枝を導入することで、複数の画像認識タスクに適用可能であり、視覚的説明と画像認識をエンド・ツー・エンドで学習可能である。我々は、画像分類、細粒度認識、複数の顔属性認識などの複数の画像認識タスクでABNを評価した。実験の結果、ABNはこれらの画像認識タスクにおいてベースラインモデルの精度を上回り、同時に視覚的説明のためのアテンションマップを生成できることがわかった。当社のコードは、このhttpsのURLで公開されています。
双方向コンテクストをモデル化する能力を持つ BERT のようなノイズ除去オートエンコーディングに基づく前処理は、自己回帰言語モデリングに基づく前処理アプローチよりも優れた性能を達成しています。しかし、BERT は、入力をマスクで破損することに依存しているため、マスクされた位置間の依存性を無視しており、事前学習と調整の不一致に悩まされています。これらの長所と短所を考慮して、我々は一般化された自己回帰型の事前学習法であるXLNetを提案する。XLNetは、(1)因子化順序のすべての順列に対する期待される尤度を最大化することで、双方向の文脈を学習することを可能にし、(2)自己回帰型の定式化によりBERTの限界を克服する。さらに、XLNetは、最先端の自己回帰モデルであるTransformer-XLのアイデアを事前学習に統合しています。経験的に、同等の実験設定の下で、XLNetは、質問応答、自然言語推論、感情分析、および文書ランキングを含む20のタスクにおいてBERTを上回り、多くの場合、大差をつけています。
効果的なモデルベースの強化学習アルゴリズムを設計することは、データ生成の容易さとモデル生成データの偏りとを比較しなければならないため、困難です。本論文では、政策最適化におけるモデル使用の役割を、理論的および経験的に研究します。まず、各ステップでの単調な改善を保証するモデルベースの強化学習アルゴリズムを定式化し、分析する。実際には、この分析は過度に悲観的であり、モデルで生成されたオンポリシーデータよりも実際のオフポリシーデータの方が常に好ましいことを示唆しているが、モデルの一般化の経験的な推定値をこのような分析に組み込むことで、モデルの使用を正当化できることを示している。この分析に刺激されて、実データから分岐した短いモデル生成ロールアウトを使用するという単純な手順が、通常の落とし穴なしに、より複雑なモデルベースのアルゴリズムの利点を持つことを実証しました。特に、このアプローチは、先行するモデルベースの手法のサンプル効率を上回り、最高のモデルフリーアルゴリズムの漸近性能に匹敵し、他のモデルベースの手法が完全に失敗するようなホライゾンにまで拡張することができる。
我々は、Neural Programmer-Interpreters (NPI)とAlphaZeroの長所を組み合わせた新しい強化学習アルゴリズムAlphaNPIを提案する。NPIは、モジュール性、階層性、再帰性という形で構造的なバイアスを貢献しており、これらはサンプルの複雑さを減らし、一般化を改善し、解釈可能性を高めるのに役立つ。AlphaZeroは、強力なニューラルネットワーク誘導型検索アルゴリズムを提供しており、これを再帰性で補強しています。AlphaNPIは、疎な報酬を持つ階層的なプログラム仕様のみを想定しています。プログラムの実行が仕様を満たす場合は1、そうでない場合は0です。この仕様を用いることで、AlphaNPIは初めてRLを用いてNPIモデルを効果的に学習することができ、実行トレースの形での強力な監視の必要性を完全に排除することができます。実験の結果、AlphaNPIは、これまでの強力な監視下にあるNPIの亜種と同様にソートできることがわかった。また、AlphaNPIエージェントは、2枚のディスクを用いたハノイの塔パズルで学習され、任意の数のディスクを用いたパズルに一般化することが示された。
世界に関する視覚的なプリオール（世界が3Dであるという事実など）を持つことは、下流の運動タスク（荷物の配達など）を行う学習にどの程度役立つのだろうか？私たちは、一般的な知覚スキルセット（距離推定器、エッジ検出器など）を強化学習フレームワークに統合することで、この問題を研究しています（図1参照）。このスキルセット（以下、中間レベルの知覚）は、生の画像と比較して、より処理された世界の状態を政策に提供する。我々は、ミッドレベルの知覚を使用することで、ナビゲーションを中心としたタスクにおいて、ゼロからエンドツーエンドでトレーニングするよりも、大きな利点があることを発見しました。エージェントは、最初からのアプローチが失敗した場合でも一般化することができ、トレーニングのサンプル効率が大幅に向上します。しかし、このような効果を得るためには、中間レベルの知覚スキルを慎重に選択する必要があることを示しています。そこで、我々の発見を、生の画像の代わりに採用できる、効率的な最大カバー率の特徴セットに改良する。本研究では、トレーニング用とテスト用の建物を完全に分けて実施し、視覚障害者向けのベースライン・ポリシーや最先端の特徴学習法と比較します。
オブジェクトは、幾何学的に整理されたパーツの集合で構成されています。本研究では、部品間の幾何学的な関係を明示的に利用して物体を推論する教師なしカプセルオートエンコーダー（SCAE）を導入しています。これらの関係は視点に依存しないため、我々のモデルは視点の変化に対してロバストです。SCAEは2つのステージで構成されています。第1段階では、画像から直接部品テンプレートの存在と姿勢を予測し、テンプレートを適切に配置することで画像の再構成を試みます。第2段階では、SCAEはいくつかのオブジェクトカプセルのパラメータを予測し、それを用いてパーツのポーズを再構築します。このモデルの推論は、従来のカプセルネットワークとは異なり、市販のニューラルエンコーダーで償却して実行します。その結果，オブジェクトカプセルの存在はオブジェクトクラスの情報量が多いことがわかり，SVHN（55％）およびMNIST（98.7％）の教師なし分類で最先端の結果を得ることができた．コードはこのhttpsのURLから入手可能です。
ラティスは，自然言語処理タスクにおける上流システムの曖昧さを符号化するための効率的かつ効果的な手法である．例えば，複数の音声認識仮説をコンパクトに捉えたり，複数の言語分析を表現したりすることができる．これまでの研究では、リカレントニューラルネットワークを拡張して格子入力をモデル化し、様々なタスクで改善を達成してきましたが、これらのモデルは計算速度が非常に遅いという問題がありました。この論文では、最近提案された自己注意のパラダイムを格子入力を扱えるように拡張しています。自己言及は、ペアごとの類似性を計算することで入力を互いに関連付けるシーケンスモデリング手法であり、その強力な結果と計算効率の両方で人気を博している。このようなモデルを格子を扱えるように拡張するために、格子構造をモデルに組み込み、利用可能であれば格子スコアをサポートする確率的到達性マスクを導入する。また、位置埋め込みを格子構造に適応させる方法を提案する。提案モデルを音声翻訳タスクに適用したところ、学習時と推論時の両方において、これまでのニューラル格子モデルよりも計算速度がはるかに速く、検討されたすべてのベースラインを上回る結果が得られました。
ウェブのサイズがますます大きくなっているため、いくつかのキーワードで形成されたクエリを用いてインターネット上の関連情報を抽出することは、大きな課題となっています。クエリー・エクスパンション（QE）は、インターネット上の検索を改善するために重要な役割を果たします。ここでは、ユーザーが最初に入力したクエリに、同じような意味を持つ用語を追加して再構成します。QEは、情報検索（IR）の一部として、長い間、研究者の注目を集めてきました。QEは、パーソナライズド・ソーシャル・ドキュメント、質問応答、クロスランゲージIR、情報フィルタリング、マルチメディアIRなどの分野で大きな影響力を持っています。TREC (Text Information Retrieval Conference)やCLEF (Conference and Labs of the Evaluation Forum)などのIR専門会議の開催により、QEの研究はさらに注目を集めている。本稿では、1960年から2017年までのIRにおけるQE技術を、コア技術、使用するデータソース、重み付けやランキングの手法、ユーザーの参加状況、アプリケーションなどについて調査し、共通点と相違点を明らかにする。
人々が料理写真を楽しむのは、料理に感謝しているからです。それぞれの食事の背後には、複雑なレシピに記述されたストーリーがあり、残念ながら、料理の画像を見るだけでは、その調理プロセスにアクセスすることはできません。そこで本稿では、料理画像から料理レシピを再現する「逆調理システム」を紹介する。我々のシステムは、新しいアーキテクチャによって食材をセットとして予測し、順序を決めずにその依存関係をモデル化する。そして、画像と推測された食材の両方を同時に見て、調理手順を生成する。大規模なRecipe1Mデータセットを用いて本システムを評価し、(1)従来のベースラインと比較して食材予測の性能が向上したこと、(2)画像と食材の両方を活用することで高品質なレシピを得ることができたこと、(3)人間の判断により、検索ベースのアプローチよりも魅力的なレシピを生成することができたことを示した。コードとモデルを公開しています。
200,000件以上の検査（1,000,000枚以上の画像）で学習・評価した、乳がん検診の検査分類用の深層畳み込みニューラルネットワークを紹介しています。このネットワークは、検診対象者でテストした場合、乳房にがんがあるかどうかを予測する際に、AUC 0.895を達成しました。このモデルの高い精度は，2段階の学習手順によるもので，非常に大容量のパッチレベルのネットワークを用いてピクセルレベルのラベルから学習したネットワークと，巨視的な乳房レベルのラベルから学習したネットワークを併用することができる．このモデルを検証するために、14人の読影者がそれぞれ720件のマンモグラム・スクリーニング検査を読影する読影試験を行ったところ、同じデータを提示した場合に、経験豊富な放射線科医と同等の精度が得られることが分かりました。最後に，放射線科医が予測した悪性腫瘍の確率と，我々のニューラルネットワークによる予測を平均化したハイブリッドモデルが，2つのモデルを別々に用いるよりも正確であることを示した．この結果をよりよく理解するために，スクリーニング集団のさまざまな部分集団に対する我々のネットワークの性能，モデル設計，学習手順，誤差，内部表現の特性を徹底的に分析した．
わずか数年の間に、深層生成モデリングは人工的な創造性についての考え方に革命を起こし、オリジナルの画像、音楽、テキストを生成する自律的なシステムを生み出しました。こうした成功に触発されて、研究者たちは現在、ディープジェネレーティブモデリングの技術を分子の生成や最適化に応用しており、過去2年間に45本の論文が発表されています。これらの研究は、このようなシステムがリード分子の生成に使用され、実験室で悪いリード分子を合成したり特性を調べたりするために下流で費やされる資源を大幅に削減できるという未来を示しています。このレビューでは、これまでに提案されたモデルや表現方法がますます複雑になっていることを概観します。ここでは、再帰的ニューラルネットワーク、オートエンコーダー、ジェネレーティブ・アドバーサリアル・ネットワーク、強化学習という4つのクラスの技術について説明する。それぞれの手法の数学的な基礎を説明した後、他の手法との高度な関連性や比較を行い、それぞれの長所と短所を明らかにします。この研究の結果、いくつかの重要なテーマが浮かび上がってきました。それは、分子のSMILES文字列表現から、グラフグラマーや3D表現のようなより洗練された表現への移行、報酬関数設計の重要性、ベンチマークとテストのためのより良い基準の必要性、最尤ベースのトレーニングに対する敵対的トレーニングと強化学習の利点などです。
医学分野では、間違った予測による倫理的・金銭的コストが大きく、また問題が複雑であるためにモデルがますます複雑になることがよくあります。最近の研究では、ランダムシードを変更するだけで、十分に調整されたディープニューラルネットワークであっても、個々の予測確率が変化してしまうことが明らかになりました。これを踏まえて、我々は医療領域におけるモデル不確実性法の役割を調査する。RNNアンサンブルと様々なベイジアンRNNを用いて、AUC-PR、AUC-ROC、対数尤度、校正誤差などの母集団レベルの指標では、モデルの不確実性を捉えることができないことを示している。一方で、患者ごとの予測や最適な判断には大きなばらつきがあることから、モデルの不確実性を捉える必要性が高まっています。個々の患者の不確実性を理解することは、モデルの決定が脆くなりそうな時期を判断するなど、臨床的に明らかに影響を与える分野です。さらに、ベイズ埋め込みのみのRNNは、アンサンブルと比較して、モデルの不確実性をより効率的に捉えることができることを示し、モデルの不確実性が個々の入力特徴や患者のサブグループにどのような影響を与えるかを分析しています。
最近の言語間単語埋め込みの研究は，ほとんどがオフライン法に焦点を当てている．オフライン法とは，異なる言語の単語埋め込みを独自に学習し，線形変換によって共有空間にマッピングするものである．異なる言語の単語埋め込みはほぼ同じ構造を持っているという同型性の仮定に疑問を呈する著者もいるが、これがマッピング手法の固有の限界なのか、それとも言語横断的な埋め込みを学習する際のより一般的な問題なのかは明らかになっていない。この問題に答えるために、我々は並列コーパスを用いて実験を行い、オフラインマッピングと、両方の埋め込み空間を共同で学習するskip-gramの拡張版とを比較することができた。このような理想的な条件の下では、共同学習はより同型の埋め込みをもたらし、ハブネスの影響を受けにくく、対訳辞書の誘導においてより強力な結果を得ることができることがわかった。このように、現在のマッピング手法には大きな限界があり、より弱い言語間シグナルで言語間埋め込みを共同で学習するためのさらなる研究が必要であると結論づけた。
気候変動は人類が直面している最大の課題の一つであり、機械学習の専門家である我々は、どのようにして支援できるのかと考えるかもしれない。ここでは、温室効果ガスの排出量を削減し、社会が変化する気候に適応するために、機械学習がどのように強力なツールとなり得るかを説明します。スマートグリッドから災害管理まで、他の分野と協力して、既存のギャップを機械学習で埋めることができるインパクトの大きい問題を特定します。私たちの提言は、エキサイティングな研究課題や有望なビジネスチャンスを含んでいます。機械学習コミュニティには、気候変動に対する世界的な取り組みへの参加を呼びかけています。
マルチヘッドセルフアテンションは、ニューラル機械翻訳の最先端のアーキテクチャであるTransformerの重要なコンポーネントです。本研究では、エンコーダー内の個々のアテンションヘッドがモデルの全体的なパフォーマンスに与える貢献度を評価し、それらが果たす役割を分析しました。その結果、最も重要で自信のあるヘッドは、一貫して、しばしば言語的に解釈可能な役割を果たしていることがわかった。確率的ゲートとL0ペナルティの微分可能な緩和に基づいた方法を用いてヘッドを刈り込むと、特殊なヘッドが最後に刈り込まれることが観察された。私たちの新しい刈り込み方法は、性能に大きな影響を与えることなく、大部分のヘッドを除去します。例えば、英語-ロシア語のWMTデータセットでは、48個のエンコーダヘッドのうち38個をプルーニングすることで、わずか0.15BLEUの低下にとどまりました。
シーングラフ予測（視覚的なシーンにおけるオブジェクトと述語のセットを分類する）には、かなりの量の学習データが必要です。しかし、ほとんどの述語は数回しか出現しないため、学習が困難である。我々は、述語の数回の学習をサポートする初めてのシーングラフ予測モデルを紹介する。既存のシーングラフ生成モデルでは、事前に学習されたオブジェクト検出器や単語埋め込みを用いてオブジェクトを表現するが、これは意味的なオブジェクト情報を取得する代わりに、どのような関係を持つかという情報を符号化する必要がある。そのため、これらのオブジェクト表現は、新しい少数ショットの関係に一般化することができない。我々は、視覚的な関係に基づいて構造化されたオブジェクト表現を誘導するフレームワークを紹介する。これまでの手法とは異なり、我々のフレームワークでは、似たような関係を持つオブジェクトをより近くに埋め込む。この特性により、我々のモデルは数ショットの設定でも十分な性能を発揮します。例えば、「人」に「乗る」という述語変換を適用すると、「スケートボード」や「馬」など、乗ることが可能なオブジェクトに向かって表現が変化します。我々は、新しいグラフ畳み込みフレームワークの中で、メッセージパッシング関数として学習された述語を学習することで、オブジェクト表現を生成します。このオブジェクト表現を用いて、ラベル付けされた例が1つしかない希少な述語を対象とした数ショットの述語分類器を構築する。その結果、5ショットで22.70 recall@50の性能を達成し、強力な伝達学習のベースラインと比較して3.7の向上を実現した。
同時機械翻訳は、ソーススピーカーが話し終わる前に各ソースセンテンスの翻訳を開始し、ライブやストリーミングのシナリオに適用します。同時翻訳システムは、品質と遅延のバランスをとるために、原文の読み上げを注意深くスケジュールする必要があります。本論文では、これまでに読み上げられたすべての原文トークンに注目するニューラル機械翻訳（NMT）モデルと共同で、適応的なスケジュールを学習する初めての同時翻訳システムを紹介する。MILk（Monotonic Infinite Lookback）アテンションは、原文の読解をスケジュールするためのハードな単調なアテンションヘッドと、単調なヘッドから原文の先頭に戻るソフトなアテンションヘッドの両方を維持する。MILkの適応的なスケジュールにより、多くの待ち時間において、最近提案されたwait-k戦略に比べて有利な待ち時間と品質のトレードオフを得ることができることを示している。
画像の深層生成モデル（DGM）は現在、十分に成熟しており、ほぼ写実的なサンプルを生成し、Frechet Inception Distance（FID）などのヒューリスティックな手法でデータ分布に近いスコアを得ることができる。これらの結果は、特にImageNetのような大規模なデータセットでは、DGMが知覚的に意味のある空間でデータ分布を学習していることを示唆しており、下流のタスクに利用することができる。この仮説を検証するために、我々は、変数オートエンコーダー、自己回帰モデル、生成的逆説ネットワーク（GAN）などのクラス条件付き生成モデルを用いて、実データのクラスラベルを推論する。この推論は、合成データのみを用いて画像分類器を学習し、その分類器を用いて実データのラベルを予測することで行います。このタスクの性能を分類精度スコア（CAS）と呼びますが、従来の評価基準ではわからなかったいくつかの驚くべき結果が明らかになり、我々の貢献につながりました。第一に、最先端のGAN（BigGAN-deep）を用いた場合、元のデータと比較して、Top-1の精度が27.9％、Top-5の精度が41.6％低下し、Vector-Quantized Variational Autoencoder-2（VQ-VAE-2）やHierarchical Autoregressive Models（HAM）など、他のモデルクラスの条件付き生成モデルがGANを大幅に上回ることがわかりました。第2に、CASは、生成モデルがデータ分布を捉えることができず、これまで文献では知られていなかった特定のクラスを自動的に抽出します。第3に、Inception Score (IS)やFIDなどの従来のGAN指標は、CASを予測するものではなく、非GANモデルを評価する際にも有用ではないことがわかった。さらに、生成モデルの診断を容易にするために、提案した指標をオープンソース化した。
最近の研究では、表現力のある音声合成（プロソディとスタイルの制御と伝達をサポートする）のための配列間潜在変数モデルが検討されているが、競合する手法間のトレードオフを理解するための首尾一貫したフレームワークは提示されていない。本論文では、音声の潜在変数モデルの振る舞いを分析する統一的な手法として、埋め込み容量（埋め込みがデータについて含む情報量）を提案し、既存のヒューリスティックな（非変量的な）手法と、表現上の相互情報の上界を用いて容量を明示的に制約できる変量的な手法を比較する。我々が提案するモデル（Capacitron）では、変分事後に条件付きの依存性を加えて真の事後の形と一致させることで、同じモデルを高精度の韻律変換、テキストに依存しないスタイル変換、自然な響きの事前サンプルの生成に利用できることを示している。多話者モデルの場合、Capacitronは話者間の韻律伝達や潜在的な事前情報からサンプルを抽出する際に、対象となる話者のアイデンティティを保持することができます。最後に、埋め込み容量を2つの潜在的なセットに渡って階層的に分解する方法を紹介します。これにより、潜在的な変動性の一部を指定し、残りの変動性を学習された事前情報からサンプリングすることができます。オーディオの例がウェブ上で公開されています。
すべてのニューラルネットワークアーキテクチャが同じように作られているわけではなく、特定のタスクにおいて他よりもはるかに優れた性能を発揮するものもあります。しかし、ニューラルネットワークの重みパラメータは、そのアーキテクチャと比較してどの程度重要なのでしょうか。本研究では、重みパラメータを一切学習せずに、ニューラルネットワークアーキテクチャだけで、どの程度まで、与えられたタスクの解を符号化できるかを問う。本研究では、明示的な重み学習を行わなくても、すでにタスクを実行できるニューラルネットワークアーキテクチャの検索方法を提案する。これらのネットワークを評価するために、一様なランダム分布からサンプリングされた単一の共有重みパラメータを接続に投入し、期待される性能を測定する。我々の手法は、強化学習のタスクをウェイトトレーニングなしで実行できる最小のニューラルネットワークアーキテクチャを見つけることができることを実証した。教師付き学習の分野では，MNISTにおいてランダムな重みを用いて偶然よりもはるかに高い精度を達成するネットワークアーキテクチャを見つけることができる．この論文のインタラクティブ版はこちらのhttpsのURLにあります。
基本的な分類フレームワークだけで、画像合成における最も困難なタスクに取り組むことができることを示しています。他の最先端のアプローチとは対照的に、我々が開発したツールキットはむしろ最小限であり、単一の既製の分類器をこれらのタスクすべてに使用します。我々のアプローチの要点は、この分類器を敵対的にロバストになるように訓練することです。敵対的な頑健性は、入力の顕著な特徴を直接操作するためにまさに必要であることがわかりました。今回の発見は、機械学習の分野における頑健性の有用性を示すものです。我々の実験のコードとモデルは、このhttpsのURLにあります。
SELFie supervised Image Embeddingの略であるSelfieと呼ばれる事前学習手法を紹介しています。Selfieは、Contrastive Predictive Coding loss（Oord et al.2018）を利用することで、BERT（Devlin et al.2019）のマスクドランゲージモデリングの概念を画像などの連続データに一般化しています。入力画像にマスクアウトされたパッチがあると、本手法は、同じ画像からサンプリングされた他の「ディストラクタ」パッチの中から、マスクされた場所を埋めるための正しいパッチを選択することを学習する。この分類目的のおかげで，ターゲットパッチの正確なピクセル値を予測する必要がなくなりました．Selfieの事前学習アーキテクチャには，パッチを処理する畳み込みブロックのネットワークと，マスクされたパッチを予測する前にマスクされていないパッチの内容を要約するアテンションプーリングネットワークが含まれています．微調整の際には、事前学習で得られた畳み込みの重みを再利用する。Selfieは3つのベンチマーク（CIFAR-10，ImageNet 32 x 32，ImageNet 224 x 224）で評価され，ラベル付きデータの量はトレーニングセットの5%から100%と様々である．我々の事前学習法は，同一ネットワークの標準的な教師付き学習と比較して，すべての設定においてResNet-50に一貫した改善をもたらした．特に，ImageNet 224 x 224，各クラス60例（5%）の場合，我々の手法はResNet-50の平均精度を35.6%から46.7%に向上させ，絶対精度で11.1ポイントの改善を実現した．また，我々の事前学習法は，異なる実行結果におけるテスト精度の標準偏差を大幅に低下させることで，特にデータ量の少ないレジームでのResNet-50の学習安定性を向上させました．
深層ニューラルネットワークと決定木は，大きく異なるパラダイムで動作します．前者は事前に指定されたアーキテクチャで表現学習を行うのに対し，後者は事前に指定された特徴に対する階層をデータ駆動型のアーキテクチャで学習するという特徴があります．これは、表現学習を決定木のエッジ、ルーティング関数、リーフノードに組み込んだモデルで、バックプロパゲーションベースの学習アルゴリズムにより、プリミティブなモジュール（畳み込み層など）から適応的にアーキテクチャを成長させる。その結果、ANTは、分類や回帰のデータセットで競争力のある性能を発揮する一方で、(i)条件付き計算による軽量な推論、(ii)予測タスクに有用な特徴の階層的な分離（例：自然物と人工物の分離など、意味のあるクラスの関連付けの学習）、(iii)学習データセットのサイズや複雑さにアーキテクチャを適応させるメカニズム、などの利点があることを実証した。
マルチホップ読解(RC)では、複数の段落にまたがる推論や集計が必要となります。本研究では、マルチホップRCのためのシステムを提案する。このシステムでは、構成的な質問を、既製のシングルホップRCモデルで回答可能な、より単純なサブ質問に分解する。このような分解のためのアノテーションは高価であるため、我々はサブ質問生成をスパン予測問題として再構成し、400のラベル付き例のみを用いて訓練された我々の方法が、人間が作成したサブ質問と同等の効果を持つサブ質問を生成することを示す。また、各分解（すなわち、小問題とその答え）を考慮して最適な最終回答を選択する新しいグローバルリスコアリングアプローチを導入し、全体のパフォーマンスを大幅に向上させる。HotpotQAでの実験では、このアプローチが最先端の結果を達成するとともに、その意思決定のための説明可能な証拠を小問題の形で提供することが示された。
強化学習（RL）が実世界のタスクで成功するためには、世界の構成的、関係的、階層的な構造を利用し、それを目前のタスクに移すことを学ぶ必要がある。近年の言語表現学習の進歩により、テキストコーパスから世界の知識を獲得し、この知識を下流の意思決定問題に統合するモデルを構築することが可能になった。そこで我々は、自然言語理解を特にRLに緊密に統合することを検討する時期に来ていると主張する。本論文では、指示に従うこと、テキストゲーム、テキストのドメイン知識からの学習など、この分野の現状を概観する。最後に、新しい環境の開発と、最近の自然言語処理(NLP)技術をこのようなタスクに使用する可能性についてのさらなる調査を求める。
本研究では、変分オートエンコーダー（VAE）における離接の一般化である潜在表現の分解を開発し、次の2つの要素を満たすことを特徴としている。分解は、特別な場合として、潜在的なものの間の独立性、すなわちdisentanglementを可能にするだけでなく、学習された表現に、スパース性、クラスタリング、独立した部分空間、あるいは複雑な階層的従属関係など、はるかに豊富なクラスの特性を課すことができる。β-VAEが標準的なVAEと異なるのは、主に潜在的なオーバーラップを制御する点であり、等方性ガウス事前分布の標準的な選択において、その目的は潜在的な表現の回転に対して不変であることを示す。分解の観点から見ると、事前処理の簡単な操作でこの不変性を破れば、再構成にほとんど、あるいは全く影響を与えることなく、より良い分離を得ることができる。さらに、事前の他の選択がどのように異なる分解の生成を助けるかを示し、原理的な方法で両方の分解要素を制御することができる代替の学習目的を紹介する。
ニューラルネットワークの学習にデータ増強を活用する際の重要な課題は、膨大な数の操作候補の中から効果的な増強ポリシーを選択することです。しかし、AutoAugmentのような最先端の手法は、一般のユーザーが実行するには計算量が多すぎて実現できない。本論文では、新しいデータ補強アルゴリズムであるPopulation Based Augmentation (PBA)を紹介する。PBAは、固定された補強ポリシーの代わりに、非定常の補強ポリシースケジュールを生成する。PBAは、CIFAR-10、CIFAR-100、およびSVHNにおいて、AutoAugmentと同等の性能を、3桁少ない計算量で実現できることを示す。CIFAR-10では、平均テストエラー1.46%を達成し、現在の最新技術よりもわずかに改善されています。PBAのコードはオープンソースで、このhttpsのURLから入手できます。
ロボットのシミュレーションとハードウェアでの実験を隔てる「リアリティ・ギャップ」を埋めることは、データの利用可能性を高めることでロボット研究を加速することができます。この論文では、ドメインランダム化について検討しています。ドメインランダム化とは、シミュレーター内のレンダリングをランダム化することで、実画像に移行するシミュレーション画像上でモデルをトレーニングするシンプルな手法です。シミュレータに十分なバリエーションがあれば、実世界はモデルにとって単なるバリエーションの一つに過ぎないと考えられる。ここでは、一般的なロボット操作スキルへの足がかりとなる、物体の定位というタスクに焦点を当てます。その結果，非現実的なランダムテクスチャを用いたシミュレータのデータのみを用いて，1.5cmの精度を持ち，注意をそらすものや部分的なオクルージョンに対してロバストな現実世界の物体検出器を訓練することが可能であることがわかった．さらに，我々の検出器の能力を示すために，散らかった環境での把持を行うことができることを示した．我々の知る限り、これは、（実画像での事前学習を行わずに）RGBのシミュレーション画像のみで学習した深層ニューラルネットワークを、ロボット制御の目的で実世界に移すことに成功した初めての例である。
トランスフォーマーのアーキテクチャは、自然言語処理に大きな期待が寄せられています。事前に学習させた1つのモデルを微調整することで、多くの異なるタスクで優れた性能を発揮することができることから、これらのネットワークは、一般的に有用な言語的特徴を抽出することができると考えられる。このようなネットワークは、この情報をどのようにして内部で表現するのかということが、当然の疑問である。本論文では、特に効果的なモデルの1つであるBERTについて、質的および量的な調査を行った。高いレベルでは、言語的特徴は、意味的サブスペースと構文的サブスペースに分けて表現されているようです。また、単語の意味を細かく幾何学的に表現していることがわかった。また、アテンションマトリクスと個々の単語の埋め込みの両方における構文表現の経験的な説明と、これらの表現の幾何学的な説明のための数学的な議論を紹介します。
本論文は、複数の自然言語理解タスクにわたってテキスト表現を学習するためのMulti-Task Deep Neural Network (MT-DNN) (Liu et al., 2019)を改善するための知識蒸留の使用を検討している。アンサンブル学習はモデルの性能を向上させることができますが、MT-DNNのような大規模なDNNのアンサンブルを提供することは、法外なコストがかかります。ここでは、マルチタスク学習の設定で知識蒸留法(Hinton et al., 2015)を適用します。各タスクに対して、単一のモデルよりも優れた、異なるMT-DNNのアンサンブル（教師）を学習し、マルチタスク学習によって単一のMT-DNN（生徒）を学習して、これらのアンサンブル教師からの知識を˶˙º̬˙º˶にします。その結果、9つのGLUEタスクのうち7つのタスクで、単一モデルのGLUEベンチマークを83.7%(1.5%absolute improvementfootnote{ 2019年4月1日時点でのGLUEリーダーボードに基づく})まで向上させることができました。このコードと事前学習済みのモデルは、このhttps URLで公開されます。
強化学習（RL）において関数近似を展開する場合、同じ問題を異なる方法で定式化することがあり、多くの場合、前処理ステップを環境の一部として、またはエージェントの一部として扱うことがあります。その結果、RLの基本的な概念である（最適な）価値関数は、エージェントと環境の境界をどこに引くかに依存するため、一意に定義できず、最適性を保証する理論的分析に問題が生じる。本論文では、代表的なRLアルゴリズムであるFitted Q-Iterationの境界不変解析を行い、仮定と保証が境界の選択に対して不変であるというシンプルかつ斬新な方法でこの問題に取り組む。また、状態のリセットとモンテカルロ木探索、決定論的システムと確率論的システム、模倣学習、データからの理論的仮定の検証可能性など、密接に関連する問題についても議論する。
標準的な逐次生成法は、単語を左から右に生成するテキスト生成法のように、あらかじめ指定された生成順序を前提としている。本研究では、非単調な順序で動作するテキスト生成モデルを学習するためのフレームワークを提案する。モデルは、追加のアノテーションを必要とせず、良い順序を直接学習する。このフレームワークでは、任意の位置に単語を生成し、その左にある単語と右にある単語を再帰的に生成することで、二分木を生成します。学習は模倣学習として行われ、神託の模倣から政策自身の好みを強化するコーチング手法も含まれている。実験の結果、提案手法を用いると、生成順序を事前に指定せずにテキストを生成するポリシーを学習することができ、従来の左から右への生成と比較しても遜色のない性能が得られることがわかった。
音声波形は、1秒間に数万回のタイムステップを経るため、高レベルの構造を捉えることは困難です。長距離依存性を時間領域で直接モデル化することは困難ですが、スペクトログラムのような2次元の時間-周波数表現であれば、より簡単にモデル化できることを示しています。この表現上の利点を活かし、表現力の高い確率モデルとマルチスケールの生成手順を組み合わせることで、時間領域のモデルではまだ達成できないタイムスケールで構造を捉えた高忠実度のオーディオサンプルを生成できるモデルを設計しました。このモデルを、無条件音声生成、音楽生成、音声合成などのさまざまな音声生成タスクに適用したところ、密度推定値と人間の判断の両方において、従来のアプローチよりも改善されました。
オブジェクトのセグメンテーションは非常に重要な問題であり、通常、画像とそれに対応するオブジェクトマスクの両方で構成される非常に大きなデータセットに対して、教師付き学習アプローチを用いて解決されます。マスクはピクセルレベルで提供されなければならないため、新しい分野のためにこのようなデータセットを構築するのは非常に時間がかかります。ReDOは、アノテーションのない画像から、教師なしでオブジェクトを抽出することができる新しいモデルです。このモデルは、データセットの全体的な分布を変えることなく、オブジェクトのテクスチャや色を変更することが可能であるという考えに基づいている。この仮定に基づいて、我々のアプローチは、生成器が入力サンプルによって導かれるという敵対的なアーキテクチャに基づいています。生成器は、画像が与えられると、オブジェクトマスクを抽出し、同じ場所に新しいオブジェクトを描き直します。生成器は，生成された画像の分布が元の画像と一致することを保証する識別器によって制御される．この手法を様々なデータセットで実験し、抽出されたマスクの品質が良いことを実証した。
生涯言語学習の設定を紹介する。この設定では、モデルはデータセットを識別することなく、テキスト例のストリームから学習する必要がある。本研究では、このような環境下で致命的な忘却を軽減するために、疎な経験の再生と局所的な適応を行うエピソード記憶モデルを提案する。テキスト分類と質問応答の実験では、疎な経験の再生と局所適応の相補的な利点を示し、モデルが新しいデータセットから継続的に学習することを可能にする。また、エピソード記憶モジュールの空間的な複雑さは、どの例を記憶するかをランダムに選択することで、性能の低下を最小限に抑えながら、大幅に（50-90％）低減できることを示す。我々は、エピソード記憶モジュールを一般的な言語知能の重要な構成要素と考えており、我々のモデルはその方向への第一歩であると考えている。
ニューラルネットワークは、入力から出力へのマッピングをモデル化するのに必要な重みよりも多くの重みを持つ場合、最適化が容易になります。このことから、まず大きなネットを学習し、次に接続や隠れユニットを刈り取るという2段階の学習方法が考えられます。しかし、標準的な学習では、ネットが刈り込みに適したものになるとは限らない。そこで本研究では、ニューラルネットワークを学習する際に、その後の刈り込みに対してロバストになるようにするための手法「ターゲットドドロップアウト」を紹介する。ターゲットドドロップアウトは、各重み更新の勾配を計算する前に、単純な自己強化スパース性基準を用いて、ドロップされるユニットまたは重みのセットを確率的に選択し、残りの重みの勾配を計算する。結果として得られるネットワークは、削除されたセットに頻繁に出現する重みやユニットを事後的に刈り込むことに対してロバストです。この手法は、複雑なスパース化正則化手法を改良したものであり、実装が簡単でチューニングも容易である。
多言語ニューラル機械翻訳（NMT）は、複数のソース言語から複数のターゲット言語への翻訳をサポートする単一のモデルをトレーニングすることができます。本論文では、使用される言語の数という点で、多言語NMTの限界に挑戦します。大規模な多言語NMTモデルを学習するための大規模な実験を行い、1つのモデルで最大102の言語を英語に翻訳したり、英語から翻訳したりしました。このようなモデルを学習するための様々な設定を検討し、翻訳品質と様々なモデル化の決定との間のトレードオフを分析する。公開されているTED talks多言語コーパスを用いた実験では、多言語多対多モデルが低リソース環境で有効であることを示し、最大59言語をサポートしながら、これまでの最先端技術を上回る結果を得ました。また、英語と英語以外の102の言語を含む大規模なデータセットを用いた実験では、強力なバイリンガルベースラインを上回る有望な結果が得られ、多言語NMTに関する今後の研究を促す結果となりました。
VQ-VAE（Vector Quantized Variational AutoEncoder）モデルを大規模な画像生成に利用することを検討しています。この目的のために、VQ-VAEで使用されている自己回帰プライアを拡張・強化し、従来よりもはるかに高いコヒーレンスと忠実度の合成サンプルを生成します。VQ-VAEは、シンプルなフィードフォワードのエンコーダおよびデコーダネットワークを使用しているため、エンコードやデコードの速度が重要なアプリケーションにとって魅力的なモデルとなっています。さらに、VQ-VAEでは、自己回帰モデルを圧縮された潜在空間でのみサンプリングする必要があり、特に大規模な画像の場合、ピクセル空間でのサンプリングよりも桁違いに高速である。我々は、VQ-VAEのマルチスケールの階層的な構成に、潜在コードに対する強力なプライアを加えることで、ImageNetのような多面的なデータセットにおいて、最先端のGenerative Adversarial Networksに匹敵する品質のサンプルを生成できることを実証した。
現在、バーチャルアシスタントは、多様な自然言語コマンドを理解するために、膨大な労力をかけて手動でアノテーションされた文を用いて訓練されています。本論文では、新しい複合コマンドを人手に頼らずに処理できる方法論とGenieツールキットを紹介します。我々は、仮想アシスタントの能力を仮想アシスタントプログラミング言語（VAPL）で公式化し、ニューラルセマンティックパーサーを使って自然言語をVAPLコードに変換することを提唱する。Genieが必要とするのは、ニューラルモデルを検証するための小さな現実的な入力文のセットだけです。開発者はデータを合成するためのテンプレートを書き、Genieは合成されたデータとともに、クラウドソースによる言い換えやデータ補強を利用して、意味解析パーサーを訓練します。また、VAPL言語を自然言語翻訳に適したものにするための設計原則を提案しています。これらの原則を適用して、仮想アシスタント「Almond」が使用する言語「ThingTalk」を改訂します。Genieを使用して、引用符のない自由形式のパラメータを持つ複合バーチャルアシスタントコマンドをサポートできる初のセマンティックパーサーを構築しました。Genieは、現実的なユーザーの入力に対して、62%の精度を達成しました。Genieは、音楽スキル、集約関数、アクセス制御において、従来の技術に比べて19%と31%の改善を示し、Genieの汎用性を示しています。
論文に定理を加えることは、論文の採択率に影響するか？投稿に著者の性別を表示すると、投稿の人気に影響するのか？本論文では、観察されたテキストデータから、主題や文章の質などの交絡する特徴を調整して、そのような因果効果を推定する方法を開発した。因果関係の調整にはテキストがあれば十分であると仮定するが、実際には、テキストは法外に高次元である。この課題を解決するために、我々は因果関係の識別に十分な情報を保持し、因果関係の効果を効率的に推定できる低次元の文書表現である因果的に十分な埋め込みを開発した。Causeally sufficient embeddingsは、2つのアイデアを組み合わせたものである。1つ目は、教師による次元削減である。因果関係の調整には、治療法と結果の両方を予測するテキストの側面のみが必要である。2つ目は、効率的な言語モデリングです。テキストの表現は、言語的に無関係な情報を排除するように設計されており、この情報は因果関係にも無関係です。我々の手法では、言語モデル（具体的には、単語埋め込みとトピックモデル）を適応して、治療と転帰の両方を予測できる文書埋め込みを学習する。半合成データセットを用いて因果的に十分な埋め込みを研究し、関連する埋め込み手法よりも因果推定が向上することを発見した。さらに、定理が論文の受理に与える影響と、性別ラベルが投稿の人気に与える影響という2つの動機付けとなる質問に答えることで、この手法を説明する。コードとデータは、このhttpsのURL}{このhttpのURL
最近の自然言語生成の進歩は、デュアルユースの問題を提起しています。要約や翻訳のようなアプリケーションはポジティブなものですが、基礎となる技術は、敵対者がニューラルフェイクニュース（本物のニュースのスタイルを忠実に模倣したターゲットプロパガンダ）を生成することを可能にするかもしれないのです。現代のコンピュータセキュリティは、敵の視点から潜在的な脅威や脆弱性を特定し、それらの脅威に対する潜在的な緩和策を探るという、慎重な脅威モデルに依存しています。同様に、ニューラルフェイクニュースに対する強固な防御策を開発するためには、まずこれらのモデルのリスクを注意深く調査し、特徴づける必要があります。そこで私たちは、「Grover」と呼ばれる制御可能なテキスト生成モデルを紹介します。Groverは、「Link Found Between Vaccines and Autism（ワクチンと自閉症の間に関連がある）」のような見出しが与えられると、記事の残りの部分を生成することができる。Groverのようなジェネレーターに対する強固な検証技術を開発することは非常に重要です。現在、最も優れた識別装置は、中程度の学習データを利用した場合、ニューラルフェイクニュースと人間が書いた本物のニュースを73％の精度で分類できることがわかっています。逆に、Groverに対する最良の防御策は、Grover自身であることが判明し、92%の精度を得ることができ、強力なジェネレーターを公開することの重要性を示しています。これらの結果をさらに調査し、暴露バイアスとその影響を緩和するサンプリング戦略の両方が、類似の識別装置が拾うことができるアーティファクトを残すことを示しました。最後に、この技術に関する倫理的な問題について議論し、Groverを公開して、ニューラルフェイクニュースのより良い検出への道を開くことを計画しています。
Disentangled representationは、データの変動の顕著な要因に関する情報を独立して符号化します。この表現形式は、現実世界の多くのダウンストリームタスクを解決するための学習に有用であるとしばしば主張されますが、この主張を裏付ける実証的な証拠はほとんどありません。本論文では、分離表現が抽象的な推論課題に適しているかどうかを調査する大規模な研究を行った。Raven's Progressive Matricesに類似した2つの新しいタスクを用いて、360個の最新の教師なし離散化モデルによって学習された表現の有用性を評価する。これらの表現に基づいて、3600の抽象的な推論モデルを学習したところ、分離した表現は実際にダウンストリームのパフォーマンスを向上させることがわかった。特に、より少ないサンプル数で迅速な学習が可能である。
新しいデータソースを活用することは、材料の設計と発見のペースを加速するための重要なステップです。過去のデータ、実験データ、計算データによる合成計画の進展を補完するために、科学文献と合成に関する知見を結びつける自動化された手法を紹介します。自然言語テキストから始めて、言語モデルからの単語埋め込みを適用し、それを名前付き実体認識モデルに与え、それに基づいて条件付き変分自動エンコーダーを学習して、任意の材料の合成を生成する。この技術の可能性を、2種類のペロブスカイト材料の前駆体を予測することで示した。この予測には、その材料の合成法が初めて報告される10年以上前に公開された学習データのみを使用した。このモデルは、合成に関連する特性に対応する材料の表現を学習し、モデルの動作が既存の熱力学的知識を補完することを実証した。最後に、このモデルを応用して、提案されている新規ペロブスカイト化合物の合成可能性スクリーニングを行った。
畳み込みニューラルネットワーク（ConvNets）は、一般的に一定のリソース予算で開発され、より多くのリソースが利用可能な場合には、精度を高めるためにスケールアップされます。本論文では、モデルのスケーリングを系統的に研究し、ネットワークの深さ、幅、および解像度のバランスを慎重に取ることで、より良い性能が得られることを明らかにしました。この結果に基づき，シンプルかつ効果的な複合係数を用いて，深さ/幅/解像度のすべての次元を均一にスケーリングする新しいスケーリング手法を提案する．この手法の有効性をMobileNetsとResNetのスケーリングで実証した。さらに、ニューラル・アーキテクチャ・サーチを用いて新しいベースライン・ネットワークを設計し、それをスケールアップすることで、従来のConvNetsよりもはるかに優れた精度と効率を実現するEfficientNetsと呼ばれるモデル群を得ました。特に、EfficientNet-B7は、ImageNetにおいて84.3%のトップ1精度を達成しましたが、既存の最良のConvNetと比較して、8.4倍のサイズと6.1倍の推論速度を実現しています。また、CIFAR-100 (91.7%)、Flowers (98.8%)、その他3つの転移学習データセットにおいても、少ないパラメータで最先端の精度を得ることができました。ソースコードはこちらのhttpsのURLにあります。
行動クローニングは、観察結果から専門家の行動を予測する識別モデルを学習することで、政策学習を教師付き学習に落とし込みます。このような識別モデルは非因果的である。つまり、学習手順は専門家と環境の間の相互作用の因果構造を意識しない。因果関係を無視することは、模倣学習における分布の変化のために、特に有害であることを指摘します。特に、因果関係を無視すると、より多くの情報を得ることでパフォーマンスが低下するという、逆に直感に反する「因果関係の誤認」現象が発生する。本研究では、この問題がどのようにして起こるのかを調査し、正しい因果モデルを決定するために、環境との相互作用や専門家への問い合わせなどのターゲットを絞った介入を行うことで、この問題に対処する解決策を提案する。因果関係の誤認識は、いくつかのベンチマーク制御領域と現実的な運転設定で発生することを示し、DAggerや他のベースライン、アブレーションに対して我々の解決策を検証した。
深層学習と記号的AIの間のギャップを埋めることを目的として、生のピクセルデータから明示的な関係構造を持つ命題表現を形成することを学習する、新しいエンドツーエンドのニューラルネットワークアーキテクチャを発表します。このアーキテクチャを評価・分析するために、様々な複雑さを持つ単純な視覚的関係推論タスク群を導入した。提案したアーキテクチャは、このようなタスクのカリキュラムで事前に学習された場合、再利用可能な表現を生成することを学習し、いくつかのベースラインアーキテクチャと比較して、以前に見たことのないタスクに対する後続の学習をより容易にすることを示した。学習に成功したモデルの動作を可視化することで，アーキテクチャの機能を明らかにした．
人気のあるMNISTデータセット[LeCun et al., 1994]は、NISTデータベース[Grother and Hanaoka, 1995]から派生したものであるが、この派生のための正確な処理手順は時間の経過とともに失われてしまった。我々は、MNISTデータセットの代替として十分な精度を持ち、かつ精度の変化が軽微な再構築を提案する。MNISTの各桁を、NISTのソースと、ライター識別子やパーティション識別子などの豊富なメタデータまで追跡する。また、MNISTのテストセットを、通常の1万サンプルから6万サンプルに変更して再構築しました。残りの5万サンプルは配布されていないため、25年間のMNIST実験が報告されているテスト性能に与える影響を調べることができます。我々の結果は、Rechtら[2018, 2019]によって観察された傾向を明確に確認している：誤分類率はわずかにずれているが、分類器の順序付けとモデル選択は広く信頼できるままである。この現象は、同じ桁で分類器を比較することで得られるペアリングのメリットによるものだと考えています。
正規化フローは、高次元連続分布のモデリングに大きな進歩をもたらしたが、離散分布への適用性はまだ不明である。本論文では、フローが実際に離散事象に拡張できること、しかもlog-determinant-Jacobian計算を必要としない単純な変数変更式の下で拡張できることを示している。離散フローは多くの応用が可能である。1つは、双方向性を可能にする離散的な自己回帰フローで、これにより、例えば、テキスト中のトークンが、厳密な言語モデルにおいて、左から右、右から左の両方のコンテキストに依存することができます。もう1つは、RealNVPのような効率的な非自己回帰生成を可能にする離散的な二部フローです。実証的には、離散自己回帰フローは、合成離散分布、加算タスク、Pottsモデルにおいて自己回帰ベースラインを上回り、二部構成フローは、Penn Tree Bankやtext8の文字レベルの言語モデルにおいて自己回帰ベースラインと競争できる性能を得ることができます。
本論文では、画像分類器のロバスト性に関する厳密なベンチマークを確立しました。最初のベンチマークであるImageNet-Cは、破損のロバスト性に関するトピックを標準化し、拡張するとともに、セーフティクリティカルなアプリケーションではどの分類器が望ましいかを示しています。次に、ImageNet-Pと呼ばれる新しいデータセットを提案します。このデータセットは、一般的な摂動に対する分類器の頑健性をベンチマークすることができます。最近の頑健性研究とは異なり、このベンチマークは、最悪のケースの敵対的摂動ではなく、一般的な破損や摂動に対する性能を評価する。その結果、AlexNet分類器とResNet分類器の間で、汚職に対する頑健性の変化はごくわずかであることが分かりました。その後、破損や摂動の堅牢性を高める方法を発見しました。さらに、敵対的防御を回避することで、共通の摂動に対する頑健性が大幅に向上することも分かりました。これらのベンチマークは、ロバストに一般化するネットワークを目指す将来の研究に役立つでしょう。
半教師付き学習は、ラベルの付いていないデータを活用して、ラベル付きの大規模なデータセットへの依存を軽減するための強力なパラダイムであることが証明されている。本研究では、半教師付き学習の現在の主要なアプローチを統合して、新しいアルゴリズムであるMixMatchを開発した。このアルゴリズムは、データで補強されたラベルなしの例に対して低エントロピーラベルを推測し、MixUpを用いてラベル付きデータとラベルなしデータを混合することで動作する。MixMatchは、多くのデータセットとラベル付きデータ量において、大きなマージンで最先端の結果を得ることができることを示している。例えば，250個のラベルを持つCIFAR-10では，エラー率を4分の1に低減し（38%から11%），STL-10では2分の1に低減しました．また、MixMatchを用いることで、精度とプライバシーのトレードオフを劇的に改善し、差分プライバシーを実現できることを示しました。最後に、MixMatchのどのコンポーネントが成功のために最も重要であるかを明らかにするために、アブレーション研究を行います。
現代の神経配列生成モデルは、トークンをゼロから段階的に生成するか、あるいは固定長に拘束されたトークンの配列を（反復的に）修正するように作られています。本研究では、より柔軟で従順なシーケンス生成のために考案された新しい部分自己回帰モデルであるLevenshtein Transformerを開発しました。これまでのアプローチとは異なり、本モデルでは挿入と削除を原子的な操作としています。この2つの操作を組み合わせることで、配列の生成だけでなく、動的な長さの変更を可能にする配列の精密化も容易になります。また、この2つの操作に特化した新しい学習手法を提案し、一方を他方の学習信号として効果的に利用することで、両者の相補性を高めています。提案モデルを適用した実験では、生成タスク（機械翻訳、テキスト要約など）と絞り込みタスク（自動ポストエディットなど）の両方において、同等の性能を発揮しながらも、効率性が大幅に向上した。さらに、機械翻訳で訓練されたLevenshtein Transformerが、自動ポストエディットに簡単に使用できることを示すことで、我々のモデルの柔軟性を確認した。
専門家の行動をデモンストレーションから模倣する学習は、特に高次元で連続的な観測や未知のダイナミクスを持つ環境では困難です。行動クローニング（BC）に基づく教師付き学習法は、分布のずれに悩まされます。エージェントは貪欲に実演された行動を真似るため、エラーの蓄積により実演された状態から離れてしまう可能性があります。強化学習（RL）に基づく最近の手法である逆RLや生成的逆襲模倣学習（GAIL）では、RLエージェントを訓練して、長い水平線上でデモンストレーションに一致させることで、この問題を克服しています。しかし、課題に対する真の報酬関数は未知であるため、これらの手法はデモから報酬関数を学習するが、多くの場合、敵対的な学習を伴う複雑で脆い近似技術を用いる。我々は、RLを用いながらも、報酬関数の学習を必要としないシンプルな代替手法を提案する。鍵となるアイデアは、エージェントに、長い水平線上でデモンストレーションに一致させるインセンティブを与えることである。これを達成するために、エージェントに、実証された状態で実証された行動に一致した場合にはr=+1の一定の報酬を与え、それ以外の行動にはr=0の一定の報酬を与えることにしました。ソフトQ模倣学習（SQIL）と呼ぶ我々の手法は、標準的なQ学習やオフポリシーのアクター批判アルゴリズムにわずかな変更を加えるだけで実装できるものである。理論的には、SQILはBCの正則化された変種と解釈でき、スパース性事前分布を用いて長期的な模倣を促すことができることを示す。実証的には、Box2D、Atari、MuJoCoなどの画像ベースの低次元タスクにおいて、SQILがBCよりも優れており、GAILと比較しても競争力のある結果が得られることを示す。
本研究では、反実仮想的な視覚的説明を生成する技術を開発する。視覚システムがクラス$c$を予測する「クエリ」画像$I$が与えられたとき、反事実的な視覚的説明は、システムが別の指定されたクラス$c'$を出力するように$I$がどのように変化しうるかを特定する。これは、システムがクラス$c'$と予測する「気晴らし」画像$I'$を選択し、$I$と$I'$の空間領域を特定することで、$I$の特定された領域を$I'$の特定された領域で置き換えることで、システムが$I$を$c'$に分類する方向に進むようにします。我々のアプローチを複数の画像分類データセットに適用し、我々の反実例の説明の解釈性と識別性を示す定性的な結果を得た。さらに、我々の説明が人間に教える際に有効であるかどうかを調べるために、細かい鳥の分類というタスクに対する機械学習実験を行った。その結果、鳥の種を識別する訓練を受けたユーザーは、訓練例に加えて反実在の説明にもアクセスできるようになると、より良い結果が得られることがわかった。
Generative Adversarial Networks（GAN）は、画像生成では大きな成功を収めているが、自然言語の領域では学習が難しいことがわかっている。勾配推定、最適化の不安定さ、モード崩壊などの問題があるため、実務者は最尤法による事前学習を行い、その後、少量の逆説的な微調整を行うことにしています。結果として得られるモデルは、従来の言語モデルと同等かそれ以上のサンプルを生成するため、言語生成におけるGANの微調整の利点は不明である。我々は、言語GANをゼロから訓練することが実際に可能であることを示す。大規模なバッチサイズ、密な報酬、識別器の正則化などの既存の技術を組み合わせることで、言語GANの安定化と改善を図ります。その結果、ScratchGANは、EMNLP2017 NewsおよびWikiText-103コーパスにおいて、品質と多様性の指標に基づき、最尤学習と同等の性能を発揮しました。
グラフニューラルネットワークは、グラフ構造を持つデータに対する機械学習問題を解決するための最も重要な技術の一つとなっています。頂点分類に関する最近の研究では、高い性能とスケーラビリティを実現するために、深層学習モデルと分散学習モデルが提案されました。しかし、ベンチマークデータセットの特徴ベクトルは、分類タスクのために既にかなりの情報量を持っており、グラフ構造はデータをノイズ除去する手段を提供するに過ぎないことが分かった。本論文では、グラフニューラルネットワークを分析するために、グラフ信号処理に基づいた理論的枠組みを開発した。その結果、グラフニューラルネットワークは、特徴ベクトルに対してローパスフィルタリングを行うだけで、非線形多様体学習の性質を持たないことがわかった。さらに、特徴量のノイズに対する耐性を調べ、GCNベースのグラフニューラルネットワークの設計に関するいくつかの洞察を提案した。
我々は、低レベル表現のプログラムを人間が読める高レベルのプログラミング言語に戻す、自動分解の問題に取り組んでいる。逆コンパイルの問題は、セキュリティ研究者にとって非常に重要です。脆弱性を発見したり、マルウェアの動作を理解したりするには、ソースコード上で行う方がはるかに簡単です。逆コンパイルの重要性から、手作りのルールベースのデコンパイラが作られるようになりました。このようなデコンパイラは、専門家によって設計されており、低レベルのコードに含まれる特定の制御フロー構造やイディオムを検出し、それをソースレベルにまで引き上げます。このようなモデルでは、追加の言語や新しい言語機能をサポートするためのコストが非常に高くなります。我々は、ニューラル機械翻訳に基づいた分解のための新しいアプローチを提案する。主なアイデアは、与えられたコンパイラから逆コンパイルを自動的に学習することである。ソース言語Sからターゲット言語Tへのコンパイラが与えられたとき，我々のアプローチは，TをSに翻訳（逆コンパイル）することができるデコンパイラを自動的に学習する．このフレームワークを用いて，LLVM IRとx86アセンブリの両方をCコードにデコンパイルしたところ，高い成功率を得ることができました．LLVMおよびx86のインスタンスを使用して、ベンチマークの97%および88%をデコンパイルすることができました。
言語モデル（LM）の事前学習は、さまざまな言語理解タスクにおいて素晴らしい性能とサンプル効率をもたらしてきました。しかし、抽象的な要約などの生成タスクにおいて、事前に学習したLMをどのように利用すれば、特にサンプル効率を向上させることができるのかはまだ明らかになっていません。このようなsequence-to-sequenceの設定では、事前に学習した重みをエンコーダやデコーダのネットワークにロードする実験が行われているが、事前に学習していないエンコーダとデコーダの注意重みを使用している。ここでは、事前に学習したデコーダのみのネットワークを使用し、同じTransformer LMがソースのエンコードとサマリーの生成を行います。これにより、ソースの状態に対する注意を制御するパラメータを含む、ネットワークのすべてのパラメータが、微調整ステップの前に事前に学習されていることが保証されます。CNN/Daily Mailデータセットを用いた実験では、事前に学習したTransformer LMが、データ数が限られた環境において、事前に学習したTransformerエンコーダ・デコーダネットワークよりも大幅に向上することが示された。例えば、学習データのわずか1％（約3000例）で13.1 ROUGE-2を達成したのに対し、学習済みのエンコーダ・デコーダモデルのスコアは2.3 ROUGE-2だった。
畳み込みニューラルネットワーク（CNN）は，重要なパターン認識タスクで驚異的な成功を収めているが，計算量が多く，解釈性に欠けるという問題がある．最近開発されたTsetlin Machine (TM)は、複雑なパターン認識問題を解決するために、解釈しやすい命題論理の接続詞節を使用することで、この問題を解決しようとしている。TMは、解釈可能性という重要な特性を維持しながら、いくつかのベンチマークで競争力のある精度を提供しています。さらに、入力、パターン、出力がビットで表現され、認識や学習がビットの操作に依存するため、ハードウェアに近い実装が容易になります。本論文では、CNNに代わる解釈可能な手法として、Convolutional Tsetlin Machine (CTM)を導入し、TMのパラダイムを利用している。TMでは、各節を画像全体に一度だけ適用して画像を分類するのに対し、CTMでは、各節を畳み込みフィルターとして使用する。つまり、1つの句が複数回評価され、畳み込みに参加する画像パッチごとに1回ずつ評価されます。畳み込み条件に位置を認識させるために、各パッチには画像内の座標が追加されます。畳み込み句の出力は、各パッチでの句の評価結果を単純にORして得られる。TMの学習段階では、1と評価された句が入力と対比されます。CTMでは、代わりに、文節を1に評価したパッチの中からランダムに選ばれた1つのパッチと対比します。これにより、古典的なTMの標準的なタイプIとタイプIIのフィードバックを、さらに変更することなく、直接採用することができます。CTMは、MNISTで99.4%、Kuzushiji-MNISTで96.31%、Fashion-MNISTで91.5%、2D Noisy XOR Problemで100.0%のピークテスト精度を得ており、単純な4層CNN、BinaryConnect、Logistic Circuits、FPGAで加速したBinary CNNなどで報告されている結果と競合している。
人間は、過去の経験から得たスキルを利用して、無数の高度なタスクを実行することができます。自律型エージェントがこのような能力を持つためには、過去の経験から再利用可能なスキルを抽出し、それを新たな方法で組み合わせて次のタスクを実行することができなければなりません。さらに、人型のような高次元の複雑な形態を制御する場合、複数のスキルを同時に調整する必要があります。スキルの組み合わせごとに個別のプリミティブを学習することは、すぐに限界に達してしまいます。このようなコンビナトリアル・エクスプロージョンをモデル化するには、組み替えて多種多様な動作を作り出すことができるコンポーザブル・プリミティブが適している。本研究では、Multiplicative compositional policies (MCP)を提案する。これは、再利用可能な運動技能を学習するための手法であり、様々な複雑な行動を生み出すために組み合わせることができる。この手法では、エージェントのスキルをプリミティブの集合体に因数分解し、複数のプリミティブを乗算合成によって同時に活性化することができる。この柔軟性により、プリミティブは、新しいタスクのために必要に応じて、新しい行動を引き出すために、転送したり、再結合したりすることができる。本研究では、MCPが、動作模倣などの事前学習タスクから、非常に複雑なシミュレーションキャラクターのための合成可能なスキルを抽出し、これらのスキルを再利用して、サッカーボールをドリブルでゴールに運んだり、物体を拾って目標の場所に運んだりするような難しい連続制御タスクを解決できることを実証した。
本研究では、(1)異なるクライアントが別々に所有し、(2)異なるクラスからなる非同一の分布から抽出された複数のデータコレクションから、生成的敵対ネットワーク（GAN）を学習するという新しい問題に取り組んでいます。このような非IDデータを入力とし、各クライアントのストレージにデータを分散させたまま、入力データが属することのできるすべてのクラスを含む分布を学習することを目的としています。この目的のための我々の主要な貢献は、Forgiver-First Update (F2U)と呼ばれる、非IDデータからGANを学習するための新しい分散型アプローチである。この更新戦略により、分散型GANはf-divergence最小化に基づいて、すべての入力クラスに対する生成器の分布を大域的に最適化することができることを理論的に証明した。さらに、F2Uの緩和版であるForgiver-First Aggregation (F2A)を提案し、実際によく機能している。画像生成タスクを用いた実証評価により、最新の分散型学習手法に対する本手法の有効性が示された。
教師なしの画像間翻訳手法は，非構造化（非登録）画像データを用いて，あるクラスの画像を別のクラスの類似画像にマッピングすることを学習する．現在の手法は非常に成功しているが、学習時にはソースクラスとデスティネーションクラスの両方で多くの画像にアクセスする必要がある。このことが、手法の利用を大きく制限していると考えています。我々は、少数の例から新しい物体の本質を見つけ出し、そこから一般化するという人間の能力からヒントを得て、数ショットの教師なし画像間翻訳アルゴリズムを模索している。このアルゴリズムは、テスト時に少数の例示画像によってのみ指定される、以前に見たことのないターゲットクラスに対して機能する。我々のモデルは、敵対的な学習スキームと新しいネットワークデザインを組み合わせることで、この数ショット生成機能を実現しています。ベンチマークデータセットを用いた広範な実験的検証と、いくつかのベースライン手法との比較を通じて、提案するフレームワークの有効性を検証した。我々の実装とデータセットは、こちらのhttps URLで公開されています。
我々は、シミュレートされたシナリオの分布上でトレーニングを行うことによって、ポリシーを実世界に移すという問題を考える。シミュレーションのランダム化を手動で調整するのではなく、ポリシーのトレーニングと並行して実世界でのロールアウトを数回行うことで、シミュレーションのパラメータ分布を適応させます。そうすることで，シミュレーションの分布を変更し，シミュレーションと実世界でのポリシーの動作を一致させることで，ポリシーの伝達を改善することができる．我々の手法でトレーニングされたポリシーは、2つの実世界タスク（Swing-peg-in-holeとキャビネットの引き出しを開ける）において、異なるロボットに確実に移行できることを示しています。実験の動画は、こちらのhttpsのURLからご覧いただけます。
Zellersら（2018）による最近の研究では、常識的な自然言語推論という新しいタスクが導入されました。"A woman sits at a piano "のようなイベント記述が与えられた場合、機械は最も可能性の高いフォローアップを選択しなければなりません。"She sets her fingers on the keys."（彼女は鍵盤に指を置いている）。BERTの導入により、人間に近い性能を実現しました。これは、機械が人間レベルのコモンセンス推論を行えることを意味するのでしょうか？本論文では、新しいチャレンジデータセットである「HellaSwag」を提示することで、最新のモデルでも常識的推論が依然として困難であることを示しています。HellaSwagは、人間にとっては些細な質問であるにもかかわらず（95%以上の精度）、最新のモデルでは苦戦しています（48%未満の精度）。これを実現するために、Adversarial Filtering（AF）というデータ収集パラダイムを採用しました。このパラダイムでは、一連の識別器が、機械が生成した誤った回答の敵対的なセットを繰り返し選択します。AFは驚くほどロバストであることがわかった。重要な洞察は、データセットの例の長さと複雑さを、生成されたテキストが人間には馬鹿げているが、最先端のモデルではしばしば誤分類されるという、重要な「ゴルディロックス」ゾーンに向かってスケールアップすることです。HellaSwagの構築とその難しさは、深層学習済みモデルの内部構造に光を当てています。より広く言えば、ベンチマークが敵対的な方法で進化する最新技術と共進化し、より困難な課題を提示するという、NLP研究の新しい道を示唆しています。
PaperRobotは、(1)人間が書いた論文を深く理解し、包括的な背景知識グラフ(KG)を構築し、(2)グラフの注目と文脈上のテキストの注目を組み合わせて、背景KGからリンクを予測して新しいアイデアを生み出し、(3)記憶注目ネットワークに基づいて新しい論文の重要な要素を段階的に書いていくことで、自動研究アシスタントとして機能します。入力されたタイトルと予測された関連エンティティから論文のアブストラクトを生成し、アブストラクトから結論と今後の課題を生成し、最後に今後の課題から次の論文のタイトルを生成する。生物医学分野の専門家がシステムの出力と人間が書いた文字列を比較するチューリングテストでは、PaperRobotが生成したアブストラクト、結論、今後の課題のセクション、そして新しいタイトルが、人間が書いたものよりもそれぞれ30％、24％、12％の割合で選ばれています。
ペネトレーションテスト（Pentesting）とは、コンピュータシステムのセキュリティを評価するために、制御された攻撃を行うことです。ペネトレーションテストは、セキュリティテストとしては効果的な手法ですが、高度なスキルを持った実施者が必要であり、現在、熟練したサイバーセキュリティの専門家が不足しています。この問題を解決する方法の一つとして、人工知能技術を用いてペンテストのプロセスを自動化することが挙げられます。しかし、サイバーセキュリティの状況は急速に変化しているため、最新の脆弱性モデルを維持することは困難です。このプロジェクトでは、モデルフリーの強化学習（RL）を自動ペンテストに適用することを検討しました。モデルフリー強化学習は、環境のモデルを必要とせず、環境とのインタラクションを通じて最適なポリシーを学習するという、モデルベースのプランニングに比べて重要な利点があります。私たちはまず、自律的なペンテスト・エージェントのトレーニングとテストのために、高速で低計算機のシミュレータを設計・構築しました。これは、ペンテストを、ネットワークの既知の構成を状態とし、利用可能なスキャンとエクスプロイトをアクションとし、ネットワーク上のマシンの値によって報酬を決定するマルコフ決定プロセスとして構成することで実現しました。そして、このシミュレータを使って、モデルフリーRLをペンテストに適用することを検討しました。標準的なQ-learningアルゴリズムを、表形式とニューラルネットワークベースの実装の両方でテストしました。その結果、表計算とニューラルネットワークの両方の実装で、行動モデルがなくても、さまざまなネットワークのトポロジーやサイズに対して最適な攻撃経路を見つけることができました。しかし、実装されたアルゴリズムは、小規模なネットワークやアクションの数に対してしか実用的ではありませんでした。スケーラブルなRLアルゴリズムの開発と、これらのアルゴリズムをより大規模かつ高忠実度の環境でテストするためには、さらなる研究が必要である。
ペネトレーションテスト（Pentesting）とは、コンピュータシステムのセキュリティを評価するために、制御された攻撃を行うことです。ペネトレーションテスト（ペンテスト）は、セキュリティを評価するためにコンピュータシステムに制御された攻撃を行うもので、セキュリティテストとしては効果的な手法ですが、高度なスキルを必要とし、現在、サイバーセキュリティの専門家が不足しています。この問題を解決する方法の一つとして、人工知能技術を用いてペンテストのプロセスを自動化することが挙げられます。しかし、サイバーセキュリティの状況は急速に変化しているため、最新の脆弱性モデルを維持することは困難です。このプロジェクトでは、モデルフリーの強化学習（RL）を自動ペンテストに適用することを検討しました。モデルフリー強化学習は、環境のモデルを必要とせず、環境とのインタラクションを通じて最適なポリシーを学習するという、モデルベースのプランニングに比べて重要な利点があります。私たちはまず、自律的なペンテスト・エージェントのトレーニングとテストのために、高速で低計算機のシミュレータを設計・構築しました。これは、ペンテストを、ネットワークの既知の構成を状態とし、利用可能なスキャンとエクスプロイトをアクションとし、ネットワーク上のマシンの値によって報酬を決定するマルコフ決定プロセスとして構成することで実現しました。そして、このシミュレータを使って、モデルフリーRLをペンテストに適用することを検討しました。標準的なQ-learningアルゴリズムを、表形式とニューラルネットワークベースの実装の両方でテストしました。その結果、表計算とニューラルネットワークの両方の実装で、行動モデルがなくても、さまざまなネットワークのトポロジーやサイズに対して最適な攻撃経路を見つけることができました。しかし、実装されたアルゴリズムは、小規模なネットワークやアクションの数に対してしか実用的ではありませんでした。スケーラブルなRLアルゴリズムの開発と、これらのアルゴリズムをより大規模かつ高忠実度の環境でテストするためには、さらなる研究が必要である。
広告のコンバージョンを正確に予測することは、コンバージョンが頻繁に発生するわけではないため、一般的に困難な課題である。本論文では、消費者に配信する前に広告テキストのコンバージョンを正確に予測することを含め、パフォーマンスの高い広告クリエイティブの作成をサポートする新しいフレームワークを提案しています。提案するフレームワークには、マルチタスク学習、条件付き注意、注意の強調という3つの重要なアイデアが含まれています。マルチタスク学習は、コンバージョンの予測精度を向上させるためのアイデアで、クリックとコンバージョンを同時に予測することで、データの不均衡という難点を解決します。また、コンディショナルアテンションは、広告クリエイティブのジャンルやターゲットの性別を考慮して、各広告クリエイティブに注目することで、コンバージョン予測精度を向上させます。また、アテンションハイライトでは、条件付きアテンションに基づいて、重要な単語やフレーズを可視化します。提案したフレームワークを実際の配信履歴データ（Gunosy社の一定回数以上表示された14,000クリエイティブ）で評価したところ、これらのアイデアによってコンバージョン予測性能が向上し、クリエイティブの属性に応じて注目すべき単語が可視化されることを確認しました。
検出は、画像内の軸の揃ったボックスとしてオブジェクトを識別します。多くの物体検出器は、物体が存在する可能性のある場所をほぼ網羅的に列挙し、それぞれを分類しています。これは無駄が多く、非効率的で、さらに後処理が必要です。本論文では、異なるアプローチをとる。物体を1つの点（バウンディングボックスの中心点）としてモデル化します。この検出器は、キーポイント推定を用いて中心点を見つけ、サイズ、3D位置、方向、さらにはポーズなど、他のすべてのオブジェクトの特性に回帰します。我々の中心点ベースのアプローチであるCenterNetは、対応するバウンディングボックスベースの検出器よりも、エンドツーエンドで微分可能で、シンプルかつ高速で、より正確です。CenterNetは、MS COCOデータセットにおいて、142 FPSで28.1%のAP、52 FPSで37.4%のAP、マルチスケールテストでは1.4 FPSで45.1%のAPと、速度と精度のトレードオフを実現しました。また，同じ手法を用いて，KITTIベンチマークでは3次元バウンディングボックスを，COCOキーポイントデータセットでは人物の姿勢を推定した．我々の手法は，洗練されたマルチステージ手法に匹敵する性能を持ち，リアルタイムで動作する．
学習済みのテキストエンコーダーは、多くのNLPタスクにおいて急速に技術水準を向上させている。本研究では、そのようなモデルの一つであるBERTに焦点を当て、ネットワーク内のどこで言語情報が取得されるかを定量化することを目的としています。このモデルは、従来のNLPパイプラインのステップを解釈可能かつローカライズ可能な方法で表現しており、各ステップを担当する領域は予想された順序で現れることがわかりました。また、各ステップを担当する領域は、POSタグ、構文解析、NER、意味的役割、そして共参照という予想される順序で現れることがわかりました。定性的な分析によると、モデルはこのパイプラインを動的に調整することが可能であり、多くの場合、上位の表現からの情報を曖昧にすることに基づいて下位レベルの決定を修正している。
探索は強化学習（RL）における最大の課題の1つであり、RLをロボット工学に応用する際の大きな障害となっています。最先端のRLアルゴリズムを用いても、十分に学習されたエージェントを構築するには、主に遠い将来の報酬と行動を一致させることが難しいため、多くの試行回数を必要とすることが多い。この問題を解決するには、ある行動に対して即座に報酬を与える人間の観察者からのリアルタイムのフィードバックを用いてエージェントを訓練する必要があります。本研究では、このようなHuman-in-the-Loop RLスキームを導入するための一連の課題に取り組んでいます。本研究の第一の貢献は、精密にモデル化された人間観察者を用いた実験である。二値化、遅延、確率、持続不可能性、自然な反応などである。また、DQN-TAMERと呼ばれるRL方式を提案し、人間のフィードバックと遠方からの報酬の両方を効率的に利用することに成功しました。DQN-TAMERエージェントは、MazeおよびTaxiのシミュレーション環境において、ベースラインを上回る性能を示すことがわかった。さらに、実際のHuman-in-the-Loop RLアプリケーションでは、エージェントが迷路を探索している間、カメラがユーザーの顔の表情を自動的に認識してエージェントにフィードバックすることを実証しました。
標準的なニューラルネットワークは、学習分布から外れたデータを提示されると、しばしば過信してしまいます。我々は、ニューラルネットワークのパラメータの分布を学習するための新しい生成モデルであるHyperGANを紹介します。HyperGANはプライヤーに制限的な仮定を必要とせず、そこからサンプリングされたネットワークは、非常に大規模で多様なアンサンブルを迅速に作成するために使用することができます。HyperGANは、事前のサンプルを相関次元を持つ潜在空間に投影する新しいミキサーを採用しており、潜在空間からのサンプルは、深層ニューラルネットワークの各層の重みを生成するために使用されます。HyperGANは、MNISTおよびCIFAR-10データセットをラベル付けするパラメータを、完全な教師付き学習に匹敵する性能で生成するように学習できることを示し、同時に有効なパラメータの豊富な分布を学習する。また、分布外のデータや敵対的な例で評価することで、HyperGANは標準的なアンサンブルよりも優れた不確実性推定値を提供できることも示している。
他の話者や背景雑音などの混合音から単一の音声信号を分離するためのオーディオ・ビジュアル合同モデルを紹介します。音声のみを入力としてこのタスクを解決することは非常に困難であり、分離された音声信号と映像内の話者との関連付けを行うことができません。本論文では、このタスクを解決するために、視覚と聴覚の両方の信号を組み込んだディープネットワークベースのモデルを紹介します。視覚的特徴は、音声をシーン内の望ましい話者に「フォーカス」し、音声分離の品質を向上させるために使用されます。この音声・視覚モデルを学習するために，ウェブ上の何千時間ものビデオセグメントからなる新しいデータセットであるAVSpeechを導入しました．従来の音声分離タスクに加え，熱のこもったインタビュー，騒がしいバー，泣き叫ぶ子供などの実世界のシナリオに対して，我々の手法が適用可能であることを示した．我々の手法は、音声が混在している場合に、最先端の音声のみの音声分離よりも明らかに優れています。さらに、話者に依存しない（一度の学習でどの話者にも適用できる）本モデルは、話者に依存する（対象となる話者ごとに個別のモデルを学習する必要がある）最近のオーディオ・ビジュアル音声分離手法よりも優れた結果を示しています。
ディープニューラルネットワーク（DNN）は、古典的な学習理論では著しくオーバーフィットすると予測されるような強い過剰パラメトリック領域においても、明示的な正則化なしに驚くほどよく一般化する。この成功を合理化するために、ある種の暗黙の正則化に関する多くの提案がなされてきたが、DNNが強くオーバーフィットしない根本的な理由については合意が得られていない。本論文では、新しい説明を提供する。アルゴリズム情報理論(AIT)から最近導き出された非常に一般的な確率-複雑性境界を適用することで、多くのDNNのパラメータ-関数マップは単純な関数に指数関数的に偏っているはずだと主張する。そして、ブール関数のモデルDNNや、CIFAR10とMNISTに適用されたより大規模な完全連結ネットワークや畳み込みネットワークにおいて、この強い単純性バイアスの明確な証拠を示す。多くの現実の問題では、対象となる関数は高度に構造化されていることが予想されるため、この本質的な単純性バイアスは、深層ネットワークが現実の問題をうまく一般化する理由を説明するのに役立ちます。また、この図式は、パラメータ空間に対する従来の事前処理ではなく、DNNの入出力関数空間に対する事前処理を行う、新しいPAC-Bayesアプローチを促進する。学習アルゴリズムがパラメータをゼロエラー領域内でほぼ一様にサンプリングすると仮定すると、PAC-Bayesの定理を用いて、高尤度の学習セットを生成するターゲット関数に対して良好な期待汎化を保証することができる。最近発見されたDNNとガウス過程の関連性を利用して周辺尤度を推定することで、MNISTやCIFAR10などの現実的なデータセットや、畳み込みネットワークや完全連結ネットワークなどのアーキテクチャにおいて、真の誤差とよく相関する比較的厳しい汎化PAC-Bayes誤差境界を生成する。
深層ニューラルネットワークの性能は、アノテーションされたデータが多いほど向上します。しかし問題は、アノテーションの予算が限られていることです。これを解決する一つの方法が能動学習であり、モデルが不確実だと認識したデータに対して人間にアノテーションを依頼するものである。アクティブラーニングをディープネットワークに適用するための手法は最近様々なものが提案されているが、その多くは対象となるタスクに特化して設計されているか、大規模なネットワークでは計算効率が悪いものである。本論文では、シンプルでありながらタスクにとらわれず、かつ深層ネットワークで効率的に動作する新しい能動学習法を提案する。損失予測モジュール」と名付けた小さなパラメトリックモジュールを対象ネットワークに取り付け、ラベルのない入力の損失を予測するように学習する。そして、このモジュールは、ターゲットモデルが誤った予測をする可能性が高いデータを示唆することができます。この方法は、対象となるタスクに関わらず、単一の損失からネットワークを学習するため、タスクにとらわれない。本研究では、画像分類、物体検出、人間の姿勢推定を行い、最新のネットワークアーキテクチャを用いて本手法を厳密に検証した。その結果、本手法は、これまでの手法よりも一貫して優れた性能を発揮することがわかった。
敵対的な例は、機械学習において大きな注目を集めているが、その存在と普及の理由はまだ不明である。本研究では、逆問題例が、非ロバストな特徴の存在に直接起因することを示します。すなわち、データ分布のパターンに由来する特徴は、予測性が高いにもかかわらず、人間には理解できない脆いものです。これらの特徴を理論的な枠組みで捉えた後、標準的なデータセットに広く存在していることを証明します。最後に，実際に観察される現象を，（人間が指定した）頑健性の概念とデータの固有の幾何学性との間のミスアライメントに厳密に結びつけることができる簡単な設定を提示する．
本レポートでは、過去の経験から学習し、ターゲットクラス内の任意のタスクに適応するサンプル効率の良い戦略を構築するツールとして、メモリベースのメタ学習をレビューします。我々の目的は、幅広い領域で動作する新しいスケーラブルなエージェントを構築するための、このツールの概念的な基盤を読者に提供することである。そのために、タスクの構造を効率的に利用できる確率モデルを持っているかのように振る舞う、ほぼ最適な予測器と強化学習器を構築するための基本的なアルゴリズムテンプレートを提示する。さらに、記憶に基づくメタ学習をベイズの枠組みで再構成し、ベイズフィルタリングされたデータを償却することで、メタ学習された戦略が最適に近いものになることを示す。基本的に、メモリベースのメタ学習は、確率的逐次推論の難しい問題を回帰問題に変換します。
自然言語は階層的に構造化されています。小さな単位（例えば、フレーズ）は、より大きな単位（例えば、節）の中に入れ子になっています。大きな構成要素が終了すると、その中に入れ子になっている小さな構成要素もすべて終了しなければなりません。標準的なLSTMのアーキテクチャでは、異なるニューロンが異なる時間スケールの情報を追跡することができるが、構成要素の階層をモデル化するための明示的なバイアスは持っていない。この論文では、ニューロンを順番に並べることで、そのような帰納的バイアスを加えることを提案している。マスター入力ゲートと忘却ゲートのベクトルにより、あるニューロンが更新されると、それに続くすべてのニューロンも更新されるようになっている。我々の新しい再帰アーキテクチャである順序付きニューロンLSTM（ON-LSTM）は、言語モデリング、教師なし構文解析、対象となる構文評価、および論理的推論という4つの異なるタスクで良好な性能を達成した。
最近開発されたCNNを使って、1枚の画像から奥行きを予測する能力は、視覚分野でますます注目されています。教師なしで学習する方法は、学習の際に、より大規模で多様な単眼ビデオデータセットを利用できるため、特に魅力的です。これまでの研究では、ポーズと奥行きのCNN予測を別々に行い、それらの共同出力が測光誤差を最小化するように決定する必要がありました。最近のダイレクト・ビジュアル・オドメトリ（DVO）の進歩に触発され、我々はポーズCNN予測器なしで深度CNN予測器を学習できることを主張する。さらに、DVOの微分可能な実装と、新しい深度正規化戦略を取り入れることで、単眼動画を学習に用いる従来の手法よりも性能が大幅に向上することを実証した。
近年、深層畳み込みネットワーク(DCN)を用いて、ラベルのない動画を見て、一枚の画像から深さを再構成する学習が注目されています。本論文では、教師なしの深度推定フレームワークのための表面法線表現を紹介する。推定された深さは、予測された法線と互換性があるように制約され、よりロバストな幾何学的結果が得られます。具体的には、エッジを考慮した深さと法線の整合性の項を定式化し、DCNの内部に深さから法線への層と法線から深さへの層を構築することで解決します。depth-to-normal層は、推定された深さを入力とし、隣接するピクセルに基づくクロスプロダクションを用いて法線方向を計算します。推定された法線が与えられると、normal-to-depth層は、局所的な平面平滑性によって正則化された深度マップを出力します。この2つの層は、奥行きと法線の不連続性の問題を解決し、シャープなエッジを維持するために、画像内のエッジを意識して計算されます。最後に，ネットワークを学習するために，深度予測と法線予測の両方に対して，測光誤差と勾配平滑性を適用した．屋外（KITTI）と屋内（NYUv2）の両方のデータセットで実験を行い、我々のアルゴリズムが最先端の技術を大幅に上回ることを示し、我々のアプローチから得られる利点を実証しました。
我々は、非構造化ビデオシーケンスからの単眼の奥行きとカメラの動きを推定するタスクのための教師なし学習フレームワークを提示する。これは、監視信号としての視点合成タスクを用いて、奥行きとカメラの姿勢推定ネットワークを同時に学習することで実現しています。このようにして，ネットワークは，学習時には視点合成の目的を介して結合されるが，テスト時には独立して適用することができる．KITTIデータセットを用いた実証評価により，我々のアプローチの有効性が実証された．1）単眼の深度は，学習のためにグランドトゥルースのポーズまたは深度のいずれかを使用する教師付き手法と同等の性能を示し，2）ポーズ推定は，同等の入力設定の下で既存のSLAMシステムと同等の性能を示した．
我々は、補完的な探索技術と新しいアーキテクチャ設計の組み合わせに基づいた、次世代のMobileNetを発表します。MobileNetV3は、ハードウェアを意識したネットワークアーキテクチャ検索（NAS）とNetAdaptアルゴリズムの組み合わせにより、携帯電話のCPUに合わせて調整されており、その後、新しいアーキテクチャの進歩により改善されています。この論文では、自動検索アルゴリズムとネットワーク設計がどのように連携し、補完的なアプローチを利用して全体的な技術水準を向上させることができるかを探ります。このプロセスを経て、2つの新しいMobileNetモデルをリリースします。MobileNetV3-LargeとMobileNetV3-Smallである。そして、これらのモデルをオブジェクト検出とセマンティックセグメンテーションのタスクに適用しました。セマンティックセグメンテーション（または高密度ピクセル予測）のタスクに対しては、新しい効率的なセグメンテーションデコーダLite Reduced Atrous Spatial Pyramid Pooling（LR-ASPP）を提案しています。モバイルの分類、検出、セグメンテーションにおいて、最先端の結果を得ることができました。MobileNetV3-Largeは、MobileNetV2と比較して、ImageNetの分類精度を3.2%向上させるとともに、レイテンシーを15%削減しています。MobileNetV3-SmallはMobileNetV2と比較して、4.6%の精度向上と5%のレイテンシー削減を実現しています。MobileNetV3-LargeはCOCO検出においてMobileNetV2とほぼ同等の精度で25%の高速化を実現しています。MobileNetV3-Large LR-ASPPはCityscapesセグメンテーションにおいてMobileNetV2 R-ASPPと同程度の精度で30%高速化しています。
半教師付き学習は、ラベル付きデータが不足している場合に深層学習モデルを改善するのに非常に有望です。最近のアプローチに共通しているのは、大量のラベルなしデータに対する一貫性学習を用いて、モデルの予測値が入力ノイズに対して不変であるように制約することです。本研究では、ラベルのない例に効果的にノイズをかける方法について新しい視点を提示し、ノイズの質、特に高度なデータ増強法によって生成されるものが、半教師付き学習において重要な役割を果たすことを主張する。単純なノイズ処理を、RandAugmentや逆翻訳などの高度なデータ補強法に置き換えることで、我々の手法は、同じ一貫性のある学習フレームワークの下で、6つの言語タスクと3つの視覚タスクにおいて大幅な改善をもたらした。IMDbテキスト分類データセットでは、ラベル付きの例がわずか20個しかないにもかかわらず、我々の手法はエラーレート4.20を達成し、25,000個のラベル付き例で学習された最先端モデルを上回りました。標準的な半教師付き学習のベンチマークであるCIFAR-10では，我々の手法はこれまでのすべてのアプローチよりも優れており，わずか250個の例で5.43のエラーレートを達成した．また、本手法は、BERTからの微調整を行う場合など、転移学習との相性が良く、ImageNetのような高データ領域において、10%のラベル付きデータしかない場合でも、1.3Mの余分なラベルなし例を含む完全なラベル付きセットを使用した場合でも、改善をもたらします。コードはこちらのhttpsのURLから入手できます。
観測されていない交絡がある場合の因果推論について考察します。ユニットをつなぐネットワークの形で、観察されない交絡の代理が利用できる場合を研究する。例えば，ソーシャルネットワークのリンク構造は，そのメンバーに関する情報を含んでいる．我々は、因果推論を行うために代理を効果的に使用する方法を示します。主なアイデアは、因果推定問題を、治療法と結果の両方の半教師付き予測に還元することである。ネットワークには、この半教師付き予測に使用できる高品質の埋め込みモデルが存在する。我々は、予測モデルの品質に関する適切な（弱い）条件の下で、この方法が有効な推論をもたらすことを示す。半合成ソーシャルネットワークデータセットを用いた実験により、この手法を検証する。コードはこのhttpのURLから入手できます。
深層学習の開発が近年急増していることを踏まえ、この記事では音声信号処理のための最先端の深層学習技術のレビューを行います。音声、音楽、環境音の処理を並べて検討し、領域間の類似点と相違点を指摘し、一般的な手法、問題点、主要な参考文献、領域間の相互肥大化の可能性を強調しています。主な特徴表現（特に、log-melスペクトルと生の波形）と深層学習モデルについて、畳み込みニューラルネットワーク、長短期記憶アーキテクチャの変形、およびよりオーディオに特化したニューラルネットワークモデルを含めてレビューします。続いて、ディープラーニングの応用分野として、音声認識（自動音声認識、音楽情報検索、環境音の検出、定位と追跡）、合成と変換（音源分離、オーディオエンハンスメント、音声・音響・音楽合成の生成モデル）を取り上げています。最後に、音声信号処理に適用される深層学習に関する重要な課題と今後の課題を明らかにします。
ニューラルネットワークのモデルを学習する際には、メモリがボトルネックになることが多くなっています。これにもかかわらず、学習時の全体的なメモリ要件を低減する技術は、推論時のメモリ要件の低減に関する広範な文献に比べて、あまり広く研究されていない。この論文では、基本的な問題を研究しています。この論文では、次のような基本的な問題を研究しています。「ニューラルネットワークの学習には、実際にどのくらいのメモリが必要なのか？この疑問に答えるために、2つの代表的な深層学習ベンチマーク--画像分類用のWideResNetモデルと機械翻訳用のDynamicConv Transformerモデル--における学習の全体的なメモリ使用量をプロファイリングし、学習メモリ要件を削減するための4つの標準的な技術を総合的に評価する。(1）モデルにスパース性を持たせる，（2）低精度を用いる，（3）マイクロバッチを用いる，（4）勾配チェックポインティングを用いる，という4つの標準的な学習メモリ削減手法を総合的に評価しました。これらの手法を単独で使用した場合，学習時のピークメモリ使用量と最終モデルの品質の両方にどのような影響があるかを調べ，また，これらの手法を組み合わせた場合に生じるメモリ，精度，計算のトレードオフを調べました．これらの技術を適切に組み合わせることで，CIFAR-10のWideResNet-28-2の学習に必要なメモリを，精度を0.4%低下させながら最大60.7倍に削減し，IWSLT'14の独英翻訳のDynamicConvモデルの学習に必要なメモリを，BLEUスコアを0.15低下させながら最大8.7倍に削減することができることを示した．
マルチホップ推論の学習は、読解モデルにとって重要な課題であり、この課題に明示的に焦点を当てたデータセットの設計につながっています。理想的には、モデルは、マルチホップ推論を行わずに、マルチホップ質問応答タスクで良い結果を出すことはできないはずである。本論文では、最近提案された2つのデータセット、WikiHopとHotpotQAについて調査する。これらのモデルは、マルチホップ推論ができないように設計されているが、それでも両データセットの多くの例を解決することができる。さらに、WikiHopのマスクされていないバージョンでは、スプリアスな相関が見られ、質問と回答のみを考慮して高い性能を達成することが容易であることがわかりました。最後に、これらのデータセットの重要な違いの1つである、QAタスクのスパンベースとマルチプルチョイスの定式化について調べました。両データセットの多肢選択版は簡単にゲーム化でき、我々が検証した2つのモデルは、この設定ではベースラインをわずかに上回るに過ぎません。全体として、これらのデータセットは有用なテストベッドであるが、高性能なモデルは、これまで考えられていたほど多くのマルチホップ推論を学習していない可能性がある。
深層生成モデルは、現代の機械学習の基礎となりつつあります。条件付き生成敵対ネットワークに関する最近の研究では，自然画像上の複雑で高次元の分布を学習することが可能であることが示されている．最新のモデルは、高解像度で高忠実度の多様な自然画像を生成することができるが、膨大な量のラベル付きデータに依存している。本研究では、自己および半教師付き学習に関する最近の研究成果を利用して、教師なしのImageNet合成、および条件付きの設定の両方において、最新の技術を上回ることができることを示します。特に、提案したアプローチは、ImageNetにおいて、現在の最先端の条件付きモデルであるBigGANのサンプル品質（FIDで測定）に、ラベルの10％のみを使用した場合に匹敵し、ラベルの20％を使用した場合には凌駕することができます。
ハイエンドの性能を持つモデルを学習するには、大規模なラベル付きデータセットを入手する必要がありますが、これは高価なものです。我々の研究の目的は、下流のタスクに関連するラベル付きデータセットを自動的に合成することである。我々は、合成シーンの生成モデルを学習するMeta-Simを提案し、グラフィックスエンジンを介して、画像とそれに対応するグランドトゥルースを得る。このニューラルネットワークは、確率的なシーングラマーから得られるシーングラフの属性を修正することを学習し、レンダリング出力とターゲットデータの間の分布ギャップを最小化するようにします。実際のデータセットにラベル付きの検証セットが少ない場合、我々はさらにメタ目的、すなわち下流のタスクパフォーマンスを最適化することを目指す。実験の結果、提案手法は、人間が作成した確率的シーン文法に比べて、コンテンツ生成の品質を質的にも量的にも大幅に改善できることがわかった。
畳み込み層は、長年にわたりコンピュータビジョンにおける主要な特徴抽出器として使用されてきた。しかし、畳み込みにおける空間的な集約は、基本的には固定されたフィルタを適用するパターンマッチングプロセスであり、空間的な分布が変化する視覚要素をモデル化するには非効率的である。本論文では、局所的なピクセルペアの構成的関係に基づいて集約の重みを適応的に決定する、局所関係層と呼ばれる新しい画像特徴抽出器を紹介する。この関係性に基づいたアプローチにより、視覚的要素をより高レベルのエンティティに効率的に合成することができ、意味論的な推論に有利となる。LR-Net（Local Relation Network）と呼ばれる局所関係層を用いたネットワークは、ImageNetの分類などの大規模な認識タスクにおいて、通常の畳み込みを用いたネットワークよりも高いモデリング能力を発揮することがわかった。
少ないストローク数で素晴らしい絵画を描くことができる人間の画家のように、機械に絵を描かせる方法を示しています。モデルベースの深層強化学習（DRL）にニューラルレンダラーを採用することで、エージェントは各ストロークの位置と色を決定し、テクスチャの豊富な画像をストロークに分解する長期的な計画を立てることを学習します。実験では、数百のストロークを使って優れた視覚効果が得られることが実証されています。この学習プロセスには、人間のペインターの経験や、ストロークのトラッキングデータは必要ありません。コードはこのhttpsのURLから入手できます。
生物医学イメージングのための機械学習は，ラベル付けされた学習データの不足に悩まされることが多い．一つの解決策は、生成モデルを使ってより多くのデータを合成することです。そこで，畳み込みカプセルとpix2pixフレームワークを組み合わせたCapsPix2Pixを紹介し，クラス分割ラベルを条件とした画像の合成を行うことにした．このアプローチを，二光子顕微鏡で撮影された皮質軸索からなる新しい生物医学データセットに適用し，小規模データセットのためのデータ増強法として利用した．本研究では，性能を定性的および定量的に評価した．定量的な評価は，CapsPix2Pixまたはpix2pixによって生成された画像データを用いて，セグメンテーションタスクについてU-netを学習させ，実際の顕微鏡データでテストすることによって行う．我々の手法は，定量的にはpix2pixと同等の性能を，1桁少ないパラメータで実現しています．さらに，CapsPix2Pixは，基本的な形状が同じであるにもかかわらず，異なる外観の画像を合成する能力がはるかに優れています．最後に、CapsPix2Pixが学習した特徴を定性的に分析すると、個々のカプセルは、シナプス、軸索、ノイズなどの構造をカバーする、多様でしばしば意味のある特徴群を捉えていることがわかります。
トランスフォーマーは強力なシーケンスモデルですが、シーケンスの長さに対して2次関数的に増加する時間とメモリを必要とします。本論文では、注目行列の疎な因子化を導入し、これを$O(n sqrt{n})$に削減する。また、a)より深いネットワークを学習するためのアーキテクチャと初期化のバリエーション、b)メモリを節約するための注目行列の再計算、c)学習のための高速な注目カーネルを紹介します。これらの変更を加えたネットワークを「スパース・トランスフォーマー」と呼び、数百の層を使って数万タイムステップのシーケンスをモデル化できることを示した。同じアーキテクチャを用いて、画像、音声、テキストを生のバイトからモデル化し、Enwik8、CIFAR-10、ImageNet-64の密度モデリングに新たな境地を開いた。大局的な一貫性と大きな多様性を示す無条件のサンプルを生成し、自己注意を用いて長さ100万以上の配列をモデル化することが原理的に可能であることを示しました。
車の運転には、様々な複雑な環境条件やエージェントの行動に対応する必要があります。想定されるすべてのシナリオを明示的にモデル化することは現実的ではありません。一方、模倣学習は、理論的には、人間が運転する大量の車のデータを活用することができます。特に行動クローニングは、単純な視覚運動方針をエンド・ツー・エンドで学習するのに成功しているが、運転行動の全領域に適用するにはまだ未解決の問題がある。本論文では、行動クローニングのスケーラビリティと限界を実験的に調べるために、新しいベンチマークを提案する。挙動クローニングは、目に見えない環境下で、複雑な横方向および縦方向の操作を、これらの反応を明示的にプログラムすることなく実行するなど、最先端の結果をもたらすことを示している。しかし、よく知られている限界（データセットの偏りとオーバーフィッティングによる）、新たな一般化の問題（動的な物体と因果関係モデルの欠如による）、トレーニングの不安定さを確認し、ビヘイビア・クローニングを実世界の運転に適用するにはさらなる研究が必要であることを示した。研究されたビヘイビアクローニングアプローチのコードは、このhttpsのURLにあります。
本論文では，2段階の方法で入力配列に基づいて出力配列を生成することができる，新しい事前学習ベースのエンコーダ・デコーダフレームワークを提案する．我々のモデルのエンコーダでは、BERTを用いて入力シーケンスをコンテキスト表現にエンコードする。デコーダには2つのステージがあり、第1ステージでは、Transformerベースのデコーダを使用して、ドラフト出力シーケンスを生成します。次に、入力シーケンスとBERTによって生成されたドラフト表現を組み合わせることにより、Transformerベースのデコーダを使用して、マスクされた各位置に対して洗練された単語を予測します。我々の知る限り、我々のアプローチは、BERTをテキスト生成タスクに適用した最初の方法である。この方向での最初のステップとして、我々はテキスト要約タスクで我々の提案した方法を評価する。実験結果は、CNN/Daily MailデータセットとNew York Timesデータセットの両方において、我々のモデルが最新の技術を達成したことを示している。
BERTは、事前に学習されたTransformerモデルであり、複数のNLPタスクにおいて画期的な性能を達成している。本論文では、抽出型要約のための、BERTのシンプルな変形であるBERTSUMについて説明します。我々のシステムは、CNN/Dailymailデータセットにおいて、ROUGE-Lにおいて以前の最高性能のシステムを1.65上回っており、最先端の技術である。我々の結果を再現するためのコードは、このhttpsのURLから入手可能です。
Transformerアーキテクチャは、RNNベースのモデルよりも計算効率に優れています。最近では、GPTとBERTが、大規模コーパス上で事前に学習した言語モデルを用いて、様々なNLPタスクにおけるTransformerモデルの有効性を実証しています。意外なことに、これらのTransformerアーキテクチャは、言語モデル自体にとっては最適ではありません。Transformerにおける自己注意も位置符号化も、言語モデル化に不可欠な単語レベルの逐次文脈を効率的に組み込むことができません。本論文では、LSTM層を追加することで、計算効率を維持しつつ逐次文脈をよりよく取り込むことを含め、言語モデルのための効果的なTransformerアーキテクチャを探求します。モデルを反復的に改良することで効果的なアーキテクチャを見つけるために、CAS（Coordinate Architecture Search）を提案します。PTB、WikiText-2、WikiText-103を用いた実験の結果、CASはすべての問題で20.42から34.11のperplexityを達成し、最先端のLSTMと比較して平均で12.0 perplexity unitsの改善を実現した。ソースコードは公開されています。
致命的な忘却への対処は、機械学習システムが逐次またはストリーミングのタスクで学習される継続的学習における重要な課題の1つです。近年、最先端の深層学習が目覚ましく発展しているにもかかわらず、深層ニューラルネットワーク（DNN）は、壊滅的な忘却問題に悩まされています。本論文では、DNNを用いた継続的な学習における壊滅的な忘却を処理するための、概念的にシンプルでありながら一般的かつ効果的なフレームワークを提案する。提案手法は、神経構造最適化コンポーネントと、パラメータ学習および/または微調整コンポーネントの2つのコンポーネントで構成される。提案手法は、明示的な神経構造の学習とパラメータの推定を分離することで、直観的に意味のある方法で神経構造を進化させることができるだけでなく、実験において壊滅的な忘却を緩和する強い能力を示している。さらに、提案手法は、継続的学習の設定において、順列付きMNISTデータセット、分割されたCIFAR100データセット、およびVisual Domain Decathlonデータセットにおいて、他のすべてのベースラインを凌駕する。
機械学習モデルに対する敵対的な攻撃は、ここ数年で関心が高まっています。畳み込みニューラルネットワークの入力にわずかな変更を加えるだけで，ネットワークの出力を揺さぶり，全く異なる結果を出力させることができる．最初の攻撃は、入力画像のピクセル値をわずかに変更することで、分類器が誤ったクラスを出力するように仕向けたものでした。また、検出器や分類器を欺くために、対象物に適用する「パッチ」を学習しようとするアプローチもあります。これらのアプローチの中には、物体に手を加えてビデオカメラで撮影することで、これらの攻撃が実世界で実現可能であることを示したものもあります。しかし、これらのアプローチはすべて、クラス内の多様性がほとんどないクラス（例：停止線）を対象としています。このような場合には、オブジェクトの既知の構造を利用して、その上に敵対的なパッチを生成します。本論文では、クラス内の多様性が多いターゲット、すなわち人物に対して敵対的なパッチを生成するアプローチを紹介します。その目的は、人物検出器から人物をうまく隠すことができるパッチを生成することです。この攻撃は、例えば、監視システムを回避するために悪意を持って使用される可能性があります。侵入者は、監視カメラに向けて小さなボール紙のプレートを体の前に持ってくることで、検出されずにこっそりと移動することができます。この結果から、私たちのシステムは、人物検出器の精度を大幅に下げることができることがわかりました。また、我々のアプローチは、パッチがカメラで撮影されているような現実のシナリオでもうまく機能します。我々の知る限りでは、人物のようなクラス内変動が大きいターゲットに対してこの種の攻撃を試みたのは我々が初めてである。
音声認識のためのシンプルなデータ補強手法であるSpecAugmentを紹介します。SpecAugmentは、ニューラルネットワークの特徴入力（フィルターバンクの係数）に直接適用される。増強政策は、特徴量のワープ、周波数チャンネルのマスキングブロック、時間ステップのマスキングブロックからなる。SpecAugmentをListen、Attend、Spellの各ネットワークに適用し、エンド・ツー・エンドの音声認識タスクを行う。その結果、LibriSpeech 960hとSwichboard 300hのタスクにおいて、先行研究を上回る最先端の性能を達成した。LibriSpeechでは、言語モデルを使用せずにtest-otherで6.8%のWERを達成し、言語モデルとの浅い融合では5.8%のWERを達成しました。これは、これまでの最先端のハイブリッドシステムの7.5%のWERと比較しています。Switchboardについては、Hub5'00テストセットのSwitchboard/CallHome部分において、言語モデルを使用せずに7.2%/14.6%、浅い融合で6.8%/14.1%を達成しており、これは従来の最先端のハイブリッドシステムの8.3%/17.3%のWERと比較しても遜色ない。
この1年間で、事前学習や伝達学習のための新しいモデルや手法が、さまざまな言語理解タスクにおいて顕著な性能向上をもたらしました。1年余り前に導入されたGLUEベンチマークは、このような多様なタスクの進捗状況を1つの数値で示す指標ですが、このベンチマークの性能は最近、専門家ではない人間のレベルを超えており、今後の研究の余地が限られていることを示唆しています。本論文では、GLUEに類似した新しいベンチマークであるSuperGLUEを紹介します。SuperGLUEは、より困難な言語理解タスクのセット、ソフトウェアツールキット、および公開リーダーボードを備えています。SuperGLUEはこのhttpのURLから入手可能です。
このモデルは、実際の非分離・非決定論的な絵画プログラムから学習された筆跡の生成モデルです。筆跡を用いて画像を「描く」エージェントを育成する際に、微分可能なニューラルペインターを用いると、収束が非常に速くなることを示す。さらに、このエージェントに、人間のようなストロークで指を再構成するように促す方法を提案する。また、ニューラルペインターを微分可能な画像パラメータとして使用することも検討しています。事前に学習した畳み込みネットワークのニューロンを活性化するためにブラシストロークを直接最適化することで、ImageNetのカテゴリを直接視覚化し、各クラスの「理想的な」絵画を生成することができます。最後に、intrinsic style transferという新しい概念を紹介します。ニューラル・スタイル・トランスファーによるコンテンツの損失のみを最小化することで、芸術的媒体（ここでは筆跡）が結果的にスタイルを自然に決定することを可能にします。
我々は、ビデオ間の時間的アライメントのタスクに基づいて、自己教師付き表現学習法を導入した。この手法では、微分可能な周期整合性損失であるTCC（Temporal Cycle Consistency）を用いてネットワークを学習し、複数の動画の時間的な対応関係を見つけることができる。得られたフレームごとの埋め込みは、学習された埋め込み空間内の最近傍を用いてフレームをマッチングするだけで、動画の位置合わせに利用できる。埋め込みの能力を評価するために、PouringとPenn Actionのビデオデータセットにアクションフェーズの密なラベルを付けた。TCCは、Shuffle and LearnやTime-Contrastive Networksのような、ビデオにおける自己教師付き学習の他の手法を補完するものであることを示した。また、この埋め込みは、ビデオペア間のアラインメント（密な時間的対応）に基づいて、ビデオ間で同期されたモダリティのメタデータ（音、時間的なセマンティックラベル）の転送、複数のビデオの同期再生、異常検知などの多くのアプリケーションに使用されています。プロジェクトのWebページ：このhttpsのURL 。
検索エンジンの検索性能を向上させる手法の1つに、文書の内容に関連した、あるいは代表的な用語で文書を拡張することがあります。このような観点から、我々は、与えられた文書に対してどのようなクエリが発行されるかを予測し、クエリと関連文書のペアからなるデータセットを用いて学習されたバニラ配列対配列モデルを用いて、その予測に基づいて文書を展開する簡単な手法を提案する。我々の手法に、非常に効果的な再ランキングコンポーネントを組み合わせることで、2つの検索タスクにおいて最先端の技術を実現しています。レイテンシーが重要な領域では、検索結果のみ（再順位付けなし）で、より計算コストの高いニューラル再順位付け装置の効果に近づき、しかもはるかに高速である。
現在の最先端の物体検出用の畳み込みアーキテクチャは、手動で設計されています。ここでは、物体検出のための特徴ピラミッドネットワークのより良いアーキテクチャを学習することを目的としています。本研究では、ニューラル・アーキテクチャ・サーチを採用し、すべてのクロススケール接続をカバーする新しいスケーラブルな探索空間において、新しい特徴ピラミッド・アーキテクチャを発見する。発見されたアーキテクチャはNAS-FPNと名付けられ、トップダウン接続とボトムアップ接続の組み合わせで構成され、スケールを超えた特徴を融合します。NAS-FPNは、RetinaNetフレームワークの様々なバックボーンモデルと組み合わせることで、最先端の物体検出モデルと比較して、より優れた精度とレイテンシーのトレードオフを実現します。NAS-FPNは、最先端のSSDLite with MobileNetV2モデル[32]と比較して、モバイル検出精度を2AP向上させ、より少ない計算時間でMask R-CNN[10]の検出精度を上回る48.3APを達成しました。
深層ニューラルネットワークモデルと強化学習アルゴリズムを組み合わせることで、カメラ画像などの生の感覚入力を直接読み取るロボット行動のポリシーを学習することが可能になり、推定と制御の両方を1つのモデルに効率的に組み込むことができます。しかし、現実の強化学習アプリケーションでは、手動でプログラムされた報酬関数によってタスクのゴールを指定する必要があります。実際には、エンド・ツー・エンドの強化学習が避けることを約束しているのと同じ知覚パイプラインを設計するか、タスクが正常に実行されたかどうかを判断するために環境に追加のセンサーを設置する必要があります。本論文では、ロボットが適度な数の成功例から学習することで、報酬の仕様を手動で作成する必要性を排除するアプローチを提案している。すべての状態に対してラベルを要求することは、ユーザーに報酬信号を手動で提供することに相当するが、本手法では、トレーニング中に見られる状態のごく一部に対してラベルを要求するだけであるため、手動で報酬を与えずにスキルを学習するための効率的かつ実用的なアプローチとなっている。本手法は，ロボットのカメラで撮影された画像を用いた実世界のロボット操作タスクで評価した．実験の結果、本手法は、画像から直接、物体の配置、本の配置、布の掛け方を学習することができ、手動で指定された報酬関数を必要とせず、わずか1〜4時間の実世界とのインタラクションで、効果的に学習することができた。
本論文では，教師なしの領域適応の問題を，理論的およびアルゴリズム的な観点から取り上げている．既存の領域適応理論は、当然ながら最小値最適化アルゴリズムを示唆しており、これは敵対的学習に基づく領域適応手法とよく結びついている。しかし、いくつかの断絶がまだ存在しており、理論とアルゴリズムの間のギャップを形成している。本研究では，従来の理論(Mansour et al., 2009c; Ben-David et al., 2010)をドメイン適応におけるマルチクラス分類に拡張し，アルゴリズム設計において得点関数とマージンロスに基づく分類器を標準的な選択肢とする．本論文では，マージンロスの非対称性を利用した分布比較や，学習を容易にするためのミニマックス最適化に合わせた，厳密な一般化境界を持つ新しい測定法であるマージン不一致不一致を紹介する．我々の理論は、領域適応のための敵対的学習アルゴリズムにシームレスに変換することができ、理論とアルゴリズムのギャップを埋めることに成功している。一連の実証研究により、我々のアルゴリズムが、困難な領域適応タスクにおいて、最先端の精度を達成することが示された。
自然界の画像では、情報は異なる周波数で伝達されます。高い周波数は詳細な情報を、低い周波数は大局的な構造をエンコードします。同様に、畳み込み層の出力特徴マップは、異なる周波数の情報の混合物と見なすことができる。本研究では、混合された特徴マップを周波数で因数分解することを提案し、空間的に「ゆっくり」変化する特徴マップを低い空間解像度で保存・処理するために、新しいOctave Convolution (OctConv)演算を設計することで、メモリと計算コストの両方を削減する。既存のマルチスケール手法とは異なり、OctConvは、単一の汎用的なプラグアンドプレイの畳み込みユニットとして定式化されており、ネットワークアーキテクチャを調整することなく、（バニラ）畳み込みを直接置き換えることができます。また、より良いトポロジーを提案したり、グループや深さ方向の畳み込みのようにチャンネルごとの冗長性を削減する方法とは直交し、補完関係にあります。我々は、畳み込みをOctConvに置き換えるだけで、メモリと計算コストを削減しながら、画像とビデオの両方の認識タスクの精度を一貫して高めることができることを実験的に示した。OctConvを搭載したResNet-152は、わずか22.2GFLOPsで、ImageNetにおいて82.9%のトップ1分類精度を達成しました。
我々は、様々な領域の幅広いMRCタスクに適用可能な共同機械読解（MRC）モデルを学習するためのマルチタスク学習フレームワークを提案する。機械翻訳におけるデータ選択の最近のアイデアに触発され、損失にサンプル固有の重みを割り当てる新しいサンプル再重み付けスキームを開発した。実証実験により、我々のアプローチが既存の多くのMRCモデルに適用できることが示された。また、事前に学習した言語モデル（ELMoなど）の文脈表現と組み合わせることで、一連のMRCベンチマークデータセットにおいて最先端の結果を得ることができました。コードはこちらのhttps URLで公開しています。
物語文の視覚的要約を作成するための機械学習アプローチを紹介します。名前付きエンティティ認識のための標準的な自然言語処理ツールとクラスタリングアルゴリズムを用いて、小説の登場人物とその別名を検出します。最も関連性の高い人物とその関係を、簡単な統計分析に基づいて評価します。これらのキャラクターは、無向グラフのノードとして視覚的に描写され、エッジは他のキャラクターとの関係を表します。文章の埋め込みに基づく特殊な感情分析技術により、文字/ノードの色とその関係/エッジが決定されます。登場人物に関する追加情報（性別など）と、その関係（兄弟やパートナーなど）は、二値分類器によって返され、グラフに視覚的に表示される。このような特殊なタスクでは、少量の手動アノテーションデータで十分な精度が得られます。類似のツールと比較して、我々が紹介する機械学習アプローチは、この種のテキストをより豊かに表現することができる。また、一連の書籍に対してこのアプローチを実証するケーススタディについても報告する。
隣接するビデオフレーム間の一貫性のみを監視信号として用いて、単眼動画から奥行き、自我の動き、物体の動き、カメラの固有性を同時に学習する新しい手法を紹介する。先行研究と同様に、本手法はフレームに微分可能なワーピングを適用し、その結果を隣接するフレームと比較することで学習を行うが、いくつかの改善点がある。オクルージョンを幾何学的かつ微分的に処理し，学習時に予測されるデプスマップを直接使用する．また，新しい強力な正則化であるランダム化された層の正規化を導入し，シーンに対するオブジェクトの動きを考慮しています．我々の知る限りでは，レンズの歪みを含むカメラの固有パラメータをビデオから教師なしで学習したのは我々の研究が初めてであり，これにより，出所不明の任意のビデオから正確な奥行きと動きをスケールで抽出することができる．Cityscapes, KITTI, EuRoCの各データセットを用いて評価した結果、奥行き予測とオドメトリに関する新たな技術を確立し、YouTube動画のコレクションから奥行き予測を学習できることを定性的に示しました。
文章を読んでいると、新しい意味を持つ多義語や、滅多に使われないイディオム、インターネットスラング、新興の実体など、見慣れない単語やフレーズに行き詰まることがよくあります。私たち人間は、そのような表現の意味をローカルな文脈から理解できない場合、辞書を引いて定義を確認したり、文書やウェブを検索して他のグローバルな文脈を見つけて解釈の助けとします。このような作業を機械が手助けすることは可能でしょうか？機械がこの問題を解決するためには、どのタイプの文脈がより重要なのでしょうか？これらの質問に答えるために、我々は、自然言語で与えられたフレーズをそのローカルおよびグローバルなコンテキストに基づいて記述するというタスクを引き受ける。この課題を解決するために、2つの文脈エンコーダーと記述デコーダーからなるニューラル記述モデルを提案する。非標準英語の説明[Ni+ 2017]や定義生成[Noraset+ 2017; Gadetsky+ 2018]のための既存の手法とは対照的に、我々のモデルはローカルおよびグローバルコンテキストの両方から重要な手がかりを適切に得る。既存の3つのデータセット（WordNet、Oxford、Urban Dictionariesを含む）およびWikipediaから新たに作成したデータセットでの実験結果により、本手法が過去の研究に比べて有効であることを実証する。
画像認識のためのニューラルネットワークは、単純な鎖のようなモデルから、複数の配線経路を持つ構造まで、広範なマニュアル設計によって進化してきました。ResNetsやDenseNetsが成功したのは、その革新的な配線計画によるところが大きい。現在、ニューラルアーキテクチャ検索（NAS）研究では、配線と操作タイプの共同最適化が模索されていますが、可能な配線の空間は制約されており、検索されているにもかかわらず、依然として手動設計に振り回されています。本論文では、ランダムに配線されたニューラルネットワークのレンズを通して、より多様な接続パターンを探索する。そのために、まず、ネットワーク生成プロセス全体をカプセル化したストキャスティック・ネットワーク・ジェネレータの概念を定義する。このカプセル化により、NASとランダムワイヤードネットワークを統一的に捉えることができる。次に、3つの古典的なランダム・グラフ・モデルを用いて、ネットワーク用のランダム・ワイヤード・グラフを生成します。その結果は驚くべきものでした。これらのランダム生成器のいくつかのバリエーションにより、ImageNetベンチマークで競争力のある精度を持つネットワークインスタンスが得られました。これらの結果は、より優れたネットワーク生成器の設計に焦点を当てた新たな取り組みが、制約の少ない探索空間を探索することで、斬新な設計の余地があり、新たなブレークスルーをもたらす可能性を示唆している。
テキストベースのアドベンチャーゲームは、自然言語のような組み合わせ行動空間の文脈で強化学習を探求するためのプラットフォームを提供します。我々は、ゲームの状態を、探索中に学習される知識グラフとして表現する、深層強化学習アーキテクチャを提案する。このグラフは行動空間の刈り込みに使われ、より効率的な探索を可能にする。どのような行動を取るべきかという問題は、質問応答タスクに還元することができ、我々のアーキテクチャの特定の部分を事前に学習させる伝達学習の一形態である。TextWorldフレームワークを用いた実験では，提案した手法がベースラインの代替手法よりも高速に制御方針を学習できることを示した．また、このコードはhttpsのURLでオープンソース化されています。
自然言語生成システムが高品質で多様な出力を生成しているかどうかは、どのようにして測定すればよいのでしょうか。人間による評価では、学習セットから盗用しただけのモデルは捕捉できないため、品質は捕捉できても多様性は捕捉できません。一方，統計的な評価（perplexity）は，多様性は捉えられるが品質は捉えられない．なぜならば，低品質のサンプルを時々出すモデルは十分に罰せられないからである．本論文では、ある文章が人間によって作られたものか機械によって作られたものかを予測する際の最適な誤り率に基づいて、多様性と品質の両方を評価する統一的なフレームワークを提案する。この誤差率は、人間評価と統計評価を組み合わせることで効率的に推定できることを、HUSEと呼ぶ評価指標を用いて示す。また、要約や雑談などを対象に、(i)HUSEは純粋な人間の評価を欺くような多様性の欠陥を検出すること、(ii)アニーリングのような品質向上のための技術は、多様性の低下によりHUSEを低下させることを示す。
近年、3Dカーネルを持つ畳み込みニューラルネットワーク（3D CNN）は、2D CNNに比べてビデオフレーム内の時空間特徴を抽出する能力に優れていることから、コンピュータビジョンの分野で非常に注目されています。近年、メモリと電力のバジェットを考慮したリソース効率のよい2D CNNアーキテクチャの構築が進んでいるが、3D CNN用の同様のリソース効率のよいアーキテクチャはほとんど存在しない。この論文では、よく知られたリソース効率のよい2D CNNを3D CNNに変換し、3つの主要なベンチマークにおいて、異なる複雑さのレベルでの分類精度の観点からその性能を評価した。(1)Kinetics-600データセットでは学習能力を、(2)Jesterデータセットではモーションパターンの捕捉能力を、(3)UCF-101では伝達学習の適用性を調べた。各モデルのランタイム性能を、1台のTitan XP GPUとJetson TX2組み込みシステムで評価しました。この研究の結果、これらのモデルは、かなりの精度とメモリ使用量でリアルタイム性能を提供するため、さまざまな種類の実世界のアプリケーションに利用できることがわかりました。複雑さのレベルを変えて分析した結果、リソース効率のよい3D CNNは、複雑さを節約するために浅すぎたり狭すぎたりする設計にすべきではないことがわかりました。本研究で使用したコードとプリトレインモデルは公開されています。
大規模な並列コーパスへの過度の依存は、大多数の言語ペアに対する機械翻訳システムの適用を著しく制限している。教師なしニューラル機械翻訳の従来のアプローチでは、再構成損失を伴うモデルを学習するために疑似文ペアを生成する逆翻訳が主に使用されてきました。しかし、擬似文は、学習中に翻訳エラーが蓄積されるため、通常は低品質となります。この根本的な問題を回避するために、我々は、ターゲットとなるモノリンガル・コーパスから実際の文を抽出してから編集するという、代替的ではあるがより効果的なアプローチであるextract-editを提案する。さらに、翻訳されたターゲットセンテンスを評価するために、比較翻訳損失を導入し、教師なし翻訳システムを学習する。実験の結果，提案手法は，2つのベンチマーク（英語-フランス語，英語-ドイツ）と2つのローリソース言語ペア（英語-ルーマニア語，英語-ロシア語）において，これまでの最先端の教師なし機械翻訳システムを一貫して2（最大3.63）BLEUポイント以上上回ることがわかった．
生成モデルは、その出力の品質を測定するために、しばしば人間の評価を用います。自動化された評価基準は，ヒューリスティックスや事前に学習された埋め込みに依存しているため，間接的な指標としてはノイズが多い．しかし、これまで、人間による直接的な評価方法は、標準化されておらず、検証もされていない、その場限りのものでした。本研究では、生成された実在性のための、人間によるゴールドスタンダードのベンチマークを確立します。HYPE（Human eYe Perceptual Evaluation）は、(1)知覚に関する心理物理学の研究に基づいており、(2)モデルからランダムにサンプリングされた異なる出力セットに対して信頼性があり、(3)分離可能なモデル性能を生成することができ、(4)コストと時間の面で効率的である人間ベンチマークを構築する。1つは、モデルの出力が本物に見える閾値（例えば250ms）を決定するための適応的な時間制約の下で視覚認識を測定するものであり、もう1つは、時間制約なしで偽物と本物の画像に対する人間のエラー率を測定する、より低コストのものである。HYPEは、4つのデータセットを用いて、条件付きおよび無条件の画像生成において、6つの最先端の生成的敵対ネットワークと2つのサンプリング技術を用いてテストした。CelebA、FFHQ、CIFAR-10、ImageNetの4つのデータセットを用いて、条件付きおよび無条件の画像生成において、HYPEを6つの最新の生成敵対ネットワークと2つのサンプリング手法でテストしました。その結果、HYPEはトレーニングエポックを超えてモデルの改善を追跡することができ、ブートストラップサンプリングによってHYPEのランキングが一貫して再現可能であることを確認しました。
最近の研究により、単語表現における言語的知識を検出する能力が向上しました。しかし、構文知識を検出する現在の方法では、構文木が全体的に表現されているかどうかをテストしていません。本研究では、ニューラルネットワークの単語表現空間の線形変換に構文木が埋め込まれているかどうかを評価する構造プローブを提案する。このプローブは、二乗L2距離が構文木の単語間の距離を表す線形変換と、二乗L2ノルムが構文木の深さを表す線形変換を特定する。我々のプローブを用いて、このような変換がELMoとBERTの両方に存在するが、ベースラインには存在しないことを示し、シンタックスツリー全体がディープモデルのベクトル幾何学に暗黙のうちに埋め込まれていることを証明した。
骨の形状や筋肉の状態など、多くの解剖学的要因が相互に影響し合い、人間の動きに影響を与えます。本研究では、筋収縮のダイナミクスによって現実的な人間の動きを再現する包括的な筋骨格モデルとその制御システムを構築することを目的としています。この解剖学的モデルのバリエーションは、典型的な動きから高度に様式化された動きまで、様々な人間の動きを生成します。そのために、スケーラブルで信頼性の高い解剖学的特徴のシミュレーション、深層強化学習に基づく過小運動力学系のロバスト制御、姿勢に依存する関節限界のモデル化について議論します。技術的な貢献としては、346個の筋肉を含む包括的な全身の筋骨格モデルに対応できる、スケーラブルな2レベルの模倣学習アルゴリズムが挙げられる。本研究では，骨の変形，筋力の低下，拘縮，義足の使用などの解剖学的条件の下で，動的な運動技能の予測シミュレーションを実証した．また、様々な病的な歩行をシミュレーションし、整形外科手術によって術後の歩行がどのように改善されるかを予測的に可視化した。
私たちは、自然画像から3D表現を教師なしで学習するタスクのために、新しい生成的敵対ネットワーク（GAN）を提案します。ほとんどの生成モデルは、画像を生成するために2Dカーネルに依存しており、3Dの世界についてはほとんど仮定していない。そのため、これらのモデルは、ノベルビュー合成などの強力な3D理解を必要とするタスクでは、ぼやけた画像やアーティファクトを作成する傾向があります。HoloGANはその代わりに、世界の3D表現を学習し、その表現を現実的な方法でレンダリングします。他のGANとは異なり、HoloGANは学習した3D特徴を剛体変換することで、生成されたオブジェクトの姿勢を明示的に制御します。我々の実験によると、HoloGANは明示的な3D特徴を使用することで、3Dポーズとアイデンティティを分離し、それをさらに形状と外観に分解することができ、しかも他の生成モデルと同等以上の視覚的品質の画像を生成することができます。HoloGANは、ラベルのない2D画像のみからエンドツーエンドで学習することができます。特に、ポーズラベルや3D形状、同じオブジェクトの複数のビューは必要ありません。このことから、HoloGANは、完全に教師なしの方法で自然画像から3D表現を学習する初めての生成モデルであることがわかります。
強化学習（RL）アルゴリズムは、複雑なタスクで有望な結果を示してきましたが、ゼロから学習するため、しばしば非実用的な数のサンプルを必要とします。メタRLは，この課題を解決するために，過去のタスクの経験を活用して，新しいタスクをより迅速に解決することを目指している．しかし、実際には、これらのアルゴリズムは、メタ学習の過程で大量のオンポリシーの経験を必要とするため、多くの問題で使用することは現実的ではありません。そこで我々は、強化学習の手順を連合的に学習することを提案する。個々のオフポリシー学習者が個々のメタトレーニングタスクを解決し、これらの解決策を単一のメタ学習者に集約する。中央のメタ学習者は、個々のタスクの解を模倣して学習するので、標準的なメタRL問題の設定にも、一部またはすべてのタスクに例示が提供されるハイブリッド設定にも対応できます。前者は、メタ学習の際に大量のオンポリシーデータがなくても、前のタスクで学習したポリシーを活用できるアプローチであり、後者は、人が簡単にデモを提供できる場合に特に有効である。連続制御のメタ学習問題において、先行研究と比較してメタ学習のサンプル効率が大幅に改善されたこと、また視覚的な観察が必要な領域にも対応できることを実証した。
人工知能の分野では、ほとんど、あるいは全く監督なしで有用な表現を学習することが重要な課題となっています。本論文では、オートエンコーダーベースのモデルに焦点を当てて、表現学習における最近の進歩を詳細にレビューする。これらの結果を整理するために、我々は、離散化や特徴の階層化など、下流のタスクに役立つと信じられているメタ仲間を利用する。具体的には、（i）（近似または集約）事後分布の正則化、（ii）符号化・復号化分布の因数分解、（iii）構造化事前分布の導入、という3つの主要なメカニズムを明らかにした。いくつかの有望な結果が出ているものの、暗示的または明示的な監視は依然として重要な実現手段であり、現在のすべての手法は強い帰納的バイアスとモデル化の仮定を使用している。最後に、オートエンコーダーを用いた表現学習をレート・ディストーション理論の観点から分析し、下流のタスクに関して利用可能な事前知識の量と、表現がこのタスクに対してどれだけ有用であるかの間に明確なトレードオフがあることを明らかにした。
文書レベルの翻訳やマルチモーダル翻訳など、より大きな文脈でのニューラル機械翻訳への関心が高まっています。複数の研究者が新しいネットワークアーキテクチャや評価スキームを提案しているが、潜在的に有用な文脈は、より大きな文脈の翻訳モデルではまだ無視されることがある。本論文では、マルチレベルのペアワイズランキングロスを用いて、ニューラル翻訳モデルに追加の文脈を考慮することを明示的に促す新しい学習アルゴリズムを提案する。提案した学習アルゴリズムを、変換器ベースの大文節翻訳システムを用いて、文書レベルの翻訳で評価した。実際の文脈とランダムな文脈を用いた場合の性能を比較することで、提案したアルゴリズムで学習したモデルが、追加の文脈に対してより敏感であることを示した。
エンティティリンク（EL）システムは、テキスト中のエンティティの言及を、ナレッジグラフ（KG）中の対応するエンティティに自動的にマッピングすることを目的としています。KG内のエンティティの接続性の度合いは、テキスト内の言及をKG内のエンティティに正しくリンクさせるELシステムの能力に直接影響します。このため、多くのELシステムは、KG内の他のエンティティとの接続性が高いエンティティに対して高い性能を発揮することになり、ELにおけるKG密度の役割が注目されています。本論文では、ELDEN (Entity Linking using Densified Knowledge Graphs) を提案する。ELDENは、大規模なテキストコーパスの共起統計を用いてKGを高密度化し、そのKGを用いてエンティティエンベッディングを学習するELシステムである。この学習されたエンティティエンベッディングを用いてエンティティの類似性を測定することで、ELを向上させることができます。ELDENは、ベンチマークデータセットにおいて、最先端のELシステムを凌駕しています。ELDENは、このような高密度化により、KG内で疎結合のエンティティに対しても優れた性能を発揮します。ELDENのアプローチはシンプルでありながら効果的です。我々はELDENのコードとデータを公開しています。
強化学習（RL）におけるオフポリシーポリシー勾配アルゴリズムのための既存の目的を統一するために、新しい目的である反実例目的を提案します。一般的に使用されているエクスカーション目的と比較して、我々の新しい目的は、展開されたときのターゲットポリシーのパフォーマンスについて誤解を招く可能性があるが、そのようなパフォーマンスをよりよく予測する。一般化されたオフポリシー政策勾配定理を証明し、反実目的の政策勾配を計算し、強調的なアプローチを用いてこの政策勾配から不偏のサンプルを得ることで、一般化されたオフポリシー・アクター・クリティック（Geoff-PAC）アルゴリズムを得ます。Geoff-PACは、Mujocoロボットシミュレーションタスクにおいて、既存のアルゴリズムと比較して、そのメリットを実証しました。
Word Embedding Association Testは、GloVeとword2vecの単語埋め込みが、性別、人種、その他の社会的構成要素に基づく人間のような暗黙のバイアスを示すことを示しています（Caliskan et al.、2017）。一方、再利用可能なテキスト表現の学習に関する研究は、文レベルのテキストを探求し始めており、いくつかの文エンコーディングは熱狂的な採用を見ています。そこで、我々はWord Embedding Association Testを拡張して、センテンスエンコーダーのバイアスを測定する。そして、ELMoやBERTなどの最先端の手法を含むいくつかの文エンコーダーを、先行研究で研究された社会的バイアスと、単語レベルでのテストが困難または不可能な2つの重要なバイアスについてテストした。その結果、テストの仮定が一般的には成り立たないことを示唆する疑わしい感度のパターンを含む、様々な結果が得られました。最後に、文のエンコーダーにおけるバイアスの測定について、今後の研究の方向性を提案します。
ここ数年、画像生成モデルが大きな成功を収めています。ニューラルネットワークによる画像生成は、通常、ピクセルベースで行われますが、これは人間が筆を使ってアートワークを作る方法とは根本的に異なります。人間が描く絵を真似るためには、環境とエージェントの相互作用で試行錯誤する必要があります。しかし、環境は通常、非微分であるため、収束が遅く、大量の計算が必要となる。本論文では、中間的な微分可能なシミュレーションを用いて、ソフトウェア環境の離散的な性質に対処することを試みる。我々はStrokeNetという新しいモデルを発表した．このモデルでは，エージェントは絵画環境のよく練られたニューラル近似で訓練される．このアプローチにより、我々のエージェントは、MNISTの数字のような文字の書き方を、教師なしの方法で強化学習アプローチよりも速く学習することができた。我々の主な貢献は、実世界の環境を神経シミュレーションしたことです。さらに、エミュレートされた環境で訓練されたエージェントは、そのスキルを実世界のソフトウェアに直接移行することができます。
バッチ・ノーマライゼーション（BN）は、ディープネットワークのトレーニングを改善するためのアバウトな手法となっています。しかし、その効果はマイクロバッチトレーニングには限られています。すなわち、各GPUは通常、トレーニング用に1～2枚の画像しか持っていません。これは、メモリ消費量に制約のある、物体検出やセマンティックセグメンテーションなどの多くのコンピュータビジョンタスクでは避けられません。この問題を解決するために，我々は，BNの2つの成功要因である，1）損失ランドスケープに対する平滑化効果，2）学習軌道に沿った有害な消去特異点を回避する能力，をマイクロバッチ学習に導入するために，重み標準化（WS）とバッチチャンネル正規化（BCN）を提案する．WSは、畳み込み層の重みを標準化し、損失と勾配のリプシッツ定数を減らすことで、損失地形を平滑化する。BCNは、バッチとチャネルの正規化を組み合わせ、畳み込み層の活性化の推定統計量を利用して、ネットワークを消去特異点から遠ざける。WSとBCNは、画像分類、オブジェクト検出、インスタンス・セグメンテーション、ビデオ認識、セマンティック・セグメンテーションなど、包括的なコンピュータ・ビジョン・タスクで検証された。すべての実験結果は、WSとBCNがマイクロバッチ学習を大幅に改善することを一貫して示している。さらに、WSとBCNをマイクロバッチ学習に用いることで、BNをラージバッチ学習に用いた場合と同等かそれ以上の性能を得ることができた。
現在の最新の関係性抽出手法は、一般的に、前処理段階で明示的に計算された語彙、構文、および意味の特徴のセットに依存している。特徴抽出モデルの学習には、アノテーションされた言語資源が必要となるため、新しい言語への関係抽出の適用性や移植性が大きく制限されます。同様に、前処理はエラーの原因となります。これらの制限に対処するために、OpenAI Generative Pre-trained Transformer [Radford et al., 2018]を拡張したTRE（Transformer for Relation Extraction）を紹介する。これまでの関係性抽出モデルとは異なり、TREは関係性の分類を知らせるために、明示的な言語的特徴の代わりに事前に訓練された深層言語表現を使用し、それを自己学習型Transformerアーキテクチャと組み合わせることで、エンティティの言及間の長距離依存性を効果的にモデル化します。TREでは、教師なしの事前学習により、プレーンテキストコーパスのみから暗黙的な言語特徴を学習し、関係性抽出タスクで学習した言語表現を微調整することができます。TREは、TACREDおよびSemEval 2010のタスク8データセットにおいて、テストF1がそれぞれ67.4および87.1という最先端の結果を得た。さらに、サンプル効率が大幅に向上したことも確認された。TREはわずか20％の学習例で、ベースラインとTACREDデータセットの100％でスクラッチから学習したモデルの性能に匹敵する。TREの学習モデル、実験、ソースコードはオープンソースで公開されている。
敵対的な例題とは、敵対者が不正な出力を引き起こすように設計された機械学習モデルへの入力である。これまでのところ、敵対的な例は、画像領域で最も広く研究されている。この領域では、誤分類を引き起こすために画像を気づかれないように修正することで敵対的な例を構築することができ、物理的な世界で実用的です。一方、現在音声認識システムに適用されているターゲット型の敵対例は、人間が敵対的な摂動を容易に識別できることや、放送中に再生しても効果がないことなど、これらの特性を備えていません。この論文では、この2つの面で進歩しています。まず、聴覚マスキングという音響心理学の原理を利用して、効果的に知覚されない音声敵対例を開発します（人間による研究で検証されました）。次に、現実的な環境の歪みを適用した後でも効果を維持する摂動を構築することで、物理的な世界である無線の音声敵対例に向けて前進します。
本研究では、入力文の長さをnとした場合に、n個のアタッチメントを構築することで、文を左から右へとストレートに解析する、新しい遷移ベースのアルゴリズムを提案する。Maら（2018）による最近のstack-pointer parserと同様に、我々は、単語が与えられれば、文からの位置を直接指し示すことができるポインタネットワークフレームワークを使用します。しかし、私たちの左から右へのアプローチは、元のトップダウンのスタックポインターパーサーよりもシンプルで（スタックを必要としない）、遷移シーケンスの長さを2n-1アクションからnに半分に減らします。 これにより、元のパーサーの2倍の速度で動作する2次非投影パーサーを実現しながら、英語PTBデータセットで、完全に教師付きの単一モデルの依存関係パーサーの中でこれまでで最高の精度（96.04% UAS, 94.43% LAS）を達成し、テストされた大多数の言語で元のトップダウンの遷移システムよりも改善します。
コンピュータビジョンでは、ほぼすべての最先端の深層学習システムがデータ補強を用いて学習されています。しかし、テキスト分類では、データ補強は学習前に行わなければならず、ラベルノイズを引き起こすリスクがあるため、あまり広く行われていません。我々はIMDB movie reviewsデータセットを、Wei and Zou [2019]によって導入されたランダムなトークンの摂動と、第二言語に翻訳した後に英語に戻すバックトランスレーションという2つの系列の技術によって生成された例で補強する。低リソース環境では、バックトランスレーションは、最先端のULMFitモデルの上に大きな改善を生み出します。wikitext103で事前に学習したULMFitモデルを、IMDBの50例とバックトランスレーションによって生成された500の合成例のみで微調整したところ、わずか9分の追加学習時間で80.6%の精度を達成し、オーグメンテーションなしのベースラインと比較して8.1%の向上を実現しました。ランダムなトークンの摂動では、改善は見られず、同等の計算コストがかかります。逆翻訳された例文を用いた学習の利点は，利用可能な学習データのサイズに応じて減少する．全データセットにおいて、どちらの拡張手法もULMFitの最先端の性能を上回ることはできませんでした。この問題に対処するために、逆翻訳をテスト時間の増強として使用したり、ULMFitを他のモデルとアンサンブルすることで、わずかな改善を実現しました。
AdaGrad、RMSprop、Adamなどの適応型最適化手法は、学習率の要素ごとのスケーリング項を用いて迅速な学習プロセスを実現するために提案されている。しかし、これらの手法は、SGDと比較して汎用性が低く、不安定で極端な学習率のために収束に失敗することもあります。最近の研究では、この問題に取り組むためにAMSGradのようなアルゴリズムが提案されているが、既存の手法を大幅に改善することはできなかった。本論文では、極端な学習率がパフォーマンスの低下につながることを示します。本論文では、AdamとAMSGradをそれぞれAdaBoundとAMSBoundと呼ぶ新しい改良版を提供し、適応型手法からSGDへの緩やかで滑らかな移行を実現するために、学習率に動的な境界を採用し、収束の理論的な証明を行う。さらに、これまでの研究では不十分なことが多い、さまざまな一般的なタスクやモデルを対象とした実験を行います。実験の結果、新しい亜種は、適応型手法とSGDの間の汎化ギャップを解消し、同時に学習の初期段階で高い学習速度を維持できることがわかった。さらに、特に複雑なディープネットワークにおいて、プロトタイプよりも大幅な改善をもたらすことができます。このアルゴリズムの実装は、このhttpsのURLにあります。
本論文では、複数の自然言語理解（NLU）タスクにわたって表現を学習するためのマルチタスクディープニューラルネットワーク（MT-DNN）を紹介します。MT-DNNは、大量のクロスタスクデータを活用するだけでなく、新しいタスクやドメインに適応するために、より一般的な表現につながる正則化効果の恩恵を受けます。MT-DNNは、Liuら（2015）で提案されたモデルを、BERT（Devlinら、2018）として知られる事前に訓練された双方向変換言語モデルを組み込むことで拡張しています。MT-DNNは、SNLI、SciTail、および9つのGLUEタスクのうち8つを含む10のNLUタスクで新しい最先端の結果を得て、GLUEベンチマークを82.7%（2.2%の絶対的な改善）に押し上げました。また、SNLIおよびSciTailデータセットを用いて、MT-DNNによって学習された表現は、事前に学習されたBERT表現よりも大幅に少ないドメイン内ラベルでドメイン適応を可能にすることを実証しました。コードと事前学習済みモデルは、このhttps URLで公開されています。
双方向変換モデルを事前学習するための新しいアプローチを紹介し、様々な言語理解問題において大幅な性能向上を実現します。このモデルは、各単語が削除され、テキストの残りの部分から予測しなければならないcloze-style word reconstructionタスクを解決します。実験では、GLUEでの大幅な性能向上と、NERおよび構成的構文解析ベンチマークでの新たな最先端の結果が示され、同時に発表されたBERTモデルと一致しています。また、データ領域とサイズ、モデルの容量、cloze目的のバリエーションなど、効果的な事前トレーニングに貢献する多くの要因の詳細な分析を紹介します。
人間の知覚は、より高度な認知の基礎となる物体を中心に構成されており、素晴らしい体系的な一般化能力を持っています。しかし、表現学習に関するほとんどの研究では、複数の物体を考慮せずに特徴量の学習に焦点を当てたり、セグメンテーションを（多くの場合、教師ありきの）前処理ステップとして扱ったりしています。その代わりに、我々はオブジェクトの分割と表現を同時に学習することの重要性を主張する。我々は、シーンが複数のエンティティから構成されているという単純な仮定から出発して、画像を分離された表現を持つ解釈可能なオブジェクトにセグメントすることを学習することが可能であることを実証する。我々の手法は、監督なしで、隠蔽された部分の不塗装を学習し、より多くのオブジェクトを持つシーンや、新しい特徴の組み合わせを持つ未見のオブジェクトに外挿することができる。また、反復変分推論を用いることで、曖昧な入力に対してマルチモーダルな後置を学習することができ、シーケンスにも自然に拡張できることを示しています。
シーンを抽象的な構成要素で分解する能力は、一般的な知能には不可欠です。このような基本的な構成要素が、意味のある特性、相互作用、その他の規則性をシーン間で共有している場合、このような分解は、推論を単純化し、新しいシナリオの想像を容易にします。特に、知覚的な観察結果をエンティティで表現することで、データの効率性が向上し、様々なタスクのパフォーマンスが向上します。そのためには、このような規則性を持つユニットを特定し、共通のフォーマットで表現することで、シーンの有用な分解を発見できるモデルが必要です。この問題を解決するために、私たちはMulti-Object Network (MONet)を開発しました。このモデルでは、VAEとリカレント・アテンション・ネットワークをエンド・ツー・エンドで学習し、純粋に教師なしで、画像の領域周辺のアテンション・マスクとその再構成を行います。このモデルは、難易度の高い3Dシーンを、オブジェクトや背景要素などの意味的に意味のあるコンポーネントに分解して表現することができることを示している。
エネルギーベースモデル（EBM）は、一般的でシンプルな尤度モデルとして魅力的ですが、従来は学習が難しいとされていました。本論文では、連続ニューラルネットワークにおけるMCMCベースのEBM学習を拡張する技術を紹介し、ImageNet32x32、ImageNet128x128、CIFAR-10、ロボットハンドの軌跡などの高次元データ領域において、データのすべてのモードをカバーしながら、他の尤度モデルよりも優れたサンプル数を達成し、現代のGANアプローチの性能に近い結果を得た上で、その成功を示した。我々は、合成性や破損した画像の再構築やインペインティングなど、暗黙的な生成のユニークな能力を強調する。最後に、EBMが様々なタスクにおいて有用なモデルであることを示し、最先端の分布外分類、敵対的ロバスト分類、最先端の継続的オンラインクラス学習、コヒーレントな長期予測軌道の展開を達成した。
深層強化学習アルゴリズムは、個々のタスクを学習するために大量の経験を必要とします。メタ強化学習（meta-RL）アルゴリズムは、原理的にはエージェントが少量の経験から新しいスキルを学ぶことを可能にしますが、いくつかの大きな課題がその実用性を阻んでいます。現在の手法は、オンポリシーの経験に大きく依存しているため、サンプルの効率性に限界があります。また、新しいタスクに適応する際にタスクの不確実性を推論するメカニズムがないため、報酬の少ない問題での有効性が制限されている。本論文では、タスクの推論と制御を分離したオフポリシーのメタRLアルゴリズムを開発することで、これらの課題に対処する。我々のアプローチでは、潜在的なタスク変数のオンライン確率的フィルタリングを行い、少量の経験から新しいタスクの解決方法を推論する。この確率的な解釈により、構造的かつ効率的な探索のための事後サンプリングが可能になる。本研究では、これらのタスク変数をオフポリシーRLアルゴリズムと統合し、メタトレーニングと適応効率を両立させる方法を示す。我々の手法は、いくつかのメタRLベンチマークにおいて、サンプル効率で先行するアルゴリズムを20-100倍、また漸近的な性能でも上回る。
ガウス過程(GP)は柔軟なノンパラメトリックモデルであり、利用可能なデータに応じて容量が増加します。しかし，標準的な推論方法では計算量に制約があるため，厳密なGPは約1万点以下の学習点の問題に限られ，より大きなデータセットでは近似的な手法が必要となる．本論文では、マルチGPUによる並列化と線形共役勾配法などの手法を用いて、カーネル行列へのアクセスが行列の乗算のみで済む、スケーラブルな厳密GPの手法を開発しました。カーネル行列の乗算を分割して分散させることで、現在の計算機ハードウェアでは不可能と考えられていた100万点以上の厳密なGPの学習を2時間以内に行うことができることを実証した。さらに、我々のアプローチは、グリッドデータや特定のカーネルクラスに制約されることなく、一般的に適用可能である。このスケーラビリティにより、104-106データポイントのデータセットにおいて、正確なGPとスケーラブルなGP近似との比較を初めて行い、劇的な性能向上を示した。
これは、入力されたセマンティックレイアウトに基づいてフォトリアリスティックな画像を合成するための、シンプルで効果的なレイヤーです。従来の手法では、意味的レイアウトを直接深層ネットワークに入力し、畳み込み、正規化、非線形性の各層を重ねて処理していました。これは、正規化層が意味情報を「洗い流してしまう」傾向があるため、最適ではないことを示している。この問題を解決するために，我々は，入力レイアウトを利用して，空間的に適応した学習済みの変換によって，正規化層の活性化を調整することを提案する．いくつかの困難なデータセットを用いた実験により，視覚的な忠実性と入力レイアウトとの整合性の両方に関して，提案手法が既存の手法よりも優れていることが実証された．最後に，我々のモデルは，セマンティックとスタイルの両方をユーザがコントロールできる．コードはこちらのhttpsのURLから入手できます。
ディープニューラルネットワークは、非線形関数の近似に広く用いられており、その応用範囲はコンピュータビジョンから制御まで多岐にわたります。これらのネットワークは，単純な算術演算の組み合わせであるにもかかわらず，特定のネットワークが特定の入出力特性を満たしているかどうかを検証することは非常に困難である．本稿では、このような特性を健全に検証するために最近登場した手法を紹介する。これらの手法は、到達可能性解析、最適化、探索などの知見を取り入れたものである。また、既存のアルゴリズムの基本的な違いや関連性についても議論する。さらに、既存の手法の教育的な実装を提供し、一連のベンチマーク問題でそれらを比較します。
本論文では、ニューラルネットワークの一般化に関する新たな視点として、ニューラルネットワークのスティフネスという概念を提案し、検討しています。我々は、ある例でのネットワークのパラメータの小さな勾配ステップが、別の例での損失にどのように影響するかを見ることで、ネットワークのスティフネスを測定する。剛性が高いほど、ネットワークが一般化する特徴を学習していることを示している。具体的には，stiffnessが，1)クラス・メンバーシップ，2)入力空間におけるデータ点間の距離，3)学習反復，4)学習率にどのように依存するかを調べる．本研究では、MNIST、FASHION MNIST、CIFAR-10/100を対象に、完全連結ニューラルネットワークと畳み込みニューラルネットワークを用いた実験と、変換器ベースのNLPモデルを用いた実験を行った。剛性と一般化の関係を示し、その学習率への依存性を観察した。CIFAR-100で学習した場合、stiffness行列は、モデルが超クラスメンバーシップを認識していることを示す粗視化された挙動を示す。さらに、2つのデータポイント間のスティフネスが相互の入力空間距離にどのように依存するかを測定し、動的臨界長（あるデータポイントに基づくパラメータの更新が近隣のデータポイントに影響を与える距離）の概念を確立した。
これまでの研究では，伝達学習のための様々な事前学習の目的やアーキテクチャに焦点が当てられてきたが，我々は，事前学習されたモデルを与えられたターゲットタスクにどのように適応させるかを問うている．本論文では，最も一般的な2つの適応方法である，特徴抽出（事前学習された重みが凍結される）と，事前学習されたモデルを直接微調整することに焦点を当てる．最先端の2つのモデルを用いて多様なNLPタスクを対象とした実証実験の結果、微調整と特徴抽出の相対的な性能は、事前学習とターゲットタスクの類似性に依存することがわかった。この結果を受けて、本研究では、NLP実務者のための適応ガイドラインを提供する。
柔軟で幅広い能力を持つ自律型エージェントには、膨大な数のスキルのレパートリーが必要です。それぞれのスキルを人手で設計された報酬関数で定義することは、このレパートリーを制限し、人手によるエンジニアリングの負担を強いることになる。目標を設定する自己監督型エージェントは、このプロセスを自動化することができるが、適切な目標設定の目的を設計することは困難であり、しばしばヒューリスティックな設計判断を伴う。本論文では、状態カバレッジを最大化するゴール到達政策のための正式な探索目的を提案する。この目的は、ゴールが完全な状態観測に対応する場合、ゴール分布のエントロピーとともにゴール到達性能を最大化することと等価であることを示す。この原理を具体化するために、最大エントロピーのゴール分布を学習するSkew-Fitと呼ばれるアルゴリズムを提示する。規則性のある条件の下では、Skew-Fitは有効な状態の集合に対する一様な分布に収束することを証明する。我々の実験では、ゴール分布を学習するためのSkew-Fitと既存のゴールリーチング手法を組み合わせることで、オープンソースの視覚的ゴールリーチングタスクにおいて、様々な先行手法よりも優れた結果を得ることができた。さらに、Skew-Fitを用いることで、実世界のロボットが、手動で報酬関数を設計することなく、ゼロから、ピクセルから、ドアを開けることを学習できることを実証した。
注意メカニズムは、ニューラルNLPモデルに広く採用されています。アテンションを備えたモデルは、アテンションされた入力ユニットの分布を提供し、これが入力の相対的な重要性を伝えるものとして（少なくとも暗黙のうちに）提示されることが多い。しかし、注意の重みとモデルの出力との間にどのような関係があるのかは不明である。本研究では、様々なNLPタスクにおいて、注意重みが予測に意味のある「説明」を与える度合いを評価することを目的とした大規模な実験を行いました。その結果、ほとんどの場合、説明になっていないことがわかりました。例えば、学習された注意重みは、勾配に基づく特徴の重要性の尺度と相関しないことが多く、非常に異なる注意分布であっても、同等の予測結果を得ることができるのである。我々の発見は、標準的な注意モジュールが意味のある説明を提供しないことを示しており、あたかもそうであるかのように扱うべきではない。すべての実験のコードは、このhttpsのURLから入手できます。
ロボットの器用な操作には、触覚が重要であることは広く知られていますが、触覚を利用して連続した非伸縮性のある操作を行うことは困難です。触覚を効果的に利用できる汎用の制御技術や、接触や力の正確な物理モデルはまだほとんど確立されておらず、望ましい動作を触覚で指定する方法さえも不明です。本論文では、高解像度の触覚センサーと、深層ニューラルネットワーク・ダイナミクスモデルを用いたデータ駆動型モデリングを組み合わせることで、これらの問題を解決するための一歩を踏み出しました。我々は、手動による監視なしに、生の触覚センサ入力から触覚サーボを実行することを学習するフレームワークである、深層触覚MPCを提案する。この方法により、GelSightスタイルの触覚センサーを搭載したロボットが、ボール、アナログスティック、20面ダイスを操作することができ、教師なしの自律的なインタラクションから学習し、学習した触覚予測モデルを用いて、ゴールの触覚読み取り値で示されるユーザー指定の構成に各オブジェクトを再配置することができることを示しています。動画、映像、コードはこちらからご覧いただけます： https URL
高品質なコンピュータビジョンモデルは、通常、実世界の画像の一般的な分布を理解するという問題に取り組んでいます。しかし，ほとんどのカメラは，この分布のごく一部しか観測していません．このため，コンパクトで低コストなモデルを，1台のカメラで観測されたフレームの特定の分布に特化することで，より効率的な推論を実現できる可能性がある．本論文では、モデル蒸留（高コストの教師の出力を用いて低コストの学生モデルを監督する）の技術を用いて、正確で低コストのセマンティックセグメンテーションモデルをターゲットのビデオストリームに特化する。モデル蒸留は，ビデオストリームのオフラインデータを用いて学生モデルを学習するのではなく，ライブビデオを用いてオンラインで学生を学習し，学習の対象となる教師を断続的に実行します．オンラインでモデルを抽出することで、対象となる映像の分布が非定常であっても、推論の実行コストを7～17倍（FLOPsでは11～26倍）削減しながら、マスクR-CNNの教師に近いセマンティックセグメンテーションモデルを得ることができました。本手法は，対象となるビデオストリームに対するオフラインの事前学習を必要とせず，フローやビデオオブジェクトのセグメンテーションに基づくソリューションよりも高い精度と低いコストを達成し，オリジナルの教師よりも優れた時間的安定性を示すことができる．また、長時間のビデオストリームに対する推論の効率を評価するために、新しいビデオデータセットを提供します。
マルチモーダル言語モデルは、言語モデリングタスクのために非言語的特徴を取り入れることを試みている。本研究では、標準的なリカレントニューラルネットワーク（RNN）の言語モデルを、動画から得られる特徴で拡張します。先行研究で用いられたデータセットよりも2桁以上大きいデータを用いてモデルを学習する。また，視覚的特徴とテキスト特徴を組み合わせたモデルのアーキテクチャを徹底的に調査した．2つのコーパス（YoCookIIと200億-something-something-v2）を用いた実験では、視覚特徴とテキスト特徴の中間的な融合からなるアーキテクチャが最も高い性能を示し、パープレキシティを25%以上相対的に改善することができた。また、マルチモーダル言語モデルが標準的なRNN言語モデルよりも優れている理由についても分析しています。
グラフの成長の生成過程をモデル化することは、ソーシャルネットワークや推薦システムに広く応用されており、コールドスタート問題によって既存のグラフから孤立した新しいノードが発生します。グラフ表現やグラフ生成の学習に関する文献は数多くありますが、その多くは、孤立した新しいノードを自明な修正なしに扱うことはできません。この問題は、観測されたグラフのノードに対する表現を生成する学習が、位相的特徴に大きく依存しているのに対し、新しいノードに対してはノード属性しか利用できないという事実に起因する。本論文では、観測されたグラフデータからグラフ生成シーケンスをサンプリングすることにより、生成モデルの枠組みで適応的に全ノードのノード表現を学習する統合生成グラフ畳み込みネットワークを提案する。我々は、グラフ再構成項と適応的なカルバック・ライブラー・ダイバージェンス正則化項からなる変分的下界を用いて最適化する。いくつかのベンチマークとなる引用ネットワークデータセットにおいて、本手法の優れた性能を実証する。
完全連結フィードフォワードニューラルネットワークにおけるバッチ正規化のための平均場理論を開発した。これにより、初期化時にバッチ正規化されたネットワークにおける信号伝播と勾配逆伝播の正確な特徴を明らかにした。我々の理論は、勾配信号が深さ方向に指数関数的に成長することを示し、これらの爆発的な勾配は、初期の重み分散の調整や非線形活性化関数の調整では除去できないことを示している。実際、バッチ式正規化自体が勾配爆発の原因となっています。その結果、スキップ接続を持たないバッチ正規化されたバニラネットワークは、一般的な初期化スキームでは大きな深さでの学習ができないという予測を、様々な経験的シミュレーションで検証しました。勾配爆発をなくすことはできませんが、ネットワークを線形領域に近づけることで勾配爆発を抑えることができ、残差接続のない深いバッチ正規化ネットワークの学習性を向上させることができます。最後に、バッチ・ノーマライズされたネットワークの学習ダイナミクスを調べ、1回の最適化ステップの後、ネットワークは比較的安定した平衡を達成し、勾配のダイナミックレンジが劇的に小さくなることを観察した。我々の理論は、ラプラス変換、フーリエ変換、ゲゲンバウアー変換を利用しており、独立した関心事である新しいアイデンティティーを導き出しています。
ドメイン適応は、テストデータを生成するターゲットの分布がソース（トレーニング）の分布からずれてしまうという一般的な問題を解決するものです。仮定がない場合、領域適応は不可能ですが、共変量やラベルシフトなどの厳しい条件を満たすことで、原理的なアルゴリズムが可能になります。最近提案されている領域逆適応アプローチは、ソースとターゲットのエンコーディングを揃えることで構成されており、このアプローチは、ターゲット誤差の理論的な境界における2項（または3項）を最小化することを動機としていることが多い。残念ながら、この最小化は第3項の任意の増加を引き起こす可能性があり、例えば、ラベル分布の変化の下で破綻する可能性がある。我々は、標準的なドメイン・アドバシアル・アルゴリズムのいくつかの限界を克服する新しいアプローチである、非対称に緩和された分布アライメントを提案する。さらに、我々のアルゴリズムが理論的に原理的であるための正確な仮定を明らかにし、合成データと実データの両方で経験的な利点を実証する。
ハイパーパラメータ最適化は、学習セットにおける最適パラメータがハイパーパラメータに依存するバイレベル最適化問題として定式化することができる。我々は、ハイパーパラメータを最適な重みとバイアスにマッピングするベストレスポンス関数にコンパクトな近似値を当てはめることで、ニューラルネットワークの正則化ハイパーパラメータを適応させることを目的としている。我々は、ベストレスポンスを、隠れユニットが正則化を条件としてゲートされた単一のネットワークとしてモデル化することで、ニューラルネットワークのスケーラブルなベストレスポンス近似を構築する方法を示す。また、L2正則化されたジャコビアンを持つ浅い線形ネットワークの正確なベストレスポンスが、同様のゲーティングメカニズムで表現できることを示し、この近似を正当化する。勾配ベースのハイパーパラメータ最適化アルゴリズムを用いて、このモデルをフィットさせます。このアルゴリズムは、現在のハイパーパラメータでベストレスポンスを近似することと、近似ベストレスポンス関数を用いてハイパーパラメータを最適化することを交互に行います。他の勾配ベースのアプローチとは異なり，学習損失をハイパーパラメータに対して微分する必要がないため，離散的なハイパーパラメータ，データ補強のハイパーパラメータ，ドロップアウト確率を調整することができます．ハイパーパラメータはオンラインで適応されるため，我々のアプローチは，固定されたハイパーパラメータ値よりも優れた性能を持つハイパーパラメータ・スケジュールを発見することができる．経験的に、我々のアプローチは、大規模な深層学習問題において、競合するハイパーパラメータ最適化手法よりも優れています。我々は、学習中に自らのハイパーパラメータをオンラインで更新するネットワークを、自己調整ネットワーク（Self-Tuning Networks: STN）と呼んでいる。
ロボット工学では、多様な汎用スキルのレパートリーを獲得することが重要な課題となっています。本研究では、人間の遠隔操作による遊びのデータを利用した自己学習型制御を提案しています。遊びは、従来のタスクデモンストレーションと比較して、魅力的な2つの特性を持っています。遊びは、タスクの分割、ラベル付け、初期状態へのリセットを行わずに、素早く大量に収集することができるため、安価である。同じ収集時間で、タスク・デモンストレーションの4倍以上のインタラクション・スペースをカバーすることができる。プレイから制御を学ぶために、私たちはPlay-LMPを導入しました。これは、プレイの行動を潜在的な空間に整理することを学習し、テスト時に特定の目標を達成するためにそれらを再利用する、自己教師付きの手法です。自己教師付き制御と多様な遊びのデータセットを組み合わせることで、スキル学習の焦点を、狭い範囲の個別のタスクセットから、環境で利用可能な一連の行動に移すことができる。この組み合わせは、経験的にうまく一般化されることがわかった。ラベルのない遊びを自己教師化した後、我々の手法は、シミュレートされたロボットの卓上環境で、ユーザーが指定した18の難しい視覚操作タスクにおいて、個々の専門家が学習したポリシーを大幅に上回ることができた。さらに、遊びに教師されたモデルは、専門家に教師されたモデルとは異なり、摂動に対してより頑健であり、再試行から成功までの行動を示すことがわかりました。最後に、我々のエージェントは、タスクラベルを使った訓練を受けていないにもかかわらず、潜在的なプラン空間を機能的なタスクを中心に整理していることがわかりました。動画、コード、データはこちらのURLからご覧いただけます。
将来のイベントのシーケンスをモデル化して予測することができる生成モデルは、原理的には、物理的な相互作用などの複雑な実世界の現象を捉えるために学習することができます。しかし、ビデオ予測の中心的な課題は、未来が非常に不確実であるということです。最近の研究では、不確実な未来を表現できる確率モデルが数多く研究されているが、そのようなモデルは、ピクセルレベルの自己回帰モデルのように計算コストが非常に高いか、データの尤度を直接最適化することができない。我々の知る限り、正規化フローを用いたマルチフレームビデオ予測を提案したのはこの研究が初めてであり、データの尤度を直接最適化することができ、高品質な確率的予測を行うことができる。また、潜在空間のダイナミクスをモデル化するためのアプローチを説明し、フローベースの生成モデルがビデオの生成モデリングに対して実行可能で競争力のあるアプローチを提供することを示します。
これは、大規模なマルチエージェント相互作用におけるエージェントの評価と順位付けのための原理的な進化力学手法であり、Markov-Conley チェーン（MCC）と呼ばれる新しい動的なゲーム理論的ソリューションコンセプトに基づいています。この手法は、経験的ゲームに適用される連続時間および離散時間の進化的力学系を利用しており、エージェント数、相互作用の種類、経験的ゲームの種類（対称および非対称）に応じて扱いやすくスケールアップします。現在のモデルは、基本的にこれらの次元の1つ以上に制限があり、望ましいゲーム理論上の解概念（通常はナッシュ均衡）に収束することが保証されていません。\α-Rankは、評価対象となるエージェントのセットに対するランキングを提供し、その強み、弱み、長期的なダイナミクスについての洞察を提供します。これは、進化モデルのランキング強度パラメータを大きくすることで、MCCソリューションの概念とリンクしており、まさに「\α-Rank」の基礎となっています。ナッシュ均衡が固定点に基づく静的な概念であるのに対し、MCCはマルコフ連鎖の形式論、Conleyの力学系の基本定理、および力学系のコア成分である固定点、再帰集合、周期軌道、限界サイクルに基づく動的な解の概念である。\一般和ゲームのナッシュ均衡の計算は難解であることが知られていますが、本研究では、純粋戦略プロファイルの総数に対して多項式時間で計算することができます。本論文では、既存の連続時間および離散時間の進化的評価モデルの統一的な視点を提供するだけでなく、「アルファランク」手法の正式な基盤を明らかにする証明を紹介する。また、AlphaGo、AlphaZero、MuJoCo Soccer、Pokerを含むいくつかのドメインで、この手法を実証的に検証します。
モデルフリー強化学習（RL）は、アタリゲームのような複雑なタスクに対して、画像観測からでも効果的なポリシーを学習することができます。しかし、これには大量のインタラクションが必要であり、人間が同じゲームを学習するよりもはるかに多くのインタラクションが必要となるのが一般的である。なぜ人間はそんなに早く学習できるのでしょうか？その答えの一部は、人がゲームの仕組みを学び、どのような行動が望ましい結果をもたらすかを予測できることにあるかもしれない。本論文では、ビデオ予測モデルによって、モデルフリーの手法よりも少ないインタラクションで、エージェントが同様にAtariゲームを解くことができるかを探る。ビデオ予測モデルに基づいた完全なモデルベースのディープRLアルゴリズムであるSimulated Policy Learning (SimPLe)について説明し、我々の設定で最良の結果をもたらす新しいアーキテクチャを含む、いくつかのモデルアーキテクチャの比較を示す。我々の実験では、エージェントと環境の間の100kのインタラクションという低いデータ領域で、様々なAtari社のゲームを対象にSimPLeを評価しました。ほとんどのゲームにおいて、SimPLeは最先端のモデルフリーアルゴリズムを上回り、中には1桁以上の差がついたゲームもありました。
機械学習システムが何をどのように学習するのかについて理解を深めることは、機械学習システムの判断に対する信頼性を高め、さらなる研究を促進するために重要です。本論文では、混合密度RNN（MD-RNN）という特定の種類のリカレント・ニューラル・ネットワークによる予測を分析します。MD-RNNは、予測値を複数のガウス分布の組み合わせとして学習するため、一連の入力が複数の異なる未来の可能性につながるような問題に適しています。例えば、環境の内部モデルを学習する場合、異なる事象が発生する可能性もあれば、発生しない可能性もありますが、異なる事象の平均値は意味を持ちません。学習されたMD-RNNの予測を分析することで、MD-RNNの異なるガウス成分が、次の2つの補完的な役割を担っていることがわかった。これらの発見は、予測型MD-RNNが何を学習しているかについての理解を深めるとともに、MD-RNNの自己組織化モデルの分解からどのような恩恵を受けることができるかをさらに理解するための新たな研究の方向性を示すものである。
深層ニューラルネットワークにスパース性を誘導するための3つの最新技術を、2つの大規模な学習タスクで厳密に評価しました。WMT 2014の英独変換で学習したTransformerと、ImageNetで学習したResNet-50です。数千回の実験を通じ、小さいデータセットで高い圧縮率を得ることが示されている複雑な技術（Molchanovら、2017年、Louizosら、2017b）は一貫性のないパフォーマンスを示し、単純なマグニチュード・プルーニング・アプローチは同等以上の結果を得ることを実証しています。さらに、(Frankle & Carbin, 2018)と(Liu et al., 2018)が行った実験を大規模に再現し、プルーニングによって学習された非構造化スパースアーキテクチャは、スパース化と最適化を併用して学習されたモデルと同じテストセットの性能を得るために、ゼロから学習することはできないことを示しています。これらの結果を合わせると、モデル圧縮の分野における大規模ベンチマークの必要性が浮き彫りになります。我々は，圧縮とスパース化に関する今後の研究のための厳密なベースラインを確立するために，コード，最高性能のモデルのチェックポイント，およびすべてのハイパーパラメータ設定の結果をオープンソース化した．
ソースコードのスニペットから自然言語配列を生成する機能は、コードの要約、文書化、検索など、さまざまな用途に利用されています。神経機械翻訳（NMT）から採用されたSequence-to-Sequence（seq2seq）モデルは、ソースコードをトークンのシーケンスとして扱うことで、これらのタスクにおいて最先端の性能を達成しています。本論文では、プログラミング言語の構文構造を利用してソースコードをより良くエンコードするための代替アプローチであるcode2seqを紹介する。このモデルは、コードスニペットを抽象構文木(AST)の構成パスの集合として表し、デコード時に関連するパスを選択するために注意を払う。本研究では、2つのタスク、2つのプログラミング言語、最大1,600万例の4つのデータセットを用いて、本アプローチの有効性を実証した。我々のモデルは、プログラミング言語に特化して設計された過去のモデルや、最先端の一般的なNMTモデルを大幅に凌駕している。我々のモデルのインタラクティブなオンラインデモは、http://code2seq.org。我々のコード、データ、学習済みモデルは、http://github.com/tech-srl/code2seq。
密なビデオキャプションは、トリミングされていないビデオのすべてのイベントに対するテキスト説明を生成することを目的としています。これには、イベントの検出と記述の両方が含まれる。そのため、高密度ビデオキャプションに関するこれまでの手法は、これらの2つのサブ問題に対して2つのモデル、すなわち、イベント提案モデルとキャプションモデルを構築することで、この問題に取り組んでいる。これらのモデルは、別々に、または交互に学習されます。これにより、正確な記述を生成するために重要な、言語記述からイベント提案への直接的な影響を防ぐことができます。この問題を解決するために、我々は、高密度ビデオキャプションのためのエンドツーエンドの変換モデルを提案する。エンコーダーは、ビデオを適切な表現にエンコードする。提案デコーダは、ビデオイベント提案を形成するために、異なるアンカーを使用してエンコーディングからデコードする。キャプションデコーダは、マスキングネットワークを使用して、エンコーディング機能よりもプロポーザルイベントに注意を制限します。このマスキングネットワークは、イベントプロポーザルを微分可能なマスクに変換することで、学習中のプロポーザルとキャプションの間の一貫性を確保する。さらに、本モデルは自己注意メカニズムを採用しているため、エンコーディング時に効率的な非再帰構造を使用することができ、パフォーマンスの向上につながります。このエンド・ツー・エンドモデルの有効性をActivityNet CaptionsおよびYouCookIIデータセットで実証し、それぞれ10.12および6.58のMETEORスコアを達成しました。
我々は、ユーザが自由形式のマスク、スケッチ、色を入力すると画像を生成する新しい画像編集システムを発表します。このシステムは、エンドツーエンドで学習可能な畳み込みネットワークで構成されています。既存の手法とは異なり、本システムでは、色と形を持つ自由形式のユーザー入力を全面的に利用しています。これにより、システムはユーザーのスケッチや色の入力に反応し、それをガイドラインとして画像を生成することができます。本研究では、ネットワークにスタイルロスを追加して学習させることで、画像の大部分が削除されているにもかかわらず、リアルな結果を得ることができました。我々の提案するネットワークアーキテクチャSC-FEGANは、ユーザーの直感的な入力を用いて高品質の合成画像を生成するのに適しています。
最新の転移学習法では、大規模な汎用コーパスで事前学習した言語モデルを用いるものが増えている。本論文では、概念的にシンプルで効果的な転移学習手法を提案する。これにより、壊滅的な忘却の問題に対処することができる。具体的には、タスク固有の最適化関数と、補助的な言語モデルの目的語を組み合わせ、学習プロセス中に調整する。これにより、言語モデルが捉えた言語の規則性を維持しつつ、ターゲットタスクを解くための十分な適応を可能にする。この手法では、ネットワークの個別のコンポーネントを事前にトレーニングしたり、微調整したりする必要はなく、1つのステップでモデルをエンドツーエンドでトレーニングします。我々は、感情やテキストの分類という困難なタスクにおいて、より複雑なレベルで確立された伝達学習法を上回る結果を示しています。
細粒度名前付き実体認識（FG-NER）は、多くのNLPアプリケーションにとって重要です。古典的な名前付き実体認識(NER)はかなりの量の研究を集めていますが、FG-NERはまだ未解決の研究領域です。現在の最先端のFG-NERモデル（SOTA）は、辞書の構築や手作りの特徴量の設計など、手作業に大きく依存しています。NERでSOTAを達成したエンド・ツー・エンドのフレームワークは、FG-NERのSOTAモデルと比較して、競争力のある結果を得ることができませんでした。本論文では、FG-NER用のエンド・ツー・エンドフレームワークにおいて、マルチタスク学習アプローチがどのように効果的であるかを様々な側面から調査する。実験の結果、文脈に基づいた単語表現を用いたマルチタスク学習アプローチを用いることで、データ作成や特徴量の設計に人手をかけることなく、エンド・ツー・エンドのニューラルネットワークモデルがSOTAの結果を得ることができることがわかった。
強化学習は、制御問題を解決するための有望なフレームワークですが、報酬関数の設計が困難であることが実用化の妨げとなっています。ロボットなどの自律的な機械の目標やタスクを指定することは大きな課題で、従来は報酬関数やゴールの状態を使って目的を伝えていました。しかし、人と人との間では、目的を説明したり示したりするだけで、目的を伝えることができます。では、どうすれば機械に目的を伝えることができる学習アルゴリズムを構築することができるのでしょうか？本研究では、逆強化学習を用いて、言語命令を報酬関数として接地する問題を調査し、言語条件付き報酬は、言語条件付きポリシーよりも新しい環境への移行性が高いことを主張する。我々は、言語コマンドを深層ニューラルネットワークで表現される報酬関数として根拠づける言語条件付き報酬学習（LC-RL）を提案する。本研究では、自然言語コマンドを用いた現実的な高次元の視覚環境において、新しいタスクや環境に移行する報酬を学習するモデルを実証した。
知的システムの中心的な能力は、過去の経験を継続的に積み重ねることで、新しいタスクの学習を高速化・強化する能力である。この問題は、2つの異なる研究パラダイムによって研究されています。メタ学習では、この問題を、新しいタスクに素早く適応するためのモデルパラメータに関する事前情報を学習することと捉えているが、一般的には、一連のタスクがバッチとして利用可能であることを前提としている。対照的に、オンライン（後悔ベース）学習では、問題が次々と明らかになるような逐次的な設定を考慮するが、従来はタスク固有の適応を行わずに単一のモデルのみを学習していた。本研究では、前述の2つのパラダイムのアイデアを融合させ、継続的な生涯学習の精神と実践をよりよく捉えるために、オンラインメタ学習の設定を導入する。本研究では、MAMLアルゴリズムをこの設定に拡張したfollow the meta leaderアルゴリズムを提案する。理論的には、標準的なオンライン設定と比較して、高次の平滑性の仮定を1つ追加するだけで、(logT)後悔保証を提供する。3つの異なる大規模タスクを対象とした実験的評価によると、提案アルゴリズムは従来のオンライン学習アプローチに基づく代替案を大幅に上回ることが示唆された。
End-to-end最適化は、多くの特定の問題で最先端の性能を達成しているが、新しい問題のために事前に学習されたモデルを組み合わせるための直接的な方法は存在しない。ここでは、新しい課題を解決するために、既存の2つのモデルの間のポストホックなインターフェースを学習することで、モジュール性を向上させることを検討する。具体的には、ニューラル機械翻訳からヒントを得て、クロスモーダル・ドメイン・トランスファーという困難な問題を、事前学習されたディープジェネレーティブモデルの潜在空間間の教師なし翻訳として捉える。データ表現を抽象化することで、異なるモダリティ（例：画像から音声）、さらには異なる種類の生成モデル（例：VAEからGAN）への転送が可能であることを実証します。最先端の技術と比較した結果、単純な変分オートエンコーダーが、共有された潜在空間を学習することで、2つの生成モデルの橋渡しをすることができることがわかった。さらに、共有潜在空間の分類器を用いて、両ドメインの属性を教師付きで整列させることができます。定性的および定量的な評価により、高い伝達精度とクラス内のスムーズな補間によって示されるように、伝達プロセスを通じて局所性と意味的な整合性が維持されることを実証した。最後に、このモジュール構造は、ベースとなる生成モデルの高価な再トレーニングから切り離すことで、新しいインターフェースモデルのトレーニングを数桁高速化することを示している。
この問題では、エージェントが自然言語による命令などの複雑な入力を受け取り、成功と失敗の2つのフィードバックのみを受け取りながら、アクションシーケンスなどの複雑な応答を生成する必要があります。このような成功-失敗の報酬は、しばしば不明確であり、意図的な成功と偶発的な成功を区別することができません。不明確な報酬からの一般化には、偶然の成功を達成した偽の軌道を割り引くことが必要であり、また、疎なフィードバックからの学習には効果的な探索が必要である。我々は、KL発散の方向をカバーするモードを用いて成功した軌道の多様なセットを収集し、続いてKL発散を求めるモードを用いてロバストな政策を訓練することで、探索に対処する。我々は、より洗練された学習のためのフィードバックを提供する補助的な報酬関数を構築するために、メタ報酬学習（MeRL）を提案する。補助報酬関数のパラメータは、学習したポリシーの検証性能に応じて最適化される。MeRLのアプローチは、ベイズ最適化に基づく代替報酬学習技術よりも優れており、弱い教師付きセマンティックパーシングにおいて最先端の成果を達成しています。また、WikiTableQuestionsとWikiSQLのデータセットにおいて、それぞれ1.2%と2.4%の改善が見られました。
人間は、自分の世界に新しさを求める強い欲求に駆られます。また、新しいパターンを観察すると、新しい情報に基づいて世界の理解を深めることができ、人間は自分の世界を発見することができます。このような人間の優れた発見能力は、科学、芸術、技術の分野で多くのブレークスルーをもたらしました。ここでは、現代のAI技術を用いて、自分の世界を発見することができるエージェントを構築する可能性を検討します。特に、NDIGO（Neural Differential Information Gain Optimisation）は、部分的でノイズの多い観測結果から世界の全体像を構築するために新しい情報を求めることを目的とした、自己監視型の発見モデルであることを紹介します。制御された2次元ナビゲーションタスクでの実験により、NDIGOは学習された表現の質の点で、最先端の情報探索手法を上回ることが示された。この性能向上は、他の情報探索手法が自分の世界を発見する代わりにノイズを追いかけるような、白色または構造化されたノイズが存在する場合に特に顕著である。
Few-shot classiﬁcationは，限られたラベル付きの例を用いた学習の際に，見たことのないクラスを認識するクラシファーを学習することを目的としている．これまでに大きな進歩を遂げてきたが，ネットワーク設計，メタ学習アルゴリズムの複雑化，実装の違いなどにより，公正な比較は困難である．本論文では、1）代表的な数ショットのクラシファイド・アルゴリズムの一貫した比較分析を行い、より深いバックボーンがベースラインを含む手法間のギャップを大幅に減少させるという結果を示した。2) mini-ImageNetおよびCUBデータセットの両方において、最先端の手法と比較して競争力のある性能を達成した、わずかに改良されたベースライン手法 3) 少数ショット・クラシフィケーション・アルゴリズムのドメイン間一般化能力を評価するための新たな実験設定 その結果，クラス内変動の低減は，特徴量のバックボーンが浅い場合には重要な要素であるが，バックボーンが深い場合にはそれほど重要ではないことがわかった．また、現実的なクロスドメイン評価において、標準的なファインチューニングを行ったベースライン手法が、他の最先端の少数ショット学習アルゴリズムと比較して良好な結果が得られた。
ニューラル・アーキテクチャ・サーチ（NAS）は、専門家が設計したネットワークを、学習したタスク固有のアーキテクチャに置き換える可能性を秘めた有望な研究方向です。本研究では、この分野での経験的な結果の根拠となるように、以下のような見解に基づいて新しいNASベースラインを提案する。(i) NASは特殊なハイパーパラメータ最適化問題である、(ii) ランダム検索はハイパーパラメータ最適化のための競争力のあるベースラインである。本研究では，これらの知見をもとに，2つの標準的なNASベンチマーク（PTBおよびCIFAR-10）を用いて，早期停止を伴うランダム探索および重み付けを伴う新規のランダム探索アルゴリズムを評価した．その結果、早期停止を用いたランダム探索は、どちらのベンチマークにおいても、主要なNAS手法であるENASと同等以上の性能を発揮するなど、競争力のあるNASベースラインであることがわかりました。さらに、weight-sharingを用いたランダム探索はearly-stopを用いたランダム探索よりも優れており、PTBでは最先端のNASの結果を、CIFAR-10では非常に競争力のある結果を得ることができました。最後に、発表されたNAS結果の再現性に関する問題点を調査しました。これらの結果を正確に再現するために必要な資料が不足していることを指摘し、さらに、NASの実験設定における様々な変動要因を考慮した上で、公表された結果の頑健性について議論します。関連して、我々の結果を正確に再現するために必要なすべての情報（コード、ランダムシード、文書）を提供し、複数回の実行で各ベンチマークについて重み付けを伴うランダム探索の結果を報告します。
最近の知識抽出に関する多くの研究は、新しいネットワークの学習プロセスを改善するために、訓練されたネットワークの知識を転送する方法を提供しているが、知識抽出のための良い技術を見つけることはまだ未解決の問題である。本論文では，分類器の最も重要な構成要素の一つである決定境界に基づいた新たな視点を提供する．分類器の汎化性能はその決定境界の適切さに密接に関係しており，良い分類器は良い決定境界を持つことになる．したがって，決定境界に密接に関連する情報を転送することは，知識の蒸留のための良い試みである．この目的を達成するために、我々は、敵対的攻撃を利用して、決定境界を支持するサンプルを発見する。この考えに基づき，提案アルゴリズムは，決定境界に関するより正確な情報を転送するために，決定境界を支持する敵対的なサンプルに基づいて学生分類器を訓練する．実験では、提案手法が実際に知識の蒸留を改善し、最先端の性能を達成することが示された。
畳み込みニューラルネットワーク（CNN）は，物体の形状の複雑な表現を学習することで物体を認識すると一般的に考えられている．最近の研究では、画像のテクスチャがより重要な役割を果たしていると示唆するものもある。本研究では、これらの相反する仮説を定量的に検証するため、テクスチャーと形状の手がかりが相反する画像を用いてCNNと人間の観察者を評価した。ImageNetで学習したCNNは、形状よりもテクスチャを認識する方向に強く偏っていることを示した。これは人間の行動証拠とは全く対照的で、分類戦略が根本的に異なることを示している。次に、ImageNet上でテクスチャベースの表現を学習する標準的なアーキテクチャ（ResNet-50）が、ImageNetをスタイル化した「Stylized-ImageNet」で学習すると、代わりに形状ベースの表現を学習できることを示す。これにより、我々が管理している心理物理学研究室の設定（97人の観察者に対する9つの実験、合計48,560回の心理物理学的試行）における人間の行動パフォーマンスにはるかによく適合し、物体検出性能の向上や、広範囲の画像歪みに対するこれまでにない頑健性など、予想外の多くの利点が得られ、形状ベースの表現の利点が強調されました。
文書の正確な抽象的要約には、その文書の重要な情報がすべて含まれていなければならず、また、入力文書から論理的に帰結されなければならない。本研究では、マルチタスク学習を用いて抽象的要約のこれらの重要な側面を改善する。マルチタスク学習では、質問生成と関連性生成という補助的なタスクを用いる。前者は、質問に値する顕著な詳細を探す方法を要約モデルに教え、後者は、入力文書の有向論理的サブセットである要約を書き換える方法をモデルに教える。また、3つのタスクの複数のエンコーダー層とデコーダー層にまたがる高レベル（意味的）レイヤー固有の共有と、ソフト共有メカニズムを備えた新しいマルチタスク・アーキテクチャを提案する（各貢献についての性能評価と分析例を示す）。その結果、CNN/DailyMailとGigawordの両データセット、およびDUC-2002の転送設定において、最先端の技術を統計的に有意に上回ることができた。また、我々のモデルが学習した顕著性と関連性のスキルについて、いくつかの定量的および定性的な分析研究を紹介します。
自然画像データセット、特にImageNetからの転送学習は、標準的な大規模モデルとそれに対応する事前学習済みの重みを用いたもので、医用画像への深層学習の応用においては事実上の手法となっています。しかし、自然画像の分類と対象となる医療タスクの間には、データサイズ、特徴、タスクの仕様に根本的な違いがあり、転送の効果についてはほとんど理解されていません。本論文では、医用画像のための転移学習の特性を探ります。2つの大規模な医用画像処理タスクで性能評価を行ったところ、驚くべきことに、転移による性能への影響はほとんどなく、単純で軽量なモデルでもImageNetアーキテクチャと同等の性能を発揮できることがわかった。学習された表現と特徴を調査した結果、伝達学習との違いの一部は、洗練された特徴の再利用ではなく、標準モデルの過剰なパラメータ化によるものであることがわかった。本研究では、有用な特徴の再利用がどのように行われているかを明らかにし、より効率的なモデル探索への影響を説明する。また、重みのスケーリングから生じる伝達学習の特徴に依存しない利点を探ります。
深層学習の研究における長年の目標は、学習と一般化を正確に特徴づけることであった。しかし、ニューラルネットワークの損失分布は複雑であることが多いため、学習ダイナミクスの理論は捉えにくいものでした。本研究では、幅の広いニューラルネットワークでは、学習ダイナミクスが大幅に単純化され、無限の幅の限界では、初期パラメータの周りのネットワークの一次テイラー展開から得られる線形モデルによって支配されることを示します。さらに、ワイドベイジアンニューラルネットワークとガウス過程との対応を反映して、二乗損失によるワイドニューラルネットワークの勾配ベースの学習は、特定の組成カーネルを持つガウス過程から引き出されたテストセット予測を生成する。これらの理論的な結果は、無限の幅の限界においてのみ正確であるが、それにもかかわらず、有限の実用的なサイズのネットワークにおいても、元のネットワークの予測と線形化されたバージョンの予測との間に優れた経験的な一致が見られた。この一致は、さまざまなアーキテクチャ、最適化手法、損失関数の間でロバストに見られます。
特徴ピラミッドは、オブジェクト・インスタンス間のスケール・バリエーションから生じる問題を軽減するために、最先端の1ステージ・オブジェクト検出器（DSSD、RetinaNet、RefineDetなど）および2ステージ・オブジェクト検出器（Mask R-CNN、DetNetなど）の両方で広く利用されています。これらの特徴ピラミッドを用いたオブジェクト検出器は、有望な結果を得ていますが、オブジェクト分類タスクのために実際に設計されたバックボーンの固有のマルチスケール、ピラミッド型のアーキテクチャに従って特徴ピラミッドを単純に構築するだけであるため、いくつかの限界があります。本研究では、異なるスケールの物体を検出するためのより効果的な特徴ピラミッドを構築するために、Multi-Level Feature Pyramid Network (MLFPN)と呼ばれる手法を新たに提案します。まず、バックボーンによって抽出されたマルチレベルの特徴（つまり複数の層）を基本特徴として融合する。次に、この基本特徴を、結合されたThinned U-shapeモジュールと特徴融合モジュールを交互に組み合わせたブロックに与え、各U-shapeモジュールのデコーダ層を物体検出用の特徴として利用します。最後に，同等のスケール（サイズ）のデコーダ層を集めて，物体検出のための特徴ピラミッドを構築し，すべての特徴マップが複数のレベルの層（特徴）から構成されるようにする．提案されたMLFPNの有効性を評価するために，SSDのアーキテクチャにMLFPNを統合することで，M2Detと呼ぶ強力なエンド・ツー・エンドの1段物体検出器を設計・学習したところ，最先端の1段検出器よりも優れた検出性能を得ることができました．具体的には、MS-COCOベンチマークにおいて、M2Detはシングルスケール推論戦略でAP41.0、速度11.8FPSを達成し、マルチスケール推論戦略ではAP44.2を達成しました。これは1段検出器の中では新しい最先端の結果です。このコードは、このhttpsのURLで公開されます。
複数のモデルを1つのパラメータセットに格納する方法を紹介します。モデルは重ね合わせた状態で共存しても、個別に取り出すことができます。ニューラルネットワークを用いた実験では、驚くほど多くのモデルを1つのパラメータインスタンスに効果的に格納できることを示しています。さらに、これらのモデルは、重ね合わせ内の他のモデルに大きな影響を与えることなく、何千もの学習ステップを経ることができます。このアプローチは、圧縮のオンライン補完とみなすことができる。つまり、学習後にネットワークのサイズを縮小するのではなく、学習中にネットワークの未実現の能力を利用するのである。
本論文では、ソーシャルネットワーク分析のためのネットワークセマンティックセグメンテーションの概念を紹介する。ここでは、研究者やソフトウェア開発者の間で注目されているソーシャルコーディングネットワーク「GitHub」を取り上げます。ネットワーク・セマンティック・セグメンテーションは、各ユーザーを興味のあるトピックなどのクラス・ラベルに関連付けるプロセスを説明する。本研究では、ノードの属性にネットワーク上の重要なつながりを付加し、機械学習アプローチを用いてユーザをクラスタリングします。この結果を、コミュニティ検出アルゴリズムを用いて行ったネットワークセグメンテーションと、ノード属性を用いたクラスタリングで行ったネットワークセグメンテーションとで比較します。結果は、セマンティックセグメント内のコミュニティの多様性とトピックの観点から比較しています。
プランニングは、環境のダイナミクスが既知の制御タスクでは非常に成功している。未知の環境でプランニングを活用するためには、エージェントは世界との相互作用からダイナミクスを学習する必要があります。しかし、プランニングに十分な精度のダイナミクスモデルを学習することは、特に画像ベースのドメインでは、長年の課題でした。我々は、画像から環境のダイナミクスを学習し、潜在空間における高速オンラインプランニングによって行動を選択する、純粋にモデルベースのエージェントであるDeep Planning Network (PlaNet)を提案する。高い性能を得るためには、ダイナミクスモデルは、複数の時間ステップで先の報酬を正確に予測する必要があります。本研究では、決定論的および確率的な遷移要素を持つ潜在的なダイナミクスモデルを用いて、この問題に取り組みます。さらに、多段階の変分推論目的を提案し、これを「潜在的オーバーシュート」と名付けました。我々のエージェントは、ピクセルの観測値のみを用いて、接触力学、部分的な観測可能性、および疎な報酬を伴う連続制御タスクを解決します。これらのタスクは、これまで学習されたモデルを用いた計画によって解決されていたタスクの難易度を超えています。PlaNetは、使用するエピソード数が大幅に少なく、最終的な性能は強力なモデルフリー・アルゴリズムに近いか、時にはそれ以上になります。
異常検知は重要な問題であり、様々な研究分野や応用分野でよく研究されています。この調査の目的は2つあり、まず、深層学習に基づく異常検知の研究手法を構造的かつ包括的に紹介します。さらに、様々な応用分野における異常検知のためのこれらの手法の採用状況を確認し、その有効性を評価する。我々は、最先端の研究手法を、基礎となる仮定と採用されたアプローチに基づいて、異なるカテゴリーに分類した。各カテゴリーでは、正常な動作と異常な動作を区別するための基本的な異常検知技術とそのバリエーションを概説し、重要な前提条件を示しています。また、それぞれのカテゴリーについて、利点と限界を示し、実際のアプリケーション・ドメインにおける技術の計算の複雑さを議論します。最後に、研究における未解決の問題と、これらの技術を採用する際に直面する課題について説明します。
双曲面空間は、基礎的な階層構造を持つデータの表現学習に適していることが知られている幾何学的な空間です。この分布は、密度を解析的に評価し、パラメータに対して微分できる双曲空間上のガウス分布である。この分布を用いることで、これまで考えられなかった双曲空間上の確率モデルの勾配ベースの学習が可能になります。また、拒絶サンプリングのような補助的な手段に頼ることなく、この双曲型確率分布からサンプリングすることができます。この分布の応用として、双曲空間上での変分自動符号化器の双曲アナログ、および確率的単語埋め込み法を開発しました。MNIST、Atari 2600 Breakout、WordNetなどの様々なデータセットで、我々の分布の有効性を実証する。
ある政策から別の政策への知識の移転は、深層強化学習の重要なツールです。蒸留と呼ばれるこのプロセスは、例えば、エージェントの最適化を強化し、より困難なドメインでより早くより強力なパフォーマンスを実現するなど、大きな成功を収めています[26, 32, 5, 8]。蒸留法は広く使用されており、概念的には単純であるにもかかわらず、実際には多くの異なる定式化が使用されており、それらの間の微妙な差異により、最適化される性能や結果としての目的が大幅に変化することが多い。本研究では、理論的および経験的な分析を通じて、各バリエーションの動機と強みを比較しながら、政策の蒸留の全体像を厳密に調査しました。その結果、タスクの詳細に応じて好まれる3つの蒸留技術が判明した。特に、新たに提案された期待エントロピー正則化蒸留法は、収束を保証しつつ、様々な状況下でより迅速な学習を可能にする。
ディープニューラルネットワークは、学習データの学習には優れていますが、わずかに異なるテスト例で評価すると、誤った自信のある予測を行うことがよくあります。これには、分布のずれ、外れ値、敵対的な例などがあります。これらの問題に対処するために、我々はManifold Mixupを提案する。これは、隠れた表現の補間について、ニューラルネットワークが自信を持って予測しないように促すシンプルな正則化である。Manifold Mixupは、意味的な補間を追加の学習信号として活用し、表現の複数のレベルでより滑らかな決定境界を持つニューラルネットワークを得る。その結果、Manifold Mixupで学習されたニューラルネットワークは、分散の方向性が少ないクラス表現を学習する。この平坦化がなぜ理想的な条件で起こるのかを理論的に証明し、実際の状況で検証し、情報理論や一般化に関する過去の研究と結びつけます。Manifold Mixupは、大きな計算を必要とせず、数行のコードで実装されているにもかかわらず、教師付き学習、シングルステップの敵対的攻撃に対するロバスト性、テストの対数尤度などの強力なベースラインを改善します。
私たちは、表現空間におけるクラス多様体の「接線」を測定するために、Soft Nearest Neighbor Lossを探求し、拡張しました。我々は、この損失のいくつかの使用例を示します。分析ツールとしては、学習中のクラスの類似性構造の進化についての洞察を提供する。意外なことに、隠れた層における異なるクラスの表現の絡み合いを最大化することが、最終層での識別に有益であることがわかった。これは、クラスに依存しない類似構造を識別するように表現を促すためであると考えられる。隠れた層でソフト最近傍損失を最大化することは、汎化の向上だけでなく、外れ値データの不確実性の推定値をより適切に調整することにもつながる。学習分布から外れたデータは、隠れ層において、予測されるクラスの近傍数が通常よりも少ないことを観察することで認識できる。
Stanford Question Answering Dataset (Rajpurkar et al., 2016)に対する多くの公開モデルはロバスト性に欠けており、AddSent (Jia and Liang, 2017)アルゴリズムに基づく敵対的評価の際にF1スコアが50%以上低下することが示されている。また、AddSentによって生成されたデータでモデルを再トレーニングしても、頑健性に対する効果は限定的であることが示されている。私たちは、特定の表面的な仮定をしたモデルを罰する効果的な例を提供することで、敵対的なトレーニングデータ内の分散を大幅に増加させる、新しい代替的な敵対的生成アルゴリズム「AddSentDiverse」を提案します。さらに、AddSentの意味的摂動（反意語など）に対するロバスト性を向上させるために、AddSentDiverseに基づく敵対的トレーニングデータの増強に加えて、モデルの意味的関係の学習能力を共同で向上させます。これらの追加により、最先端のモデルのロバスト性を大幅に向上させることができ、通常のSQuADタスクでの性能を維持しつつ、様々な種類の敵対的評価の下でF1スコアを36.5%向上させることができた。
従来のニューラル自己回帰デコーディングでは、一般的に固定された左から右への生成順序を仮定していますが、これは最適ではない可能性があります。本研究では、挿入操作によって任意の順序で柔軟に配列を生成できる新しい復号化アルゴリズムInDIGOを提案します。本研究では，最先端の配列生成モデルであるTransformerを拡張し，提案手法を効率的に実装することで，あらかじめ定義された生成順序やビームサーチから得られる適応的な生成順序のいずれでも学習できるようにした．語順回復、機械翻訳、画像キャプション、コード生成などの4つの実世界のタスクを対象とした実験では、本アルゴリズムが任意の順序に従った配列を生成することができ、従来の左から右への生成と比較して、競争力のある、あるいはそれ以上の性能を達成できることを実証した。InDIGOは、入力情報に基づいて適応的な生成順序を採用していることが、生成された配列からわかります。
機械翻訳は、従来、大量の並列コーパスに依存していたが、最近の研究では、単言語コーパスのみを用いて、ニューラル機械翻訳（NMT）と統計的機械翻訳（SMT）の両方のシステムを訓練することに成功している。本論文では、サブワード情報を利用し、理論的に確立された教師なしチューニング法を開発し、ジョイントリファインメント手順を取り入れることで、既存の教師なしSMTアプローチのいくつかの欠陥を特定し、解決する。さらに、改良されたSMTシステムを用いてデュアルNMTモデルを初期化し、オンザフライでの逆翻訳によってさらに微調整を行う。その結果、これまでの教師なし機械翻訳の最先端技術と比較して、大幅に改善することができました。例えば、2014年の英独WMTでは、22.5 BLEUポイントを獲得しました。これは、これまでの教師なし機械翻訳の最高水準を5.5ポイント上回り、2014年の（教師あり）共有タスクの勝者を0.5ポイント上回っています。
グラフ上の表現学習のための最近の深層学習アプローチは、近傍集約手順に従っています。私たちは、これらのモデルのいくつかの重要な特性を分析し、それらを克服するための戦略を提案しています。特に、ノードの表現が引き出される「近隣」ノードの範囲は、ランダムウォークの広がりに類似して、グラフ構造に強く依存する。本研究では、局所的な近傍特性やタスクに適応するために、Jumping Knowledge (JK)ネットワークというアーキテクチャを検討した。ソーシャルネットワーク、バイオインフォマティクスネットワーク、引用ネットワークを対象とした多くの実験において、我々のモデルが最先端の性能を達成することを実証した。さらに、JKフレームワークをGraph Convolutional Networks, GraphSAGE, Graph Attention Networksなどのモデルと組み合わせることで、これらのモデルの性能を一貫して向上させることができる。
Cross-lingual word embeddings (CLEs) は、意味の多言語モデリングを可能にし、NLPモデルの言語間移植を容易にするものである。CLEは下流のタスクで広く利用されているにもかかわらず、最近普及しつつある投影ベースのCLEモデルは、ほとんどが対訳辞書誘導（BLI）という単一のタスクでのみ評価されている。また、BLIの評価には大きなばらつきがあるため、さまざまなCLEモデルの性能や特性を正しく解釈することができません。本研究では、クロスリンガルの単語埋め込みを包括的に評価するための第一歩を踏み出しました。本研究では、BLIタスクとその下流の3つのタスクにおいて、多数の言語ペアを対象に、教師付きおよび教師なしのCLEモデルを徹底的に評価し、最先端のCLEモデルが言語横断的なNLPをサポートする能力について、新たな知見を提供します。本研究では、CLEモデルの性能はタスクに大きく依存し、BLIにCLEモデルを最適化すると下流の性能が低下することを実証的に示した。また、教師ありおよび教師なしのCLEモデルの中で最も堅牢なモデルを示し、既存のベースラインを再評価する必要性を強調していますが、これらのモデルは全般的に競争力のある性能を示しています。今回の研究が、CLEの評価とモデル分析に関するさらなる研究のきっかけとなることを期待しています。
正規化層は、最先端の深層ニューラルネットワークアーキテクチャの定番となっています。正規化層は、学習を安定させ、より高い学習率を可能にし、収束を加速し、一般化を向上させると広く信じられていますが、その有効性の理由はまだ活発な研究課題です。本研究では、これらの効果が正規化に固有のものではないことを示すことで、一般的に考えられている信念に疑問を投げかけます。具体的には、Fixed-update initialization (Fixup)を提案する。Fixupは、標準的な初期化を適切に再スケーリングすることで、学習開始時の爆発的な勾配と消滅する勾配の問題を解決することを動機とした初期化である。Fixupを用いて残差ネットワークを学習すると、1万層のネットワークであっても正規化を用いた学習と同等の安定性が得られることがわかった。さらに、Fixupは適切な正則化を行うことで、画像分類や機械翻訳において、正則化を行わない残差ネットワークが最先端の性能を発揮することを可能にする。
マルチエージェントの協力関係は自然界の重要な特徴である。多くのタスクには、共通の利益とはずれた個人のインセンティブが含まれているが、バクテリアから昆虫、人間まで幅広い生物が、それぞれの違いを乗り越えて協力することができる。そのため、利己的な個体間の協調行動の出現は、マルチエージェント強化学習（MARL）や進化論の分野において重要な問題である。本研究では、個人と集団の間の対立が特に顕著な、時間間社会的ジレンマ（ISD）と呼ばれるマルチエージェント問題を研究する。MARLと適切に構造化された自然淘汰を組み合わせることで、協力に対する個人の帰納的バイアスをモデルフリーで学習できることを実証した。これを実現するために、我々は深層強化学習エージェントのための革新的なモジュール式アーキテクチャを導入し、複数レベルの選択をサポートする。また、2つの厳しい環境での結果を示し、文化的・生態的進化の文脈で解釈する。
深層ニューラルネットワーク（DNN）は、多くの複雑な知覚課題に優れていますが、その決定方法を理解することは難しいことがわかっています。本研究では、ImageNet上に高性能なDNNアーキテクチャを導入し、その判断をかなり簡単に説明できるようにした。このモデルは、ResNet-50アーキテクチャの単純な変形であるBagNetと呼ばれるもので、画像の局所的な小さな特徴の出現に基づいて、その空間的な順序を考慮せずに画像を分類します。この戦略は、深層学習が登場する前に流行したBag-of-feature（BoF）モデルと密接に関連しており、ImageNetでは驚くほど高い精度を達成しています（32 x 32 pxの特徴で87.6%トップ5、16 x16 pxの特徴でAlexnetのパフォーマンス）。局所的な特徴に制約があるため、画像の各部分が分類にどのような影響を与えるかを簡単に分析することができます。さらに、BagNetsは、特徴感度、エラー分布、画像パーツ間の相互作用の点で、VGG-16、ResNet-152、DenseNet-169などの最先端のディープニューラルネットワークと同様の動作をします。これは、ここ数年のDNNの改良は、以前のBag-of-Feature分類器と比べて、質的に異なる決定戦略ではなく、より良い微調整によって達成されていることを示唆しています。
最近の研究では、シーケンスタスクにおけるTransformerアーキテクチャの強さが強調されていますが、同時に、ニューラルアーキテクチャ検索（NAS）が人間が設計したモデルよりも優れた性能を発揮し始めています。我々の目的は、NASをTransformerに代わるより良いモデルの探索に適用することです。まず、最近のフィードフォワードシーケンスモデルの進歩に触発されて大規模な探索空間を構築し、初期集団にTransformerをシードすることから始めて、進化的アーキテクチャ探索をWarmで実行しました。計算量の多いWMT 2014英独翻訳タスクを直接探索するために、Progressive Dynamic Hurdles法を開発し、より有望な候補モデルに動的に多くのリソースを割り当てることができるようにした。実験で得られたアーキテクチャ「Evolved Transformer」は、定評のある4つの言語タスクにおいて、Transformerよりも一貫した改善効果を示しました。WMT 2014 English-German、WMT 2014 English-French、WMT 2014 English-Czech、LM1Bの4つの定評ある言語タスクにおいて、Evolved TransformerはTransformerよりも一貫して向上しました。大きなモデルサイズでは、Evolved Transformerは、WMT'14 English-Germanにおいて29.8という最先端のBLEUスコアを確立しました。小さなサイズでは、37.6%少ないパラメータでオリジナルの「大きな」Transformerと同等の品質を達成し、モバイルフレンドリーな7Mパラメータのモデルサイズでは、Transformerを0.7BLEU上回る結果となりました。
我々は、一般的な言語的知能を、ある言語の語彙、構文、意味、語用論的慣習に関する以前に獲得した知識を再利用して、新しいタスクに素早く適応する能力と定義している。この定義を用いて、最先端の自然言語理解モデルを分析し、学習過程で獲得される知識のタスク非依存性を評価する一連の実験を通して、これらの基準に照らして評価する広範な実証的調査を行った。また、タスクパフォーマンスに加えて、テストデータのオンラインエンコーディングに基づいた新しい評価指標を提案し、既存のエージェント（モデル）が新しいタスクをどれだけ早く学習するかを定量化します。我々の結果は、多くのタスクに一般化するモデルアーキテクチャという点で、この分野は目覚ましい進歩を遂げているが、これらのモデルは、（例えば、微調整やタスク固有のモジュールの学習のために）多くのドメイン内の学習例を必要とし、壊滅的な忘却が起こりやすいことを示している。さらに、我々のモデルは、一般的なタスク（例えば、文書の質問応答）を解決するどころか、特定のデータセット（例えば、SQuAD）のクセに過剰に適合していることが分かった。不足している要素を議論し、一般的な言語知能に向けてどのように進歩するかを推測する。
強化学習の大きな課題は、特に報酬がまばらで欺瞞的な場合に、知的な探索を行うことである。Atari社の2つのゲームは、このような難しい探索領域のベンチマークとなっています。Montezuma's Revenge」と「Pitfall」です。この2つのゲームでは、現在のRLアルゴリズムは、ハードな探索領域でパフォーマンスを向上させる主流の手法である内発的動機付けを用いたものであっても、パフォーマンスが低い。この欠点を解決するために、我々はGo-Exploreと呼ばれる新しいアルゴリズムを導入しました。このアルゴリズムは、以下の原理を利用している。(1)以前に訪れた状態を記憶する、(2)まず有望な状態に戻り（探索せずに）、そこから探索する、(3)利用可能なあらゆる手段（決定論の導入を含む）を用いて模擬環境を解決し、その後、模倣学習によって頑健化する。これらの原則を組み合わせることで、探索が困難な問題での性能が飛躍的に向上しました。モンテズマの復讐」では、Go-Exploreは平均43kポイント以上のスコアを出しており、これは以前の技術水準の約4倍にあたります。Go-Exploreは、人間が提供したドメイン知識を利用することもでき、それを増強した場合、Montezuma's Revengeでは平均650kポイント以上のスコアを出しました。最大で約1,800万点のパフォーマンスは、人間の世界記録を上回り、「超人的」なパフォーマンスの厳密な定義にも合致しています。落とし穴」では、ドメイン知識を持つ「Go-Explore」が初めて0点を超えるスコアを出しました。その平均スコアは約6万点で、人間の熟練したパフォーマンスを超えています。Go-Exploreは、高性能なデモンストレーションを自動的かつ安価に作成するため、人間が解答のデモンストレーションを行う模倣学習をも凌駕します。Go-Exploreは、現在のRLアルゴリズムに改良を加えたり、その洞察を織り込んだりするための、多くの新しい研究の方向性を示しています。Go-Exploreは、多くの分野、特に訓練中にシミュレータを使用する分野（ロボット工学など）において、これまで解決できなかったハードな探索問題の解決を可能にするでしょう。
中国語のような文字の多い言語のNLPタスクには、その言語のグリフ情報を利用することが有効であると直感的に考えられます。しかし、グリフには豊富な絵文字の証拠がないことや、文字データに対する標準的なコンピュータビジョンモデルの一般化能力が弱いことから、グリフ情報を効果的に利用する方法はまだ見つかっていない。本論文では、中国語文字表現のためのグリフベクトルであるGlyceを提示することで、このギャップに対処します。我々は3つの大きな革新を行います。(1) 中国の歴史的な文字（青銅器文字、篆書、繁体字など）を用いて、文字の絵文字の証拠を充実させる。(2) 漢字の画像処理に適したCNN構造（tianzege-CNNと呼ぶ）を設計する。(3) モデルの一般化能力を高めるために、マルチタスク学習の設定で画像分類を補助タスクとして使用する。我々は、グリフベースのモデルが、広範囲の中国語NLPタスクにおいて、単語/文字IDベースのモデルを一貫して凌駕できることを示した。タグ付け（NER、CWS、POS）、文ペア分類、単文分類タスク、係り受け解析、意味的役割のラベル付けなど、様々な中国語NLPタスクにおいて、最先端の結果を新たに設定することができました。例えば、NERのOntoNotesデータセットにおいて、提案モデルはF1スコア80.6を達成し、BERTに比べて+1.5となりました。また、テキスト分類のFudanコーパスにおいて、99.8%というほぼ完璧な精度を達成しました。コードはこちらのhttpsのURLにあります。
アナログICの設計は、人間の専門家が経験と勘で回路仕様を満たすパラメータを探索することに依存していますが、これは非常に手間がかかり、時間もかかり、最適ではありません。機械学習は、このプロセスを自動化するための有望なツールです。しかし、教師付き学習は、学習データの入手性が低いため、このタスクには困難です。1) 回路シミュレーションには時間がかかるため、大規模なデータセットの作成には時間がかかる。 2) ほとんどの回路設計は、個々のIC企業内の提案型IPであるため、大規模なデータセットの収集にはコストがかかる。私たちは、強化学習を利用して、新しい回路データの効率的な生成と回路の最適化を学習するL2DC（Learning to Design Circuits）を提案します。回路の最適化に関する予備知識を持たないRLエージェントを学習させることで、回路図を固定し、トランジスタのパラメータを自動的に最適化する。観測値の取得、新しいトランジスタのパラメータセットの生成、報酬の取得、モデルの調整を繰り返した結果、L2DCは回路を最適化することができる。L2DCを2つのトランスインピーダンスアンプで評価しました。1日かけて学習したRLエージェントは、4分の1時間かけて学習した人間のエキスパートと同等以上の性能を発揮する。L2DCは、まず、利得や帯域幅などのハードな制約条件を満たすことを学習し、次に、面積や電力など、あると便利な目標を最適化することを学習する。グリッドサーチを用いた人間による設計と比較すると、L2DCは同等の性能で250倍のサンプル効率を達成することができます。また、同じランタイム制約の下では、L2DCの性能はベイズ最適化よりも優れています。
最近の研究では、ノルム境界の敵対的摂動に対して証明可能なロバスト性を持つディープニューラルネットワークを訓練することが可能であることが示されています。これらの手法のほとんどは、すべての可能な敵対的摂動に対する最悪のケースの損失の上界を最小化することに基づいています。これらの手法は将来性があるものの、しばしば難しい最適化手順を必要とし、大規模なネットワークへの拡張は困難です。本論文では、包括的な分析により、単純な境界処理技術である区間境界伝播法（IBP）を利用して、検証精度において最先端の技術を凌駕する大規模で証明可能なロバストなニューラルネットワークを学習できることを示す。一般的なネットワークでは、IBPによって計算される上限値は非常に弱いものですが、適切な損失と巧みなハイパーパラメータのスケジュールによって、IBPの上限値が厳しくなるようにネットワークを適応させることができることを示します。この結果、高速で安定した学習アルゴリズムが得られ、より洗練された手法を凌駕し、MNIST、CIFAR-10、SVHNにおいて最先端の結果を得ることができました。また、ダウンスケール版のImageNetにおいて、空虚境界を超えて検証された最大のモデルを学習することができます。
最適輸送（OT）理論は、フランスの数学者Gaspard Monge（1746-1818）の言葉を用いて非公式に説明することができます。シャベルを持った作業員が、建設現場にある大きな砂の山を移動させなければならない。作業員の目的は，その砂をすべて使って，所定の形（たとえば，巨大な砂の城）をした目標の山を築くことである．当然のことながら，作業者は自分の総努力を最小にしたいと考えている．これは，たとえば，砂のシャベルを運ぶのに費やす総距離や時間として定量化される．OTに関心のある数学者は，この問題を，2つの確率分布，つまり同じ体積の2つの異なる砂の山を比較する問題とみなしている．そして，砂粒をある場所から別の場所に移動させるのにどれだけの費用がかかるかという "ローカル "な考察を用いて，そのような移動のすべてに "グローバル "な費用を関連付けるのである。近年、データサイエンスに適したサイズや次元に拡張できる近似ソルバーが登場したことで、さまざまな分野でOTが普及しています。この新しいスケーラビリティのおかげで，画像科学（色やテクスチャの処理など），コンピュータビジョンやグラフィックス（形状の操作など），機械学習（回帰，分類，密度の適合など）における様々な問題を解決するために，OTがますます使用されるようになっています。この短い本は，数値的手法に偏ってOTをレビューし，データ科学におけるその応用を紹介するとともに，これらの応用に特に有用なOTの理論的特性に光を当てている．
本論文では，ワードエンベッディングとその次元性についての理論的な理解を提供する．本論文では，単語埋め込みの単位不変性に着目し，単語埋め込み間の非類似性に関する新しい指標であるPairwise Inner Product (PIP) 損失を提案する．また、行列摂動論の手法を用いて、単語埋め込みの次元選択における基本的な偏りと分散のトレードオフを明らかにした。この偏りと分散のトレードオフは、最適な次元の存在など、これまで説明のつかなかった多くの経験的観測に光を当てます。さらに、単語埋め込みがオーバーフィッティングに対していつ、どのようにロバストになるのかなど、新たな洞察や発見が明らかになりました。PIP損失のバイアスと分散のトレードオフを最適化することで、単語埋め込みの次元選択という未解決の問題に明示的に答えることができます。
チェスやポーカーなどのゼロサムゲームは、抽象的にはエージェントのペアを評価する関数であり、例えば「勝ち組」と「負け組」というラベルを付けることができます。ゲームが近似的に推移的であれば、セルフプレイによって強さの増すエージェントのシーケンスが生成される。しかし，じゃんけんのような非推移的なゲームでは，戦略的なサイクルが発生する可能性があり，もはや明確な目的はない--エージェントの強さが増すことを望むが，誰に対するものかは不明である．本論文では、ゼロサムゲームにおけるエージェントの目的を定式化するための幾何学的なフレームワークを紹介し、オープンエンドな学習をもたらす目的の適応的なシーケンスを構築する。このフレームワークにより、非遷移的なゲームにおける集団のパフォーマンスを推論することができ、ゲーム理論的なニッチングを用いて効果的なエージェントの多様な集団を構築する新しいアルゴリズム（rectified Nash response, PSRO_rN）の開発が可能となり、既存のアルゴリズムよりも強力なエージェントのセットを生み出すことができる。PSRO_rNを非遷移性の高い2つの資源配分ゲームに適用し、PSRO_rNが既存の代替案を一貫して上回ることを明らかにした。
環境中の因果構造を発見し利用することは、知的エージェントにとって重要な課題である。本研究では、メタ強化学習によって因果関係の推論が可能かどうかを検討する。本研究では、モデルフリー強化学習を用いて再帰ネットワークを学習し、因果構造を含む様々な問題を解決する。その結果、学習されたエージェントは、新しい状況で因果的な推論を行い、報酬を得ることができることがわかった。エージェントは、有益な介入を選択したり、観察データから因果推論を行ったり、反事実的な予測を行ったりすることができる。確立された正式な因果推論アルゴリズムも存在するが、本論文では、このような推論がモデルフリーの強化学習から生じることを示し、複雑な設定における因果推論が、ここで紹介するよりエンド・ツー・エンドの学習ベースのアプローチから恩恵を受ける可能性があることを示唆している。また、強化学習における構造化された探索のための新しい戦略を、実験を行い、解釈する能力をエージェントに与えることで提案する。
最近の研究では、英語の自然言語理解における生成的な事前学習の効率性が実証されています。本研究では、この手法を複数の言語に拡張し、言語横断的な事前学習の有効性を示す。本研究では、クロスリンガル言語モデル（XLM）を学習するための2つの手法を提案する。1つは単言語データのみに依存する教師なし、もう1つは新しいクロスリンガル言語モデルを目的とした並列データを活用する教師ありである。その結果，クロスリンガル分類，教師なし・教師あり機械翻訳において，最先端の結果を得ることができました．XNLIにおいて、我々のアプローチは、4.9%の絶対的な精度向上により、最先端の技術を押し上げることができました。教師なし機械翻訳では，WMT'16 German-Englishにおいて34.3 BLEUを達成し，従来の技術水準を9 BLEU以上向上させた．教師付き機械翻訳では、WMT'16のルーマニア語-英語において38.5 BLEUを達成し、これまでの最良のアプローチを4 BLEU以上上回る結果となりました。我々のコードとプリトレーニングされたモデルは一般に公開される予定です。
本研究では、DARPAのチャレンジ以降に開発された、SAEレベル3以上に分類される自律走行システムを搭載した自律走行車を中心に、文献に掲載されている自動運転車の研究を調査しました。自動運転車の自律システムのアーキテクチャは、一般的に、知覚システムと意思決定システムに分けて構成されています。知覚システムは、自動運転車の定位、静的障害物のマッピング、移動障害物の検出と追跡、道路マッピング、交通信号の検出と認識などのタスクを担当する多くのサブシステムに分かれています。また，意思決定システムは，経路計画，経路計画，行動選択，動作計画，制御などのタスクを担当する多くのサブシステムに分割されるのが一般的である．本調査では、自動運転車の自律システムの典型的なアーキテクチャを紹介します。また、知覚と意思決定に関連する手法の研究をレビューします。さらに、エスピリトサント連邦大学（UFES）で開発された自動運転車（Intelligent Autonomous Robotics Automobile（IARA））の自律システムのアーキテクチャを詳細に説明します。最後に、アカデミアやテクノロジー企業が開発し、メディアで報道されている著名な自動運転車研究プラットフォームを列挙する。
最近の学習済み文エンコーダは、言語理解タスクで最先端の結果を出しているが、これは構文構造の暗黙の知識を持っていることを意味するのだろうか？我々は、Corpus of Linguistic Acceptability（CoLA; Warstadt et al., 2018）の文法的に注釈された開発セットを導入し、これを用いて、人気の高いOpenAI Transformer（Radford et al., 2018）やBERT（Devlin et al., 2018）を含む3つの前処理されたエンコーダの文法的知識を調査する。これらのエンコーダーを微調整してCoLA上のアクセプタンス分類を行い、アノテーション付きの分析セットでモデルの性能を比較します。補助語による修飾など、どのモデルでも学習しやすい現象もあれば、長距離移動など、総合的な性能が高いモデルのみが効果的に学習し、さらに形態的な一致など、どのモデルでもほとんど学習しない現象もあります。
ディープニューラルネットワークは、ここ数年で目覚ましい進化を遂げ、現在では多くの知的システムの基本的なツールとなっています。その一方で、これらのネットワークの計算の複雑さとリソース消費量も増加し続けています。このことは、特にリアルタイムアプリケーションやリソースの限られたデバイス上で、このようなネットワークを展開する上で大きな課題となります。そのため、ネットワーク・アクセラレーションは、深層学習コミュニティのホットなトピックとなっています。深層ニューラルネットワークのハードウェア実装に関しては、近年、FPGA/ASICをベースにしたアクセラレータが数多く提案されています。本稿では、アルゴリズムとハードウェアの両方の観点から、ネットワーク・アクセラレーション、圧縮、アクセラレータ・デザインの最近の進歩を包括的に調査します。具体的には、ネットワーク・プルーニング、低ランク近似、ネットワーク量子化、教師と生徒のネットワーク、コンパクトなネットワーク設計、ハードウェア・アクセラレータなどの各テーマについて徹底的に分析する。最後に、いくつかの可能な将来の方向性を紹介し、議論します。
マルチタスク学習（MTL）は、ディープニューラルネットワークが他のネットワークとパラメータを共有することで、関連するタスクから学習することができます。しかし、実際には、MTLでは、可能なパラメータ共有アーキテクチャの膨大な空間を検索して、(a)共有の恩恵を受ける層または部分空間、(b)適切な共有量、(c)異なるタスクの損失の適切な相対的重みを見つける必要があります。最近の研究では、上記の各問題を個別に扱っています。本研究では、(a)～(c)を共同で解決する潜在的なマルチタスクアーキテクチャを学習するアプローチを提案する。4つの異なるタスクと7つの異なるドメインを含む合成データとOntoNotes 5.0のデータに関する実験を紹介する。我々の拡張機能は、マルチタスク問題の潜在的なアーキテクチャを学習する従来のアプローチよりも一貫して優れており、一般的なMTLのアプローチと比較して、平均で最大15%のエラー削減を達成した。
近年、精度と速度のトレードオフにおいて、2段検出器がシングルショット検出器を凌駕している。しかし、シングルショット検出器は、エンベデッド・ビジョン・アプリケーションでは非常に人気があります。本論文では，シングルショット検出器を現在の2段検出器と同等のレベルにまで引き上げます．そのために、最新のシングルショット検出器であるRetinaNetの学習を3つの方法で改善しました。このようにして得られた拡張ネットワークを RetinaMask と呼んでいます．RetinaMask の検出コンポーネントは，元の RetinaNet と同じ計算コストで，より高い精度を実現しています．COCO テスト・デモの結果は，RetinaMask-101 では最大 41.4mAP，RetinaNet-101 では 39.1mAP でしたが，評価中のランタイムは同じでした．グループ正規化を追加すると、RetinaMask-101のパフォーマンスは41.7mAPに向上します。コードはこちらのhttpsのURLにあります。
エッジ、境界、輪郭は、コンピュータグラフィックスとコンピュータビジョンの両方において重要な研究対象です。境界線は、3D形状を伝える2D要素であると同時に、オクルージョン現象を示すものでもあり、物体や意味的概念の分離にもつながります。本論文では、視覚的シーンの輪郭を捉える境界線のような描画である輪郭線を生成することを目的とする。従来の技術では、この問題を境界検出と呼んでいた。しかし、境界検出の出力に提示される視覚的な手がかりのセットは、輪郭図のものとは異なり、また芸術的なスタイルも無視されている。我々は、新しい輪郭図のデータセットを収集し、アノテーションの多様性を解決し、境界検出器とは異なり、アノテーションと実際のグランドトゥルースのアライメントが不完全でも動作する学習ベースの方法を提案することで、これらの問題に対処する。我々の手法は、量的にも質的にも従来の手法を上回っています。驚くべきことに、BSDS500上で我々のモデルを微調整すると、顕著な境界検出で最先端の性能を達成します。これは、輪郭描画が、境界アノテーションに代わるスケーラブルな代替手段である可能性を示唆しています。
対話エージェントが一生の間に目にする会話の大部分は、既に訓練されて配備された後に発生します。そのため、潜在的な訓練信号の膨大な量が未利用となります。本研究では、自己学習型チャットボットを提案する。これは、会話に参加することで新たな学習例を抽出する能力を持つ対話エージェントである。このエージェントは、会話に参加すると、その応答の中からユーザーの満足度を推定します。会話がうまくいっているように見えるときは、ユーザーの応答が新しい学習例となり、それを真似します。また、自分が間違っていると思ったときには、フィードバックを求めます。フィードバックの予測を学習することで、チャットボットの対話能力をさらに高めることができます。131k以上の学習例を含むPersonaChat雑談データセットでは、従来の監視の量に関わらず、自給自足のチャットボットとの対話から学習することで、パフォーマンスが大幅に向上することが分かりました。
機械学習モデルは、敵対的な例に対して脆弱です。画像にわずかな変更を加えると、スクールバスをダチョウと認識してしまうなど、コンピュータビジョンモデルがミスを犯すことがあります。しかし、人間が同様のミスを犯しやすいかどうかは、まだ未解決の問題です。ここでは、パラメータやアーキテクチャが既知のコンピュータビジョンモデルから、パラメータやアーキテクチャが未知の他のモデルに敵対的な例を転送する最近の技術を活用し、人間の視覚システムの初期処理をマッチングさせることで、この問題に取り組みました。その結果、コンピュータビジョンモデル間で強く伝達された敵対的事例は、時間制限のある人間の観察者が行う分類に影響を与えることがわかりました。
脚式ロボットは、ロボット工学における最大の課題の1つです。動物のダイナミックで俊敏な動きは、人間が作った既存の手法では真似できません。強化学習は、人手を必要とせず、制御方針の自然な進化を促す有力な手段である。しかし、これまでの強化学習の研究は、主にシミュレーションに限られており、実システムに導入されている例は少なく、比較的シンプルなものばかりでした。その主な理由は、実際のロボット、特に動的にバランスをとるシステムを使ったトレーニングが、複雑でコストがかかることです。本研究では、シミュレーションでニューラルネットワークポリシーを学習し、それを最新の脚式システムに移植する方法を紹介し、高速で自動化された費用対効果の高いデータ生成スキームを活用します。この手法は、洗練された中型犬の四足歩行システムであるANYmalロボットに適用された。シミュレーションで学習されたポリシーを用いて、この四足歩行ロボットは従来の方法では達成できなかった運動能力を獲得しました。ANYmalは、高度な体速指令に正確かつエネルギー効率よく従うことができ、従来よりも速く走ることができ、複雑な構成でも転倒から回復することができます。
人間の学習方法は、機械には真似のできない柔軟性を持っています。例えば、「ダックス」という動詞を覚えると、「2回ダックスする」、「歩きながらダックスする」、「勢いよくダックスする」などの方法を簡単に理解することができます。近年、自然言語処理のための機械学習は目覚ましい進歩を遂げていますが、優れたアルゴリズムは膨大な経験を必要とし、新しい概念を構成的に一般化するのに苦労しています。私たちは、このような人間特有の能力を理解するために、言語に似た命令を学習する課題を通して、人の構成能力を研究しました。その結果、人は非常に少ない例から新しい機能的な概念を学び、使いこなすことができ（少数ショット学習）、慣れ親しんだ機能を新しい入力にうまく適用することができることがわかった。また、人は、提供されたデモンストレーションを超えた複雑な方法で概念を構成することができる。さらに2つの実験では、これらの課題を解決する際に人々が下す仮定と帰納的バイアスを調べ、相互排他性、一対一マッピング、アイコン連結の3つのバイアスがあることを明らかにした。認知モデリングへの影響と、より人間に近い言語学習能力を持つ機械の構築の可能性について議論する。
少ないデータでも適応可能な音声合成（TTS）のためのメタ学習アプローチを紹介します。学習時には、共有された条件付きWaveNetコアと、各話者に対して独立して学習された埋め込みを用いて、複数話者モデルを学習する。学習の目的は、固定された重みを持つニューラルネットワークを生成し、それをTTSシステムとして展開することではありません。その代わりに、新しい話者に迅速に適応するために、展開時に必要なデータが少ないネットワークを作成することが目的です。我々は、3つの戦略を導入し、ベンチマークを行った。(i) WaveNetのコアを固定したまま話者の埋め込みを学習する方法、(ii) 確率的勾配降下法を用いてアーキテクチャ全体を微調整する方法、(iii) 訓練されたニューラルネットワークエンコーダを用いて話者の埋め込みを予測する方法。実験の結果、これらのアプローチは、複数話者対応ニューラルネットワークを新しい話者に適応させることに成功し、新しい話者からのわずか数分の音声データで、サンプルの自然さと音声の類似性の両方において最先端の結果を得ることができた。
名前付きエンティティ認識のための新しいアーキテクチャを提案します。このモデルでは、同じ入力に対して複数の独立した双方向LSTMユニットを用い、モデル間正則化項を採用することでユニット間の多様性を促進します。計算を複数の小さなLSTMに分散させることで、パラメータの総数を大幅に減らすことができる。また、CoNLL 2003 NERデータセットにおいて、本研究のアーキテクチャが最先端の性能を達成していることがわかった。
本論文では、ビジョンベースのロボット把持のための深層強化学習アルゴリズムを研究している。モデルフリーの深層強化学習(RL)は、様々なチャレンジングな環境に適用され成功を収めているが、アルゴリズムの急増により、把持のような豊かで多様なタスクにどのアプローチが最も適しているかを見極めることが困難になっている。この問題を解決するために、我々は、オフポリシー学習と未見の物体への一般化に重点を置いたロボット把持のシミュレーションベンチマークを提案する。オフポリシー学習では，多様な物体に対する把持データを利用することができ，多様性では，学習時に見られなかった新しい物体に一般化することができる．本研究では、様々なQ関数推定法、ディープニューラルネットワークモデルを用いたロボット把持のために以前に提案された手法、モンテカルロリターン推定とオフポリシー補正を組み合わせた新しいアプローチに対してベンチマークタスクを評価した。その結果、いくつかの単純な手法が、ダブルQラーニングなどの一般的なアルゴリズムに対して驚くほど強力な競争相手となることがわかり、安定性の分析により、アルゴリズム間の相対的なトレードオフに光が当てられました。
近年、ニューラル・アーキテクチャ・サーチ（NAS）は、大規模な画像分類において、人間が設計したものを上回るニューラル・ネットワーク・アーキテクチャの特定に成功している。本論文では、セマンティック画像セグメンテーションのためのNASを研究する。既存の研究では、空間分解能の変化を制御する外側のネットワーク構造を手作業で設計する一方で、反復可能なセル構造を探索することに焦点を当てていることが多い。この選択は、探索空間を単純化するが、ネットワークレベルのアーキテクチャの変化がより多く見られる高密度の画像予測では、ますます問題となる。そこで我々は、セルレベルの構造に加えて、ネットワークレベルの構造を検索することを提案し、階層的なアーキテクチャ検索空間を形成する。我々は、多くの一般的なデザインを含むネットワークレベルの探索空間を提示し、効率的な勾配ベースのアーキテクチャ探索を可能にする定式化を開発した（Cityscapes画像で3 P100 GPU日数）。提案した手法の有効性を、難易度の高いCityscapes、PASCAL VOC 2012、ADE20Kの各データセットで実証しました。また、セマンティック画像セグメンテーションに特化したアーキテクチャであるAuto-DeepLabは、ImageNetの事前学習なしで最先端の性能を達成しています。
Transformerは、長期的な依存関係を学習する可能性がありますが、言語モデリングの設定では、固定長のコンテキストによって制限されています。本研究では、Transformer-XLという新しいニューラルアーキテクチャを提案します。これは、セグメントレベルの再帰メカニズムと、新しい位置符号化スキームから構成されています。本手法は、より長期的な依存関係を捉えることができるだけでなく、文脈の断片化の問題を解決することができます。その結果、Transformer-XLは、RNNよりも80％、Vanilla Transformersよりも450％長い依存性を学習し、短いシーケンスと長いシーケンスの両方で優れた性能を発揮し、評価時にはVanilla Transformersの最大1,800倍以上の速度を実現しています。特に、bpc/perplexityの最先端の結果は、enwiki8で0.99、text8で1.08、WikiText-103で18.3、One Billion Wordで21.8、Penn Treebankで54.5まで向上しています（微調整なし）。WikiText-103のみで学習した場合、Transformer-XLは、数千のトークンを持つ、適度にまとまった新規のテキスト記事を生成することができます。当社のコード、事前学習済みモデル、ハイパーパラメータは、TensorflowとPyTorchの両方で利用可能です。
深層強化学習は、強化学習（RL）と深層学習の組み合わせです。この分野の研究では、これまで機械では手の届かなかった複雑な意思決定タスクを幅広く解決できるようになりました。したがって、深層RLは、ヘルスケア、ロボット工学、スマートグリッド、金融などの領域で多くの新しいアプリケーションを開きます。この原稿では、深層強化学習のモデル、アルゴリズム、テクニックについて紹介しています。特に、一般化に関連する側面と、深層強化学習がどのように実用化されるかに焦点を当てています。読者が機械学習の基本的な概念に精通していることを前提としています。
Generative Adversarial Networks（GAN）は、リアルな画像を生成する能力に優れています。しかし、多くの深層学習分野と同様に、結果を得るためには膨大な量のデータを必要とするため、新しさを生み出す上での有用性は限られていました。同じように、最近のメタ学習の進歩は、多くの少数ショット学習のアプリケーションへの扉を開いた。本研究では、Reptileを用いてメタ学習したGANであるFIGR（Few-shot Image Generation using Reptile）を提案する。このモデルは、MNISTとOmniglotの両方において、未見のクラスからわずか4枚の画像で新規画像を生成することに成功した。さらに、FIGR-8は、18,409以上のクラスに分類された1,548,944個のアイコンを含む、数ショットの画像生成のための新しいデータセットです。FIGR-8で学習した結果、我々のモデルは、以前に見たことのないクラスの画像からわずか8個のサンプルと、その8個の画像からわずか10回の学習ステップで、より高度な概念（「鳥」や「ナイフ」など）に一般化できることがわかった。本研究は、数ショットの画像を生成するためにGANを学習することの可能性を示し、この分野における将来の研究のための新しいベンチマークを設定することを目的としています。
ユーザーが選択したトピックで魅力的な会話を行うことができるオープンドメインの会話システムを構築することは、困難な課題です。Alexa Prizeは、自然で、持続的で、まとまりがあり、魅力的なオープンドメインの対話を実現するという問題に取り組むために、2016年に開始されました。第2回目となる2018年のコンペティションでは、大学チームが、ダイアログモデルにおけるコンテキストの利用、言語理解のためのナレッジグラフの活用、複雑な発話の処理、統計的・階層的なダイアログマネージャーの構築、ユーザーの応答からのモデル駆動型シグナルの活用などにより、最先端の技術を進歩させました。また、2018年のコンペティションでは、CoBot（会話ボット）ツールキット、トピックおよびダイアログアクト検出モデル、会話評価器、センシティブコンテンツ検出モデルなど、一連のツールとモデルを競技者に提供し、競技チームが知識豊富で首尾一貫した魅力的なマルチターンダイアログシステムの構築に集中できるようにしました。本論文では、会話AIの科学を発展させるという共通の目標を達成するために、大学チームとAlexa Prizeチームが開発した成果を紹介します。会話音声認識、オープンドメイン自然言語理解、常識的推論、統計的対話管理、対話評価など、いくつかの重要なオープンエンドの問題に取り組んでいます。これらの共同作業により、2018年のコンテスト開始以来、Alexaユーザーの体験は、平均評価3.61、中央値2分18秒、平均ターン数14.6と、それぞれ14％、92％、54％の向上を達成しました。会話型音声認識では、Alexa Prizeの開始以降、相対的なWord Error Rateが55％、相対的なEntity Error Rateが34％向上しました。ソーシャルボットは、CoBotツールキットのリリースもあって、2018年は大幅に急速に品質が向上しました。
これまでの機械学習の歴史は、研究者が提起した問題と、その解決策を学習するアルゴリズムという一連の流れを主に網羅していますが、重要な問題は、問題自体を解決するのと同時にアルゴリズムが生成することができるかという点です。このようなプロセスでは、多様で拡張性のある独自のカリキュラムが構築され、各段階での問題の解決策は、プロセスの後半でさらに困難な問題を解決するための足がかりとなります。本論文で紹介するPOET（Paired Open-Ended Trailblazer）アルゴリズムは、環境課題の生成と、その課題を解決するためのエージェントの最適化をペアで行うものです。POETは、可能性のある問題と解決策の空間の中で、様々な経路を同時に探索し、重要なのは、これらの踏み台となる解決策が、より良い場合には問題間で移行できるようにして、イノベーションの触媒となることです。open-ended」という言葉は、POETのようなアルゴリズムが、斬新でますます複雑な機能を際限なく作り続けることができるという魅力的な可能性を表しています。私たちの結果は、POETが幅広い環境課題を解決する多様で洗練された行動を生み出すことを示しています。これらの課題の多くは、直接的な最適化だけでは解決できませんし、野心的な課題を解決する上でオープンエンド性が重要な役割を果たすことを強調するために導入された、直接的な経路のカリキュラム構築制御アルゴリズムでも解決できません。また、ある環境から別の環境に解決策を移す能力は、システム全体の可能性を最大限に引き出すために不可欠であり、偶然の踏み台の予測不可能な性質を示しています。POETのようなアルゴリズムが、さまざまな分野でのオープンエンドな発見に向けて新たな一歩を踏み出すきっかけになることを期待しています。
自己注意は、言語や画像の生成モデルを構築するための有用なメカニズムです。これは、各要素を現在のタイムステップと比較することで、コンテキスト要素の重要性を決定します。本論文では、非常に軽量な畳み込みが、報告されている最良の自己言及の結果と競合して実行できることを示す。次に、自己注目よりもシンプルで効率的な動的畳み込みを紹介する。この方法では、現在のタイムステップのみに基づいて個別の畳み込みカーネルを予測し、コンテキスト要素の重要性を判断する。この手法では、自己注視が2次関数的であるのに対し、入力の長さに比例して必要な演算数が増加します。大規模な機械翻訳、言語モデリング、抽象的な要約などの実験では、動的な畳み込みが、強力な自己注意モデルよりも改善されることが示された。WMT'14の英語-ドイツ語のテストセットにおいて、動的畳み込みは29.7BLEUという新しい技術水準を達成した。
グラフエンベッディングは、グラフをベクトルに変換し、リンク予測やグラフクラスタリングなどのグラフ分析タスクを容易にすることを目的としている。グラフエンベッディングに関する多くのアプローチは、グラフの構造を保持することや、グラフデータの再構成誤差を最小化することに重点を置いています。これらのアプローチでは、潜在的なコードの埋め込み分布が見落とされており、残念ながら多くの場合、劣った表現になってしまう可能性がある。本論文では、グラフ埋め込みのための新しい敵対的正則化フレームワークを提案する。このフレームワークでは、グラフ畳み込みネットワークを符号化器として用いることで、トポロジー情報とノードの内容をベクトル表現に埋め込み、そこからグラフ復号器を構築して入力グラフを再構成する。また、敵対的学習原理を用いて、潜在的なコードが事前のガウス分布または一様分布と一致するように強制します。このフレームワークに基づいて、敵対的モデルの2つのバリエーション、敵対的正則化グラフ自動符号化器（ARGA）とその変分版である敵対的正則化変分グラフ自動符号化器（ARVGA）を導き出し、グラフ埋め込みを効率的に学習する。また、ARGAとARVGAの他のバリエーションも利用して、設計の理解を深めています。12種類のリンク予測アルゴリズムと20種類のグラフクラスタリングアルゴリズムを比較した実験結果により、我々のソリューションが検証された。
新しいディープニューラルネットワークモデルのファミリーを導入しました。隠れた層の不連続なシーケンスを指定する代わりに、ニューラルネットワークを用いて隠れた状態の微分をパラメータ化します。ネットワークの出力は、ブラックボックスの微分方程式ソルバーを用いて計算されます。これらの連続深度モデルは，一定のメモリコストを持ち，各入力に対して評価戦略を適応させ，数値精度と速度を明示的に交換することができる．これらの特性を、連続深度残差ネットワークと連続時間潜在変数モデルで実証します。また、データ次元の分割や順序付けを行わずに、最尤法で学習できる生成モデルである連続正規化フローを構築する。学習に関しては、任意のODEソルバーの内部操作にアクセスすることなく、スケーラブルにバックプロパゲートする方法を示している。これにより、大規模なモデル内のODEをエンド・ツー・エンドで学習することができます。
最近導入されたBERTモデルが英語の構文現象をどの程度捉えているかを、（1）自然に発生する主語と動詞の一致刺激、（2）自然文の内容語を同じ品詞と屈折を共有する語にランダムに置き換えた「colorless green ideas」主語と動詞の一致刺激、（3）主語と動詞の一致および反射的アナフォラ現象のために手動で作成した刺激を用いて評価しました。BERTモデルは、すべてのケースで非常に優れた性能を示しました。
文章理解のための再利用可能なニューラルネットワークコンポーネントの開発である、文脈に基づいた単語表現の問題に関する研究は、ELMoのような手法による言語モデリングの教師なしの事前学習タスクを中心に、最近急速に進展しています。この論文は、言語モデリングを補完するものとして、また代替となりうるものとして、この文脈における様々な事前トレーニングタスクを比較した初めての大規模な体系的研究である。この研究の主要な結果は、事前トレーニングタスクとしての言語モデリングの使用をサポートし、言語モデルを用いたマルチタスク学習を使用した比較可能なモデルの中で新しい状態を設定しています。しかし、これらの結果を詳しく見てみると、心配になるほど強力なベースラインと、ターゲットタスクによって著しく異なる結果が明らかになりました。このことは、広く使われているパラダイムである、文のエンコーダーを事前にトレーニングしてフリーズさせるという方法が、今後の研究にとって理想的なプラットフォームではない可能性を示唆しています。
動物の脳における素晴らしい生涯学習は、主にシナプス結合の可塑的な変化によって可能になる。重要なのは、これらの変化は受動的なものではなく、神経調節によって能動的に制御されているということで、それ自体が脳の制御下にある。このような脳の自己修正能力は、学習や適応において重要な役割を果たしており、生物学的強化学習の主要な基盤となっている。本論文では、このような神経調節された可塑性をもつ人工ニューラルネットワークを、勾配降下法で学習できることを初めて示した。微分可能なヘブの可塑性に関するこれまでの研究を拡張して、可塑性の神経調節に関する微分可能な定式化を提案する。神経調節された可塑性は、強化学習と教師付き学習の両方の課題において、ニューラルネットワークの性能を向上させることを示した。あるタスクでは、数百万のパラメータを持つ神経変調可塑性LSTMが、ベンチマークとなる言語モデリングタスクにおいて標準的なLSTMよりも優れた性能を示した（パラメータ数を制御）。微分可能なニューロモジュレーションによる可塑性は、ニューラルネットワークを学習するための強力な新しい枠組みを提供すると結論づけています。
ビデオ認識のためのSlowFastネットワークを紹介します。このモデルでは、(i)低フレームレートで動作し、空間的な意味を捉えるSlow経路と、(ii)高フレームレートで動作し、細かい時間解像度で動きを捉えるFast経路を含んでいる。高速経路は、チャネル容量を小さくすることで非常に軽量化できるが、映像認識に有用な時間情報を学習することができる。我々のモデルは、ビデオ内のアクションの分類と検出の両方で強力な性能を達成し、大きな改善は我々のSlowFastコンセプトによる貢献であると特定されている。Kinetics、Charades、AVAといった主要なビデオ認識ベンチマークにおいて、最先端の精度を報告する。コードは次のURLで公開されています：このhttpsのURL
近年、双曲幾何学は、階層的な情報や含意情報を符号化する埋め込みを構築するのに有効であることが証明されています。これは、漢字と単語の間の複雑な非対称関係をモデル化するのに特に適している。本論文では、まず中国語コーパスを用いて大規模なハイパーボロイド・スキップ・グラム・モデルを学習し、次にその文字埋め込みを、ポアンカレ・ディスク・モデルのジャイロベクトル空間の原理に基づいて下流のハイパーボリック・トランスフォーマー・モデルに適用する。我々の実験では、文字ベースのTransformerは、単語ベースのEuclideanの同等品よりも優れていました。我々の知る限り、中国語NLPにおいて、文字ベースのモデルが単語ベースのモデルを上回ったのは初めてのことであり、これにより、困難でドメインに依存するタスクである中国語単語分割（CWS）を回避することができる。
本研究では、30以上の異なる族に属し、28の異なるスクリプトで書かれた93の言語のために、共同の多言語文表現を学習するアーキテクチャを紹介する。本システムでは、すべての言語に共通のBPE語彙を持つ単一のBiLSTMエンコーダを使用し、これに補助的なデコーダを結合し、公開されているパラレルコーパスで学習する。これにより、英語で注釈されたデータのみを用いて、得られた埋め込みの上に分類器を学習し、それを93の言語のいずれにも変更せずに転送することができます。クロスリンガル自然言語推論（XNLIデータセット）、クロスリンガル文書分類（MLDocデータセット）、パラレルコーパスマイニング（BUCCデータセット）の実験により、我々のアプローチの有効性が示された。また，112の言語の文を並べた新しいテストセットを導入し，我々の文の埋め込みが，リソースの少ない言語であっても，多言語類似性検索において強力な結果を得ることを示した．我々の実装、事前に学習したエンコーダ、多言語テストセットは、この https URL で入手可能である。
教師なし学習の主な目的は、学習時に教師付きラベルにアクセスすることなく、後続のタスクに有用なデータ表現を発見することである。一般的には、生成モデルの負の対数尤度のような代理目的を最小化することで、後続のタスクに有用な表現が副次的に生じることを期待している。本研究では、その代わりに、後続のタスクに有用な表現を導く教師なし学習ルールをメタ学習することで、後続のタスクを直接ターゲットにすることを提案する。 具体的には、半教師付き分類の性能を目標とし、このタスクに有用な表現を生成するアルゴリズム（教師なしの重み更新規則）をメタ学習する。さらに、この教師なし更新規則を、生物学的に動機づけられたニューロンローカルな関数とすることで、異なるニューラルネットワークアーキテクチャ、データセット、データモダリティに一般化することができるようにした。我々は、メタ学習された更新規則が有用な特徴を生み出し、時には既存の教師なし学習技術よりも優れた性能を発揮することを示す。さらに、メタ学習された教師なし更新規則は、異なる幅、深さ、非線形性を持つネットワークの学習に一般化することを示します。さらに、メタ学習された教師なし更新規則は、異なる幅、深さ、非線形性を持つネットワークの学習を一般化し、ランダムに配列された入力次元を持つデータの学習を一般化し、さらには画像データセットからテキストタスクへの一般化も行います。
自然言語処理の分野では、近年、ニューラルネットワークモデルが従来のシステムの多くに取って代わるなど、目覚ましい発展を遂げています。膨大な数の新しいモデルが提案されていますが、その多くは、機能が豊富なモデルに比べて不透明であると考えられています。そのため、研究者たちは、ニューラルネットワークの分析、解釈、および評価を、新規かつより細かい方法で行うようになっています。本論文では，ニューラル言語処理における解析手法をレビューし，著名な研究トレンドに沿って分類し，既存の限界を明らかにし，今後の研究の方向性を示す。
ELMo（Peters et al., 2018a）やBERT（Devlin et al., 2018）などの文脈表現モデルは、最近、多様なダウンストリームNLPタスクで最先端の結果を達成している。最近のトークンレベルのプロービング作業を基に、新規のエッジプロービングタスクデザインを導入し、従来の構造化NLPパイプラインから派生したサブセンテンスタスクの幅広いスイートを構築します。最近の4つのモデルから単語レベルの文脈表現を探り、構文、意味、局所的、長期的な現象の範囲で文構造をどのように符号化するかを調べた。その結果、言語モデリングや翻訳の訓練を受けた既存のモデルは、統語的な現象に対しては強力な表現を行うが、意味的なタスクに対しては、文脈を無視したベースラインと比較して、わずかな改善しか得られないことがわかった。
ニューラル機械翻訳は通常、自己回帰モデルを採用しており、露出バイアスとそれに伴う誤差伝播の問題に悩まされています。これまでの研究では、エラーの伝播と精度の低下の関係について議論されてきました。(左から右への復号モデルでは，翻訳文の左部分が右部分よりも優れていることが多い）問題との関係が議論されています。本論文では、この問題を深く理解するために一連の分析を行い、いくつかの興味深い結果を得ました。(1)誤差伝播は精度低下問題に貢献しているにもかかわらず、精度低下に対する誤差伝播の役割は文献上過大評価されている。(2) 言語の特性は、精度低下の原因としてより重要な役割を果たしている。右分岐の言語（例：英語）では、翻訳結果の左部分が右部分よりも正確である可能性が高く、左分岐の言語（例：日本語）では、右部分がより正確である可能性が高い。我々の発見は、TransformerやRNNなどの異なるモデル構造や、テキスト要約などの他のシーケンス生成タスクで確認されています。
多くの学習課題では、要素間の豊富な関係情報を含むグラフデータを扱う必要があります。物理システムのモデル化、分子指紋の学習、タンパク質インターフェースの予測、病気の分類などでは、グラフ入力から学習するモデルが必要となります。また、文章や画像などの非構造的なデータからの学習では、抽出された構造（文章の依存関係ツリーや画像のシーングラフなど）に対する推論が重要な研究テーマであり、グラフ推論モデルも必要となります。グラフニューラルネットワーク（GNN）は、グラフのノード間のメッセージパッシングによってグラフの依存関係を表現するニューラルモデルです。近年、グラフ畳み込みネットワーク(GCN)、グラフアテンションネットワーク(GAT)、グラフリカレントネットワーク(GRN)などのGNNが、多くの深層学習課題において画期的な性能を示しています。本調査では、GNNモデルの一般的な設計パイプラインを提案し、各コンポーネントのバリエーションを議論し、アプリケーションを体系的に分類し、今後の研究のための4つの未解決問題を提案します。
畳み込みニューラルネットワーク（CNN）は、近年、自然言語処理（NLP）のための人気の高いビルディングブロックとして登場しました。その成功にもかかわらず、NLPに採用されている既存のCNNモデルのほとんどは、すべての入力文に対して同じ学習された（そして静的な）フィルターのセットを共有している。本論文では、テキスト処理のための文脈依存型の畳み込みフィルタを学習するために、小さなメタネットワークを使用するアプローチを検討する。メタネットワークの役割は、文や文書の文脈情報を抽象化して、入力を考慮したフィルタのセットを作ることである。さらに、このフレームワークを文のペアをモデル化するために一般化し、共依存の文表現をカプセル化するために、双方向のフィルタ生成メカニズムを導入する。オントロジー分類、センチメント分析、解答文選択、言い換え表現識別などの4つの異なるタスクを対象としたベンチマークにおいて、提案モデルである文脈感応型フィルタを用いた改良型CNNは、標準的なCNNやアテンションベースのCNNのベースラインを一貫して凌駕した。また、学習した文脈感応型フィルタを可視化することで、提案フレームワークの有効性をさらに検証し、合理化する。
グラフにおけるコミュニティ検出は、スペクトル法や、ある確率的なグラフモデルの下での事後推論によって解決することができる。最近の研究では、stochastic block modelのようなランダムグラフファミリーに焦点を当て、両方のアプローチを統合し、S/N比の観点から統計的および計算上の検出しきい値を特定した。コミュニティ検出をグラフ上のノードごとの分類問題として捉え直すことで、学習の観点からも研究することができる。我々は、教師付き学習の設定でコミュニティ検出問題を解決するための、新しいグラフニューラルネットワーク（GNN）のファミリーを提示する。我々は、データドリブンな方法で、基礎となる生成モデルにアクセスすることなく、バイナリおよびマルチクラスのストキャスティック・ブロック・モデル上の信念伝搬アルゴリズムの性能に匹敵するか、あるいは凌駕できることを示す。特に、我々は、エッジの隣接関係の折れ線グラフ上で定義される非バックトラッキング演算子でGNNを補強することを提案する。このGNNは、実世界のデータセットで良好な性能を得ることができた。 さらに、コミュニティ検出問題を解決するために（線形）GNNを使用した場合の最適化ランドスケープを初めて分析し、ある種の単純化と仮定の下で、任意のローカル・ミニマムでの損失値がグローバル・ミニマム/ミニマムでの損失値に近いことを実証した。
グラフニューラルネットワーク（GNN）は、グラフの表現学習に有効なフレームワークです。GNNは近傍集約方式を採用しており、あるノードの表現ベクトルは、その近傍ノードの表現ベクトルを再帰的に集約し、変換することで算出される。これまでに多くのGNNが提案され、ノードとグラフの両方の分類タスクで最先端の結果を得てきました。しかし、GNNはグラフ表現の学習に革命をもたらしたにもかかわらず、その表現特性や限界についての理解は限られています。ここでは、異なるグラフ構造を捉えるためのGNNの表現力を分析するための理論的枠組みを提示する。その結果、Graph Convolutional NetworksやGraphSAGEなどの一般的なGNNの識別力を明らかにし、これらのGNNでは、ある種の単純なグラフ構造を識別することができないことを示す。そして、GNNの中で最も表現力が高く、Weisfeiler-Lehmanグラフ同型性テストと同等の能力を持つ、シンプルなアーキテクチャを開発しました。そして、理論的に得られた知見を多数のグラフ分類ベンチマークで実証し、本モデルが最先端の性能を達成することを示します。
最近の研究では、深層強化学習エージェントが、頻度の低い環境報酬から言語のような指示に従うことを学習できることが示されています。しかし、この方法では、環境設計者は言語条件付きの報酬関数を設計する必要があり、環境や言語の複雑さが増すにつれ、容易には実装できない可能性があります。この限界を克服するために、我々は、環境から得られる報酬ではなく、専門家の例から共同で学習された報酬モデルから得られる報酬を用いて、指示条件付きRLエージェントを学習する枠組みを提示する。 報酬モデルは、エキスパートのデータには存在しない環境構成や指示に対して、タスクを完了したエージェントに正確に報酬を与えるようになる。このフレームワークは、命令が必要とするものの表現と、それがどのように実行されるかを効果的に分離します。単純なグリッドの世界では、エージェントはブロックとのインタラクションや、空間的な関係や特定されていない抽象的な配置の理解を必要とする一連の命令を学習することができる。さらに、この手法を用いることで、新たな専門家の例を必要とせずに、エージェントが環境の変化に適応できることを示す。
モデルフリーの深層強化学習エージェントに、構造化された表現に対する関係推論のメカニズムを追加するアプローチを紹介し、性能、学習効率、一般化、および解釈可能性を向上させる。我々のアーキテクチャは、画像をベクトルのセットとしてエンコードし、反復的なメッセージパッシング手順を適用して、シーン内の関連するエンティティと関係を発見し、推論します。StarCraft IIの学習環境で行われた7つのミニゲームのうち、6つのゲームで最先端の性能を発揮し、4つのゲームでは人間のグランドマスターレベルを超えました。また、新しいナビゲーションとプランニングのタスクでは、エージェントの性能と学習効率は非関係性の基準をはるかに上回り、トレーニング時に経験したよりも複雑なシーンに一般化することができました。さらに、学習した内部表現を調べたところ、問題やエージェントの意図に関する重要な構造が反映されていました。本研究の主な貢献点は、モデルフリーの深層強化学習エージェントにおいて、関係性のある帰納的バイアスを用いて状態を表現し、推論する技術を導入することである。我々の実験によると、この手法は、効率性、一般化、解釈可能性の点で優位性があり、現代の人工知能における最も困難なテスト環境のいくつかを満たすためにスケールアップできる。
本論文では、オープンドメインの質問応答のための新しいフレームワークを紹介しています。このフレームワークは、読み手のトークンレベルの隠された表現にアクセスできることを条件に、機械読み取りモデルのアーキテクチャに依存しません。このリトリーバーは、高速な最近傍探索を用いており、数百万のパラグラフを含むコーパスにも対応しています。読者の状態に応じて、各ステップでクエリを更新し、そのクエリを用いてリトリーバーが段落の再評価を行います。分析の結果、反復的なインタラクションにより、コーパスから有益なパラグラフを取り出すことができることを示しました。最後に、我々のマルチステップ推論フレームワークを、広く使われている2つのリーダーアーキテクチャ（\drqa, \bidaf）に適用した場合、様々な大規模オープンドメインデータセット（\tqau, ˶ˆ꒳ˆ˵）において、一貫した改善をもたらすことを示しています。
実世界のデータ、特にロボティクスの領域では、収集にコストがかかることが知られています。この問題を解決するには，シミュレーションの力を利用して，大量のラベル付きデータを作成する方法があります．しかし、シミュレーション画像でモデルを学習しても、実世界の画像には容易に移行できません。この「現実とのギャップ」を埋めるために領域適応法を用いると、ラベル付けされていない大量の現実世界のデータが必要となり、領域ランダム化だけではモデル化能力を浪費してしまう。本論文では、実世界のデータを使わずに視覚的リアリティのギャップを越えるための新しいアプローチであるRandomized-to-Canonical Adaptation Networks (RCANs)を紹介します。この手法では、ランダムにレンダリングされた画像を、ランダムではない正規のバージョンに変換することを学習します。これにより、実物の画像も正規のシミュレーション画像に変換することができます。我々は、視覚ベースの閉ループ把持強化学習エージェントをシミュレーションで学習させ、それを現実世界に移植することで、見たことのない物体をゼロショットで70％把持することに成功し、この結果は、同じタスクをドメインランダム化だけで直接学習した場合の約2倍の成功率となった。さらに、5,000個の実世界の把持を用いて実世界での共同微調整を行うことで、58万個の実世界の把持を用いて学習した最先端のシステムと同等の性能である91%を達成し、実世界のデータを99%以上削減することに成功しました。
AlphaGoの開発では、ベイジアン最適化を用いて多くのハイパーパラメータを何度もチューニングしました。この自動調整プロセスにより、棋力が大幅に向上しました。例えば、Lee Sedol氏との対局に先立ち、最新のAlphaGoエージェントをチューニングしたところ、自力対局での勝率が50%から66.5%に向上しました。決勝戦ではこのチューンナップされたバージョンが投入されました。もちろん、AlphaGoの開発期間中に何度もチューニングを行ったため、複合的な貢献度はこの割合よりもさらに高いものとなりました。この簡単なケーススタディが、囲碁ファンの方々に興味を持っていただけるだけでなく、ベイジアン最適化の実務家の方々にも、いくつかの洞察やインスピレーションを提供できれば幸いです。
現在の最先端のセマンティックロールラベリング（SRL）は、明示的な言語的特徴を持たないディープニューラルネットワークを使用しています。しかし、先行研究では、金の構文木がSRLのデコーディングを劇的に改善することが示されており、構文の明示的なモデル化によって精度が向上する可能性が示唆されている。本研究では、言語的に情報を与えられた自己注意（Linguistically-informed Self-attention: LISA）を発表する。これは、多頭の自己注意と、依存性解析、品詞タグ付け、述語検出、SRLのマルチタスク学習を組み合わせたニューラルネットワークモデルである。従来のモデルでは、言語的特徴を準備するためにかなりの前処理が必要でしたが、LISAでは、生のトークンを入力として構文を組み込むことができます。トークンごとに構文の親に注目するように1つのアテンションヘッドをトレーニングすることで、構文を組み込む。さらに、高品質な構文解析がすでに利用可能であれば、SRLモデルを再学習することなく、テスト時にその構文を注入することができるという利点がある。CoNLL-2005 SRLを対象とした実験において、LISAは、予測された述語と標準的な単語埋め込みを用いたモデルで最先端の性能を達成し、ニュースワイヤーでは従来の最先端モデルよりも2.5F1以上、アウトオブドメインデータでは3.5F1以上を達成し、誤差を約10%削減した。また、ConLL-2012の英語SRLにおいても、2.5F1以上の改善が見られた。また、文脈的にエンコードされた（ELMo）単語表現においても、LISAはニュースで約1.0F1、ドメイン外のテキストでは2.0F1以上の差をつけて、最先端の技術を上回っている。
近年、リカレントニューラルネットワークを用いた言語モデリングの進歩により、言語を文字の分布としてモデル化することが可能になりました。このようなモデルは、前の文字に基づいて次の文字を予測するように学習することで、単語、文、サブクラウス、さらにはセンチメントなどの言語的概念を自動的に内包することが示されている。本論文では，学習された文字言語モデルの内部状態を利用して，新しいタイプの単語埋め込みを行うことを提案する．我々の提案する埋め込みは、(a)明示的な単語の概念を持たずに学習されるため、基本的に単語を文字のシーケンスとしてモデル化する、(b)周囲のテキストによって文脈化される、つまり同じ単語でもその文脈上の使用に応じて異なる埋め込みを持つ、という特徴を持つ。従来の埋め込みとの比較評価を行った結果、我々の埋め込みは、下流のタスクにおいて非常に有用であることがわかった。4つの古典的なシーケンスラベリングタスクにおいて、我々は一貫して従来の最先端技術を上回っている。特に、英語とドイツ語の名前付き実体認識（NER）においては、これまでの研究を大幅に上回り、CoNLL03共有タスクにおいて最先端のF1スコアを報告することができました。これらの実験を再現したり、提案した埋め込みを他のタスクに適用したりできるように、すべてのコードと事前に学習した言語モデルを使いやすいフレームワークで研究コミュニティに公開しています。https://github.com/zalandoresearch/flair
深層学習モデルは、データ効率を犠牲にすることなく、比較的大きなバッチサイズで学習できることが、ますます多くのドメインで実証されています。しかし、この大規模なデータ並列化の限界は、ImageNetにおける数万のバッチから、ゲームDota 2をプレイするRLエージェントにおける数百万のバッチまで、ドメインごとに異なるようです。我々の知る限り、なぜこれらのバッチサイズの限界が異なるのか、また、新しいドメインでどのように正しいバッチサイズを選択すればよいのか、概念的な理解は限られています。本論文では、勾配ノイズスケールと呼ばれるシンプルで測定しやすい統計値が、多くのドメインやアプリケーションにおいて、最大の有用なバッチサイズを予測することを実証する。これには、多くの教師付き学習データセット（MNIST、SVHN、CIFAR-10、ImageNet、Billion Word）、強化学習ドメイン（AtariとDota）、さらには生成モデル学習（SVHN上のオートエンコーダー）が含まれる。その結果、ノイズの大きさは学習中の損失の減少に伴い増加し、主にモデル性能の向上を通じてモデルサイズに依存することがわかった。また、我々の経験的に動機づけられた理論は、計算効率と時間効率の間のトレードオフを説明し、適応的なバッチサイズのトレーニングの利点の大まかなモデルを提供している。
我々は、スタイル・トランスファーの文献を参考にして、生成的敵対的ネットワークのための代替的な生成器アーキテクチャを提案する。このアーキテクチャは、高レベルの属性（人間の顔で学習した場合のポーズやアイデンティティなど）と、生成された画像の確率的な変化（そばかすや髪の毛など）を、自動的に学習された教師なしの状態で分離することを可能にし、直感的でスケールに応じた合成の制御を可能にする。この新しい生成器は，従来の分布品質メトリクスの点で最先端の技術を改善し，明らかに優れた補間特性をもたらし，また，潜在的な変動要因をよりよく分離することができる．補間品質と分離を定量化するために，どのようなジェネレータ・アーキテクチャにも適用可能な2つの新しい自動化手法を提案する．最後に、人間の顔を対象とした、非常に多様で高品質な新しいデータセットを紹介します。
よく構造化された視覚的表現は、ロボットの学習を高速化し、一般化を向上させることができる。本論文では、ロボットと環境との自律的なインタラクションを利用して、人間のラベリングなしにロボットの操作タスクのための効果的なオブジェクト中心の表現を獲得する方法を研究する。このような表現学習法は、ロボットがより多くの経験を収集する際に表現を継続的に改良することで、人間の介入なしに効果的にスケールアップすることができる。我々の表現学習手法は、オブジェクトの持続性に基づいている。ロボットがシーンからオブジェクトを取り除くと、そのシーンの表現は、取り除かれたオブジェクトの特徴に応じて変化するはずである。これを用いてシーンとオブジェクトの表現を学習し、オブジェクトのインスタンスを識別したり、シーン内での位置を特定したり、ロボットが命令されたオブジェクトをビンから取り出すという目標指向の把持タスクを実行することができる。また、同じ把持手順を用いて、シーンの画像を記録し、物体を把持・除去し、その結果を記録することで、本手法の学習データを自動的に収集することができる。実験の結果、タスク付き把持のためのこの自己教師付きアプローチは、画像からの直接強化学習や先行する表現学習法を大幅に上回ることがわかった。
我々の目標は、実車を運転するのに十分なロバスト性を備えた模倣学習による自律走行の方針を訓練することである。その結果、複雑な運転シナリオに対応するためには、入力を前処理するための知覚システムや、出力を車に実行させるためのコントローラを活用したとしても、標準的な行動クローニングでは不十分であることがわかりました。3,000万例でもまだ十分ではありません。そこで私たちは、エキスパートの運転を妨害する形で合成されたデータを学習者に提供することを提案します。このデータは、衝突や道路からの逸脱などの興味深い状況を作り出します。すべてのデータを純粋に模倣するのではなく、望ましくない事象にペナルティを課し、進歩を促す追加の損失で模倣損失を補強する。摂動はこれらの損失のための重要なシグナルとなり、学習したモデルのロバスト性につながる。ChauffeurNetモデルが複雑な状況をシミュレーションで扱えることを示し、我々が提案した各変更の重要性を強調し、モデルが適切な因果要因に反応していることを示すアブレーション実験を紹介する。最後に、このモデルが現実の世界で車を運転する様子をデモンストレーションします。
コーナーネットは、単一の畳み込みニューラルネットワークを用いて、オブジェクトのバウンディングボックスを左上隅と右下隅の2つのキーポイントとして検出する、新しいオブジェクト検出手法です。オブジェクトを対になったキーポイントとして検出することで、従来のシングルステージ検出器で用いられていたアンカーボックスのセットを設計する必要がなくなりました。さらに，コーナープーリングという新しいタイプのプーリング層を導入することで，ネットワークがコーナーをより正確に検出できるようにしました．実験によると，CornerNetは，MS COCOにおいて42.2%のAPを達成し，既存の1段検出器よりも優れている．
本論文では、自律走行などの安全性が重視される領域において、学習システムを評価するという問題に取り組んでいます。本論文では、学習したエージェントが失敗するシナリオの探索と、失敗の確率の評価という2つの問題に焦点を当てています。強化学習におけるエージェント評価の標準的な手法であるバニラモンテカルロ法は、失敗を完全に見逃してしまう可能性があり、安全でないエージェントを展開してしまうことになる。この問題は、現在のエージェントでも発生しており、学習時の計算量に合わせても評価には不十分な場合があることを示している。この欠点を解決するために、我々はレアイベント確率推定の文献を利用して、敵対的評価アプローチを提案する。このアプローチでは、故障確率を不偏的に推定しつつ、敵対的に選ばれた状況での評価に焦点を当てる。重要な問題は、このような逆境を特定することです。故障はまれなので、最適化を促す信号はほとんどありません。この問題を解決するために、我々は、関連するがロバスト性の低いエージェントの故障モードを学習する継続的なアプローチを提案する。このアプローチでは、エージェントのトレーニングのために既に収集されたデータを再利用することができる。我々は、ヒューマノイド制御と模擬運転という2つの標準的なドメインにおいて、敵対的評価の有効性を実証する。実験結果によると、我々の手法は、標準的な評価スキームに比べて、壊滅的な障害を発見し、エージェントの故障率を数桁、数日ではなく数分から数時間で推定できることを示している。
MACネットワークは、完全に微分可能な新しいニューラルネットワークアーキテクチャであり、明示的かつ表現力豊かな推論を可能にするよう設計されています。MAC は、モノリシックなブラックボックス型のニューラルアーキテクチャーではなく、透明性と汎用性を兼ね備えたデザインを採用しています。このモデルでは、問題を一連の注意ベースの推論ステップに分解してアプローチします。それぞれのステップは、制御と記憶の分離を維持する新しいリカレントのMemory, Attention, and Composition (MAC)セルによって実行されます。MACセルは、制御と記憶の分離を維持する新しい再帰的な記憶・注意・構成セルによって実行されます。MACセルを連結し、その相互作用を制御する構造的な制約を課すことで、MACセルは、エンド・ツー・エンドのアプローチでデータから直接推測される反復的な推論プロセスを効果的に実行することを学習します。このモデルの強さ、頑健性、解釈可能性を、難易度の高い視覚的推論のためのCLEVRデータセットで実証し、最新の98.9%の精度を達成し、これまでの最良モデルのエラー率を半減させました。さらに重要なのは、このモデルが計算効率とデータ効率に優れていること、特に強力な結果を得るために必要なデータ量が既存のモデルよりも5倍少ないことを示していることです。
多くのタスク指向の会話AIシステムの発話解釈パイプラインの最初のステップの1つは、ユーザーの意図とそれに対応するスロットを識別することです。このタスクのための機械学習モデルのデータ収集には時間がかかるため、高リソース言語の既存データを利用して低リソース言語のモデルを学習させることが望ましいとされています。しかし、このようなモデルの開発は、多言語の学習データがないことが大きな障害となっていた。本論文では、英語（43k）、スペイン語（8.6k）、タイ語（5k）の57kのアノテーション付き発話からなる、天気、アラーム、リマインダーのデータセットを紹介する。このデータセットを用いて、3種類の異なる言語間翻訳手法を評価した。(1)学習データを翻訳する方法、(2)言語間で事前に学習した埋め込みを用いる方法、(3)多言語機械翻訳エンコーダを文脈上の単語表現として用いる新しい方法。その結果、ターゲット言語で数百の学習例があれば、後者の2つの方法は学習データの翻訳よりも優れていることがわかった。さらに、非常にリソースの少ない環境では、多言語の文脈的な単語表現の方が、多言語の静的な埋め込みを使用するよりも良い結果が得られる。また、クロスリンガル手法を、文脈的ELMo表現の形で単言語リソースを使用する方法と比較し、少量のターゲット言語データが与えられた場合、この方法はすべてのクロスリンガル手法よりも優れていることがわかり、より洗練されたクロスリンガル手法の必要性が浮き彫りになった。
我々は、Compositional Imitation Learning and Execution (CompILE)を紹介する。これは、階層的に構造化された行動の再利用可能な可変長セグメントをデモデータから学習するフレームワークである。CompILEは、新しい教師なしの完全に区別可能なシーケンスセグメント化モジュールを使用して、新しいタスクを実行するために再構成して実行することができるシーケンスデータの潜在的なエンコーディングを学習します。一度学習したモデルは、より長いシーケンスや、学習時には見られなかった環境のインスタンスにも一般化します。本研究では、難易度の高い2次元マルチタスク環境と連続制御タスクを用いてCompILEを評価し、教師なしで正しいタスク境界とイベントエンコーディングを見つけられることを示した。CompILEによって発見された潜在コードとそれに関連する行動ポリシーは、階層型エージェントによって利用することができ、高レベルのポリシーは潜在コード空間における行動を選択し、低レベルのタスク固有のポリシーは単に学習されたデコーダである。CompILEをベースにしたエージェントは、タスク固有のポリシーを持たないエージェントが苦戦するような、疎な報酬しか与えられない場合でも学習できることがわかった。
顕著性（saliency）法は、学習したモデルの予測に関連すると考えられる入力の特徴を強調するための一般的なツールとして登場しました。これまでにいくつかの顕著性法が提案されているが、その多くは画像データの視覚的な魅力に基づいている。本研究では、ある手法が提供できる説明と提供できない説明を評価するための実用的な方法論を提案します。その結果、視覚的な評価のみに頼ると誤解を招く可能性があることがわかりました。また、大規模な実験により、いくつかの既存の顕在化手法は、モデルとデータ生成プロセスの両方に依存しないことを示しました。その結果、提案したテストに失敗した手法は、データの外れ値を見つけたり、モデルが学習した入力と出力の関係を説明したり、モデルをデバッグしたりといった、データとモデルのどちらにも敏感なタスクには不向きである。私たちは、この発見を、学習データもモデルも必要としない画像のエッジ検出になぞらえて解釈しました。線形モデルと単層の畳み込みニューラルネットワークの場合の理論は、私たちの実験結果を支持しています。
強化学習を効率的に行うためには、不確実性への対応が不可欠です。固定データセットからの深層学習のための不確実性推定に関する文献は増えていますが、最も人気のあるアプローチの多くは、逐次決定問題にはあまり適していません。ブートストラップサンプリングのような他の方法は、観測されたデータから得られない不確実性のためのメカニズムを持っていません。本論文では、この点が重大な欠点となりうる理由を明らかにし、各アンサンブルメンバーにランダム化された学習不可能な「事前」ネットワークを追加することで、簡単な改善策を提案する。このアプローチが線形表現では効率的であることを証明し、非線形表現ではその有効性を簡単な図解で示し、このアプローチが大規模な問題に対して、これまでの試みよりもはるかにうまく対応できることを示す。
この問題は、入力されたソースビデオ（例えば、セマンティックセグメンテーションマスクのシーケンス）から、ソースビデオの内容を正確に描写する出力フォトリアリスティックビデオへのマッピング関数を学習することを目的としている。画像に対応する問題である画像間合成問題はよく知られたトピックですが，映像間合成問題は文献ではあまり検討されていません．時間的なダイナミクスを理解せずに，既存の画像合成手法を入力映像に直接適用すると，時間的に支離滅裂な低品質の映像になってしまうことが多い．本論文では，生成的敵対学習の枠組みの下で，新しい映像間合成アプローチを提案する．慎重に設計された生成器と識別器のアーキテクチャに、時空間的な敵対目的を組み合わせることで、セグメンテーションマスク、スケッチ、ポーズなどの多様な入力フォーマットに対して、高解像度でフォトリアリスティックな、時間的にコヒーレントなビデオ結果を得ることができる。複数のベンチマークを用いた実験により、本手法が強力なベースラインと比較して有利であることが示されました。特に、我々のモデルは、30秒までのストリートシーンの2K解像度のビデオを合成することができ、ビデオ合成の最先端を大きく前進させました。最後に、我々の手法を未来のビデオ予測に適用したところ、いくつかの最先端の競合システムよりも優れた結果が得られました。
ソースコードのような複雑な出力を生成するタスクでは、既存の出力を編集する方が、ゼロから複雑な出力を生成するよりも簡単な場合があります。このような動機から、我々は、まず入力（例：自然言語の記述）に基づいて学習例を検索し、次にそれを所望の出力（例：コード）に編集するアプローチを提案する。我々の貢献は、手作りの指標に頼ったり、検索者と編集者を共同で訓練する費用をかけずに、タスクに依存した方法で入力を埋め込む検索モデルを学習するための計算効率の良い方法である。我々の検索・編集フレームワークは、あらゆるベースモデルの上に適用することができる。GitHubのPythonコードを対象とした新しいオートコンプリートタスクと、Hearthstoneのカードベンチマークにおいて、retrieve-and-editは、バニラのsequence-to-sequenceモデルの性能を大幅に向上させることを示した。
高解像度の写真画像を合成するための新しい introspective variational autoencoder (IntroVAE) モデルを発表する。IntroVAEは、生成されたサンプルの品質を自己評価し、それに応じて自己改善することができる。推論モデルと生成モデルは、内省的な方法で共同で学習されます。一方、生成器は、通常のVAEのように、推論モデルのノイズのある出力から入力画像を再構成することが求められます。一方、推論モデルは生成されたサンプルと実際のサンプルを分類することを求められ、生成器はそれをGANとして誤魔化そうとします。これら2つの有名な生成フレームワークは、シンプルかつ効率的なシングルストリームアーキテクチャに統合されており、シングルステージで学習することができます。IntroVAEは、安定した学習と優れた潜在的多様性といったVAEの利点を保持しています。他の多くのVAEとGANのハイブリッドモデルとは異なり、IntroVAEは追加の識別器を必要としない。なぜなら、推論モデル自体が生成されたサンプルと実サンプルを区別する識別器として機能するからである。実験では、最先端のGANと同等以上の高解像度フォトリアリスティック画像（例えば、CELEBA画像：1024^{2}\）を生成することができました。
モデル蒸留は、複雑なモデルの知識をより単純なモデルに蒸留することを目的としている。本論文では、モデルを固定したまま、代わりに大規模な訓練データセットから小さなデータセットに知識を抽出しようとする、データセットディスティレーションと呼ばれる別の方式を検討する。このアイデアは、正しいデータ分布から来る必要はないが、学習データとして学習アルゴリズムに与えられたときに、元のデータで学習されたモデルに近似する少数のデータポイントを合成することである。例えば、60,000枚のMNIST学習画像をわずか10枚の合成蒸留画像（クラスごとに1枚）に圧縮し、固定のネットワーク初期化を行った場合、わずか数回の勾配降下ステップで元の性能に近い結果を得ることができることを示している。我々の手法を、様々な初期化設定と異なる学習目的で評価した。複数のデータセットを用いた実験により、他の手法と比較して本手法の優位性が示された。
我々はGraph R-CNNと呼ばれる新しいシーングラフ生成モデルを提案し、画像内のオブジェクトとその関係を検出するのに有効かつ効率的である。このモデルには、関係提案ネットワーク（Relation Proposal Network: RePN）が含まれており、画像内のオブジェクト間の潜在的な関係の二次数を効率的に処理します。また、注目型グラフ畳み込みネットワーク(aGCN)を提案し、オブジェクトと関係の間の文脈情報を効果的に捉える。最後に、既存の評価指標よりも総合的かつ現実的な新しい評価指標を紹介する。本研究では、既存の評価指標と提案した評価指標の両方を用いて評価した結果、シーングラフ生成において最先端の性能を報告する。
深層ニューラルネットワーク（DNN）は、定常的なテストセットでは優れた性能を発揮するものの、実世界の環境でよく見られる自然で非対向的なものを含む分布外（OoD）の入力に対しては一般化できないことがある。本論文では、3Dレンダラーと3Dモデルを利用してDNNの失敗を発見するフレームワークを紹介する。すなわち、対象となるDNNがレンダリングされた画像に対して誤動作を起こす原因となる3Dレンダラーのパラメータを推定する。このフレームワークと、自分で作成した3Dオブジェクトのデータセットを用いて、ImageNetに登録されている有名なオブジェクトのOoDポーズに対するDNNの脆弱性を調査した。その結果、DNNが正統的なポーズで認識できるオブジェクトに対して、DNNはそのポーズ空間の97％を誤って分類していた。さらに、DNNはわずかなポーズの乱れにも非常に敏感である。重要なのは、敵対的なポーズがモデルやデータセットを超えて伝達されることである。Inception-v3で誤って分類されたポーズの99.9%と99.4%が、同じImageNetデータセットで学習したAlexNetとResNet-50の画像分類器に、75.5%がMS COCOで学習したYOLOv3の物体検出器にも移行することがわかった。
本論文では，既存の畳み込みニューラルネットワークのドロップインモジュールとして利用できる，シンプルかつ効果的なパディング方式を紹介している．これは、パディングされた領域を穴として、元の入力を非穴として扱うことができるという直感に基づいて、部分的な畳み込みに基づくパディングと呼んでいます。具体的には、畳み込み演算の際に、パディング領域と畳み込みスライディングウィンドウ領域の比率に基づいて、画像の境界付近で畳み込み結果を再重み付けします。ImageNetの分類とセマンティックセグメンテーションにおいて、様々なディープネットワークモデルを用いた広範な実験を行った結果、提案されたパディングスキームは一貫して標準的なゼロパディングよりも優れた精度であることが実証された。
エントロピー正則化は、強化学習におけるポリシー最適化を改善するために一般的に使用されます。エントロピー正則化は、より確率的な政策の選択を促進することで、˶˙º̬˙º˶に役立つと考えられています。本研究では、損失関数のランダムな摂動に基づく最適化ランドスケープの新しい可視化を用いて、この主張を分析します。まず、正確な勾配が得られたとしても、目的関数の形状のために政策の最適化は困難であることを示す。そして、ある環境下では、より高いエントロピーを持つポリシーが最適化ランドスケープをより滑らかにし、それによって局所最適をつなぎ、より大きな学習率を使用することができることを定性的に示す。本論文は、最適化ランドスケープを理解するための新しいツールを提示し、ポリシーエントロピーが正則化の役割を果たすことを示し、汎用的なポリシー最適化アルゴリズムを設計するという課題を明らかにしている。
私たちは、知覚、運動制御、記憶を統合した複雑なヒューマノイド・エージェントの構築を目指しています。本研究では、この問題を、プロプリオセプションからの低レベルの運動制御と、視覚から得られる低レベルのスキルの高レベルの調整に部分的に因果関係を持たせています。本研究では、低レベルの運動制御装置の事前学習と、低レベルのサブポリシーを切り替える高レベルでタスクに特化した制御装置を組み合わせることで、比較的高DoFのヒューマノイドボディを驚くほど柔軟にタスク指向で運動制御できるアーキテクチャを開発した。その結果，物理的にシミュレートされたヒューマノイドボディを制御して，環境中を移動する際に，安定していない自我中心のRGBカメラからの視覚を結合する必要があるタスクを解決することができました．補足のビデオリンクはこちらのhttps URLをご覧ください。
本研究では、ユーザーが指定した領域の画像の意味情報を変更することができる、CNNベースの新しい画像編集手法を紹介します。この手法は、多様体射影と空間条件付きバッチ正規化（sCBN）を組み合わせることで実現しています。sCBNは、ユーザーが指定できる空間重みマップを持つ条件付きバッチ正規化です。sCBNと多様体射影を用いることで、(1)任意の領域で対象物のクラスを変更する「空間クラス変換」と、(2)参照画像の任意の領域に含まれる意味情報を対象画像の任意の領域に移植する「意味移植」を行うことができる。この2つの変換は同時に使用することができ、「ビーグルの鼻をブルドッグの鼻に変え、口を開ける」といった複雑な合成画像編集タスクを実現することができる。また、ユーザーは、直感的なコピー・ペーストスタイルの操作で、本手法を使用することができます。私たちは、様々な画像を使ってこの手法の威力を実証します。コードはこのhttpsのURLから入手できます。
Generative Adversarial Networks（GAN）は、近年、多くの実世界のアプリケーションで素晴らしい結果を達成しており、サンプルの質や学習の安定性を向上させた多くのGANの亜種が登場しています。しかし、GANの可視化や理解は進んでいません。GANはどのようにして我々の視覚世界を内部で表現しているのか？GANの結果のアーティファクトの原因は何か？アーキテクチャの選択はGANの学習にどのように影響するのか？このような疑問に答えることで、新しい洞察やより良いモデルを開発することが可能になります。本研究では、GANをユニット、オブジェクト、シーンの各レベルで視覚化し、理解するための分析フレームワークを提示する。まず、セグメンテーションベースのネットワーク分解法を用いて、オブジェクトの概念に密接に関連する解釈可能なユニット群を特定する。次に、出力されたオブジェクトを制御するための介入能力を測定することで、解釈可能なユニットの因果効果を定量化する。さらに、発見されたオブジェクト概念を新しい画像に挿入することで、これらのユニットとその周囲の文脈的な関係を調べる。異なるレイヤー、モデル、データセット間での内部表現の比較から、アーティファクトの原因となるユニットの位置を特定して除去することによるGANの改善、シーン内のオブジェクトのインタラクティブな操作まで、本フレームワークによって実現されるいくつかの実用的なアプリケーションを紹介します。私たちは、研究者や実務者がGANモデルをよりよく理解するためのオープンソースの解釈ツールを提供しています。
表現学習アルゴリズムは、データを特徴づける抽象的な特徴を学習するように設計されています。状態表現学習（SRL）は、学習された特徴が低次元であり、時間とともに進化し、エージェントの行動によって影響を受けるような特定の種類の表現学習に焦点を当てている。表現は、エージェントの行動によって生じる環境の変化を捉えるように学習される。この種の表現は、特にロボット工学や制御のシナリオに適している。特に、表現が低次元であることは、次元の呪いを克服し、人間による解釈と利用を容易にし、強化学習などの政策学習アルゴリズムの性能と速度を向上させるのに役立つ。本調査では、近年の状態表現学習の最新技術を網羅することを目的としています。環境とのインタラクションを伴う様々なSRL手法、それらの実装、およびロボット制御タスク（シミュレーションまたはリアル）への応用についてレビューしています。特に、レビューされたアルゴリズムにおいて、一般的な学習目的がどのように利用されているかを明らかにしている。最後に、学習された表現を評価するための評価方法について述べ、現在および将来の研究の方向性をまとめています。
表現の学習は、様々な機械学習の分野で中心的な課題となっている。強化学習において、効果的で機能的な表現は、学習の進歩を飛躍的に加速し、より困難な問題を解決する可能性を秘めている。表現学習に関する先行研究の多くは、生成的なアプローチに焦点を当てており、観測空間における変動のすべての基本的な要因を、より分離された、あるいは秩序立った方法で捉える表現を学習している。この論文では、代わりに、機能的に顕著な表現を学習することを目的としている。つまり、観測空間のすべての変動要因を捉えるという点では必ずしも完全ではなく、むしろ、意思決定に重要な変動要因、つまり「行動可能」な変動要因を捉えることを目的とした表現である。これらの表現は、環境のダイナミクスを意識しており、観測データを明示的に再構成することなく、すべての変動要因ではなく、意思決定に必要な要素のみを捉えることができます。これらの表現は、疎な報酬問題の探索を改善したり、長い水平線の階層的強化学習を可能にしたり、下流のタスクのための政策を学習するための状態表現として、どのように役立つかを示している。この手法をいくつかのシミュレーション環境で評価し、表現学習、探索、階層的強化学習の先行手法と比較する。
本論文では、特に消費電力の少ないモバイル機器向けに設計された、2値の重みと低ビット幅の活性化を持つネットワークの学習を提案する。CNNの量子化に関するこれまでの研究のほとんどは、精度を落としても同じアーキテクチャを無批判に想定している。しかし、我々は、最高のパフォーマンスを得るためには、低精度の重みと活性化を扱うのに別のアーキテクチャが適している可能性があると考えている。具体的には、「ネットワーク拡張」戦略を提案しています。この戦略では、同種の低精度ブランチのセットを集約して、全精度の中間特徴マップを暗黙的に再構築します。さらに、非常に柔軟で高精度なグループ単位の特徴近似戦略も提案しています。ImageNetの分類タスクを用いた実験により、Group-Netと名付けられた提案モデルが、様々な一般的なアーキテクチャよりも優れた性能を持つことが実証された。特に、二値の重みと活性化を用いた場合、ImageNetにおいてResNet-18とResNet-50を用いた場合、精度の点で従来の最良の二値ニューラルネットワークよりも優れているだけでなく、計算量を5倍以上節約することができます。
我々は、ニューラルネットワークの一般化能力と、セグメント化されていない文字列に潜在する単語のようなユニットを発見する能力を組み合わせた、セグメント化ニューラル言語モデルを提案します。これまでのセグメンテーションモデルは、単語の分割を単独のタスクとして扱っていたが、本モデルでは、単語の発見、単語がどのように組み合わされて文を形成するかの学習、そして、視覚的な文脈を条件とすることで、単語の意味がどのように非言語的なモダリティの表現に定着するかの学習を統合する。実験によると、無条件モデルはキャラクターLSTMモデルよりも予測分布を学習し、ノンパラメトリックベイズ単語分割モデルと競合して単語を発見し、視覚的文脈を条件とした言語モデルは両方のパフォーマンスを向上させる。
3次元の畳み込みニューラルネットワークは、入力に加えられる変換に敏感である。これは、3Dオブジェクトのボクセル化されたバージョンと、その回転されたクローンが、ネットワークの最後の層を通過した後、お互いに無関係に見えるという問題である。その代わり、理想化されたモデルは、ボクセル化されたオブジェクトの意味のある表現を維持しつつ、2つの入力の間のポーズの違いを説明することができます。等変表現のベクトルには、不変の同一性の部分と、変換の識別可能な符号化の2つの要素があります。姿勢の違いを説明できないモデルは、分類や回帰の損失関数を最適化するために、表現を「希釈」してしまう危険性があります。私たちは、3次元の平行移動と直角回転に対して線形の等変量を持つグループ畳み込みニューラルネットワークを導入しました。このネットワークは、その立方体のような対称性を反映してCubeNetと呼ばれています。このネットワークは、3次元形状のグローバルおよびローカルなシグネチャを保持することができます（連続したレイヤーで変換されます）。このネットワークをさまざまな3D推論問題に適用した結果、ModelNet10の分類問題では最先端の性能を、ISBI 2012 Connectome Segmentation Benchmarkでは同等の性能を達成しました。我々の知る限り、これはボクセル表現のための初めての3次元回転等変量CNNです。
Learning from demonstration（LfD）は，行動や報酬関数を手でコーディングすることができない場合に有効です．これは幅広い問題で成功しているが、一般的には手動で生成されたデモンストレーションや特別に設置されたセンサーに依存しており、野生で利用可能な大量のデモンストレーションを活用することはできなかった。例えば、自動車、自転車、歩行者の自然な行動のデモンストレーションを撮影した交通カメラの映像のように、すでに別の目的で設置されたセンサーを使用して、いずれにせよ発生していた行動をキャプチャするものである。Video to Behaviour (ViBe)は、通常の解像度の単眼カメラから収集された、最初は校正されていない交通シーンのラベルのない生のビデオデータから、行動のモデルを学習する新しいアプローチを提案する。本手法では、カメラのキャリブレーションを行い、関連する物体を検出し、時間的に追跡し、得られた軌跡を用いてLfDを行い、自然な行動のモデルを得ることができる。ViBeを交通交差点の生のビデオに適用し、専門家の知識を追加することなく、純粋にビデオから学習できることを示す。
グラフの精密化、つまり完全ではないグラフから興味のある部分グラフを得る作業は、様々な応用が可能である。本研究では、まず、ボリュームデータのグラフベースの表現を導き出し、次に、木の抽出をグラフ精密化タスクとして提起することにより、画像データから木またはサブツリーの集合を抽出する。グラフの精密化には2つの方法があります。まず、平均場近似(MFA)を用いてサブグラフの事後密度を近似し、そこから目的の最適サブグラフを推定する。平均場ネットワーク（MFN）は、MFAの反復がニューラルネットワークにおけるフィードフォワード操作とみなすことができるという解釈に基づいて、推論に使用されます。これにより、勾配降下法を用いてモデルのパラメータを学習することができます。次に、最頻値の一般化と考えられるグラフニューラルネットワーク（GNN）を用いた教師付き学習手法を紹介します。サブグラフは、GNNベースのグラフ洗練モデルを学習することで得られ、エッジ確率を直接予測します。この2つのクラスの手法の関連性を議論し、3Dの低線量胸部CTデータから気道を抽出するタスクについて比較します。MFNモデルとGNNモデルは、EXACT'09チャレンジでトップの性能を示した手法と同様のベースライン手法や、3D U-Netベースの気道セグメンテーションモデルと比較して、より少ない誤検出でより多くの分岐を検出することで、大幅な改善を示しました。
また，ランダムな初期化から学習した標準的なモデルを用いて，COCOデータセットにおける物体検出とインスタンス・セグメンテーションの競争結果を報告した．この結果は、ベースラインシステム（Mask R-CNN）のハイパーパラメータを事前学習モデルの微調整に最適化して使用した場合でも、ImageNetの事前学習モデルと比べて劣ることはありませんが、唯一の例外は、ランダム初期化モデルが収束するように学習の反復回数を増やすことです。ランダムな初期化による学習は驚くほど頑健で，次のような場合にも結果が得られた．(この結果は、次のような場合にも当てはまります。（i）トレーニングデータの10％のみを使用する場合、（ii）より深く、より広いモデルを使用する場合、（iii）複数のタスクとメトリクスを使用する場合。実験によると、ImageNetの事前学習は、学習の初期段階で収束を早めますが、必ずしも正則化を提供したり、最終的なターゲットタスクの精度を向上させたりするわけではありません。さらに、外部データを一切使用せずにCOCOの物体検出で50.9APを実証しました。この結果は、ImageNetの事前学習を使用したCOCO 2017の上位大会の結果と同等のものです。これらの観察結果は、依存性のあるタスクに対するImageNetの事前学習の常識を覆すものであり、これらの発見は、コンピュータビジョンにおける「事前学習と微調整」という現在のデファクトパラダイムを再考するきっかけになると期待しています。
モデルによって合成されたデータ上で政策を学習することは、原理的には、強化学習アルゴリズムが大量の実際の経験を得ることへの渇望を癒すことができますが、それはしばしばコストがかかります。しかし、多くの複雑な環境では、妥当な経験を新たにシミュレートすることは困難であり、モデルベースのポリシー評価や探索に偏りが生じることが多い。ここでは、データを新たに合成するのではなく、記録された実際の経験を想定し、その経験に基づく代替的な結果を、実際には行われなかった行動であるカウンターファクト・アクションの下でモデル化する。これに基づいて、オフポリシーの経験からPOMDPのポリシーを学習するためのCounterfactually-Guided Policy Search (CF-GPS)アルゴリズムを提案する。このアルゴリズムでは、構造的な因果モデルを利用して、個々のオフポリシーのエピソードに対する任意のポリシーの反事実的評価を行います。CF-GPSは、利用可能なログデータを利用してモデル予測の偏りをなくすことで、モデルベースのRLアルゴリズムを改善することができます。データを再重み付けする重要度サンプリングに基づくオフポリシーアルゴリズムとは対照的に、CF-GPSはモデルを活用して代替結果を明示的に考慮し、アルゴリズムが経験データをより有効に活用できるようにします。これらの利点は、非自明なグリッドワールドタスクにおけるポリシー評価と検索結果の改善につながることを実証的に示しています。最後に、CF-GPSは以前に提案されたGuided Policy Searchを一般化し、Stochastic Value Gradientのような再パラメータ化に基づくアルゴリズムが反実例法として解釈できることを示す。
現在の強化学習（RL）のベンチマーク課題は、この分野の進歩を促すのに有用であるが、多くの点で実世界のデータを用いた学習の代用にはならない。複雑化していくRLアルゴリズムを複雑性の低いシミュレーション環境でテストすることで、特定の領域を超えて一般化することができない脆弱なRLポリシーができあがってしまうことが多い。この問題を解決するために、我々は、自然界の複雑さの一部を含み、かつ高速で広範なデータ取得をサポートする、3つの新しいRLベンチマークドメインを提案する。これらのドメインでは、訓練とテストを公平に分離することで汎化の特徴を明らかにし、結果の比較と再現を容易にする。この研究を通して、RL研究コミュニティが高い評価基準を満たす、よりロバストなアルゴリズムを開発することに挑戦しています。
音声エージェントとユーザーのインタラクションは、大量のラベルのない発話を生成する。この論文では、音声言語理解（SLU）タスクにおけるモデルの性能を向上させるために、これらのラベルのない発話からの知識を効率的に転送する技術を探求しています。我々はEmbeddings from Language Model (ELMo)を用いて、文脈に基づいた単語表現を学習することで、ラベルのないデータを活用する。さらに、ELMo-Light (ELMoL)を提案する。これは、SLUのためのより高速でシンプルな教師なし事前学習法である。その結果、ラベル付けされていない発話の大規模なコーパスに対して教師なしの事前学習を行うことで、ゼロからの学習に比べてSLUの性能が大幅に向上し、従来の教師付き転送を上回ることがわかった。さらに、教師なし転送技術から得られた利益は、教師あり転送によってさらに向上することが示された。この改善は、リソースの少ない環境で顕著に見られ、1000個のラベル付きドメイン内サンプルのみを使用した場合、我々の技術は、10-15倍のラベル付きドメイン内データを使用してスクラッチからトレーニングする場合と同等の性能を発揮する。
創発的なコミュニケーションの場で相互作用するエージェントが作成する言語への関心が高まっています。これまでの研究では、視覚的な入力の表現ではなく、エージェントの記号使用に焦点を当てていた。本論文では、Lazaridouら(2017)の参照ゲームを考慮し、エージェントが進化する相互作用の間に開発する表現を調査する。その結果、エージェントは、ほぼ完全に一致する視覚表現を誘導することで、成功したコミュニケーションを確立するが、驚くべきことに、入力画像に描かれたオブジェクトの概念的な特性を捉えていないことがわかった。言語的なコミュニケーションシステムを開発するためには、エージェントが使用するシンボルに関連する視覚的なセマンティクスにもっと注意を払わなければならないと結論づけている。
本質的に動機づけられたゴール探索プロセスは、エージェントが自律的にゴールをサンプリングし、高次元の連続的な行動を伴う複雑な環境を効率的に探索することを可能にする。このアルゴリズムは、実世界のロボットに適用され、様々な効果を生み出すポリシーのレパートリーを発見することに成功している。これらのアルゴリズムは、多くの場合、人工的なゴール空間に依存していましたが、最近では、深層表現学習アルゴリズムを用いて、単純な環境において適切なゴール空間を学習できることが示されています。しかし、複数のオブジェクトやディストラクタを含むより複雑な環境の場合、効率的な探索のためには、ゴール空間の構造が環境の1つを反映している必要がある。本論文では、絡み合っていないゴール空間を用いることで、絡み合ったゴール空間よりも優れた探索性能が得られることを示す。さらに、ゴール空間の表現が分離されている場合、学習の進捗を最大化するゴールをモジュール方式でサンプリングすることで、ゴール空間を活用できることを示す。最後に、好奇心に駆られた探索を行うために用いられる学習進捗の測定値は、環境の抽象的で独立に制御可能な特徴を発見するためにも同時に用いることができることを示す。
マルチタスク学習を活用して、様々な自然言語処理（NLP）のダウンストリーム・アプリケーションで使用できる豊かな表現を学習できるかどうかを評価するために、多くの努力が払われてきた。しかし、マルチタスク学習が大きな効果を発揮する環境については、まだ理解が不足している。本研究では、厳選された意味論的タスクのセットに対して、マルチタスク学習の設定で学習された階層モデルを紹介する。このモデルは、低レベルのタスクをモデルの下層で、より複雑なタスクをモデルの上層で監視することにより、帰納的バイアスを導入するために階層的に学習される。このモデルは、名前付きエンティティ認識、エンティティ・メンション検出、関係性抽出などの多くのタスクにおいて、手作業で作成した特徴量や構文パーサーなどの外部NLPツールを使用せずに、最先端の結果を達成しました。階層化された学習監督は、モデルの下位層で共有された意味的表現のセットを誘導します。また、モデルの下層から上層に向かうにつれて、層の隠れた状態がより複雑な意味情報を表す傾向があることを示している。
あるタスクを実行するモデルを学習するには、通常、そのタスクが適用されるドメインからの大量のデータが必要です。しかし、あるドメインではデータが豊富であっても、他のドメインではデータが不足しているということがよくあります。ドメイン適応とは、データの豊富なソースドメインで学習したモデルを、データの少ないターゲットドメインでもうまく機能するように適応させるという課題を扱うものである。一般的には、ドメイン間の妥当なマッピングを学習する必要があります。CycleGANは、あるドメインから別のドメインへの入力のマッピングを、敵対的な学習とサイクル・コンシステンシー制約を用いて効率的に学習する強力なフレームワークです。しかし、従来の手法である再構成による周期整合性の確保は、1つまたは複数のドメインの学習データが限られている場合には、過度に制限される可能性がある。本論文では、外部のタスク特有のモデルを用いて周期整合性制約を適用する拡張周期的敵対学習モデルを提案する。このモデルは、厳密な再構成ではなく、タスクに関連するコンテンツの保存を推奨する。このタスク特有のモデルは、サイクル・コンシステンシー制約を緩和するとともに、学習中の識別器の役割を補完し、マッピングを学習するための拡張情報源として機能する。本研究では、音声および視覚領域において、低リソースでの教師あり環境での適応を検討する。音声領域では、各領域の音声認識モデルをタスク固有のモデルとして採用している。TIMITデータセットでは、男性の音声が大半を占める中、女性の音声に対して2％の音声認識性能の向上が見られた。低リソースの視覚領域適応において、我々のアプローチは、SVHNをMNISTに適応する際に14％、逆にMNISTをSVHNに適応する際に4％、絶対的な性能を向上させることができ、高リソースのラベルのないターゲット領域を必要とする教師なし領域適応法よりも優れていることがわかった。
強化学習を用いて現実世界の複雑な問題を解決するためには、手動で指定された報酬関数に頼ることはできません。代わりに、人間がエージェントに直接目的を伝えることができる。本研究では，人間のフィードバックから学習するための2つのアプローチ，すなわち，専門家の実演と軌道の好みを組み合わせる．報酬関数をモデル化するために深層ニューラルネットワークを学習し、その予測された報酬を用いてDQNベースの深層強化学習エージェントを9つのAtariゲームで学習する。我々のアプローチは、7つのゲームで模倣学習のベースラインを上回り、2つのゲームではゲームの報酬を使わずに厳密に超人的なパフォーマンスを達成した。さらに、報酬モデルの適合性を調査し、報酬のハッキング問題を提示し、人間のラベルに含まれるノイズの影響を研究する。
単言語データを用いたニューラル機械翻訳を改善するための効果的な方法は、ターゲット言語の文のバックトランスレーションでパラレルトレーニングコーパスを補強することです。本研究では、逆翻訳の理解を深め、合成原文を生成するためのいくつかの方法を検討しました。その結果、リソースの乏しい環境を除いて、サンプリングやノイズの入ったビーム出力によって得られた逆翻訳が最も効果的であることがわかりました。分析の結果、サンプリングやノイズを含んだ合成データは、ビームやグリーディサーチによって生成されたデータよりもはるかに強い学習信号を与えることがわかった。また、合成データを本物のビットテキストと比較し、様々なドメイン効果を調べました。最後に、数億のモノリンガルセンテンスに拡張し、WMT'14英独テストセットにおいて35BLEUという新たな技術水準を達成しました。
半教師付きのグラフのノード分類は、グラフマイニングの基本的な問題であり、最近提案されたグラフニューラルネットワーク（GNN）は、このタスクで比類のない結果を出しています。最近提案されたグラフニューラルネットワーク(GNN)は、この課題で比類のない成果を上げている。その大成功のため、GNNは多くの注目を集め、多くの新しいアーキテクチャが提唱されている。この論文では、GNNモデルの既存の評価戦略には重大な欠点があることを示しています。同じデータセットの同じ訓練／検証／テストの分割を使用したり、訓練手順に大幅な変更を加えたり（例えば、早期停止基準）すると、異なるアーキテクチャの公正な比較ができなくなることを示しています。我々は、4つの著名なGNNモデルを徹底的に実証的に評価し、データの異なる分割を考慮することで、モデルの順位が劇的に異なることを示しました。さらに重要なことは、ハイパーパラメータと学習手順がすべてのモデルに対して公平に調整されていれば、より単純なGNNアーキテクチャがより洗練されたものを上回ることができることを示唆している。
我々は、Embodied Question Anseringのためのブラインドフォールド（質問のみ）のベースラインを調査した。EmbodiedQAタスクは、エージェントがシミュレートされた環境をインテリジェントにナビゲートして質問に答えることを要求し、最終的に回答する前に一人称の視覚を通してのみ必要な視覚情報を収集する。そのため、環境と視覚情報を無視した目隠しベースラインは退化したソリューションとなります。しかし、EQAv1データセットでの実験により、単純な質問のみのベースラインは、エージェントが対象物に極端に接近して起動した場合を除くすべてのケースにおいて、EmbodiedQAタスクで最先端の結果を達成することが示されました。
最近の研究では、指紋認識システムがマスタープリントに基づく辞書攻撃に対して脆弱であることが示されている。マスタープリントとは、多数の指紋と偶然に一致する可能性のある実在の指紋または合成指紋のことで、これにより指紋システムが提供するセキュリティが損なわれます。Royらによる以前の研究では、合成マスタープリントを特徴レベルで生成していました。本研究では、DeepMasterPrintsと呼ばれる完全な画像レベルのマスタープリントを生成し、その攻撃精度は以前の手法よりもはるかに優れていることがわかった。提案された手法は、Latent Variable Evolution（潜在変数進化）と呼ばれ、実在する指紋画像のセットでGenerative Adversarial Network（生成的逆行列ネットワーク）を学習することに基づいています。共分散行列適応進化戦略の形での確率的探索は、指紋認識装置によって評価された偽者マッチの数を最大化することができる生成ネットワークへの潜在的な入力変数を探索するために使用されます。実験では、DeepMasterPrintsの生成における提案手法の有効性が示された。この手法は、指紋のセキュリティや指紋の合成に幅広く応用できる可能性があります。
ニューラルモデルの予測を解釈する1つの方法は、最も重要な入力特徴を強調することであり、例えば、入力文中の単語をヒートマップで視覚化する。既存のNLPの解釈方法では、単語の重要性は、その単語を削除したときのモデルの信頼性の低下を測定する入力摂動、またはその単語に関する勾配のいずれかによって決定されます。これらの方法の限界を理解するために、我々は入力から最も重要でない単語を反復的に除去する入力削減を使用する。これにより、神経モデルの病的な動作が露呈する。つまり、残った単語は人間にとって無意味なものに見え、解釈法で重要と判断されたものではないのだ。人間の実験で確認したように、削減された例は、どのラベルを予測するにも情報が不足していますが、モデルは依然として高い信頼性で同じ予測を行っています。これらの直感に反する結果を説明するために、我々は敵対的な例と信頼性のキャリブレーションとの関連を導き出した。病的な行動は、最尤で訓練された神経モデルの解釈が困難であることを示している。病的な行動は、最尤で訓練されたニューラルモデルの解釈が困難であることを示している。その欠陥を軽減するために、我々は、還元された例で高エントロピー出力を促すことでモデルを微調整する。微調整されたモデルは、入力を減らしても通常の例での精度を落とすことなく、より解釈しやすくなる。
勾配ベースの手法は、コンピュータグラフィックス、機械学習、コンピュータビジョンなどの分野でますます重要になってきています。勾配を計算する能力は、最適化、逆問題、および深層学習に不可欠です。レンダリングでは、カメラのパラメータ、光源、シーンのジオメトリ、またはマテリアルの外観などの変数に関して、グラデーションが必要になります。しかし、レンダリング積分には微分できない可視性項が含まれているため、レンダリングのグラデーションを計算することは困難です。微分可能なレンダリングに関するこれまでの研究では、近似解が中心でした。これらの手法では、影やグローバルイルミネーションなどの二次的な効果を処理できなかったり、ピクセル座標以外の変数に対するグラデーションを提供できなかったりします。我々は、汎用の微分可能なレイトレーサーを紹介します。これは、我々の知る限り、カメラのポーズ、シーンのジオメトリ、マテリアル、照明パラメータなどの任意のシーンパラメータに関して、レンダリング画像上のスカラ関数の微分を計算できる初めての包括的なソリューションです。本手法の鍵となるのは，不連続な積分値の導関数によってもたらされるディラックデルタ関数を直接サンプリングする新しいエッジサンプリングアルゴリズムです．また、空間階層に基づいた効率的な重要度サンプリング手法も開発しています。この手法では、シーンの複雑さや必要な精度に応じて、数秒から数分でグラデーションを生成することができます。微分可能なレイトレーサーを深層学習ライブラリであるPyTorchと連携させ、逆方向のレンダリングやニューラルネットワークのための敵対的な例の生成への応用のプロトタイプを示します。
検索ランキングへの応用は、Airbnbにおける機械学習の最大の成功例の一つです。初期の利益の多くは、勾配ブーストされた決定木モデルによってもたらされました。しかし、その利益は時間の経過とともにプラトー化していった。本稿では、その停滞を打破するための試みとして、ニューラルネットワークを適用して行われた作業について説明します。私たちの視点は、新しいモデリング技術のフロンティアを押し広げることを意図したものではありません。むしろ、ニューラルネットワークを実際の製品に適用した際に有用だと感じた要素を紹介しています。深層学習は私たちにとって急な学習でした。同じような旅に出ようとしている他のチームにとって、私たちの苦闘と勝利の記録が何かの参考になることを願っています。それでは、良い旅を
近年のハードウェアの発展により、ニューラルネットワークの学習に利用できるデータ並列の規模は劇的に拡大しています。次世代のハードウェアを利用する最も簡単な方法は、標準的なミニバッチ型のニューラルネットワーク学習アルゴリズムのバッチサイズを大きくすることです。本研究では、バッチサイズの増加が学習時間に与える影響を実験的に明らかにすることを目的としています。これは、目標とするサンプル外誤差に到達するために必要なステップ数で測定します。この関係が、学習アルゴリズム、モデル、データセットによってどのように変化するかを調べたところ、作業負荷によって非常に大きなばらつきがあることがわかりました。また、バッチサイズがモデルの品質にどのように影響するかについての文献の不一致は、メタパラメータのチューニングとバッチサイズごとの計算バジェットの違いによってほぼ説明できることを示しています。また、バッチサイズを大きくすることで、サンプル外のパフォーマンスが低下するという証拠は見つかりませんでした。最後に，今回の結果が，将来的にニューラルネットワークをより高速に学習するための取り組みに与える影響について述べます．実験データは，35種類のワークロードで168,160個のモデルを学習した際に得られた71,638,836個の損失測定値のデータベースとして公開されています．
本研究では、深層政策勾配アルゴリズムの挙動が、その開発の動機となった概念的な枠組みをどのように反映しているかを研究しています。この目的のために，このフレームワークの主要な要素である「勾配推定」「値の予測」「最適化ランドスケープ」に基づいて，最先端の手法を細かく分析することを提案した．その結果、深層政策勾配アルゴリズムの挙動は、その動機付けとなるフレームワークが予測するものとは異なることが多いことがわかった。すなわち、代理目的は真の報酬ランドスケープとは一致せず、学習された価値推定値は真の価値関数に適合せず、勾配推定値は「真の」勾配との相関性が低い。予測された動作と経験的な動作のミスマッチは、現在の手法の理解不足を浮き彫りにし、ベンチマーク中心の評価手法からの脱却が必要であることを示しています。
十分な多様性を持つ高品質なテキストを生成することは、さまざまな自然言語生成（NLG）タスクに不可欠です。教師の強制力を用いて学習された最尤（MLE）モデルは、一貫して弱いベースラインとして報告されており、その性能の低さは暴露バイアスに起因するとされています（Bengio et al.2015; Ranzato et al.2015）。推論時に、モデルはグランドトゥルストークンの代わりに自分の予測値を与えられるため、エラーが蓄積され、サンプルが貧弱になる可能性があります。この推論は、GANが暴露バイアスに悩まされないという説明のもと、NLGのための敵対的ベースのアプローチの発生につながっています。本研究では、これまでの常識を覆す、いくつかの驚くべき結果を得た。まず、NLGの標準的な評価フレームワークを再検討し、品質のみの評価の根本的な欠陥を指摘します。モデルの条件付き分布のエントロピーを人為的に減少させるために、単純でよく知られた温度パラメータを使用して、そのようなメトリクスを上回ることができることを示します。次に、品質と多様性のトレードオフをコントロールするこのパラメータを活用して、品質と多様性のスペクトル全体でモデルを評価し、MLEモデルが品質と多様性の空間全体で提案されたGANの亜種を常に凌駕することを発見しました。この結果にはいくつかの意味があります。1）サンプルの品質に対する暴露バイアスの影響は、これまで考えられていたよりも軽微である。2）温度調整は、逆問題トレーニングよりも品質と多様性のトレードオフを改善し、かつトレーニングが簡単で、クロスバリデートが容易で、計算コストも低い。実験を再現するためのコードはこちらのURLから入手可能です。
我々は、内部モデルを持つエージェントが世界で継続的に行動し、学習する必要がある場合のために、POLO（Plan Online and Learn Offline）フレームワークを提案する。本研究では、局所モデルに基づく制御、大域的な価値関数の学習、および探索の間の相乗的な関係に基づいています。局所的な軌道最適化によって、価値関数の近似誤差に対処し、価値関数学習を安定化・高速化できることを研究しています。逆に、近似値関数が計画地平線の短縮に役立ち、局所解を超えたより良い政策を可能にすることも研究しています。最後に、価値関数近似の不確実性を推定することと併せて、時間的に協調した探索を行うために、軌道最適化をどのように利用できるかについても示します。このような探索は、価値関数を高速かつ安定的に学習するために重要です。これらの要素を組み合わせることで、ヒューマノイドの移動や手先の器用な操作など、複雑なシミュレーション制御タスクを、実世界での数分の経験に相当する時間で解決することができる。
与えられた目的を、与えられた基本的なルールに従いながら最適化する新しいグラフ構造を生成することは、化学、生物学、社会科学の研究にとって基本的なことです。このことは、化学的な原子価などの物理法則に従いながら、薬剤への適合性や合成のしやすさなどの望ましい特性を持つ新規分子を発見することを目的とする分子グラフ生成の課題において、特に重要である。しかし、非常に複雑で差別化できないルールを組み込みながら、望ましい特性を最適化する分子を発見するモデルを設計することは、依然として困難な課題である。本研究では、強化学習による目標指向型グラフ生成のための一般的なグラフ畳み込みネットワークベースのモデルであるGraph Convolutional Policy Network (GCPN)を提案する。このモデルは、ポリシー勾配によってドメイン固有の報酬と敵対的損失を最適化するように学習され、ドメイン固有のルールを組み込んだ環境で動作する。実験結果によると、GCPNは、既知の分子に似せながら化学的性質の最適化を行う際に、最先端のベースラインと比較して61％の改善を達成し、制約付きの性質の最適化タスクでは184％の改善を達成しました。
ビーム探索は、ニューラルネットワークデコーダの近似探索戦略として広く用いられており、機械翻訳などのタスクでは一般的に単純なグリーディデコーダよりも優れた性能を発揮します。しかし、この改善にはかなりの計算コストがかかる。本論文では、ビームサーチの利点をほぼ完全に享受しながら、追加の計算コストをほとんど必要としない、柔軟で新しい手法を提案する。この方法は、事前に学習したデコーダの隠れた状態を観察し、操作するように訓練された小さなニューラルネットワークのアクターを中心に展開される。このアクターネットワークを学習するために、ベースモデルに対するビームサーチの出力を用いて構築された疑似パラレルコーパスをBLEUのような目標品質指標でランク付けして使用します。この手法は、この問題に関する以前の研究からヒントを得ているが、強化学習を必要とせず、様々なモデルに対して信頼性の高い学習が可能である。3つの並列コーパスと3つのアーキテクチャを用いた実験では、この手法によって翻訳品質と翻訳速度が各ベースシステムよりも大幅に向上することが示された。
交通量の予測は、ITS（Intelligence Transportation System）の基本的かつ重要なタスクですが、交通量の時空間的特性のため、特に大都市環境下では、計算量を抑えながら高い精度を得ることは非常に困難です。本研究では，道路ネットワークをモデル化し，交通流の伝搬パターンを提示するために，Linkage Networkと呼ばれる新しいトポロジーフレームワークを提案する．このLinkage Networkモデルに基づいて，Graph Recurrent Neural Network (GRNN)と呼ばれる新しいオンライン予測器を設計し，グラフ内の伝播パターンを学習する．GRNNは、グラフ全体から収集した情報に基づいて、すべての道路セグメントの交通流を同時に予測することができ、高い精度を維持しながら、計算量をO(nm)からO(n+m)に大幅に削減することができる。さらに、交通傾向の変動を予測することも可能です。実世界のデータを用いた実験により、提案手法が既存の予測手法を上回ることが実証された。
マルチホップ推論は、不完全なナレッジグラフ（KG）上のクエリアンサー（QA）のための効果的なアプローチである。この問題は、強化学習（RL）の設定で定式化することができ、ポリシーベースのエージェントが目標に到達するまで推論経路を順次延長していきます。しかし、不完全な知識グラフの環境では、エージェントは訓練データの偽陰性によって破壊された低品質の報酬を受け取ることになり、テスト時の一般化に悪影響を及ぼす。さらに、トレーニングには黄金の行動シーケンスが用いられないため、エージェントは偶然にも正解につながる偽の探索軌道に惑わされる可能性がある。この問題を解決するために、我々は2つのモデリングを提案する。(1)事前に学習されたワンホップ埋め込みモデルを採用して、観察されていない事実の報酬を推定することで、偽陰性監視の影響を低減する。(2)ランダムに生成されたエッジマスクを用いて、エージェントに多様なパスを探索させることで、オンポリシーRLの偽のパスに対する感度に対抗する。我々のアプローチは、いくつかのベンチマークデータセットにおいて、既存のパスベースのKGQAモデルを大幅に改善し、エンベッディングベースのモデルと比較しても同等以上の結果を得た。
本論文では、メル・スペクトログラムから高品質な音声を生成することができるフローベースのネットワークであるWaveGlowを提案する。WaveGlowは、GlowとWaveNetの知見を組み合わせ、自動回帰を必要としない、高速で効率的かつ高品質な音声合成を実現しています。WaveGlowは、単一のネットワークを用いて実装されており、学習データの尤度を最大化するという単一のコスト関数を用いて学習されるため、学習手順がシンプルで安定しています。PyTorchの実装では，NVIDIA V100 GPUを用いて，500kHz以上のオーディオサンプルを生成しています．平均オピニオンスコアを見ると、一般に公開されている最高のWaveNet実装と同等のオーディオ品質を実現しています。すべてのコードはオンラインで公開される予定です。
ニューラル・ダイアログ・モデリングにおける探索戦略の影響を調査します。まず、2つの標準的な検索アルゴリズムである貪欲検索とビーム検索を比較し、さらに、より多様な応答候補を生成するために新たに提案した反復ビーム検索を比較する。さらに、人間との現実的な会話を用いてこれらの戦略を評価し、アノテーターのバイアスに対処するためにモデルベースのベイズキャリブレーションを提案する。これらの会話は，モデルによって割り当てられた対数確率と発話の多様性という2つの自動測定基準を用いて分析される．我々の実験では、優れた検索アルゴリズムがより高い評価の会話をもたらすことが明らかになった。しかし、より多様な候補から選択するための最適な選択メカニズムを見つけることは、まだ未解決の問題である。
最近の情報抽出（IE）システムのほとんどは、シーケンシャルタガーとして実装されており、局所的な依存性しかモデル化していません。しかし、非局所的、非逐次的なコンテキストは、予測を改善するための貴重な情報源である。本論文では、GraphIEを紹介する。GraphIEは、テキストユニット（単語や文）間の広範な依存関係を表すグラフ上で動作するフレームワークである。このアルゴリズムは、グラフの畳み込みによって、接続されたノード間の情報を伝達し、単語レベルの予測を向上させるために利用できる、より豊かな表現を生成する。テキスト、ソーシャルメディア、ビジュアル情報の抽出という3つの異なるタスクで評価した結果、GraphIEは、最先端のシーケンスタギングモデルを一貫して大幅に上回ることがわかった。
深層強化学習法のための探索ボーナスを導入しました。このボーナスは、実装が容易で、実行される計算のオーバーヘッドを最小限に抑えることができます。このボーナスは、固定されたランダムに初期化されたニューラルネットワークによって与えられた観測結果の特徴を予測するニューラルネットワークの誤差である。また、内発的な報酬と外発的な報酬を柔軟に組み合わせる方法を紹介します。我々は、Random Network Distillation (RND)ボーナスとこの柔軟性の向上を組み合わせることで、いくつかの難解な探索用Atariゲームを大きく前進させることができることを発見した。特に、深層強化学習手法にとって難しいゲームとして有名な「Montezuma's Revenge」では、最先端のパフォーマンスを確立しました。我々の知る限りでは、このゲームにおいて、デモンストレーションを用いたり、ゲームの基本的な状態にアクセスしたりすることなく、人間の平均的な性能よりも優れた性能を達成し、時折、最初のレベルを完了することができる初めての手法です。
我々は、人間がタスクを実行している1つのビデオから、他のオブジェクトを使ったサブタスクのデモデータを活用しながら、実際のロボットの多段階のビジョンベースのタスクを学習するという問題を考えます。この問題には、いくつかの大きな課題があります。遠隔操作を伴わないビデオデモンストレーションは、人間が提供するのは簡単ですが、直接的な監督を行うことはできません。生のピクセルからポリシーを学習することで、一般性を確保することができますが、多くのパラメータを持つ大規模な関数近似器を学習しなければなりません。また、複合的なタスクは、単一のスキルとして扱われる場合、実用的でない量のデモデータを必要とする可能性があります。これらの課題を解決するために、本研究では、実演映像から原始的な動作を学習する方法と、実演者を見ながらこれらの動作を動的に組み合わせて多段階のタスクを実行する方法の両方を学習する手法を提案する。模擬Sawyerロボットと実物PR2ロボットを用いた結果、新規のオブジェクトと生のピクセル入力を用いて、様々な注文処理やキッチンでの配膳作業を学習することができた。
品質ダイバーシティは、進化的探索アルゴリズムの一種であり、探索中に発散と収束の適切なバランスを維持することを目的として、性能が良く（品質）、かつ異なる（多様性）複数の解を見つけることに焦点を当てています。品質の多様性はすでに複雑な問題で有望な結果をもたらしているが、品質の多様性のための発散型探索のバリエーションの能力については、まだほとんど調査されていない。本論文では、発散探索の効果的な推進力としての驚きの概念と、その新規性との直交性にヒントを得て、品質多様性のパフォーマンスに対する驚きの影響を調査する。この目的のために、驚きを多様性の指標として用いる3つの新しい品質多様性アルゴリズムを導入し、その性能を、最新の品質多様性アルゴリズムである「局所的な競争を伴う新奇探索」と比較する。これらのアルゴリズムは、60個の高度に欺瞞的な迷路でのロボットナビゲーション課題でテストされた。その結果、驚きと新しさを相乗的に作用させて発散させたり、局所的な競争を併用したりすることで、効率、速度、頑健性が著しく高い品質多様性アルゴリズムを実現できることが示唆された。
注意関数の学習には大量のデータが必要ですが、多くのNLPタスクは人間の行動をシミュレートしています。本論文では、人間の注意が実際にNLPにおける多くの注意関数に良い帰納的バイアスを提供することを示します。具体的には、アイトラッキングコーパスから得られた人間の注意の推定値を用いて、リカレントニューラルネットワークの注意関数を正則化します。その結果、感情分析、文法エラーの検出、罵倒語の検出など、さまざまなタスクで大幅な改善が見られました。
最近の深層学習モデルは、画像、ビデオ、音声などの低次元の規則的なグリッドから、ソーシャルネットワーク、脳のつながり、知識グラフなどの高次元のグラフ構造のデータへと移行しています。この進化は、既存の深層学習フレームワークの設計範囲を超えた、大規模なグラフベースの不規則で疎なモデルをもたらしました。さらに、これらのモデルは、GPUなどの並列ハードウェア上で効率的かつ大規模に加速することが容易ではありません。我々は、グラフベースのディープニューラルネットワーク（GNN）のための初の並列処理フレームワークであるNGraを紹介します。NGraは、深層ニューラルネットワークを頂点プログラムとして表現するための新しいSAGA-NNモデルを提案しています。このモデルは、GNNを直感的に表現できるだけでなく、効率的なデータフロー表現へのマッピングを容易にします。NGraは、グラフを自動的に分割し、チャンクベースのストリーム処理をGPUコアの外や複数のGPU上で行うことで、スケーラビリティの課題に透過的に対処します。この際、データの局所性、データの移動、並列処理とデータの移動の重複などを慎重に考慮します。NGraはさらに、GPU上で高度に最適化されたScatter/Gather演算子によって、その疎性にもかかわらず効率性を実現しています。我々の評価によると、NGraは既存のフレームワークが直接処理できない大規模な実在のグラフにも対応し、一方でTensorFlow上の複数ベースライン設計に比べて小さなスケールでも最大約4倍のスピードアップを達成しています。
マルチエージェント環境では、協力することを学ぶことが非常に重要です。そのためには、エージェント間の相互作用を理解することが重要です。しかし、マルチエージェント環境は、エージェントが移動し続け、隣人もすぐに変わるような、非常にダイナミックな環境です。このため、エージェント間の相互作用の抽象的な表現を学ぶことは困難である。そこで本研究では、グラフ畳み込み強化学習を提案する。グラフ畳み込みは、マルチエージェント環境の基礎となるグラフのダイナミクスに適応し、関係カーネルは、関係表現によってエージェント間の相互作用を捉える。畳み込み層の受容野を徐々に増やしていくことで生成される潜在的な特徴を利用して協調性を学習し、時間的関係の正則化によって協調性をさらに向上させます。経験的に、我々の手法は、様々な協力関係のシナリオにおいて、既存の手法を大幅に上回ることを示す。
グラフ構造データの表現学習に関する最近の研究は、主にノードやサブグラフなどのグラフ部分構造の分散表現の学習に焦点を当てています。しかし、グラフの分類やクラスタリングなど、多くのグラフ解析タスクでは、グラフ全体を固定長の特徴ベクトルとして表現する必要があります。前述のアプローチでは、このような表現を学習することはできませんが、グラフカーネルは、このような表現を得るための最も効果的な方法です。しかし、これらのグラフカーネルは、手作りの特徴（最短経路、グラフレットなど）を使用しているため、一般化が難しいという問題があります。この問題を解決するために、本研究では、任意の大きさのグラフのデータ駆動型の分散表現を学習するために、graph2vecというニューラル埋め込みフレームワークを提案している。そのため、グラフの分類やクラスタリング、さらには教師付き表現学習アプローチのシードなど、下流のあらゆるタスクに利用することができます。いくつかのベンチマークデータや大規模な実世界データを用いた実験により、graph2vecは、下位構造表現学習アプローチと比較して、分類やクラスタリングの精度を大幅に向上させ、最先端のグラフカーネルに対抗できることが示された。
マルチエージェント強化学習（Multi-Agent Reinforcement Learning: MARL）において、他のエージェントの行動に因果的な影響を与えたエージェントに報酬を与えることで、協調とコミュニケーションを実現する統一的なメカニズムを提案する。因果的な影響力は、反事実的な推論を用いて評価される。各タイムステップにおいて、エージェントは自分が取りうる代替行動をシミュレートし、他のエージェントの行動に対する影響を計算する。他のエージェントの行動に大きな変化をもたらした行動は、影響力があるとみなされ、報酬が与えられる。これは、行動の相互情報量が多いエージェントに報酬を与えることと同等であることを示している。実証実験の結果、影響力は、困難な社会的ジレンマ環境における協調とコミュニケーションの強化につながり、深層RLエージェントの学習曲線を劇的に向上させ、より意味のある学習されたコミュニケーションプロトコルにつながることがわかった。また、エージェントが他のエージェントのモデルを深層ニューラルネットワークを用いて学習することで、すべてのエージェントに対する影響力報酬を分散的に計算することができます。一方、MARL環境での創発的コミュニケーションに関するこれまでの主要な研究は、多様なポリシーを分散的に学習することができず、中央集権的な学習に頼らざるを得ませんでした。その結果、影響力報酬は、この分野の研究に新たな機会を与えることになる。
私たちは、カーディナリティ推定のための新しい深層学習アプローチを説明します。MSCNは、リレーショナルクエリプランを表現するために作られたマルチセット畳み込みネットワークで、クエリの特徴と真のカーディナリティを捉えるためにセットセマンティクスを採用しています。MSCNは、サンプリングベースの推定を基にしており、サンプリングされたタプルが述語を修飾していない場合や、結合-交差相関を捉える際の弱点を解決しています。実世界のデータセットを用いてMSCNを評価した結果、深層学習は、クエリ最適化の中核問題であるカーディナリティ推定の品質を大幅に向上させることがわかった。
深層学習アーキテクチャにおける多くの変換は、疎結合である。このような変換は、手作業で設計できない場合、例えば注意メカニズムのように、単純なバックプロパゲーションによっても学習することができます。しかし、学習時には、どの要素が最終的に非ゼロになるかが事前にわからないため、そのような疎な構造はしばしば密な形で表現されます。本研究では、適応的で疎な超層を紹介する。これは、疎な変換を学習するための方法で、パラメータは疎に、つまり関連する値を持つインデックスタプルとして表現される。このような離散的な構造からの勾配の欠如を克服するために、接続をランダムにサンプリングし、ランダムに配線された計算グラフ上でバックプロパゲーションを行う方法を導入します。この手法により、実際のデータで競争力のある性能を発揮するモデルを学習できることを示すために、この手法を用いて2つのアーキテクチャを構築した。1つ目は、視覚的分類のための注意メカニズムです。第二に、微分可能なソートのための手法を実装する。具体的には、ラベルのないMNISTの数字を、正しい順序だけを与えられてソートすることを学習する。
これは、新しい損失関数で学習された深層ニューラルネットワークで、学習中に棄権のオプションを提供する。これにより、DNNは混乱した例や学習が困難な例では棄権し、棄権しない例では性能を向上させることができる。我々は、このような深層棄権型分類器が以下のことを可能にすることを示す。(i)構造化されたノイズ（ノイズの多い訓練ラベルや混乱した例が基本的な特徴と相関している）に対する表現を学習し、そのような特徴に基づいて棄権を学習する。(ii)ノイズの多いサンプルを識別することで、任意のノイズや構造化されていないノイズの存在下でのロバストな学習を可能にする。本研究では、精度とカバー率の自動調整を可能にする損失関数の振る舞いに関する分析結果を提供し、複数の画像ベンチマークを用いて深層棄権分類法の有用性を実証した。 その結果、ラベルノイズがある場合の学習が大幅に改善されたことがわかった。
自然界に配備されたニューラルネットワークは、学習データの分布とは異なる分布から引き出された入力に対する予測を求められることがあります。多くの研究が、ニューラルネットワークが高い自信を持っているにもかかわらず間違っている入力を見つけたり、合成したりすることが容易であることを示している。生成モデルは、入力特徴の密度をモデル化することで、新規の分布外の入力を検出することができるため、このような誤った自信に対して頑健であると広く考えられている。本論文では、この仮定に挑戦する。フローベースモデル、VAE、PixelCNNが学習した密度は、犬、トラック、馬などの一般的な物体の画像（CIFAR-10など）と家の番号の画像（SVHNなど）を区別することができず、前者の画像でモデルを学習すると後者に高い尤度が割り当てられることを発見しました。さらに、この現象は、いくつかの一般的な画像データセットを組み合わせたときにも見られます。FashionMNISTとMNIST、CelebAとSVHN、ImageNetとCIFAR-10 / CIFAR-100 / SVHNです。この不思議な挙動を調べるために、特にフローベースの生成モデルに焦点を当てて分析を行いました。フローベースの生成モデルは、正確な周辺尤度によって学習・評価されるからです。その結果、フローを一定体積の変換に限定しても、このような挙動が続くことがわかりました。これらの変換はいくつかの理論的な分析を必要とし、尤度の違いはデータの位置と分散、モデルの曲率によって説明できることを示した。我々の結果は、分布外の入力に対する動作がよりよく理解されるまでは、学習分布に類似した入力を識別するために、深層生成モデルからの密度推定値を使用しないように注意を促すものである。
現実世界の学習タスクの多くは、複雑な、あるいは指定しにくい目的を含んでおり、指定しやすいプロキシを使用すると、パフォーマンスの低下や行動のズレにつながる可能性があります。1つの解決策は、人間がパフォーマンスを示したり判断したりして学習信号を提供することであるが、タスクが複雑すぎて人間が直接評価できない場合、このアプローチは失敗する。そこで、より簡単な問題の解答を組み合わせることで、難しい問題の学習信号を段階的に構築する学習戦略「反復増幅」を提案する。Iterated Amplificationは、外部の報酬関数を使用しないことを除いて、Expert Iteration（Anthony et al., 2017; Silver et al., 2017）と密接に関連しています。アルゴリズム環境での結果を示し、Iterated Amplificationが複雑な行動を効率的に学習できることを示します。
Imitation Learning（IL）は、望ましい自律行動を学習するための魅力的なアプローチです。しかし、任意の目標を達成するためにILを指示することは難しい。一方、プランニングベースのアルゴリズムでは、ダイナミクスモデルと報酬関数を用いて目標を達成する。しかし、望ましい行動を喚起する報酬関数を指定することは困難である。本論文では、ILとゴール指向のプランニングの利点を組み合わせるために、Imitative Modelsを提案する。Imitative Modelsは、指定された目標を達成するために、解釈可能な専門家のような軌道を計画できる、望ましい行動の確率的な予測モデルである。我々は、制約のあるゴール領域、制約のないゴールセット、エネルギーベースのゴールなど、柔軟なゴール目標のファミリーを導き出す。本手法は、これらの目標を用いて行動を誘導することができることを示している。我々の手法は、動的な自律走行タスクのシミュレーションにおいて、6つのILアプローチと計画ベースのアプローチを大幅に上回り、オンラインデータを収集することなく専門家のデモンストレーションから効率的に学習することができる。また、オンラインデータを収集することなく、専門家のデモンストレーションから効率的に学習することができる。さらに、我々の手法は、道路の反対側にあるゴールなど、指定されていないゴールに対しても頑健であることを示す。
我々は、シーケンスモデリングのための新しいアーキテクチャであるトレリスネットワークを紹介します。トレリスネットワークとは、特殊な構造を持つ時間的な畳み込みネットワークであり、深さ方向の重み付けと、深層への入力の直接注入を特徴とする。一方、切り詰められたリカレントネットワークは、重み行列に特別な疎密構造を持つトレリスネットワークと等価であることを示しています。このように、一般的な重み行列を持つトレリスネットワークは、切断型リカレントネットワークを一般化します。これらの関係を利用して，リカレントモデルと畳み込みモデルの両方から構造的・アルゴリズム的な要素を吸収した高性能なトレリスネットワークを設計する．実験では、単語レベルの言語モデリングや文字レベルの言語モデリングタスク、長期記憶の保持を評価するためのストレステストなど、さまざまなチャレンジングなベンチマークにおいて、トレリスネットワークが現在の最先端の手法を上回ることを実証した。コードは、このhttpsのURLから入手できます。
抽象的な要約は、大規模な文書と要約のペア例のデータセットを用いて、神経配列変換法を用いて研究されてきた。しかし，そのようなデータセットは稀であり，そこから学習したモデルは他のドメインには一般化しない．最近では、対になっていない例のみを用いて、配列から配列へのマッピングを学習することで、いくつかの進歩が見られた。本研究では、要約が提供されていない文書（製品やビジネスレビュー）のみが存在するという設定を考慮し、教師なしで抽象的な要約を行うためのエンド・ツー・エンドのニューラルモデルアーキテクチャを提案する。提案モデルは、入力されたレビューの表現の平均値が、レビュー特有の特徴に依存せずに、妥当な要約レビューにデコードする自動エンコーダーから構成される。我々は、提案したアーキテクチャのバリエーションを検討し、特定のコンポーネントの重要性を示すために、アブレーションの研究を行う。自動化されたメトリクスと人間の評価により、生成された要約は抽象度が高く、流暢で、関連性があり、入力レビューの平均的な感情を代表するものであることを示す。最後に、参照評価データセットを収集し、我々のモデルが強力な抽出型のベースラインよりも優れていることを示す。
マルチタスク学習では、複数のタスクが共同で解決され、それらのタスク間で帰納的バイアスを共有します。マルチタスク学習は、異なるタスクが衝突する可能性があり、トレードオフが必要になるため、本質的に多目的問題である。一般的な妥協案は、タスクごとの損失の加重線形結合を最小化する代理目的を最適化することです。しかし、この回避策は、タスクが競合しない場合にのみ有効であり、そのようなケースはほとんどありません。本論文では、マルチタスク学習を多目的最適化と捉え、パレート最適解を求めることを目的としています。この目的のために、我々は勾配ベースの多目的最適化の文献で開発されたアルゴリズムを使用する。これらのアルゴリズムは、勾配の次元やタスクの数に応じてスケールが小さくなるため、大規模な学習問題には直接適用できない。そこで我々は、多目的損失の上界を提案し、それが効率的に最適化できることを示す。さらに、この上界を最適化することで、現実的な仮定の下でパレート最適解が得られることを証明する。本手法を、数字の分類、シーン理解（セマンティックセグメンテーション、インスタンスセグメンテーション、深度推定の結合）、マルチラベル分類など、さまざまなマルチタスク深層学習問題に適用した。我々の手法は、最近のマルチタスク学習の定式化やタスクごとの学習よりも高い性能のモデルを生成する。
]
BERT（Bidirectional Encoder Representations from Transformersの略）と呼ばれる新しい言語表現モデルを紹介します。最近の言語表現モデルとは異なり、BERTは、すべての層で左右両方の文脈を共同で条件付けすることにより、ラベルのないテキストから深い双方向表現を事前に学習するように設計されています。その結果、事前学習された BERT モデルは、質問応答や言語推論などの広範なタスクに対す る最先端のモデルを作成するために、タスク固有のアーキテクチャを大幅に変更することなく、わずか 1 つの出力層を追加するだけで微調整することができます。BERT は、概念的にシンプルでありながら、経験的に強力です。BERT は、GLUE スコアを 80.5%（7.7%ポイントの絶対的な向上）、MultiNLI 精度を 86.7%（4.6%の絶対的な向上）、SQuAD v1.1 の質問応答テスト F1 を 93.2 （1.5 ポイントの絶対的な向上）、SQuAD v2.0 のテスト F1 を 83.1 （5.1 ポイントの絶対的な向上）にするなど、11 の自然言語処理タスクにおいて最先端の結果を得た。
私たちは、質問応答（QA）を強化学習タスクとしてとらえ、このアプローチをActive Question Answeringと呼んでいます。我々は、ユーザーとブラックボックスのQAシステムの間に位置するエージェントを提案し、可能な限り最良の回答を引き出すために質問を再構成することを学習します。エージェントは、最初の質問に対する自然言語による再定式化を多数行う可能性のある質問をシステムに送信し、返された証拠を集約して最適な回答を導き出します。再構成システムは、ポリシー・グラディエントを使用して回答品質を最大化するようにエンド・ツー・エンドでトレーニングされます。評価は、Jeopardy!から抽出した複雑な質問のデータセットであるSearchQAで行った。エージェントは、環境の役割を果たす最先端のベースモデルや、その他のベンチマークよりも優れた性能を示した。また、質問応答システムとの対話中にエージェントが学習した言語を分析した。その結果、成功した質問の再構成は、自然言語の言い換えとは全く異なるものであることがわかりました。エージェントは、用語の再重み付け（tf-idf）やステミングなどの古典的な情報検索技術に似た、自明ではない再定式化戦略を発見することができます。
メタ学習（learning to learn）とは、さまざまな機械学習アプローチが広範な学習タスクでどのように実行されるかを体系的に観察し、この経験（メタデータ）から学習することで、新しいタスクを他の方法よりもはるかに速く学習することができる科学です。これにより、機械学習パイプラインやニューラルアーキテクチャーの設計が劇的に高速化・改良されるだけでなく、手作業で作られたアルゴリズムを、データドリブンな方法で学習された新しいアプローチに置き換えることが可能になります。本章では、この魅力的で継続的に進化している分野における技術の現状を概観します。
強化学習の多くの課題では、設計が固定されているエージェントを操作して、ある累積報酬の概念を最大化するための方針を学習することが目標とされています。エージェントの物理的構造の設計が、目下の課題に対して最適化されることはほとんどありません。本研究では、タスクに適したエージェントのデザインを、ポリシーと一緒に学習する可能性を探る。本研究では、人気の高いOpenAI Gymフレームワークに変更を加え、環境の一部をパラメータ化し、エージェントがポリシーとともにこれらの環境パラメータを変更することを共同で学習できるようにすることを提案する。その結果、エージェントはタスクに適した身体の構造を学習できるだけでなく、ポリシーの学習も容易になることを実証した。ポリシーと構造の共同学習により、設計支援アプリケーションに有用な設計原理を発見することもできる。結果の動画はこちらのhttps URL
2人のエージェントが自然言語を用いて商品の交渉を行う場面を考える。エージェントは、ハイレベルな戦略（例えば、50ドルを提案する）と、その戦略の実行（例えば、「この自転車は新品です。 ちょうど50ドルで販売します」と生成する）の両方を決定する必要があります。最近のネゴシエーションに関する研究では、ニューラルモデルを訓練するが、エンド・ツー・エンドの性質上、戦略を制御することが難しく、また、強化学習では退化した解が得られる傾向がある。本論文では、戦略と生成を切り離す、粗い対話行為（例：propose(price=50)）に基づくモジュラーアプローチを提案する。本論文では、教師付き学習、強化学習、ドメイン固有の知識を用いて、戦略を柔軟に設定することができることを示す。また、検索に基づく生成により、文脈を認識し、多様な発話を行うことができる。最近提案されたDEALORNODEALゲームで我々のアプローチをテストし、Craigslist上の実際のアイテムに基づいたより豊富なデータセットも収集した。人間による評価の結果、我々のシステムは従来のアプローチよりも高いタスク成功率と、より人間らしい交渉行動を達成した。
本研究では、生成ニューラル機械翻訳（Generative Neural Machine Translation: GNMT）を導入しています。GNMTは、ソース文とターゲット文のセマンティクスをモデル化するために設計された潜在変数アーキテクチャです。GNMTは、言語に依存しない潜在変数を追加することで、エンコーダ・デコーダ翻訳モデルを改良し、文の意味を学習するように促します。GNMTは純粋な翻訳タスクにおいて競争力のあるBLEUスコアを達成し、原文に欠落している単語がある場合には優れている。GNMTは、パラメータを追加することなく、多言語翻訳や半教師付き学習を容易にするためにモデルを拡張します。このフレームワークは、利用可能なペアデータが限られている場合のオーバーフィッティングを大幅に削減し、学習時に見られなかった言語ペア間の翻訳にも有効である。
セマンティックロールラベリング（SRL）のための、シンプルで正確なスパンベースのモデルを紹介します。我々のモデルは、すべての可能な引数のスパンを直接考慮し、各ラベルに対してそれらをスコアリングする。デコーディング時には、より高いスコアのラベル付きスパンを貪欲に選択する。このモデルの利点は、トークンベースのBIOタグ付けアプローチでは使用することが難しいスパンレベルの特徴を設計し使用することができることです。実験結果によると，本研究のアンサンブルモデルは，CoNLL-2005データセットおよび2012データセットにおいて，それぞれ87.4 F1および87.0 F1という最先端の結果を達成した．
長短期記憶ネットワーク（LSTM）などのリカレントニューラルネットワーク（RNN）は，機械翻訳，言語モデリング，質問応答などの多くのシーケンス学習タスクにおいて，基本的な構成要素として機能している．本論文では，単語レベルの言語モデリングという特殊な問題を検討し，LSTMベースのモデルを正則化および最適化するための戦略を検討する．本論文では、再帰的正則化の一形態として、隠れた部分の重みにDropConnectを用いるweight-droped LSTMを提案する。さらに、平均化確率的勾配法の一種であるNT-ASGDを導入し、ユーザーが調整するのではなく、非単調な条件で平均化トリガーを決定する。これらの正則化戦略やその他の正則化戦略を用いて、2つのデータセットで最先端の単語レベルのパープレキシティを達成しました：Penn Treebankでは57.3、WikiText-2では65.8です。また、ニューラルキャッシュの有効性を検証した結果、Penn Treebankでは52.8、WikiText-2では52.0と、さらに低い水準のパープレキシティを達成しました。
Generative Adversarial Network (GAN) は、今日、画像を生成する最も一般的な手法の一つです。印象的な結果は視覚的な検査によって検証されてきましたが、いくつかの定量的な基準は最近になって登場しました。我々はここで、既存のものでは不十分であり、目前の課題に適したものにする必要があると主張する。本論文では、画像分類に基づいた2つの指標---GAN-trainとGAN-testを紹介する。これらはそれぞれ、GANのリコール（多様性）とプレシジョン（画像の質）に近似している。この2つの尺度に基づいて、最近の多くのGANアプローチを評価したところ、性能に明確な差があることがわかった。さらに、CIFAR10からCIFAR100を経てImageNetに至るまで、データセットの難易度が上がるにつれて、GANの品質と逆相関を示すことが、我々の指標から明らかになった。
敵対的学習法は幅広い用途で提案されていますが、敵対的モデルの学習は不安定であることが知られています。非常に高い精度を達成した識別器は、比較的情報の少ない勾配を生成するため、生成器と識別器の性能を効果的にバランスさせることが重要である。本研究では、情報ボトルネックを用いて識別器の情報の流れを制限する、シンプルで一般的な手法を提案する。観測値と識別器の内部表現の間の相互情報に制約を加えることで、識別器の精度を効果的に調整し、有用で情報量の多いグラデーションを維持することができる。本論文では，提案する変分弁別器ボトルネック（VDB）が，敵対的学習アルゴリズムの3つの異なる応用分野において，大幅な改善をもたらすことを実証する．第一の評価では、走るなどの動的な連続制御スキルの模倣学習へのVDBの適用性を研究する。その結果、VDBは、ビデオのデモンストレーションから直接スキルを学習することができ、先行する敵対的模倣学習法を大幅に上回ることができました。また、VDBは敵対的逆強化学習と組み合わせることで、新たな設定に移行して再最適化できる解析的な報酬関数を学習することができます。最後に、VDBは画像生成のためにGANをより効果的に訓練することができ、先行する多くの安定化手法を改善することができることを示します。
本論文では、RLエージェントの分散学習の最近の成功例に基づいて、分散した優先順位付けされた経験の再生からRNNベースのRLエージェントを学習することを検討します。本論文では、パラメータラグによる表現ドリフトとリカレント状態の陳腐化の影響を研究し、経験的に改良された学習戦略を導き出す。単一のネットワークアーキテクチャと固定されたハイパーパラメータのセットを使用して、結果として得られたエージェント「Recurrent Replay Distributed DQN」は、Atari-57では従来の技術の4倍、DMLab-30では最新の技術に匹敵するものとなりました。このエージェントは、Atari社の57種類のゲームのうち52種類で人間レベルの性能を超えた初めてのエージェントです。
少数ショット学習の分野では、最近、大幅な進歩が見られます。モデル不可知論的メタ学習(MAML)は、メタ学習を介した少数ショット学習のための最良のアプローチの一つです。モデル不可知論的メタ学習(MAML)は、シンプルで洗練された非常に強力な手法であるが、ニューラルネットワークのアーキテクチャに非常に敏感であり、学習中に不安定になることが多いこと、学習を安定させて高い汎化能力を得るためには膨大なハイパーパラメータの探索が必要であること、学習時と推論時の両方で非常に高い計算量が必要であることなど、様々な問題を抱えている。本論文では、システムを安定化させるだけでなく、MAMLの汎化性能、収束速度、計算オーバーヘッドを大幅に改善するMAMLの様々な修正を提案し、これをMAML++と呼ぶことにする。
放射線診断報告書の印象欄は、重要な放射線医学的所見を自然言語で要約したものであり、これらの所見を医師に伝える上で中心的な役割を果たしています。しかし、所見を要約して印象を生成するプロセスは、放射線技師にとって時間がかかり、エラーが発生しやすい。我々は、ニューラルシーケンス学習を用いて、放射線画像の印象を自動生成することを提案する。さらに、このタスクのためにカスタマイズされた神経モデルを提案する。このモデルは、研究の背景情報を符号化し、この情報を復号化プロセスのガイドとして使用することを学習する。実際の病院で行われた研究から収集した放射線報告書の大規模なデータセットにおいて、我々のモデルはROUGE指標の下で既存の非ニューラルおよびニューラルベースラインを上回る性能を示した。ブラインド実験では，認定放射線科医が，サンプルされたシステムの要約の67%が，対応する人間が書いた要約と少なくとも同等であると指摘し，臨床的な有効性が高いことを示唆した．私たちの知る限りでは、この方向性の最初の試みです。
近年、機械読解のための深層学習手法は驚くべき進歩を遂げています。機械読解では、機械読解者は与えられたグランド・トゥルース・パラグラフから答えを抽出する必要があります。最近では、最先端の機械読解モデルが、読解形式の質問応答（QA）タスクであるSQuADにおいて、人間レベルの性能を達成しています。機械読解の成功を受けて、研究者は情報検索と機械読解を組み合わせて、オープンドメインのQAに取り組むようになりました。しかし、これらのシステムは、質問に対する答えを含むパラグラフの断片を検索することが難しいため、読解形式のQAに比べて性能が低い。本研究では、与えられた質問に対する答えを含む可能性に基づいて、異なる文章にスコアを割り当てる2つのニューラルネットワークランカーを提案する。さらに、オープンドメインQAにおける意味的類似性と単語レベルの関連性マッチングの相対的な重要性を分析します。
本論文では、現在の質問応答タスクをモジュール化し、文書エンコーダーと質問エンコーダーの完全な独立性を確保することで、新しいモジュール化されたタスクを形式化する。この形式では、文書の談話を独立して表現する必要があるため、機械理解における重要な課題に対応しています。さらに、文書内の回答候補フレーズのエンコーディングを事前に計算し、オフラインでインデックスを作成することで、効率的な検索が可能になるため、スケーラビリティの面でも大きなメリットがある。本研究では、この新しいタスクに対するベースラインモデルを用いて実験を行ったが、これらのモデルは妥当な精度を達成したものの、制約のないQAモデルを大幅に下回る結果となった。このギャップを埋めるために、フレーズ・インデックス付き質問応答（PIQA, pika）に取り組むことを、品質保証の研究コミュニティに呼びかけています。リーダーボードは以下のURLにあります。
word2vecやELMoなどの教師なし表現学習アルゴリズムは、主に大量のラベルなしテキストを活用できるため、多くの教師ありNLPモデルの精度を向上させます。しかし、教師付きモデルは、主な学習段階において、タスク固有のラベル付きデータからしか学習しない。そこで我々は，ラベル付きとラベルなしのデータを組み合わせてBi-LSTM文エンコーダの表現を改善する半教師付き学習アルゴリズムであるCross-View Training (CVT)を提案する．ラベル付きの例では，標準的な教師付き学習が用いられる．ラベル付けされていない例では，CVT は入力の限定されたビュー（例：文の一部のみ）を見る補助的な予測モジュールを教え，入力全体を見る完全なモデルの予測と一致させる．補助モジュールとフルモデルは中間表現を共有しているため、これによりフルモデルが改善されます。さらに、CVTはマルチタスク学習と組み合わせると特に効果的であることを示しています。CVTを5つのシーケンスタグ付けタスク、機械翻訳、依存関係解析で評価したところ、最先端の結果が得られました。
まだ証明されていませんが、経験的には、モデルの一般化は、ヘシアンを介して記述することができる最適点の局所的な特性に関連していることを示唆しています。我々は、PAC-Bayesパラダイムの下で、モデルの一般化を解の局所的な特性と結びつける。特に、モデルの一般化能力は、ヘシアン、ヘシアンのリプシッツ定数によって特徴づけられる高次の「滑らかさ」の項、およびパラメータのスケールに関連することを証明する。この証明をもとに，モデルの汎化能力を評価する指標を提案し，それに基づいて摂動モデルを最適化するアルゴリズムを提案する．
BN（Batch Normalization）は、深層ニューラルネットワークの中間層の活性化を正規化する技術である。BNは、精度の向上と学習の高速化を実現することから、深層学習におけるお気に入りの手法として定着しています。しかし、BNが大きな成功を収めているにもかかわらず、これらの改善の背後にある正確な理由とメカニズムについては、ほとんどコンセンサスが得られていません。本論文では、BNの理解を深めるために、経験的なアプローチを採用しています。いくつかの実験を行い、BNは主に、より大きな学習率での学習を可能にし、それがより速い収束とより良い一般化の原因であることを示しました。BNのないネットワークでは、大きな勾配更新によって損失が発散したり、活性化がネットワークの深さに応じて制御できないほど大きくなったりして、可能な学習率が制限されてしまうことを示した。BNは活性化をゼロ平均と単位標準偏差になるように常に修正することでこの問題を回避し、より大きな勾配ステップを可能にし、より速い収束をもたらし、急激なローカルミニマムを回避するのに役立ちます。さらに、正規化されていない深層ネットワークの勾配と活性化がどのように問題を起こすかを示します。これらの結果を、ランダム行列理論における最近の知見と比較することで、古典的な初期化スキームとその結果に新たな光を当てます。
教師なしでハイパニムを検出する手法は、大きく分けてパターンベースと分布ベースの2つのパラダイムに分類されます。本論文では、いくつかのハイパーニームのタスクにおける両手法の性能を研究し、一般的なベンチマークデータセットにおいて、単純なパターンベースの手法が常に分布型の手法を上回ることを発見した。この結果は、パターンベースのモデルが、分布型の手法ではまだ捉えられていない重要な文脈上の制約を提供することを示している。
テキストの分類は、自然言語処理における重要かつ古典的な問題である。畳み込みニューラルネットワーク（配列などの規則的なグリッド上での畳み込み）を分類に適用した研究は数多くあります。しかし、より柔軟性の高いグラフ畳み込みニューラルネットワーク（非グリッド上での畳み込み、例えば任意のグラフ）をこの課題に検討した研究は限られています。本研究では、グラフ畳み込みネットワークをテキスト分類に用いることを提案する。我々は、単語の共起と文書の単語関係に基づいて、コーパスのための単一のテキストグラフを構築し、次に、コーパスのためのテキストグラフ畳み込みネットワーク(Text GCN)を学習する。テキストGCNは、単語と文書のワンショット表現で初期化され、文書の既知のクラスラベルで監視されながら、単語と文書の両方の埋め込みを共同で学習する。複数のベンチマークデータセットを用いた実験の結果、外部の単語埋め込みや知識を持たないバニラのテキストGCNは、最新のテキスト分類手法を凌駕することがわかった。一方、テキストGCNは、予測的な単語埋め込みや文書埋め込みも学習する。さらに、実験結果によると、学習データの割合を下げると、テキストGCNの最先端の比較手法に対する改善が顕著になり、テキストGCNが少ない学習データにも頑健であることを示唆している。
領域適応、転移学習、特徴学習などの動機から、希少な単語や未知の単語、Nグラム、シンセット、その他のテキスト特徴のための埋め込みを誘導することへの関心が高まっている。本論文では、アラカルト埋め込みを紹介する。これは、このような表現を構築するための通常のword2vecベースのアプローチに代わる、シンプルで一般的な手法であり、GloVe-like embeddingsに関する最近の理論的な結果に基づいている。本手法は、主に線形変換に依存しており、事前に学習した単語ベクトルと線形回帰を用いて効率的に学習することができる。この変換は、新しいテキストの特徴や珍しい単語に遭遇したときに、たとえ使用例が1つしかなくても、将来的にその場で適用することができる。アラカルト方式では、高品質な埋め込みを学習するために必要な文脈中の単語の例が少ないことを示す新しいデータセットを紹介し、nonceタスクといくつかの教師なし文書分類タスクで最先端の結果を得た。
専門家との対話や強化信号へのアクセスなしに、専門家の行動例から政策を学習することを考える。1つのアプローチは、逆強化学習によってエキスパートのコスト関数を復元し、強化学習によってそのコスト関数からポリシーを抽出することである。このアプローチは間接的であり、時間がかかる可能性がある。我々は、逆強化学習に続く強化学習によって得られたかのように、データから直接ポリシーを抽出する新しい一般的なフレームワークを提案する。我々のフレームワークのあるインスタンス化は、模倣学習と生成的敵対ネットワークの間のアナロジーを描くことを示し、そこからモデルフリーの模倣学習アルゴリズムを導き出した。
深層ニューラルネットワークは関数の近似に優れているが、新しい関数ごとにゼロから学習するのが一般的である。一方、ガウス過程（GP）などのベイジアン手法は、事前の知識を利用して、テスト時に新しい関数の形状を素早く推測する。しかし、GPは計算コストが高く、また、適切なプライヤーを設計することが難しい。本論文では、両者の利点を兼ね備えたニューラルモデル、Conditional Neural Processes (CNP)を提案する。CNPは、GPのような確率過程の柔軟性にヒントを得ているが、ニューラルネットワークとして構成され、勾配降下法で学習される。CNPは、わずか数個の訓練データポイントを観察するだけで正確な予測を行うが、複雑な関数や大規模なデータセットにも対応できる。本研究では、回帰、分類、画像補完など、さまざまな機械学習タスクにおいて、CNPの性能と汎用性を実証した。
モデルベースの強化学習アプローチは、データを効率的に利用できるという利点があります。しかし、実世界のダイナミクスに十分にマッチしたダイナミクスモデルを学習することが困難であるため、モデルフリー手法と同等の漸近的な性能を得ることができない。我々は、モデルベース・メタポリシ最適化（MB-MPO）を提案する。これは、学習した正確なダイナミクスモデルに強く依存しないアプローチである。MB-MPOは、学習したダイナミクスモデルのアンサンブルを用いて、1回のポリシー勾配ステップでアンサンブル内のどのモデルにも迅速に適応できるポリシーをメタ学習します。これは、アンサンブル間の一貫したダイナミクス予測を内包するようにメタポリシーを誘導する一方で、モデルの不一致に対して最適な行動をとる負担を適応ステップに移すことになります。実験の結果、MB-MPOは従来のモデルベースのアプローチに比べて、モデルの不完全性に対してより頑健であることが分かりました。最後に、我々のアプローチは、モデルフリーの手法の漸近的な性能に匹敵する一方で、必要とされる経験が大幅に少ないことを実証しました。
文章圧縮（元の意味を保ったまま文章を短縮する作業）では、冗長な文章と圧縮された文章のペアを含む大規模なコーパスでモデルが学習される傾向がある。本研究では、対となるコーパスを必要としないように、要約タスクをエミュレートし、文を拡張するためにノイズを加え、元の文を回復するためにノイズ除去オートエンコーダーを学習することで、圧縮された文の例を必要としないエンドツーエンドの学習体制を構築する。このモデルを、標準的なテキスト要約データセットを用いて人間が評価したところ、文法的な正しさと意味の保持に基づいて、教師ありのベースラインと同等の性能を示すことができました。対象となるデータがないにもかかわらず、我々の教師なしモデルは、不完全ではあるが適度に読みやすい文章要約を生成することを学習する。ROUGEスコアでは教師ありモデルに劣るものの、文法的な正しさと意味の保持については、人間の評価に基づく教師ありモデルとの競争力があります。
白人の10%が貧困ライン以下で生活しているのに対し、アフリカ系アメリカ人の28%が貧困ライン以下で生活している」という文章を理解するためには、個々の事実、例えば異なる人口集団の貧困率だけでなく、それらの間の高次の関係、例えばそれらの間の格差を特定することが重要である。この論文では、この高次の意味をモデル化するために、Textual Analogy Parsing (TAP) というタスクを提案しています。TAPの出力は、フレームスタイルの意味表現であり、構成要素であるファクト間で共有されるもの（例：貧困率）と比較されるもの（例：白人アメリカ人とアフリカ系アメリカ人、10%と28%）を明示的に指定する。このような意味表現を用いることで、定量的なテキストからチャートを自動生成するなど、談話理解に依存した新しいアプリケーションを実現することができる。本論文では、TAPのための新しいデータセット、ベースライン、およびILPを用いて問題の構造的制約を強化することに成功したモデルを紹介する。
効率的でロバストな強化学習手法の探求においては、モデルフリーとモデルベースの両方のアプローチが利点を提供する。この論文では、環境の低次元の学習済みエンコーディングを共有することで、両アプローチを明示的に橋渡しする新しい方法を提案しています。このアプローチによってもたらされるモジュール性は、より小さな潜在的な状態の空間で計画を行うことで、計算効率を高めつつ、優れた一般化をもたらすことを示す。さらに、このアプローチは、環境の十分な低次元表現を回復し、解釈可能なAI、探索、伝達学習のための新しい戦略を開きます。
強化学習コミュニティは、特定のタスクにおいて人間のパフォーマンスを上回る能力を持つアルゴリズムを設計することで、大きな進歩を遂げてきました。これらのアルゴリズムは、ほとんどの場合、一度に1つのタスクを学習し、新しいタスクごとに全く新しいエージェントインスタンスを学習する必要があります。これは、学習アルゴリズムは一般的であるが、各ソリューションは一般的ではないことを意味する。本研究では、1つのタスクではなく、複数の逐次決定タスクを一度に習得するための学習問題を研究します。マルチタスク学習における一般的な問題は、1つの学習システムの限られたリソースの中で、複数のタスクのニーズが競合するバランスを見つけなければならないことである。多くの学習アルゴリズムは、解決すべきタスクのセットの中の特定のタスクに気を取られてしまうことがある。そのようなタスクは、例えば、タスク内報酬の密度や大きさのために、学習プロセスにとってより重要に見える。これにより、アルゴリズムは、一般性を犠牲にして、それらの顕著なタスクに集中することになります。そこで、エージェントの更新に対する各タスクの貢献度を自動的に調整し、すべてのタスクが学習ダイナミクスに同様の影響を与えるようにすることを提案しました。その結果、57種類の多様なAtari社のゲームの中から、すべてのゲームをプレイすることを学習するという、最先端のパフォーマンスが得られました。驚くべきことに、我々の手法は、単一の重みセットを用いて単一の学習ポリシーを学習し、人間のパフォーマンスの中央値を超えました。我々の知る限り、このマルチタスク領域で単一のエージェントが人間レベルの性能を超えたのは初めてのことである。また、この手法は、3D強化学習プラットフォーム「DeepMind Lab」の30のタスクセットにおいても、最先端の性能を示しました。
係り受け木は、関係性抽出モデルが単語間の長距離関係を捉えるのに役立ちます。しかし、既存の依存関係に基づくモデルでは、依存関係ツリーを積極的に刈り込むことで重要な情報（否定など）を無視しているか、異なるツリー構造に対して並列化することが困難であるため、計算効率が悪い。本研究では、関係性抽出に適したグラフ畳み込みネットワークの拡張を提案する。これは、任意の依存関係構造上の情報を並列に効率よくプールする。さらに、関連性のある情報を取り込みつつ、無関係なコンテンツを最大限に除去するために、関係が成立する可能性のある2つのエンティティ間の最短パスのすぐ近くにある単語を残すという、新しい刈り込み戦略を入力木に適用する。このモデルは、大規模なTACREDデータセットにおいて、既存のシーケンスモデルや依存関係ベースのニューラルモデルを上回る最先端の性能を達成した。また、詳細な分析により、このモデルがシーケンスモデルと相補的な強みを持ち、それらを組み合わせることで最先端の技術がさらに向上することを示している。
深層学習は、話者認識におけるi-vectorに代わる有効な手段として、徐々に人気を集めています。最近では、畳み込みニューラルネットワーク（CNN）に生の音声サンプルを直接入力することで、有望な結果が得られています。後者のCNNは、標準的な人手による特徴を用いるのではなく、波形から低レベルの音声表現を学習するため、ピッチやフォルマントなどの重要な狭帯域の話者特性をよりよく捉えることができる可能性がある。この目標を達成するためには、ニューラルネットワークの適切な設計が重要である。この論文では、SincNetと呼ばれる新しいCNNアーキテクチャを提案している。これは、第1畳み込み層がより意味のあるフィルタを発見するよう促すものである。SincNetは、バンドパスフィルタを実装したパラメトリックなsinc関数に基づいています。標準的なCNNでは、各フィルターのすべての要素を学習しますが、提案手法では、低域と高域のカットオフ周波数のみをデータから直接学習します。これにより、目的のアプリケーションに合わせてカスタマイズされたフィルターバンクを、非常にコンパクトかつ効率的に導き出すことができる。話者識別と話者検証の両方のタスクで行われた実験では、提案されたアーキテクチャは、生の波形に対して標準的なCNNよりも速く収束し、優れた性能を発揮することが示されました。
モデルフリーの深層強化学習アルゴリズムは、幅広いロボットスキルの学習が可能であることが示されていますが、通常、良好な性能を得るためには非常に多くのサンプル数が必要です。モデルベースのアルゴリズムは、原理的にははるかに効率的な学習が可能ですが、ディープニューラルネットワークのような表現力のある大容量モデルに拡張することは困難であることがわかっています。本研究では、中規模のニューラルネットワークモデルをモデル予測制御（MPC）と組み合わせることで、モデルベースの強化学習アルゴリズムにおいて優れたサンプルの複雑さを実現し、様々な複雑な運動課題を達成するための安定したもっともらしい歩容を生み出すことができることを実証しました。また、モデルフリー学習器の初期化にディープニューラルネットワークのダイナミクスモデルを用いることで、モデルベース手法のサンプル効率とモデルフリー手法の高いタスク特異性を両立させることを提案する。本研究では、MuJoCoロコモーションタスクにおいて、ランダムなアクションデータで学習した純粋なモデルベースアプローチが、優れたサンプル効率で任意の軌道をたどることができることを実証した。また、本ハイブリッドアルゴリズムは、高速ベンチマークタスクにおいてモデルフリー学習を加速することができ、スイマー、チーター、ホッパー、アリの各エージェントで3～5倍のサンプル効率を達成した。動画はこちらのhttpsのURLからご覧いただけます。
本論文では、KeypointNetを紹介します。これは、カテゴリ固有の3Dキーポイントとその検出器の最適なセットを学習するエンドツーエンドの幾何学的推論フレームワークです。KeypointNetは、1枚の画像から、下流のタスクに最適化された3Dキーポイントを抽出します。我々は、物体の2つのビュー間の相対的なポーズを回復するためのキーポイントの最適なセットを求める微分可能な目的を提案することにより、このフレームワークを3Dポーズ推定で実証する。我々のモデルは、視野角やオブジェクトカテゴリのインスタンスに関わらず、幾何学的および意味論的に一貫したキーポイントを発見する。重要なのは、我々のエンド・ツー・エンドのフレームワークが、グランドトゥルースのキーポイントアノテーションを使用せずに、同じニューラルネットワークアーキテクチャを使用した完全な教師ありのベースラインよりも、ポーズ推定のタスクにおいて優れていることです。発見された3Dキーポイントは、ShapeNetのcar, chair, planeカテゴリ上で、このhttpのURLで可視化されています。
ウェブは、テキスト、構造、および空間的な特性を持つ、豊かでオープンなドメイン環境を提供します。自然言語によるコマンド（例：「2つ目の記事をクリックしてください」）が与えられた場合、ウェブページ上の適切な要素（例：ハイパーリンクやテキストボックス）を選択するという、この環境に言語を基づかせるための新しいタスクを提案しています。我々は、機能的な参照（例：「このサイトを作った人を探す」）、関係的な推論（例：「article by john」）、視覚的な推論（例：「top-most article」）などの様々な現象を捉えた50,000以上のコマンドのデータセットを収集した。また、データセットに存在するさまざまな現象を捉える3つのベースラインモデルを実装し、分析しました。
物体検出は、コンピュータビジョンにおける最も基本的で困難な問題の一つであり、自然な画像の中の多数の事前定義されたカテゴリーから物体インスタンスを探し出すことを目的としています。深層学習技術は、データから直接特徴表現を学習するための強力な戦略として登場し、一般的な物体検出の分野で顕著なブレークスルーをもたらしています。このような急速な進化の時期を踏まえ、本稿の目的は、深層学習技術によってもたらされたこの分野の最近の成果を包括的に調査することである。このサーベイには，検出フレームワーク，物体特徴表現，物体提案生成，文脈モデリング，学習戦略，評価指標など，汎用的な物体検出の様々な側面をカバーする300件以上の研究成果が含まれている。最後に、今後の研究の方向性を示して、本調査を締めくくります。
テキスト処理のための変分オートエンコーダ（VAE）の特徴は，LSTMのような強力なエンコーダ・デコーダモデルと，多変量ガウシアンのような単純な潜在分布との組み合わせにあります．これらのモデルは、難しい最適化問題を引き起こします。特に悪い局所最適があり、変分事後が常に事前と等しく、モデルが潜在変数を全く使用しないというもので、目的のKLダイバージェンス項によって奨励される一種の「崩壊」です。本研究では、潜在分布の別の選択、すなわちvon Mises-Fisher (vMF)分布を実験しました。これは質量を単位超球の表面に置くものです。この事前・事後の選択により、KLダイバージェンス項はvMF分布の分散にのみ依存するようになり、固定のハイパーパラメータとして扱うことができるようになった。これにより、KL崩壊が回避されるだけでなく、リカレント言語モデリングやBag-of-Wordsドキュメントモデリングなどの様々なモデリング条件において、ガウス分布よりも一貫して優れた尤度が得られることを示した。また、vMF表現の特性を分析したところ、vMFはガウシアン表現に比べて、より豊かで微妙な構造を潜在的な表現の中で学習することがわかった。
科学論文の実体、関係、共参照クラスタを識別・分類するマルチタスクのセットアップを紹介する。また、3つのタスクのアノテーションを含むデータセットSciERCを作成し、科学情報抽出器（SciIE）と呼ばれる統合フレームワークを開発した。マルチタスクの設定により、タスク間のカスケードエラーを減らし、共参照リンクを介して文間の関係を活用する。実験によると、我々のマルチタスクモデルは、ドメイン固有の特徴を使用せずに、科学情報抽出における従来のモデルよりも優れている。さらに、このフレームワークが科学知識グラフの構築をサポートしていることを示す。
本論文では、複雑な複数人の映像における人体のキーポイントを推定・追跡するという問題に取り組んでいます。本論文は、複雑な複数人の映像における人体のキーポイントの推定と追跡という問題に取り組み、人物検出と映像理解における最新の進歩を基にした、極めて軽量かつ効果的なアプローチを提案する。この手法は、フレームまたは短いクリップにおけるキーポイントの推定と、ビデオ全体にリンクしたキーポイント予測を生成するための軽量トラッキングの2段階で動作します。フレームレベルの姿勢推定には、Mask R-CNNと、このモデルの3D拡張を独自に提案して実験を行いました。新たにリリースされた複数人のビデオポーズ推定ベンチマークであるPoseTrackにおいて、我々のモデルの様々な設計上の選択を検証するために、広範なアブレーション実験を行った。我々のアプローチは、MOTA（Multi-Object Tracking Accuracy）指標を用いて、検証セットで55.2％、テストセットで51.8％の精度を達成し、ICCV 2017 PoseTrack keypoint tracking challengeにおいて、最先端の性能を達成した。
本論文では、オブジェクト間の関係についての複雑な質問に答えたり、解決策の小さな要素が相互に制約しあうパズルを解くような、相互に依存する関係推論のステップの連鎖を必要とするタスクを解決するための学習に取り組んでいます。本論文では、オブジェクトのグラフ表現を操作する汎用モジュールである、リカレント関係ネットワークを紹介する。Santoroら[2017]のリレーショナル・ネットワークの一般化として、多段階のリレーショナル推論を行う能力で、あらゆるニューラル・ネットワーク・モデルを補強することができます。リカレント関係ネットワークを用いて、bAbIテキスト質問応答データセットで最先端の結果を達成し、一貫して20/20のタスクを解決しました。bAbIは関係推論の観点からは特に難しいものではないので、関係推論のための新しい診断データセットであるPretty-CLEVRを紹介する。Pretty-CLEVRの設定では、質問を変えて、答えを得るために必要な関係推論のステップ数をコントロールすることができる。Pretty-CLEVRを用いて、多層パーセプトロン、リレーショナルネットワーク、リカレントリレーショナルネットワークの限界を探ります。最後に、再帰リレーショナルネットワークが、教師付きのトレーニングデータから数独パズルを解くことを学習する方法を示す。これは64ステップ以上の関係推論を必要とする難しいタスクである。その結果、最も難易度の高い数独パズルの96.6%を解くことができ、同種の手法の中で最先端の結果を得ることができました。
マルチモーダル学習における注意ネットワークは、与えられた視覚情報を選択的に利用する効率的な方法です。しかし、マルチモーダルな入力チャネルのすべてのペアに対する注意分布を学習するための計算コストは、非常に高価です。この問題を解決するために、co-attentionは、マルチモーダル入力間の相互作用を無視して、各モダリティに対して2つの別々の注意分布を構築する。本論文では、視覚と言語の情報をシームレスに利用するために、バイリニアな注意分布を見つけるバイリニア・アテンション・ネットワーク（BAN）を提案する。BANでは、2つの入力チャネルグループ間の双線形相互作用を考慮し、低ランク双線形プーリングによって各チャネルのペアの共同表現を抽出する。さらに、BANの8つのアテンションマップを効率的に利用するために、マルチモーダル残差ネットワークの変形を提案しています。我々のモデルをVisual Question Answering (VQA 2.0)およびFlickr30k Entitiesデータセットで定量的および定性的に評価し、BANが従来の手法を大幅に上回り、両データセットで新たな技術を達成したことを示す。
構文依存性アノテーションが文の表面や機能的な構造に焦点を当てているのに対し、意味依存性アノテーションは、グラフ構造の表現を用いて、文の意味とより密接に関連する単語間の関係を捉えることを目的としています。我々は、Dozat and Manning (2017)のLSTMベースの構文解析器を拡張し、これらのグラフ構造上で訓練し、生成する。結果として得られたシステムは、単独で最先端の性能を達成し、以前の大幅に複雑な最先端のシステムにラベル付きF1で0.6%勝った。さらに、言語的に豊かな入力表現を追加すると、マージンがさらに高くなり、ラベル付きF1で1.9%上回ることができました。
Visual Question answeringは、Computer VisionとNatural Language Processingのコンセプトを組み合わせた、挑戦的な問題です。既存のアプローチのほとんどは、画像と質問の特徴を計算し、様々な技術を用いてそれらを統合するという、2つのストリーム戦略を使用しています。それにもかかわらず、意味的・空間的な関係を捉えることができる、より高レベルの画像表現に依存しているものはほとんどありません。本論文では、視覚的質問応答のための新しいグラフベースのアプローチを提案する。我々の手法は、入力画像の質問固有のグラフ表現を学習するグラフ学習モジュールと、質問固有のインタラクションをキャプチャする画像表現を学習することを目的とした最近の概念であるグラフコンボリューションを組み合わせたものである。提案されたグラフ学習モジュールで強化されたシンプルなベースライン・アーキテクチャを用いて、VQA v2データセットで我々のアプローチをテストした。66.18%の精度という有望な結果を得て、提案手法の解釈可能性を実証した。コードはこのhttpのURLにあります。
LUCSSは、シーンスケッチを意味的に理解することで、対話的に共同作業を行う言語ベースのシステムです。LUCSSは、シーンスケッチや漫画風カラー画像の大規模なリポジトリを用いて学習したディープニューラルネットワークをベースに構築されています。LUCSSは、3つのモジュールから構成されています。まず、シーンスケッチが与えられると、セグメンテーションモジュールは、入力スケッチを個々のオブジェクトインスタンスに自動的に分割します。次に、キャプションモジュールは、インスタンスレベルのセグメンテーションの結果に基づいて、空間的な関係を持つテキスト記述を生成します。最後に、インタラクティブな色付けモジュールにより、ユーザーはキャプションを編集し、変更されたキャプションに基づいて色付きの画像を作成することができます。我々の実験は、我々のアプローチの有効性と、その構成要素が他の選択肢よりも望ましいことを示している。
製品レビューを対象としたきめ細かな感情分析では，ユーザが意見を表明した製品の側面や特徴を抽出することが重要な課題となる．本論文では、深層学習を用いた教師付きアスペクト抽出に焦点を当てている。他の高度な教師付き深層学習モデルとは異なり、本論文では、アスペクト抽出のために事前に学習された2種類のエンベディング（汎用エンベディングとドメイン固有エンベディング）を採用した、斬新でシンプルなCNNモデルを提案する。このモデルは、追加の監視を使用せずに、最先端の洗練された既存の手法を上回る驚くべき結果を達成しています。我々の知る限り、アスペクト抽出のためのこのようなダブルエンベディングベースのCNNモデルを報告し、非常に良い結果を得たのはこの論文が初めてです。
抽象的な要約のためのニューラルネットワークベースの手法は、他の手法よりも流暢な出力を得ることができるが、コンテンツの選択が苦手な場合がある。本研究では、この問題に対処するための簡単な手法を提案する。データ効率の良いコンテンツセレクタを使用して、要約の一部となるべきソースドキュメント内のフレーズを過剰に決定する。このセレクタをボトムアップのアテンションステップとして使用し、モデルを可能性の高いフレーズに制約する。このアプローチにより、テキストを圧縮する能力が向上するとともに、流暢な要約を生成できることを示している。この2段階のプロセスは、他のエンド・ツー・エンドのコンテンツ選択モデルよりもシンプルかつ高性能であり、CNN-DMとNYTコーパスの両方においてROUGEを大幅に改善することができた。さらに、コンテンツセレクタは1,000文程度でも学習できるため、学習したサマライザーを新しいドメインに簡単に移植することができます。
機械翻訳システムは、一部の言語では人間に近い性能を達成しているが、その効果は大量の並列文の利用に強く依存しており、大多数の言語ペアへの適用を妨げている。本研究では、各言語の大規模な単言語コーパスしか利用できない場合に、どのように翻訳を学習するかを検討する。本研究では、ニューラルモデルとフレーズベースモデルの2種類のモデルを提案する。どちらのモデルも、パラメータの初期化、言語モデルのノイズ除去効果、反復的な逆翻訳による並列データの自動生成を利用している。これらのモデルは、よりシンプルでハイパーパラメータの数が少ないにもかかわらず、文献に記載されている手法よりも格段に優れています。広く使用されているWMT'14英仏およびWMT'16独英のベンチマークにおいて、我々のモデルは、1つの並列文を使用することなく、それぞれ28.1および25.2BLEUポイントを獲得し、11BLEUポイント以上も既存の手法を上回った。英語-ウルドゥー語や英語-ルーマニア語などの低リソース言語において、我々の手法は、利用可能なビットレットが少ないことを利用して、半教師付きや教師付きのアプローチよりもさらに優れた結果を得ることができました。NMTとPBSMTのコードは公開されています。
読解力に関する研究の多くは、個々の文書、あるいは単一のパラグラフに基づいて質問に答えることに焦点を当てています。本研究では、文書内や複数の文書にまたがる情報を統合して推論するニューラルモデルを紹介します。これは、グラフ上の推論問題である。エンティティの言及はこのグラフのノードであり、エッジは異なる言及間の関係（例えば、文書内および文書間の共参照）を表す。グラフ畳み込みネットワーク(GCN)は、これらのグラフに適用され、多段階の推論を行うように訓練される。我々のEntity-GCN法はスケーラブルでコンパクトであり、マルチドキュメントの質問応答データセットであるWikiHopで最先端の結果を達成している（Welbl et al.2018）。
生成モデル、特に生成的逆説ネットワーク（GAN）は、最近大きな注目を集めている。数多くのGANの変種が提案され、多くのアプリケーションで活用されている。理論的には大きな進歩を遂げていますが、GANを評価・比較することは依然として困難な課題です。いくつかの尺度が導入されていますが、どの尺度がモデルの長所と限界を最もよく捉え、公正なモデル比較に使用されるべきかについては、まだコンセンサスが得られていません。コンピュータビジョンや機械学習の他の分野と同様に、この分野の進歩を導くためには、1つまたはいくつかの優れた尺度に落ち着くことが重要である。本論文では、特にGAN由来のモデルに重点を置いて、生成モデルを評価するための24以上の定量的な尺度と5つの定性的な尺度をレビューし、批判的に議論する。また、7つの望ましい基準を提示し、ある基準または基準のファミリーがそれらと互換性があるかどうかを評価します。
モデルベースの強化学習（RL）は、制御タスクを学習するためのデータ効率の良いアプローチであることが証明されているが、画像のような複雑な観測を行うドメインでは活用することが難しい。本論文では、基礎となる力学系が複雑なダイナミクスや画像観測を持つ場合でも、モデルベースのポリシーを反復的に改善するのに適した表現を学習する手法を紹介する。この表現は、現在のポリシーからデータが与えられたときに、単純なダイナミクスやコストモデルを推論するのに最適な表現である。これにより、線形二次レギュレータ（LQR）に基づくモデルベースのRL手法を、画像観測を伴うシステムに用いることができる。本研究では、実世界のロボットアームを画像から直接操作するなど、さまざまなロボティクスのタスクで本手法を評価しました。その結果、本手法は、他のモデルベースのRL手法と比較して、最終的な性能を大幅に向上させるとともに、モデルフリーのRL手法と比較して、大幅に効率を向上させることができました。
機械による読解（MRC）のためのデータセットを作成する際の課題は、表面的な手がかりを使って回答する以上に、高度な言語理解を必要とする質問を集めることである。本研究では、3つの質問スタイル（答えの抽出、説明、多肢選択）を持つ最近の12のMRCデータセットにおいて、何が質問を容易にするかを調査する。本研究では、簡単なヒューリスティクスを用いて各データセットを易しいものと難しいものに分け、それぞれのサブセットについて2つのベースラインモデルの性能を調べることを提案する。次に、各サブセットから抽出した問題に、有効性と必要な推論スキルの両方を手動でアノテーションし、どのスキルが易しい問題と難しい問題の違いを説明するのかを調査する。その結果，(1)難問サブセットのベースライン性能は，データセット全体のベースライン性能と比較して著しく低下する，(2)難問は易問と比較して，知識の推論や複数文の推論を必要とする，(3)多肢選択問題は，答えの抽出や記述問題と比較して，より幅広い推論スキルを必要とする傾向がある，ことがわかった．これらの結果は、近年のMRCの進歩を過大評価している可能性を示唆している。
抽象度の高いテキスト要約は、長いテキスト文書を、元の文書から最も重要な事実を含んだ人間が読みやすい形に短縮することを目的としている。しかし、既存の手法では、原文にはない新しいフレーズで測定される実際の抽象度は低いままである。本研究では、生成された要約の抽象度を向上させるための2つの手法を提案する。まず，デコーダを，原文の関連部分を検索する文脈ネットワークと，言語生成に関する事前知識を組み込んだ事前学習済みの言語モデルに分解する．次に，新奇なフレーズの生成を促すために，ポリシー学習によって直接最適化される新奇性指標を提案する．我々のモデルは、ROUGEスコアと人間の評価によって決定されるように、最先端のモデルと同等の結果を達成する一方で、ソース文書とのn-gramのオーバーラップによって測定されるように、大幅に高い抽象度を達成している。
畳み込みニューラルネットワーク（CNN）は、様々なコンピュータビジョンアプリケーションで優れた性能を発揮しますが、その一方で高い計算コストがかかります。アルゴリズムと専用ハードウェアの両方で効率を上げる努力をしているが、電力予算が厳しいため、CNNを組み込みシステムに導入することは依然として困難である。そこで本稿では，電子計算機の前に光学計算機のレイヤーを組み込むことで，電子計算機の計算コストや処理時間を最小限に抑えながら，画像分類タスクの性能を向上させるという補完的な戦略を検討する．本研究では，最適化された回折光学素子を用いた光畳み込み層の設計を提案し，学習型光相関器と光電子2層CNNの2つのシミュレーションで検証した．シミュレーションと光学プロトタイプを用いて、光学システムの分類精度が電子的な実装に匹敵すること、また計算コストを大幅に削減できることを実証しました。
現代のニューラルネットワークは非常に強力な予測モデルですが、予測が間違っているかもしれないことを認識できないことがしばしばあります。これと密接に関連しているのが、分布外検出のタスクであり、ネットワークは、ある入力が、安全に実行することが期待されるセットの外にあるかどうかを判断しなければならない。これらの問題に共同で取り組むために、我々は、ニューラルネットワークの信頼性推定値を学習する方法を提案する。本手法は、分布外検出の課題において、ラベルの追加や分布外の例へのアクセスを必要とせず、ネットワークの出力分布に基づいて信頼度を構築する最近提案された手法を上回ることを実証する。さらに、分布外検出器の校正の問題にも取り組み、分類ミスのある分布内例を分布外例の代理として使用できることを示す。
多くのNLPアプリケーションは、グラフから配列への学習問題として構成されます。この問題に対するニューラルアーキテクチャを提案した以前の研究では、文法ベースのアプローチと比較して有望な結果が得られたが、最高の性能を得るためには線形化ヒューリスティックや標準的なリカレントネットワークに依存している。本研究では、グラフに含まれる完全な構造情報を符号化する新しいモデルを提案する。このモデルは、最近提案されたゲーテッド・グラフ・ニューラル・ネットワークに、ノードとエッジがそれぞれの隠れた表現を持つことができるような入力変換を組み合わせたもので、従来の研究で問題となっていたパラメータ爆発の問題に取り組んでいる。実験結果によると、我々のモデルは、AMRグラフからの生成や、構文ベースのニューラル機械翻訳において、強力なベースラインを上回る性能を示しています。
テキスト生成は、自然言語処理タスクにおける基本的な構成要素です。既存の逐次モデルは、テキストの配列に対して直接自己回帰を行うため、複雑な構造を持つ長文を生成することが困難である。本論文では、文の生成をツリー生成タスクとして扱うシンプルなアプローチを提唱する。本研究では、構文構造を構成する構文木で明示的にモデル化し、トップダウンで広義の木生成を行うことで、依存関係を適切に修正し、暗黙のグローバルプランニングを行う。これは、遷移ベースの深さ優先生成プロセスとは対照的である。このプロセスでは、構文解析時に不完全なテキストを処理することが困難であり、また、将来のコンテキストを計画に組み込むこともできない。2つの生成タスクと1つの解析タスクでの予備的な結果は、この戦略が有効であることを示しています。
最近の多くの論文では、読解問題が取り上げられており、例題は（質問、文章、答え）のタプルで構成されています。おそらく、モデルは、質問と通路の両方からの情報を組み合わせて、対応する答えを予測しなければならないでしょう。しかし、このテーマへの関心は高く、何百もの論文がリーダーボードの覇権を争っているにもかかわらず、多くの人気ベンチマークの難易度に関する基本的な疑問は解決されていない。本論文では、bAbI、SQuAD、CBT、CNN、Who-did-Whatの各データセットについて、妥当なベースラインを確立し、質問とパスのみのモデルがしばしば驚くほどの性能を発揮することを発見しました。20$のbAbIタスクのうち14$のタスクで、passage-onlyモデルは50%$以上の精度を達成し、フルモデルに匹敵することもあります。興味深いことに、CBTは20$センテンスのストーリーを提供していますが、同等の精度の予測に必要なのは最後のセンテンスだけです。それに比べて、SQuADとCNNはより良く構成されているように見えます。
この論文では、強化学習（RL）における探索のためのシンプルなアプローチを紹介します。これにより、表形式の場合には理論的に正当なアルゴリズムを開発することができますが、関数の近似が必要な設定にも拡張することができます。このアプローチは、後継状態の類似性によって状態の一般化を定義する表現として導入された後継表現(SR)に基づいている。ここでは、学習中のSRのノルムが、探索の動機付けとなる報酬ボーナスとして使用できることを示す。このSRのノルムの過渡的な振る舞いを理解するために、我々は substochastic successor representation (SSR)を導入し、各状態（または特徴）が観測された回数を暗黙的にカウントしていることを示す。この結果を利用して、理論的にサンプル効率の良いアプローチと同等の性能を持つアルゴリズムを紹介します。最後に、これらのアイデアを深層RLアルゴリズムに拡張し、Atari 2600のゲームにおいて、サンプル効率の低い領域で最先端の性能を達成することを示します。
Aspect Term Extraction (ATE)は、アスペクトベースのセンチメント分析の重要なサブタスクであり、オンラインユーザーレビューから明示的なアスペクト表現を抽出することを目的としています。ATEに取り組むための新しいフレームワークを紹介します。このフレームワークは、意見の要約とアスペクト検出の履歴という2つの有用な手がかりを利用することができます。意見要約は入力文全体から抽出され、アスペクト予測のために現在の各トークンを条件としています。もう1つの手がかりは、アスペクト検出履歴の情報であり、過去のアスペクト予測から抽出され、座標構造やタグスキーマの制約を利用してアスペクト予測を向上させます。4つのベンチマークデータセットを用いた実験結果から、我々のフレームワークが最先端の手法を凌駕できることが明らかになった。
本論文では、"do as I do "モーショントランスファーのためのシンプルな手法を紹介します。ある人物がダンスをしているソースビデオが与えられた場合、ターゲットとなる人物が標準的な動きをしているところを数分見ただけで、そのパフォーマンスを新規の（アマチュアの）ターゲットに移すことができます。私たちはこの問題を、ポーズを中間表現として用いたビデオからビデオへの翻訳として取り組みます。モーションを転送するために、ソースの被写体からポーズを抽出し、学習したポーズと外観のマッピングを適用してターゲットの被写体を生成します。時間的にコヒーレントなビデオ結果を得るために、連続する2つのフレームを予測し、リアルな顔の合成のために別のパイプラインを導入します。この手法は非常にシンプルですが、驚くほど説得力のある結果が得られました（ビデオを参照）。このことから、我々のシステムで合成されたビデオを実際のデータと区別することができる、信頼性の高い合成コンテンツ検出のためのフォレンジックツールも提供したいと考えています。さらに、トレーニングやモーション・トランスファーに合法的に使用できる、世界初のオープンソースのビデオ・データセットを公開します。
本論文では、家と体験を共有するオンラインマーケットプレイスであるAirbnbで展開されている価格戦略モデルについて説明しています。価格最適化の目的は、Airbnbで家をシェアするホストが、自分のリスティングに最適な価格を設定できるようにすることです。大量の同一商品に価格戦略を適用する従来の価格問題とは対照的に、Airbnbでは、プラットフォーム上の各リスティングがゲストにユニークな価値と体験を提供しているため、「同一の」商品は存在しません。Airbnbのリスティングはユニークな性質を持っているため、従来の収益最大化の価格戦略を適用するために必要な正確な需要曲線を推定することは非常に困難です。当社の価格設定システムは、3つの要素で構成されています。まず、バイナリ分類モデルにより、各リスティング・ナイトの予約確率を予測します。次に、回帰モデルにより、各宿泊施設の最適な価格を予測します。最後に、2つ目のモデルからの出力の上に、さらにパーソナライズロジックを適用して、最終的な価格提案を生成します。本稿では、当社の価格設定システムの第2段階における回帰モデルの説明に重点を置いています。また、オフラインで評価するための新しい指標についても説明します。提案された価格設定戦略は、AirbnbのPrice TipsとSmart Pricingツールを動かすために実運用で展開されました。オンラインでのA/Bテストの結果、提案した戦略モデルの有効性が実証されました。
視覚データの不規則性をリアルタイムで検出することは、監視システムや患者監視システムなど、多くの前向きなアプリケーションにおいて非常に貴重で有用です。近年の深層学習手法の急増に伴い、研究者たちはさまざまな用途に応じて幅広い手法を試してきました。しかし、動画の不規則性や異常を検出する場合、不規則性が十分に定義されていないことが多く、また学習時に使用できる不規則なサンプルが十分にないため、エンド・ツー・エンドのモデルを学習することは、まだ未解決の課題である。本論文では、生成的敵対ネットワーク（GAN）が、教師なしあるいは教師ありの設定で深層モデルを学習するのに成功したことにヒントを得て、動画（および画像）における不規則性の検出と詳細な位置特定のためのエンド・ツー・エンドの深層ネットワークを提案する。我々の提案するアーキテクチャは、2つのネットワークで構成されており、これらのネットワークは、不規則性を見つけるために協力しながら、互いに競合して学習されます。1つのネットワークはピクセルレベルの不規則性インペインティングとして働き、もう1つのネットワークはパッチレベルの検出器として働きます。一方のネットワークはピクセルレベルの不規則性を持つInpainterとして、もう一方のネットワークはパッチレベルのDetectorとして動作します。敵対的な自己教師付きトレーニングでは、IがDを騙してその不規則性のある出力を通常の出力として受け入れさせようとします。3つの異なるデータセットを用いた結果、我々の手法は最先端の技術を凌駕し、不規則性を細分化できることがわかった。
現在の機械翻訳システムは、エンコーダとデコーダを組み合わせたアーキテクチャを採用しており、まず入力シーケンスをエンコードし、次に入力エンコードに基づいて出力シーケンスを生成する。両者は、デコーダの状態に基づいてソーストークンの固定されたエンコーディングを再結合するアテンションメカニズムと連動している。我々は、両方のシーケンスを単一の2次元畳み込みニューラルネットワークに依存する代替アプローチを提案する。このネットワークの各層は、これまでに生成された出力シーケンスに基づいてソーストークンを再コード化する。そのため、注意に似た特性がネットワーク全体に浸透しています。このモデルは、概念的にシンプルでパラメータ数も少ないにもかかわらず、最先端のエンコーダー・デコーダーシステムを上回る優れた結果をもたらしています。
深層学習は、画像認識、音声認識、機械翻訳などの様々なタスクにおいて、ここ数年で目覚ましい進歩を遂げています。この進歩に欠かせないのが、新しいニューラル・アーキテクチャーです。現在採用されているアーキテクチャは、そのほとんどが人間の専門家によって手動で開発されており、時間がかかり、エラーが発生しやすいプロセスです。そのため、自動化されたニューラル・アーキテクチャの検索方法への関心が高まっています。本研究では、この分野における既存の研究を概観し、探索空間、探索戦略、性能評価戦略の3つの側面から分類する。
sequence to sequenceモデルにおける注意メカニズムは、文の埋め込み、テキスト生成、機械翻訳、機械読解などの様々な自然言語処理（NLP）タスクにおいて、優れた能力と素晴らしい性能を示している。残念ながら、既存の注目メカニズムは、高レベルまたは低レベルの特徴を学習するだけである。本論文では、階層的なメカニズムの欠如が注意メカニズムの性能向上のボトルネックになっていると考え、多階層注意の異なる層の加重和に基づいた新しい階層的注意メカニズム（Ham）を提案する。Hamは、漢詩生成タスクにおいて、最先端のBLEUスコア0.26を達成し、BIDAFやMatch-LSTMなどの既存の機械読解モデルと比較して、平均で6.5%近くの改善を実現した。さらに、我々の実験と定理は、Hamが既存の注意メカニズムよりも高い汎化能力と表現能力を持つことを明らかにしています。
強化学習アルゴリズムは、エージェントに外在する環境報酬を注意深く工学することに依存しています。しかし、手作業でデザインされた高密度の報酬を各環境にアノテーションすることはスケーラブルではないため、エージェントに内在する報酬関数を開発する必要性があります。好奇心は、予測誤差を報酬信号として使用する内在的報酬機能の一種です。本論文では (a) Atariゲームスイートを含む54の標準的なベンチマーク環境において、純粋に好奇心に基づく学習、すなわち外在的な報酬を伴わない学習について、初めて大規模な研究を行った。その結果、多くのゲーム環境において、内在的な好奇心の目的と、手作業でデザインされた外在的な報酬との間に高い整合性が見られ、驚くほど良好なパフォーマンスが得られた。(b) 予測誤差を計算するために異なる特徴空間を使用する効果を調査し、多くの一般的なRLゲームベンチマークではランダムな特徴で十分であるが、学習された特徴の方がより一般化することを示す（例：Super Mario Bros.の新しいゲームレベル）。(c) 確率的な設定における予測ベースの報酬の限界を示しています。ゲームプレイの動画とコードはこちらのhttpsのURLにあります。
人間同士の対戦ゲームの評価から得られた知見を用いて、生成モデルを評価する新しい方法を模索しています。生成器と識別器の間で行われるトーナメントが、生成モデルを評価する効果的な方法であることを実験的に示します。トーナメントの結果を要約するために、トーナメントの勝率とスキル評価という2つの方法を紹介する。評価は、学習過程で学習する1つのモデルの進捗状況を監視したり、完全に学習された2つの異なるモデルの能力を比較したりするなど、さまざまな状況で有用である。我々は、単一のモデルが過去と未来のバージョンのモデルと対戦するトーナメントでは、トレーニングの進捗を測るのに有効であることを示した。複数のモデル（異なるシード、ハイパーパラメータ、アーキテクチャを使用）を含むトーナメントでは、異なる訓練されたGAN間の相対的な比較に役立ちます。トーナメントベースの評価法は、生成モデルを評価するためのこれまでの数多くのアプローチとは概念的に異なり、補完的な長所と短所を持っている。
様々なタスクに対応する最新の視覚認識モデルは、教師付きの事前学習に依存しています。ImageNetの分類は、これらのモデルにとって、事実上の事前学習タスクです。しかし、ImageNetは10年近く前に作られたもので、現在の基準では「小さい」ものです。それでも、桁違いに大きいデータセットでの事前学習の挙動については、ほとんど知られていません。その理由は明らかで、そのようなデータセットは収集やアノテーションが難しいからです。本論文では，何十億ものソーシャルメディア画像のハッシュタグを予測するように訓練された大規模な畳み込みネットワークを用いた転移学習のユニークな研究を紹介する．我々の実験では、大規模なハッシュタグ予測のための学習が優れた結果をもたらすことを実証した。また、画像分類や物体検出のタスクにおいても改善が見られ、ImageNet-1kのシングルクロップ、トップ1の精度は85.4%(トップ5では97.6%)とこれまでで最も高い値を示しました。また，大規模な事前学習と伝達学習の性能との関係について，新たな実証データを提供する広範な実験を行いました．
手動でデータセットにオブジェクトマスクのラベルを付けるのは非常に時間がかかります。本研究では、Polygon-RNNのアイデアに基づき、人間がループの中に入ってオブジェクトのポリゴンアノテーションを対話的に生成します。このモデルにはいくつかの重要な改良点があります。1) 新しいCNNエンコーダ・アーキテクチャを設計し、2) 強化学習を用いてモデルを効果的に学習する方法を示し、3) グラフ・ニューラル・ネットワークを用いて出力解像度を大幅に向上させることで、画像中の高解像度のオブジェクトに正確に注釈を付けることができるようになりました。Cityscapesデータセットを用いた広範な評価の結果、我々のモデル（Polygon-RNN++）は、自動モード（平均IoUの絶対値で10％、相対値で16％の改善）と対話モード（アノテーターによるクリック数が50％少ない）の両方において、オリジナルモデルを大幅に上回ることがわかった。さらに、我々のモデルを1つのデータセットで学習し、様々なドメインのデータセットですぐに使用するという、クロスドメインシナリオを分析しました。その結果、Polygon-RNN++は強力な汎化能力を発揮し、既存のピクセル単位の手法に比べて大幅な改善を実現しました。また、オンラインでの簡単な微調整により、新しいデータセットのアノテーションにかかる時間を大幅に短縮することができ、実際に使用できるインタラクティブなアノテーションツールに一歩近づきました。
リカレントニューラルネットワーク（RNN）は、新しいデータポイントごとに状態を更新することでデータを逐次処理するため、シーケンスモデリングのタスクには長い間、事実上の選択肢となっていました。しかし、RNNは本来、逐次的な計算を行うため、学習に時間がかかります。最近では，フィードフォワード型や畳み込み型のアーキテクチャが，機械翻訳などのシーケンスモデリングタスクにおいて優れた結果を示すことが明らかになっている．また，フィードフォワード型や畳み込み型のアーキテクチャは，シーケンス内のすべての入力を同時に処理するため，並列化が容易で学習時間も短縮できるという利点もある．しかし、これらの成功にもかかわらず、Transformerのような一般的なフィードフォワードシーケンスモデルは、リカレントモデルが容易に処理できる多くの単純なタスク、例えば、文字列のコピーや、文字列や数式の長さが学習時に観測されたものを超える場合の単純な論理的推論では一般化できない。Universal Transformer (UT)は、Transformerモデルを一般化したものであり、これらの問題を解決するための時間内並列自己学習型リカレントシーケンスモデルです。UTは、Transformerのようなフィードフォワードシーケンスモデルの並列性とグローバルな受容野を、RNNの再帰的帰納的バイアスと組み合わせたものである。また、位置ごとの動的な停止メカニズムを追加し、いくつかのタスクで精度が向上することを発見しました。標準的なTransformerとは対照的に、ある仮定の下で、UTはTuring-completeであることが示される。我々の実験によると、UTは、アルゴリズムや言語理解の幅広いタスクにおいて、標準的なTransformerを上回る性能を示している。例えば、難易度の高いLAMBADA言語モデリングタスクではUTが新たな状態を達成し、機械翻訳ではWMT14 En-DeデータセットにおいてUTがTransformerに対して0.9BLEUの向上を達成している。
ニューラルネットワーク（NN）は，ラベル付けされたデータの集合を高精度に近似するために，勾配降下法によって調整可能なパラメータ化された関数である．一方，ガウスプロセス（GP）は，可能な関数の分布を定義する確率モデルであり，確率的推論のルールに基づいて，データに応じて更新されます．GPは、確率的で、データ効率が良く、柔軟性があるが、計算量が多く、適用範囲が限られていた。我々は、ニューラル潜在変数モデルのクラスを導入し、これをニューラル・プロセス（NP）と呼び、両者の長所を組み合わせた。GPと同様に、NPは関数上の分布を定義し、新しい観測結果に迅速に適応することができ、その予測の不確実性を推定することができる。NPはNNと同様に、学習と評価の際に計算効率が高く、またデータに応じてプライアを適応させることができる。我々は、回帰や最適化を含む様々な学習タスクにおけるNPの性能を実証し、文献にある関連モデルと比較対照する。
マルチモーダル研究は、人工知能の新たな分野であり、この分野の主な研究課題の一つがマルチモーダル融合である。マルチモーダルデータの融合とは、複数のユニモーダルな表現を1つのコンパクトなマルチモーダルな表現に統合するプロセスである。この分野のこれまでの研究では、テンソルの表現力を利用してマルチモーダル表現を行ってきた。しかし、これらの手法では、入力をテンソルに変換することで次元が指数関数的に増加し、計算量が増大するという問題がある。本論文では、低ランクのテンソルを用いてマルチモーダルフュージョンを行うことで、効率化を図る「低ランクマルチモーダルフュージョン」を提案する。このモデルを，マルチモーダル感情分析，話者特性分析，感情認識という3つの異なるタスクで評価した．このモデルは、計算量を大幅に削減しながら、これらのタスクで競争力のある結果を得ることができました。また、テンソル表現を利用する他の手法と比較して、学習と推論の両方で非常に効率的なモデルであることを示している。
アスペクト用語の抽出は、アスペクトベースの感情分析における重要なサブタスクの1つである。これまでの研究では、依存木構造表現を用いることがこのタスクに有望であることが示されている。しかし、ほとんどの依存木構造では、依存木上の一方向の伝搬しか行われない。本論文では、まず、与えられた文から依存構造の特徴を抽出するために、新しい双方向依存木ネットワークを提案する。ここで重要なアイデアは、与えられた依存性構文木上のボトムアップとトップダウンの伝播から別々に得られた両方の表現を明示的に組み込むことである。そして、アスペクト用語抽出問題を解決するために、埋め込まれた表現とBiLSTMとCRFを統合して、木構造的な特徴と順序的な特徴の両方を学習するエンド・ツー・エンドのフレームワークを開発する。実験結果は、4つのベンチマークであるSemEvalデータセットにおいて、提案モデルが最先端のベースラインモデルを上回ることを示している。
本論文では、質問応答の文脈における幾何学的推論の問題を研究します。本論文では、潜在的な視覚表現を認める質問に答えるために設計された新しい深層ネットワークアーキテクチャであるDynamic Spatial Memory Network (DSMN)を紹介します。DSMNは、そのような表現の生成と推論を学習する。さらに、質問応答システムの幾何学的推論能力を評価するために、「FloorPlanQA」と「ShapeIntersection」という2つの合成ベンチマークを提案します。実験結果から、我々の提案するDSMNが視覚的思考タスクに有効であることを検証する。
近年、オピニオンマイニングは、テキストマイニングや分析、自然言語処理の分野で活発な研究が行われています。オピニオンマイニングとは、実体やその側面に対する人々の意見を、書き言葉やテキストで表現し、計算によって研究することです。インターネットの発展に伴い、ソーシャル・ネットワーキング・サイト、ブログ、ディスカッション・フォーラム、eコマース・ウェブサイトは非常に重要になっており、人々が実体やその側面について意見を表明し、共有するためのプラットフォームを提供しています。レビュー、コメント、ブログ、ステータスアップデート、ツイートなどの形で、意見付きのウェブコンテンツが急速に増加しているため、人々や組織が一度にすべての意見を分析して適切な意思決定を行うことは事実上不可能です。そのため、意見を評価し、正確な結果を生成するための効果的な自動化システムが必要とされています。本論文では、オピニオンマイニングについて説明し、サブトピックであるアスペクトベースのオピニオンマイニング、アスペクトベースのオピニオンマイニングにおけるタスク、アスペクトベースのオピニオンマイニングに使用される最新の手法、これらの手法の利点と欠点、アスペクトベースのオピニオンマイニングにおける最新の研究課題に焦点を当てています。また、いくつかのアスペクト抽出技術に基づいた実験結果により、どのアスペクト抽出技術が実用的なオピニオンマイニングアプリケーションにおいて効率的で正確な結果をもたらすかを知ることができます。一般用語 データマイニング、テキストマイニング、自然言語処理
アスペクト抽出は、オピニオンテキストからきめ細かいオピニオンターゲットを抽出することを目的としている。最近の研究では、意見語とアスペクトの間の文法依存関係のルールを用いた構文的なアプローチが非常に良い結果を示す。このアプローチは、教師なしでドメインに依存しないため、実際には非常に望ましいものである。しかし、ルールは慎重に選択される必要があり、エラーが多すぎないように手動で調整する必要があります。各ルールの精度を自動的に評価することは容易であるが，ルールの適用範囲が重複しているため，全体として最良の結果をもたらすルールのセットを選択することは容易ではない．本論文では，効果的なルールのセットを選択するための新しい手法を提案する．我々の知る限り，これはルールを自動的に選択する最初の作品である．実験の結果、提案手法は、与えられたルールセットのサブセットを選択することで、完全なルールセットや既存の最先端のCRFベースの教師付き手法よりも有意に良い結果を得ることができた。
大規模なナレッジグラフは、エンティティに関する膨大な量の構造化された事実を提供する一方で、短いテキスト記述は、エンティティとそのタイプを簡潔に特徴づけるのに役立つことが多い。残念ながら、多くの知識グラフのエンティティには、そのようなテキスト記述がありません。本論文では、誘導されたファクトの埋め込みと、生成された一連の単語の動的なコンテキストを共同で利用することで、エンティティの短いオープンボキャブラリーの説明を生成する、動的メモリベースのネットワークを紹介します。このシステムをいくつかの強力なベースラインと比較することで、型の説明をより正確に生成するために関連情報を識別する本アーキテクチャの能力を実証します。
アスペクト用語抽出（ATE）は、アスペクトベースのセンチメント分析を行うことを目的として、文やテキストスパンから意見のあるアスペクト用語を検出します。ATE用の教師付きデータセットの数は少なく、また、それらはいくつかのドメインしかカバーしていないという事実から、新しく創造的な方法で他のデータソースを利用する必要があります。公開されているレビューコーパスには、意見のあるアスペクト用語が多数含まれており、より広いドメインスペクトルをカバーしている。本論文では、このようなレビューコーパスを用いて、ATE用の新しいデータセットを作成する方法を提案する。この手法では、注目メカニズムを用いて、実際の意見的側面を含む可能性の高い文章を選択する。これにより、抽出されたアスペクトの品質を向上させることができる。次に、構築したデータセットを用いてモデルを学習し、遠隔監視下でATEを実行する。人間が注釈をつけたデータセットを用いて評価することで、本手法が、様々な教師なし・教師ありのベースラインよりも大幅に性能を向上させることを証明する。最後に、ATE用の新しいデータセットを作成する際には、文の選択が重要であることを証明する。具体的には、選択された文のセットを使用すると、文のセット全体を使用する場合と比較して、より高いATE性能が得られることを示している。
畳み込みニューラルネットワーク（CNN）をモバイル機器向けに設計することは、モバイルモデルが小型で高速であり、かつ正確である必要があるため、困難を伴います。モバイル用CNNの設計と改良には、あらゆる側面から多大な努力が払われてきたが、考慮すべきアーキテクチャの可能性が非常に多い場合、これらのトレードオフのバランスを手動で取ることは非常に困難である。本論文では、モデルのレイテンシーを主な目的に明示的に組み込むことで、精度とレイテンシーの間で良好なトレードオフを実現するモデルを検索する、自動モバイル・ニューラル・アーキテクチャ検索（NAS）アプローチを提案する。レイテンシーは、FLOPSなどの不正確なプロキシを用いて検討される従来の手法とは異なり、本アプローチでは、モデルを携帯電話で実行することで、実世界の推論レイテンシーを直接測定します。さらに，柔軟性と探索空間の大きさのバランスをとるために，ネットワーク全体のレイヤーの多様性を促進する新しい因数分解された階層的な探索空間を提案する．実験結果によると、我々のアプローチは、複数の視覚タスクにおいて、最先端のモバイルCNNモデルを一貫して凌駕している。ImageNet分類タスクにおいて、我々のMnasNetはPixel phone上で78msのレイテンシで75.2%のトップ1精度を達成しました。これは、0.5%の精度を持つMobileNetV2 [29]よりも1.8倍、1.2%の精度を持つNASNet [36]よりも2.3倍高速です。また，我々のMnasNetは，COCOオブジェクト検出において，MobileNetsよりも優れたmAP品質を達成している．コードはこのhttpsのURLにあります。
Aspect Term Extraction (ATE)は、テキスト中の意見のあるアスペクト用語を特定するもので、SemEval Aspect Based Sentiment Analysis (ABSA)コンテストのタスクの1つです。教師付きATEに利用できるデータセットは少なく、アスペクト用語のラベル付けには人間によるアノテーションが必要であるため、教師なしATEの必要性が高まっている。本論文では、教師付きATEでトップクラスの性能を達成するアーキテクチャを紹介します。さらに、教師なしATEの特徴抽出器や分類器としても効率的に利用できる。2つ目の貢献は、ATE用のデータセットを自動的に構築する方法です。我々は、自動的にラベル付けされたデータセットで分類器を学習し、人間が注釈を付けたSemeval ABSAテストセットで評価した。強力なルールベースのベースラインと比較して、劇的に高いFスコアが得られ、80%以上の精度が達成されました。この教師なしの手法は、高い精度を維持しつつ、SemEvalの教師ありABSAベースラインを凌駕しています。
ニューラルネットワークは、数値情報の表現や操作を学習することができますが、学習時に遭遇した数値の範囲を超えてうまく一般化することはほとんどありません。より体系的な数値の外挿を促すために、数値を線形活性化として表現し、学習したゲートで制御される原始的な算術演算子を用いて操作するアーキテクチャを提案する。このモジュールを、従来のプロセッサの算術論理ユニットになぞらえて、NALU（Neural Arithmetic Logic Unit）と呼んでいる。実験によると、NALUで強化されたニューラルネットワークは、時間の追跡、数字のイメージに対する演算、数値言語の実数スカラーへの変換、コンピューターコードの実行、画像中の物体の計数などを学習することができる。従来のアーキテクチャとは対照的に、学習時に遭遇した数値の範囲の内外で、大幅に優れた汎化能力を得ることができ、学習した数値の範囲を超えて外挿することも多い。
顔認識データの大規模化に伴い、顔認識のための強力な畳み込みネットワークを学習することができるようになりました。様々なアーキテクチャや損失関数が考案されていますが、既存のデータセットに内在するラベルノイズの原因と結果については、まだ十分な理解が得られていません。私たちは以下のような貢献をしています。1) 有名な顔データベースであるMegaFaceおよびMS-Celeb-1Mデータのサブセットを洗浄し、ノイズを抑制したIMDb-Faceデータセットを新たに構築する。2) オリジナルのデータセットとクリーンアップされたサブセットを用いて，MegaFaceとMS-Celeb-1Mのラベルノイズ特性をプロファイリングし，分析する。その結果、クリーンなサブセットと同じ精度を得るためには、数桁多いサンプル数が必要であることがわかった。ラベル反転や外れ値などのノイズの種類と顔認識モデルの精度との関連性を調査する。データのラベリング戦略がアノテーション精度に与える影響についての包括的なユーザー調査を含め、データのクリーン度を向上させる方法を調査する。IMDb-Faceデータセットは、このhttpsのURLで公開されています。
質の高い議論は、人間の推論や意思決定プロセスに不可欠な要素です。しかし、効果的な議論の構築は、人間にとっても機械にとっても困難な作業です。本研究では、与えられた文に対して異なるスタンスの議論を自動的に生成するという新しい課題を研究する。本研究では、エンコーダ・デコーダ方式のニューラルネットワークを用いた論証生成モデルに、Wikipediaから外部で取得した証拠を加えたものを提案する。このモデルでは、まず中間表現として話の要点となるフレーズのセットを生成し、続いて別のデコーダが入力とキーフレーズの両方に基づいて最終的な議論を生成する。Redditから収集した大規模なデータセットを用いた実験では、自動評価と人間の評価の両方において、我々のモデルは、一般的なsequence-to-sequence生成モデルよりもトピックに関連した内容を持つ議論を構築することが示された。
遠隔監視は、関係性抽出の標準的な手法となっています。しかし、効率的な手法とはいえ、コストがかからないわけではありません。なぜなら、結果として得られる遠隔監視の学習サンプルは、非常にノイズが多いからです。このノイズに対抗するために、最近の最先端のアプローチは、1つのベストセンテンスを選択することや、1つの特定のエンティティペアのセンテンスのセットに対してソフトアテンションウェイトを計算することに焦点を当てている。しかし、これらの方法は最適ではなく、誤認識の問題が性能を低下させる重要なボトルネックとなっている。我々は、誤ってラベル付けされた候補文は、ソフトな注目度で処理するのではなく、ハードな判断で処理しなければならないと主張する。そのために、本論文では抜本的な解決策を提案しています。それは、深層強化学習戦略を用いて偽陽性インジケーターを生成することです。先行研究での除去操作とは異なり、我々はそれらを否定的な例に再分配する。実験結果から，提案する戦略は，最先端のシステムと比較して，遠隔監視の性能を大幅に向上させることがわかった．
画像キャプション作成のための新しいフレームワークを紹介します。我々のアプローチは、古典的なスロットフィリングアプローチ（一般的に、画像に基づいている方が良い）と最新のニューラルキャプションアプローチ（一般的に、より自然な響きと正確さを持つ）を調和させるものである。このアプローチでは、まず、スロットの位置が特定の画像領域に明示的に関連付けられた文の「テンプレート」を生成します。これらのスロットは、オブジェクト検出器によって領域内で特定された視覚的な概念によって埋められます。文章テンプレートの生成とオブジェクト検出器によるスロットの充填という全体のアーキテクチャは、エンドツーエンドで微分可能です。提案モデルの有効性を、様々な画像キャプションタスクで検証する。標準的な画像キャプションと新しいオブジェクトキャプションにおいて、我々のモデルはCOCOデータセットとFlickr30kデータセットの両方で最先端に到達した。また、シーン構成の訓練分布とテスト分布、つまり関連するキャプションの言語プリオールが異なる場合に、我々のモデルが独自の利点を持つことを実証した。コードは次のURLで公開されています：このhttpsのURL
生物学的な知覚における注意メカニズムは、すべての感覚入力に対して実行するには困難な、より高度な処理のために知覚情報のサブセットを選択すると考えられています。しかし、コンピュータビジョンでは、一部の情報を選択的に無視するハードアテンションの研究はほとんど行われていません。ここでは、ハードアテンションのための新しいアプローチを紹介し、最近公開された視覚的質問応答データセットにおいて、いくつかの特徴を完全に無視しながらも、類似のソフトアテンション・アーキテクチャと同等、場合によってはそれを上回る、非常に競争力のある性能を達成することがわかった。また、ハードアテンションのメカニズムは区別できないと考えられているが、特徴の大きさが意味的な関連性と相関していることを発見し、このメカニズムの注意選択基準に有用なシグナルを提供している。ハードアテンションは入力情報の重要な特徴を選択するため、類似のソフトアテンションメカニズムよりも効率的であるとも言えます。これは、非局所的なペアワイズ演算を使用する最近のアプローチでは特に重要であり、計算コストとメモリコストは、特徴のセットのサイズの2次になります。
機械学習モデルは、解釈やデバッグが難しいことで知られている。これは特にニューラルネットワークに当てはまります。本研究では、まれな入力に対してのみ発生するエラーを発見するのに適した、ニューラルネットワークの自動ソフトウェアテスト技術を紹介します。具体的には、ニューラルネットワークを対象としたcoverage-guided fuzzing (CGF)手法を開発しました。CGFでは、ニューラルネットワークへの入力のランダムな変異は、ユーザーが指定した制約を満たすという目的に向かって、カバレッジメトリックによって導かれます。本論文では、高速な近似最近傍アルゴリズムがどのようにしてこのカバレッジメトリックを提供するかを説明する。また、CGFの応用例として、学習済みニューラルネットワークの数値誤差の発見、ニューラルネットワークとその量子化バージョンとの間の不一致の生成、文字レベルの言語モデルにおける望ましくない動作の顕在化などを挙げています。最後に、説明した技術を実装したTensorFuzzというオープンソースのライブラリを公開します。
ここ数年、自然言語処理の分野では、深層学習モデルの使用が爆発的に増加しています。この調査では、この分野を簡単に紹介し、深層学習のアーキテクチャと手法の概要を説明しています。次に、膨大な数の最近の研究に目を通し、関連する多数の貢献をまとめています。分析された研究分野には、計算言語学の多くの応用分野に加えて、いくつかの中核的な言語処理問題が含まれています。そして、現在の技術の状態を議論し、この分野における将来の研究のための推奨事項を提示する。
新しいNLIテストセットを作成し、語彙や世界の知識を必要とする推論において、最先端のモデルが不足していることを示す。新しい例題は、SNLIテストセットよりも単純で、トレーニングセットの文とせいぜい1語しか違わない文を含んでいる。しかし、新しいテストセットでの性能は、SNLIで学習したシステムよりも大幅に悪く、これらのシステムの一般化能力には限界があり、多くの単純な推論を捉えることができないことが示された。
安定性は力学系の基本的な特性であるが、今日までリカレントニューラルネットワークの実用化にはほとんど関係していない。本研究では、安定なリカレントモデルを徹底的に調査しました。理論的には、安定型リカレント・ニューラル・ネットワークが、勾配降下法による推論と学習の両方の目的で、フィード・フォワード・ネットワークによく近似されることを証明します。実証的には、安定したリカレントモデルが、ベンチマークとなるシーケンスタスクにおいて、不安定なモデルと同等の性能を発揮することを示しています。これらの結果は、リカレントネットワークの効果的なパワーを明らかにし、シーケンス学習の多くが安定領域で行われている、あるいは行わせることができることを示唆している。さらに、我々の結果は、多くの場合、実務家がリカレントモデルをフィードフォワードモデルに置き換えることに成功する理由を説明するのに役立ちます。
本研究では、深層学習に基づいてパッシブな回折層を設計することで、様々な機能の実装を学習することができる全光学式の回折型ディープニューラルネットワーク（D2NN）アーキテクチャを紹介しています。我々は、3DプリントしたD2NNを作成し、手書きの数字の分類やテラヘルツ帯のイメージングレンズの機能を学習させることで、このフレームワークの成功を実験的に示しました。3Dプリントをはじめとするリソグラフィ技術や空間光変調器を用いれば、コンピュータベースのニューラルネットワークでは実現できないような複雑な機能を光速で実現することができ、全光学的な画像解析や特徴検出、物体分類などへの応用が期待できるほか、D2NNを用いて独自の機能を学習させる新しいカメラの設計や光学部品の開発も可能になります。
アルツハイマー型認知症の早期診断は困難です。軽度認知障害（MCI）は、通常、アルツハイマー型認知症に先行して発症しますが、バイオマーカーを用いてスクリーニングしても、MCI患者の一部しか認知症に進行しません。私たちはここで、認知症になることを予測する共通の脳シグネチャーを共有する個人のサブセットを特定することを提案します。このシグネチャーは、脳の萎縮と機能的結合不全から構成されており、認知症患者の機械学習モデルを用いて発見された。このモデルは、MCI患者の90％が3年以内に認知症に移行した場合にも、同じ脳の特徴を認識しました。この結果は、最先端の予知精度を大幅に向上させたものであるが、一方で、この脳シグネチャはMCI進行者の47%を識別した。このように、私たちは、アルツハイマー病の前駆段階における臨床試験の優れたリクルートターゲットとなる、かなり大きなMCI亜集団を発見しました。
電子医療データから機械学習を行うアプローチの多くは、単一のエンドポイントしか予測できません。ここでは、教師なしの深層学習を用いて、患者の詳細な軌跡をシミュレートする方法を紹介します。本研究では、軽度認知障害またはアルツハイマー病の患者1908人の44の臨床変数の18カ月間の軌跡からなるデータを用いて、疾患の進行を個別に予測するモデルを学習した。認知機能検査、臨床検査、ベースラインの臨床特性との関連性などの各サブコンポーネントの変化を含む合成患者データをシミュレーションし、予測値とその信頼区間を生成した。この教師なしモデルは、ADAS-Cogスコアの変化を、特別に訓練された教師ありモデルと同等の精度で予測し、単語想起に関連するサブコンポーネントを進行の予測因子として特定した。何十もの患者の特徴を同時にシミュレートする能力は、アルツハイマー病の個別化医療に向けた重要なステップである。
我々は、アルツハイマー病の分類のために、3次元畳み込みニューラルネットワーク（3D-CNN）から視覚的な説明を生成するための3つの効率的なアプローチを開発した。1つのアプローチは、階層的な3D画像セグメンテーションの感度分析を行い、他の2つのアプローチは、空間マップ上のネットワーク活性化を視覚化します。視覚的なチェックと定量的な局在化ベンチマークにより，すべてのアプローチがアルツハイマー病診断のために重要な脳部位を特定することが示された．比較分析の結果、感度分析に基づくアプローチは、分散した大脳皮質を扱うのが困難であり、活性化の視覚化に基づくアプローチは、畳み込み層の解像度に制約されることがわかった。これらの手法の相補性により、アルツハイマー病分類における3D-CNNの理解が異なる視点から向上する。
ブラックボックス分類器の局所的な決定境界を近似するためのローカルサロゲートモデルは、バックボックスが行う個々の予測の背後にある根拠を説明するための1つのアプローチを構成します。この論文では、ローカルなブラックボックス判定境界を正確に近似するためには、ローカルサロゲートが学習される近傍である適切なローカリティを定義することの重要性を強調しています。残念ながら、本論文で示されているように、この問題はパラメータやサンプリング分布の問題だけではなく、局所的なブラックボックスの決定境界の近似の関連性と品質、ひいては生成された説明の意味と正確さに大きな影響を与えています。このような問題を解決するために、我々は、従来のように予測そのものではなく、説明すべき予測に関連する決定境界の特定の場所を中心としたサンプリングに基づいて、個々の予測に対する代理説明を生成することを提案する。UCIの4つのデータセットを用いて、この新しい手法を最先端の手法と比較して評価したところ、素直な改善が見られた。
本論文では、医用画像のセグメンテーションのための新しい、より強力なアーキテクチャであるUNet++を紹介する。我々のアーキテクチャは、本質的には、深い教師付きのエンコーダ-デコーダネットワークであり、エンコーダとデコーダのサブネットワークは、一連の入れ子になった高密度のスキップパスウェイで接続されている。再設計されたスキップパスウェイは、エンコーダーサブネットワークとデコーダーサブネットワークの特徴マップ間の意味的ギャップを減らすことを目的としている。我々は、デコーダとエンコーダのネットワークの特徴マップが意味的に類似していれば、オプティマイザはより簡単な学習タスクを扱うことができると主張する。我々は、胸部低線量CTスキャンにおける結節のセグメンテーション、顕微鏡画像における核のセグメンテーション、腹部CTスキャンにおける肝臓のセグメンテーション、および大腸内視鏡ビデオにおけるポリープのセグメンテーションという複数の医用画像セグメンテーションタスクにおいて、U-NetおよびワイドU-Netアーキテクチャと比較して、UNet++を評価した。我々の実験では，ディープスーパビジョンを導入したUNet++は，U-NetおよびWide U-Netと比較して，それぞれ3.9および3.4ポイントの平均IoUゲインを達成しました．
クラスタリングは教師なし学習法の一種であり、コンピュータビジョンで広く適用され、研究されてきました。しかし、この手法を大規模なデータセットにおける視覚的特徴のエンドツーエンドの学習に適用することはほとんど行われていません。本研究では、ニューラルネットワークのパラメータと、結果として得られる特徴のクラスタ割り当てを共同で学習するクラスタリング手法であるDeepClusterを発表する。DeepClusterは、標準的なクラスタリングアルゴリズムであるk-meansを用いて特徴量を反復的にグループ化し、その後の割り当てをネットワークの重みを更新するための監視として使用します。DeepClusterは、ImageNetやYFCC100Mなどの大規模データセットにおける畳み込みニューラルネットワークの教師なしトレーニングに適用されます。その結果、すべての標準的なベンチマークにおいて、現在の技術水準を大幅に上回るモデルが得られました。
勾配ベースのメタ学習技術は、広く適用可能であり、困難な少数ショット学習や高速適応の問題を解決することに長けています。しかし、極端な低データ領域で高次元のパラメータ空間を扱う場合には、実用上の問題があります。我々は、データに依存したモデルパラメータの潜在的な生成表現を学習し、この低次元の潜在空間で勾配ベースのメタ学習を行うことで、これらの制限を回避できることを示す。この手法は、潜在埋め込み最適化（LEO）と呼ばれ、モデル・パラメータの高次元空間から勾配ベースの適応手順を切り離す。評価の結果、LEOは、miniImageNetおよびTieredImageNetの数ショットの分類タスクにおいて、最先端の性能を達成することができました。さらに解析を進めると、LEOはデータの不確実性を捉えることができ、潜在空間で最適化することでより効果的に適応を行うことができる。
Open Information Extractionのタスクを解決するために、これまでに提案された様々なアプローチの詳細な概要を説明します。このようなシステムが直面する主要な課題を提示し、提案されたアプローチの時系列での進化を示し、それらが対処する特定の問題を描きます。さらに、オープンIEシステムのパフォーマンスを評価するために一般的に適用されている評価手順を批判し、今後の研究の方向性を明らかにします。
ポリシー探索アルゴリズムの多くは、効果的なポリシーを見つけるために何千ものトレーニングエピソードを必要としますが、これは物理的なロボットでは実現不可能な場合が多いです。この調査記事では、ロボットがわずかな試行回数（十数回）と数分でどのように適応できるのかという、極端な反対側に焦点を当てています。ビッグデータ」という言葉になぞらえて、この課題を「マイクロデータ強化学習」と呼んでいます。我々は、第一の戦略として、ポリシーの構造（例：ダイナミックな動きのプリミティブ）、ポリシーのパラメータ（例：デモンストレーション）、またはダイナミクス（例：シミュレータ）に関する事前の知識を活用することを示す。2つ目の戦略は、期待される報酬のデータ駆動型の代理モデルを作成し（例：ベイズ最適化）、動的モデルを作成し（例：モデルベースのポリシー検索）、ポリシーオプティマイザが実システムの代わりにモデルに問い合わせを行うようにすることである。全体として、成功しているマイクロデータ・アルゴリズムはすべて、モデルと事前知識の種類を変えることで、これら2つの戦略を組み合わせています。現在の科学的な課題は、複雑なロボット（ヒューマノイドなど）へのスケールアップ、汎用的なプライヤーの設計、計算時間の最適化に集約されています。
研究者の中には、機械学習システムの解釈可能性は、特定のエージェントやタスクに関連して定義されるべきだと主張する者もいる。すなわち、システムが解釈可能かどうかではなく、誰に対して解釈可能かを問うべきである。我々は、機械学習システムに関連してエージェントが果たすことのできる様々な役割を特定することで、この質問に答える手助けとなるモデルを説明する。このモデルの使用方法を様々なシナリオで説明し、エージェントの役割がその目標にどのように影響するか、そして解釈可能性の定義にどのような影響があるかを探ります。最後に、我々のモデルが解釈可能性の研究者、システム開発者、および機械学習システムを監査する規制機関にとってどのように役立つかについて提案する。
近年の解釈可能な機械学習（iML）やeXplainable AI（XAI）では、分類タスクにおける特徴の重要性に基づいて説明を構築している。しかし、高次元の特徴空間では、重要な特徴のセットを制限しなければ、このアプローチは実行不可能になる可能性がある。我々は、「なぜ、あの出力（箔）ではなく、この出力（事実）なのか」というような質問をする人間の傾向を利用して、質問された対比において主要な役割を果たす特徴の数を減らすことを提案する。本研究では，局所的に学習された一対全決定木を用いて，データポイントを事実ではなく箔として分類させるルールの不分離セットを特定する．本研究では、この手法を3つのベンチマーク分類タスクで説明する。
視覚的な質問に自動的に答えるアルゴリズムの研究は、現在、人工的なVQA設定で構築された視覚的質問応答（VQA）データセットが動機となっている。我々は、自然なVQAセッティングから生まれた最初のゴール指向のVQAデータセットであるVizWizを提案する。VizWizは、目の不自由な人が携帯電話で写真を撮り、それに対する質問を録音した31,000件以上の視覚的質問と、視覚的質問ごとにクラウドソースで作成された10件の回答で構成されている。VizWizが既存の多くのVQAデータセットと異なる点は、(1)画像は盲目の写真家が撮影したものであるため、画質が悪い場合が多いこと、(2)質問は音声であるため、より会話的であること、(3)視覚的な質問には答えられない場合が多いこと、などが挙げられる。視覚的な質問に答えたり、視覚的な質問に答えられるかどうかを判断するための最新のアルゴリズムを評価したところ、VizWizは難しいデータセットであることがわかりました。このデータセットを導入することで、より多くのコミュニティが、目の不自由な人を支援できる、より一般化されたアルゴリズムを開発することを奨励します。
不正行為の検知は、予測モデルから恩恵を受けることができる難しい問題です。しかし、予測の検証は困難であり、一つの保険契約に対して、モデルは予測スコアしか提供しません。本発表では、不正検知チームの作業を支援するために、異なるインスタンスレベルのモデル説明技術を反映させたケーススタディを紹介します。この目的のために、我々は様々な最新の説明技術を組み合わせた2つの新しいダッシュボードを設計しました。これらにより、ドメインエキスパートは予測を分析・理解することができ、潜在的な不正事例をフィルタリングするプロセスを劇的にスピードアップすることができます。最後に、学んだ教訓と未解決の研究課題について説明します。
本研究では、自閉症の子供たちのロボット支援によるセラピーセッションで撮影された、ステージのない動画を対象とした、きめ細かな行動と感情の認識タスクを新たに導入しました。このタスクにはいくつかの課題があります。それは、長時間の動画を含む大規模なデータセット、非常に変化の多いアクション、部分的にしか見えない子供、異なる年齢、予測不可能な行動を示す可能性のある子供、そして非標準的なカメラの視点です。本研究では、最先端の3D人物姿勢再構成手法が、新たに導入された課題に対してどのように機能するかを調査し、これらの課題に対処するための拡張機能を提案する。また、人間の3Dポーズデータから行動や感情を認識するための複数のアプローチを分析し、いくつかのベースラインを設定し、子供とロボットのインタラクションの文脈における結果とその意味を議論します。
顔の表情、体の動き、手のジェスチャーなど、複数のスケールの人間の動きをマーカーレスでキャプチャするための統一された変形モデルを提案します。初期のモデルは、人体の各部分のモデルを局所的につなぎ合わせて生成されますが、これを「フランケンシュタイン」モデルと呼びます。このモデルは、顔や手などのパーツの動きを1つのシームレスなモデルで表現することを可能にします。私たちは、普段着を着た人々の大規模なキャプチャを用いて、フランケンシュタインモデルを最適化し、「アダム」を作成しました。アダムは、初期モデルと同じ骨格階層を持ちながら、髪や服の形状を表現することができ、日常生活での人物のフィッティングに直接使用できるキャリブレーション済みのモデルです。最後に、これらのモデルを総合的なモーション・トラッキングに使用し、社会的なグループの大規模な体の動きと微妙な顔や手の動きを同時に捉えることを実証します。
我々は、説明の頑健性（同じような入力から同じような説明が得られること）が、解釈可能性の重要な要件であると主張する。本論文では、頑健性を定量化するための指標を紹介し、現在の手法がこれらの指標に照らして良好な結果を得られないことを示す。最後に、既存の解釈可能性アプローチに頑健性を強制する方法を提案する。
UMAP（Uniform Manifold Approximation and Projection）は、次元削減のための新しい多様体学習技術です。UMAPは、リーマン幾何学と代数的位相幾何学に基づいた理論的枠組みから構築されている。その結果、実世界のデータに適用できる実用的でスケーラブルなアルゴリズムが完成しました。UMAPアルゴリズムは、視覚化の品質においてt-SNEと競合し、優れたランタイム性能でグローバル構造をより多く保存することができることは間違いない。さらに、UMAPには埋め込み次元に関する計算上の制限がないため、機械学習のための汎用的な次元削減技術として実行可能である。
最新の画像セグメンテーションアルゴリズムは、一般的に、少なくとも2つの連続した異なる計算から構成されています。1つは、局所的な画像情報を使用して画像の位置をオブジェクト間の境界として分類する境界検出プロセスで、もう1つは、ピクセルをセグメントにクラスタリングする流域または連結成分などのピクセルグループ化ステップです。先行研究では、境界予測を行うために多層ニューラルネットワークを組み込んだり、ピクセルのクラスタリング時にグローバルな最適化を行ったりするなど、これら2つのステップで採用される複雑さやアプローチが異なっていた。本研究では，統一されたエンド・ツー・エンドの学習可能な機械学習手法である flood-filling ネットワークを提案している．提案手法は、未知の物体の数や大きさが変化する画像をロバストにセグメント化します。我々は、体積電子顕微鏡データからのコネクトミック再構築という困難な3D画像セグメンテーションタスクでこのアプローチを実証し、フラッドフィリング・ニューラルネットワークが他の最新の手法よりも大幅に精度を向上させたことを示した。提案されたアプローチは、複雑なマルチステップのセグメンテーションパイプラインを、エンドツーエンドで学習される単一のニューラルネットワークに置き換えることができます。
機械学習の進歩により、重要な問題に対して優れた性能を発揮するシステムが広く普及しています。しかし、これらのシステムは、学習されたシステムが正しく処理する例と驚くほど類似したデータに対してエラーを起こすことがあります。このようなエラーの存在は、サンプル外の一般化や、悪意のある者がそのような例を使って展開されたシステムを悪用するのではないかという、さまざまな疑問を引き起こします。このようなセキュリティ上の懸念から、最近では、正しく処理された例に対する悪意のある摂動から守るためのアルゴリズムを提案する論文が相次いでいる。しかし、このような誤分類が、他のエラーや、破壊されていない入力との特定の関係を持たない攻撃者が作成した例と、どのように異なる種類のセキュリティ問題を表すのかは不明である。本論文では、これまでの敵対的事例の防衛論文は、ほとんどが特定のセキュリティ問題とは関係のない、抽象的でおもちゃのようなゲームを検討していたと主張します。さらに、防御論文は、実用的なセキュリティに関連する攻撃者のすべての能力と制限をまだ正確に記述していない。この目的のために、我々は、より妥当な敵対者の動機、制約、および能力の分類法を確立する。最後に、脅威モデルをより明確に表現し、より意味のある評価を行うために、今後の研究の道筋を示す一連の提言を行います。
能動学習（AL）は，固定されたアノテーション・バジェットのもとで予測性能を最大化するために広く用いられている学習戦略である。ALでは、現在のモデルが最も不確実であると思われるトレーニング例を繰り返し選択してアノテーションを行います。能動的なサンプリングにより、独立同分布（i.i.d.）のランダムなサンプルよりも優れた性能が得られることを期待している。ALはレトロスペクティブな評価で有望視されているが、これらの研究では、その使用に対する実用的な障害を無視していることが多い。本論文では、ALが特定のモデルや特定の領域で使用された場合には利点があるかもしれないが、現在のアプローチの利点は、モデルやタスク間で確実に一般化しないことを示している。この問題は、実際にはAL戦略を検討したり比較したりする機会がないことに起因している。さらに、ALは、トレーニングデータセットとその取得に使用されたモデルを結びつける。我々は、積極的に獲得したデータセットを用いて後継モデルを後から学習しても、i.i.d.でサンプリングしたデータを用いた学習よりも一貫して優れているとは言えないことを発見した。今回の発見は、ALに内在する欠点が、それによって得られる控えめで一貫性のない性能向上に見合うものかどうかという疑問を投げかけます。
少数ショット学習のためのメタ学習では、少量のデータから新しいタスクを学習するために、以前のタスクや経験に関する事前情報を獲得する必要があります。しかし、少数ショット学習における重要な課題は、タスクの曖昧さである。たとえ多数の先行タスクから強力な事前情報をメタ学習できたとしても、新しいタスクのための少量のデータセットは単純に曖昧すぎて、そのタスクのための正確な単一モデル（例えば、分類器）を獲得できない場合がある。本論文では、モデル分布から新しいタスクのモデルをサンプリングできる確率的なメタ学習アルゴリズムを提案する。我々のアプローチは、勾配降下法によって新しいタスクに適応するモデル不可知論的メタ学習を拡張し、変分低界によって学習されたパラメータ分布を組み込む。メタテスト時には、我々のアルゴリズムは、勾配降下にノイズを注入する簡単な手順で適応し、メタトレーニング時には、この確率的適応手順が近似モデル事後からのサンプルを生成するようにモデルを学習する。我々の実験結果は、この手法が、曖昧な数ショットの学習問題において、もっともらしい分類器と回帰器をサンプリングできることを示している。また、曖昧さに関する推論が下流の能動的学習問題にも利用できることを示す。
深層学習は新たな研究分野であり、より効率的な知的システムの展開に向けてその有効性が証明されています。一方で、セキュリティは、現代の通信システムにおいて最も重要な問題の一つです。近年、多くの論文で、深層学習モデルをセキュリティ領域に適用した場合、有望な結果が得られることが示されています。本研究では、深層学習技術をセキュリティ分野に適用した最近の研究について概要を説明する。
生成システムを評価するために、BLEUのような自動指標はコストがかかりませんが、人間の判断との相関性が低く、特定のモデルの改良に対して系統的なバイアスがかかることが示されています。一方、偏りのないゴールドスタンダードである人間の判断を平均化することは、しばしばコストがかかりすぎる。この論文では、制御変量を用いて、自動測定基準と人間の評価を組み合わせることで、人間の評価だけよりも低コストで不偏の推定値を得ることができます。しかし、実際には、要約システムや公開質問応答システムの評価において、7-13%のコスト削減しか得られなかった。そして、我々の推定量が最適であることを証明します。つまり、より低いコストの不偏の推定量は存在しないのです。さらに、この理論は、2つの基本的なボトルネック、すなわち、自動測定基準と人間の評価者に表示されるプロンプトを強調しています。これらは、より大きなコスト削減を得るために改善する必要があります。
言語コミュニケーションは、人間の学習や知識の獲得に重要な役割を果たしています。新世代のコグニティブ・ロボットの出現により、これらのロボットが人間のパートナーから直接学べるようにすることがますます重要になってきている。本論文では、人間が自然言語によるコミュニケーションや動作のデモンストレーションを通じて物理的なエージェントに新しいタスクを教えることができる、インタラクティブなタスク学習について簡単に紹介します。本論文では、このプロセスで重要となる言語とコミュニケーションの基礎に関する研究の課題と機会について述べています。さらに、言語を知覚や行動に結びつけるためには、常識的な知識、特に非常に基本的な物理的因果関係の知識が重要であることを強調しています。
非常に深い畳み込みニューラルネットワーク（CNN）は、最近、画像の超解像（SR）で大きな成功を収め、階層的な特徴も提供している。しかし、ほとんどのCNNベースのSRモデルは、元の低解像度（LR）画像からの階層的な特徴を十分に利用しておらず、それにより比較的低い性能を達成している。本論文では、画像SRにおけるこの問題を解決するために、新しい残差密碼（RDN）を提案する。本研究では、すべての畳み込み層からの階層的な特徴を完全に利用する。具体的には、高密度に接続された畳み込み層を介して豊富な局所的特徴を抽出するために、residual dense block（RDB）を提案する。RDBは、先行するRDBの状態から現在のRDBのすべての層への直接接続を可能にし、コンティグス・メモリー（CM）メカニズムを実現しています。RDBの局所特徴融合は、先行する局所特徴と現在の局所特徴から、より効果的な特徴を適応的に学習し、より広いネットワークの学習を安定させるために使用されます。さらに、高密度な局所特徴量を完全に取得した後、大規模な特徴量融合を用いて、大規模な階層的特徴量を共同で適応的に学習します。異なる劣化モデルのベンチマークデータを用いた大規模な実験により、我々のRDNが最先端の手法に対して良好な性能を達成することが示された。
一般的な確率的多段階時系列回帰のためのフレームワークを提案する。具体的には、Sequence-to-Sequence Neural Networksの表現力と時間的性質（リカレント構造や畳み込み構造など）、Quantile Regressionのノンパラメトリックな性質、Direct Multi-Horizon Forecastingの効率性を利用しています。新しい学習スキームである*forking-sequences*は、安定性と性能を高めるためにシーケンシャル・ネット用に設計されています。このアプローチは、時間的および静的な共変量に対応し、複数の関連する系列間での学習、季節性のシフト、将来の計画されたイベントのスパイクやコールドスタートなど、現実の大規模予測に対応することを示します。このフレームワークの性能は、このhttpのURLで販売されているアイテムの将来の需要を予測するアプリケーションと、電力価格と負荷を予測する公共の確率的予測競技で実証されています。
テキスト列の構成性をモデル化するために、多くの深層学習アーキテクチャが提案されてきましたが、相当数のパラメータと高価な計算が必要でした。しかし、高度な構成関数の付加価値に関する厳密な評価はなされていない。本論文では、パラメータなしのプーリング演算からなるSimple Word-Embedding-based Models (SWEMs)と、Word-embedding-based RNN/CNNモデルとをポイントごとに比較検討した。驚くべきことに、SWEMはほとんどのケースで同等、あるいはそれ以上の性能を発揮しています。この理解に基づいて、我々は学習した単語埋め込みに対する2つの追加のプーリング戦略を提案する。(i)解釈のしやすさを向上させるための最大プーリング操作、(ii)テキストシーケンス内の空間情報（n-gram）を保持するための階層的プーリング操作。本研究では，以下の3つのタスクを含む17のデータセットで実験を行った．(i) 長い文書の分類、(ii) テキストシーケンスのマッチング、(iii) 分類やタグ付けを含む短いテキストのタスク。ソースコードおよびデータセットは、https:// このhttpのURLから入手できます。
近年、大規模な質問応答（QA）データセットが開発されたことをきっかけに、QAのためのエンド・ツー・エンドのニューラル・アーキテクチャに関する研究が盛んに行われるようになりました。しかし、その複雑さを正当化するような、より単純なニューラルベースラインシステムとの比較がなされないまま、ますます複雑なシステムが考案されている。本研究では、抽出型QAタスクのための神経ベースラインシステムの開発を導くための簡単なヒューリスティックを提案します。その結果、高性能なニューラルQAシステムを構築するためには、2つの要素が必要であることがわかった。1つ目は、文脈を処理する際に質問語を認識すること、2つ目は、リカレント・ニューラル・ネットワークのような単純な単語のバッグ・オブ・ワード・モデリングを超えた合成機能である。我々の結果は、この2つの要件を満たすシステムであるFastQAが、既存のモデルと比較して非常に競争力のある性能を達成できることを示している。この驚くべき発見は、これまでのシステムの結果と最近のQAデータセットの複雑さを考慮に入れたものであると言える。
服を作るとき、スタイルは各ファッションアイテムを選択するための基準となります。つまり、スタイルは服全体の特徴とみなすことができます。しかし、服の生成に関する様々な先行研究では、服から得られるグローバルな情報に着目した手法はほとんどありませんでした。そこで我々は，教師なしのスタイル抽出モジュールを服の学習モデルに組み込みました。提案モデルは，服のスタイル情報を利用することで，追加の情報を必要とせず，より柔軟に服を生成することに成功した．さらに，提案モデルが抽出したスタイル情報は，解釈が容易である．提案モデルは，人間が生成した2つの服のデータセットで評価された．ファッションアイテムの予測タスク（missing prediction task）では，提案モデルはベースライン手法よりも優れていた．スタイル抽出タスクでは，提案モデルは，簡単に区別できるスタイルを抽出した．服の生成タスクでは，提案モデルはスタイルを制御しながら服を生成した．これにより，様々な好みに応じたファッショナブルな衣装を生成することが可能になる．
最近の研究では，Dilated/Atrous convolutionの採用，マルチスケール特徴の利用，境界の精緻化などにより，完全畳み込みネットワーク（FCN）フレームワークを用いたピクセル単位のラベリングのための空間分解能の向上が大きく進展した．本論文では，シーンの意味的コンテキストを取得し，クラスに依存する特徴マップを選択的に強調するContext Encoding Moduleを導入することで，意味的セグメンテーションにおけるグローバルなコンテキスト情報の影響を探る．提案されたコンテキスト・エンコーディング・モジュールは，FCNに比べてわずかな計算コストで，セマンティック・セグメンテーションの結果を大幅に改善することができる．我々のアプローチは、PASCAL-Contextで51.7% mIoU、PASCAL VOC 2012で85.9% mIoUという、最先端の結果を達成しました。我々の単一モデルは、ADE20Kテストセットで0.5567の最終スコアを達成し、これは2017年のCOCO-Place Challengeの優勝エントリーを上回ります。さらに、CIFAR-10データセットの画像分類において、コンテキストエンコーディングモジュールが比較的浅いネットワークの特徴表現をどのように改善できるかについても調査しています。我々が開発した14層のネットワークは3.45%のエラーレートを達成しており、これは10倍以上の層を持つ最先端のアプローチに匹敵するものです。このシステムのソースコードは公開されています。
建物性能シミュレーション（BPS）では，室内気候や暖房・換気・空調（HVAC）のエネルギー消費を現実的にモデル化するために，乗員行動（OB），特に窓の開口部を考慮する必要があります．しかし、提案されているOBの窓開口部モデルは、窓が閉じたままのクラスに偏っていることが多い。また、居住者ごとにチューニングが必要であり、居住者数の増加に対応できないという問題がある。本論文では、深層学習手法を用いた商業ビルの窓開閉モデルを提案する。このモデルは、ドイツにあるオフィスビルの居住者のデータを用いて学習された。このモデルは、アーヘン、フランクフルト、フィラデルフィアにある3つの独立したビルから得られた約2,000万個のデータポイントを用いて評価されました。最終的には、3100コア時間に及ぶモデル開発の結果がまとめられ、この種の窓の状態のモデリングでは最大の研究となりました。さらに、提案したモデルをModelicaベースの熱建物シミュレーションに組み込むことで、その実用性を検証しました。その結果，オフィスビルの評価精度は86〜89％，F1スコアは0.53〜0.65となった．入力データが少ない場合には，F1スコアは高いままであるが，性能は約15%ポイント低下した。
本論文では、ビデオゲームのチュートリアルを完全に自動で生成する手法を紹介します。AtDELFIシステム（AuTomatically DEsigning Legible, Full Instructions for games）は、プレイヤーにビデオゲームの遊び方を教える説明書の手続き的な生成を研究するために作られた。このシステムでは、ゲームのルールや仕組みをグラフで表現し、そのグラフを使ってチュートリアルを生成する手法を提案しています。本論文では、8つの異なるゲームに対して生成されたチュートリアルを取り上げ、GVG-AI（General Video Game Artificial Intelligence）フレームワーク内のゲームでテストすることで、このコンセプトを実証しました。その結果、「スペースインベーダー」や「パックマン」のような単純なアーケードゲームでは、グラフ表現を用いたチュートリアルが有効であることがわかったが、より複雑なゲームのチュートリアルでは、ゲームの仕組みだけでなく、より高度な理解が必要であると考えられる。
自律運転ポリシーの学習は、コンピュータビジョンにとって最も困難でありながら有望な課題の一つです。多くの研究者は、将来の研究やアプリケーションでは、カメラ、ビデオレコーダー、レーザースキャナーを組み合わせて、実際の交通を包括的に意味的に理解する必要があると考えています。しかし、現在のアプローチでは、精密なレーザースキャナのデータからなるベンチマークがないため、大規模なビデオからしか学習できない。本論文では、Velodyne社製レーザースキャナーでスキャンされた大規模で高品質な点群、ダッシュボードカメラで記録された動画、および標準的なドライバーの行動を提供するLiDAR-Videoデータセットを初めて提案するものである。このデータセットは、Velodyne社のレーザーでスキャンされた大規模で高品質な点群と、ダッシュボードカメラで撮影された動画、そして標準的なドライバーの行動を提供します。
畳み込みほど、深層学習に大きな影響を与えているアイデアはありません。ピクセルや空間表現を含む問題には、畳み込みニューラルネットワークが適していると一般的に考えられています。本論文では、(x,y)デカルト空間の座標とワンショットのピクセル空間の間のマッピングを学習するだけの、一見些細な座標変換問題を通じて、この直感に対する顕著な反例を示します。畳み込みネットワークはこの問題に適しているように見えますが、見事に失敗することを示しています。まず、おもちゃの問題で失敗を実証し、慎重に分析しますが、その時点で簡単な修正方法が明らかになります。この解決策を「CoordConv」と呼んでいます。この解決策は、追加の座標チャンネルを使用することで、畳み込みが自分の入力座標にアクセスできるようにすることで機能します。CoordConvは、通常の畳み込みの計算効率やパラメータ効率を犠牲にすることなく、最終的なタスクの要求に応じて、完全な並進不変性または様々な程度の並進依存性をネットワークに学習させることができます。CoordConvは座標変換問題を完全に一般化し、コンボリューションに比べて10-100倍少ないパラメータで150倍の速度で解決します。畳み込みができないことが、他のタスクの内部でどの程度まで浸透し、パフォーマンスを微妙に低下させているのかという疑問が生じます。この疑問に対する完全な答えを得るには、さらなる調査が必要ですが、我々は、畳み込みをCoordConvに置き換えることで、様々なタスクのモデルを改善できるという予備的な証拠を示しています。CoordConvをGANに使用すると、高レベルの空間的な潜在要素とピクセルの間の変換が学習しやすくなるため、モード崩壊が少なくなります。MNISTで学習したFaster R-CNNの検出モデルは、CoordConvを使用することで24%のIOU改善を示し、RLドメインではAtariゲームをプレイするエージェントがCoordConvレイヤーを使用することで大きな利益を得た。
教師付き学習が多くのアプリケーションで大きな進歩を遂げている一方で、教師なし学習はこれほど広く普及しておらず、人工知能にとって重要かつ挑戦的な試みであり続けています。本研究では、高次元データから有用な表現を抽出するための普遍的な教師なし学習アプローチを提案する。これをContrastive Predictive Codingと呼ぶ。我々のモデルの重要な洞察は、強力な自己回帰モデルを用いて潜在空間で未来を予測することにより、そのような表現を学習することである。このモデルでは、確率的コントラスト損失を用いて、将来のサンプルを予測するために最大限有用な情報を潜在空間に誘導します。また、負のサンプリングを用いることで、モデルを扱いやすくしています。これまでの研究では、特定のモダリティの表現を評価することに重点が置かれていたが、本研究では、音声、画像、テキスト、3D環境での強化学習という4つの異なるドメインにおいて、有用な表現を強力に学習できることを実証する。
人間の専門家の間で意見が一致しないという問題は、機械学習と医学の両方において普遍的なものです。医学分野では、患者の診断について医師の意見が一致しないことがよくあります。本研究では、機械学習モデルを学習することで、専門家の意見の相違が大きいデータインスタンスに不確実性スコアを与えることができることを示している。特に、セカンドオピニオンが最も有益な患者のケースを特定することができます。我々の方法論的な発見は、患者の生の特徴から直接不確実性スコアを予測するモデルを学習する「直接不確実性予測（DUP）」が、分類器を学習し、出力分布を後処理して不確実性スコアを与えるという2段階のプロセスである「不確実性による分類」よりも有効であるということです。このことは、理論的な結果と、大規模な医用画像処理アプリケーションでの広範な評価の両方で示されています。
実験結果の統計的有意性を一貫して確認することは、深層強化学習におけるいわゆる「再現性の危機」に対処するための必須の方法論的ステップの一つです。このチュートリアル論文では、ランダムシードの数が統計的エラーの確率にどのように関係するかを説明します。また、t検定とブートストラップ信頼区間検定の両方について、2つのアルゴリズムの性能を統計的に有意に比較するために使用すべきランダムシードの数を決定するための理論的なガイドラインを思い出します。最後に、統計的検定の前提条件からの逸脱の影響について説明します。統計的誤差の評価が不正確になる可能性があることを示し，これらの悪影響に対抗するためのガイドラインを提供します．また、テストを行うためのコードを公開しています。
運転シーンの理解は、インテリジェントな交通システムの重要な要素です。複雑な物理的・社会的環境で動作するシステムを実現するためには、人間がどのように運転し、交通シーンと相互作用するかを理解・学習する必要があります。私たちは、実生活環境におけるドライバーの行動を学習する研究を可能にするための挑戦的なデータセットである、Honda Research Institute Driving Dataset (HDD)を紹介します。このデータセットには、さまざまなセンサを搭載した計測車両を用いて、サンフランシスコ・ベイエリアで人間が実際に運転した104時間分のデータが含まれています。他の運転データセットと比較しながら、HDDの詳細な分析を行います。また、新しいアノテーション手法を導入し、トリミングされていないデータシーケンスからドライバーの行動を理解する研究を可能にします。最初のステップとして、運転者の行動を検出するためのベースライン・アルゴリズムを学習し、テストすることで、提案するタスクの実現可能性を示す。
NLPのための複雑な機械学習モデルは、意味的に極めて類似した入力インスタンスに対して異なる予測を行うなど、脆いことが多い。個々のインスタンスに対するこのような振る舞いを自動的に検出するために、我々は意味的に等価な敵対者（SEA）、すなわちモデルの予測に変化をもたらす意味的に保存された摂動を提示する。また、これらの敵対因子を、意味的に等価な敵対規則（SEAR）に一般化します。SEARは、多くのインスタンスで敵対因子を誘発する単純で普遍的な置換規則です。本論文では、機械理解、視覚的質問応答、感情分析の3つの分野における最先端のブラックボックスモデルのバグを検出することで、SEAとSEARの有用性と柔軟性を実証した。また、SEARは、人間の専門家が発見したバグの4倍のミスを誘発することを実証しました。また、SEARは実用的であり、データ増強を用いてモデルを再トレーニングすることで、精度を維持しながらバグを大幅に減らすことができます。
Q-learningに代表されるモデルフリー強化学習（RL）アルゴリズムは、環境を明示的にモデル化することなく、価値関数やポリシーを直接パラメータ化して更新します。これらは一般的に、モデルベースのアプローチよりもシンプルで柔軟に使用できるため、最新のディープRLでは普及している。しかし、モデルフリーのアルゴリズムは、学習に必要なサンプル数が多くなる可能性があることが経験的に示唆されている[Deisenroth and Rasmussen 2011, Schulman et al.2015]。モデルフリー・アルゴリズムをサンプル効率的にすることができるかどうか」という理論的な問題は、RLにおける最も基本的な問題の一つであり、有限個の状態と行動を持つ基本シナリオにおいても未解決である。ここで、SとAは状態と行動の数、Hはエピソードごとのステップ数、Tは総ステップ数である。このサンプル効率は，どのようなモデルベースのアプローチでも達成できる最適な後悔と，1つの要素まで一致しています．我々の知る限り、これはモデルフリーの設定で、"シミュレータ "へのアクセスを必要とせずに、"T "の後悔を確立した最初の分析です。
フローベースの生成モデル(Dinh et al., 2014)は、正確な対数尤度の扱いやすさ、正確な潜在変数の推論の扱いやすさ、学習と合成の両方の並列性により、概念的に魅力的です。本論文では、反転可能な1x1畳み込みを用いたシンプルなタイプの生成フローであるGlowを提案する。我々の手法を用いることで、標準的なベンチマークにおいて対数尤度が大幅に向上することを実証した。おそらく最も注目すべきは、単純な対数尤度目的に最適化された生成モデルが、大きな画像の効率的で現実的な合成と操作を可能にすることを実証したことである。我々のモデルのコードは、以下のURLから入手できます： https
我々は、深層ニューラルネットワークの異なる正規化層に異なる正規化器を選択することを学習するSwitchable Normalization（SN）を提案することで、正規化の学習問題に取り組んでいる。SNは、チャンネル、レイヤー、ミニバッチを含む3つの異なるスコープを用いて統計量（平均と分散）を計算します。SNは、エンド・ツー・エンドで重要度の重みを学習することで、それらを切り替えます。SNはいくつかの優れた特性を持っています。第一に、様々なネットワーク・アーキテクチャやタスクに適応できること（図1参照）。第2に、幅広いバッチサイズに対応しており、小さなミニバッチ（例：2画像/GPU）でも高い性能を維持します。3つ目は、グループ数をハイパーパラメータとして検索するグループ正規化とは異なり、SNは敏感なハイパーパラメータを持たないことです。SNは、ImageNet、COCO、CityScapes、ADE20K、Kineticsなどの様々なチャレンジングなベンチマークにおいて、ベルやホイッスルを使わずに、カウンターパートよりも優れた性能を発揮します。また、SNの分析結果も紹介されています。SNが、深層学習における正規化技術の使用と理解を容易にする一助となることを願っています。SNのコードはこのhttpsのURLで公開されています。
本論文では、実世界のシーンの写真を漫画風の画像に変換するためのソリューションを提案しています。これは、コンピュータビジョンやコンピュータグラフィックスにおいて貴重で挑戦的なものです。我々の解決策は、最近、絵画のような芸術的な形で画像を様式化するために普及している学習ベースの手法に属するものである。しかし、既存の手法では、カートゥーン化において満足のいく結果が得られていない。その理由として、(1)カートゥーンスタイルは高度な単純化と抽象化を伴うユニークな特徴を持っていること、(2)カートゥーン画像は明確なエッジ、滑らかなカラーシェーディング、比較的単純なテクスチャを持つ傾向があり、既存の手法で使用されているテクスチャディスクリプタベースの損失関数にとって大きな課題となっていることが挙げられる。本論文では，カートゥーンのスタイル化のための生成的敵対ネットワーク（GAN）フレームワークであるCartoonGANを提案する．我々の手法では、ペアになっていない写真と漫画の画像を学習に用いるため、簡単に利用できる。漫画化に適した2つの新しい損失を提案する。(1)セマンティックコンテンツロスは、VGGネットワークの高レベル特徴マップの疎な正則化として定式化され、写真と漫画の間の実質的なスタイルの変化に対処するものであり、(2)エッジ促進逆問題ロスは、明確なエッジを保存するものである。さらに、初期化フェーズを導入することで、ネットワークの目標多様体への収束性を向上させています。また、本手法は、既存の手法に比べてはるかに効率的に学習することができる。実験の結果、我々の手法は、実世界の写真から高品質のカートゥーン画像（特定のアーティストのスタイルに沿って、明確なエッジと滑らかなシェーディングを持つ）を生成することができ、最先端の手法よりも優れていることがわかった。
コピーメカニズムは、抽象的な文章の要約や質問の生成などのテキスト生成タスクのための、シーケンスからシーケンスに基づくニューラルネットワークモデルにおいて有効性を示しています。しかし、コピーやポインティングメカニズムのモデル化に関する既存の研究では、ソースセンテンスからの単一単語のコピーしか考慮されていない。本論文では、SeqCopyNet（Sequential Copying Networks）と名付けられた新しいコピーフレームワークを提案する。このフレームワークは、単一の単語をコピーすることを学習するだけでなく、入力文からシーケンスをコピーすることもできる。SeqCopyNetは、ソース側からターゲット側へのサブスパンを明示的に選択するためのポインタネットワークを活用し、このシーケンシャルコピーメカニズムをエンコーダ・デコーダパラダイムの生成プロセスに統合する。抽象的な文章の要約や質問の生成タスクを対象とした実験では、提案するSeqCopyNetが意味のあるスパンをコピーすることができ、ベースラインモデルよりも優れていることが示された。
人間が長い文書を要約する方法にヒントを得て、まず顕著な文を選択し、それを抽象的に書き換えて（すなわち、圧縮と言い換え）、簡潔な全体の要約を生成する、正確で高速な要約モデルを提案する。我々は、新しい文レベルの方針勾配法を用いて、言語の流暢性を維持しつつ、これらの2つのニューラルネットワーク間の非差別的な計算を階層的に橋渡しする。実証的には、CNN/Daily Mailデータセットにおいて、すべての評価指標（人間による評価を含む）で最先端の結果を得ることができ、抽象度のスコアも大幅に向上した。さらに、最初に文レベル、次に単語レベルで動作させることで、ニューラル生成モデルの並列デコーディングを可能にし、これまでの長パラグラフのエンコーダー・デコーダーモデルと比較して、推論速度が10～20倍、学習収束が4倍と大幅に向上した。また、テスト専用のデータセットであるDUC-2002において、本モデルの一般化を実証し、最先端のモデルよりも高いスコアを得ることができました。
自然言語を理解するためには、常識的な知識や背景知識が必要であるが、多くのニューラル自然言語理解（NLU）システムでは、これらの知識は学習時に訓練コーパスから獲得しなければならず、テスト時には静的なものとなってしまう。本研究では、NLUモデルに明示的な背景知識を動的に統合するための新しいアーキテクチャを紹介する。汎用の読解モジュールは、自由文の形で背景知識を読み取り（タスク固有のテキスト入力も一緒に）、洗練された単語表現をタスク固有のNLUアーキテクチャに与えることで、タスクの入力をこれらの表現で再処理する。文書質問応答（DQA）とテキストの含意関係の認識（RTE）の実験により、本アプローチの有効性と柔軟性が実証された。分析の結果、我々のモデルは、意味的に適切な方法で知識を利用することを学習することがわかった。
機械学習モデルはその複雑な性質のため、導入時に誤動作や悪用される可能性のある方法を特徴づけることは困難です。最近の研究では、モデルの予測値が大きく異なるような小さな摂動を持つ入力など、敵対的な例を用いることで、モデルが失敗する敵対的なシナリオを明らかにし、モデルの頑健性を評価することができます。しかし、このような悪意のある摂動は、不自然であったり、意味的に意味のないものであったり、言語のような複雑な領域には適用できないことが多い。本論文では、生成的敵対ネットワークの最近の進歩を利用して、高密度で連続的なデータ表現の意味空間を探索することにより、データ多様体上に存在する自然で読みやすい敵対例を生成するフレームワークを提案する。生成された敵対例を提示することで、画像分類、テキストの裏付け、機械翻訳などの幅広いアプリケーションのブラックボックス分類器に対する提案手法の可能性を示す。また、生成された敵対物は自然で、人間が読んでも判読可能であり、ブラックボックス分類器の評価・分析に有用であることを示す実験も行っています。
隠れ層ごとに1つのニューロンを持つモジュールを積み重ね、活性化関数をReLUとした非常に深いResNetは、$d$次元のあらゆるルベーグ積分可能な関数を一様に近似できることを実証しました。ResNetsに固有のアイデンティティーマッピングにより、我々のネットワークは1次元と$d$次元の層を交互に持っています。これは、その幅が入力次元$d$である場合、普遍的な近似器ではない完全連結ネットワークとは対照的です[Lu et al, 2017; Hanin and Sellke, 2017]。したがって、私たちの結果は、ResNetアーキテクチャによって狭義の深層ネットワークの表現力が向上することを意味します。
読解モデルは、文書のトークンを逐次処理するリカレントニューラルネットワークに基づいています。しかし、より複雑な質問への回答が求められるようになると、テキストの大部分を逐次処理することが大きなボトルネックとなります。本研究では、人間が文書構造を利用する方法にヒントを得て、読解のための新しいフレームワークを提案する。本研究では、文書を木として表現し、文書の木を素早くナビゲートすることと、より高価な回答を抽出することを学習するエージェントをモデル化する。文書ツリーの探索を促進するために、Deep Q-Network (DQN)に基づいた新しいアルゴリズムを提案する。経験的に、我々のアルゴリズムは、DQNや強力な情報検索（IR）ベースラインと比較して、質問応答性能を向上させ、我々のモデルとIRベースラインをアンサンブルすることで、さらに性能を向上させることがわかった。
畳み込みニューラルネットワーク（CNN）は、一般的に、小さな画像変換に対して不変であると考えられている。これは、畳み込みアーキテクチャのため、あるいはデータ補強を用いて学習されたためである。しかし，最近になって，そうではないことが明らかになった．入力画像の小さな変換やリスケールが，ネットワークの予測を大きく変えてしまうのである．本論文では，この現象を定量化し，なぜ畳み込みアーキテクチャやデータ補強では望ましい不変性を達成できないのかを考察する．具体的には、畳み込みアーキテクチャは古典的なサンプリング定理を無視したアーキテクチャであるため不変性が得られず、データ増強はCNNが学習セットからの典型的な画像と非常によく似た画像に対してのみ変換に不変であることを学習するため、不変性が得られないことを示している。この問題の解決策として、(1)中間表現にアンチエイリアスをかける、(2)データ増強量を増やす、という2つの方法が考えられるが、これらはせいぜい部分的な解決にしかならないことを示している。これらの結果は、ニューラルネットワークにおいて、高い精度を維持しつつ、小さな画像変換に対する不変性を確保するという問題が未解決であることを示している。
逆強化学習（IRL）は、エージェントの方針や観察された行動から、エージェントの報酬関数を推論する問題です。RLと同様に、IRLは問題としても手法のクラスとしても認識されています。本論文は、IRLに関する現在の文献を分類的に調査することで、機械学習をはじめとする研究者や実務者がIRLの課題を理解し、目前の問題に最適なアプローチを選択するための参考資料となる。本論文では、正確な推論とその一般化が困難であること、事前の知識に敏感であること、問題の大きさに比例して解答の複雑さが増大することなどの中心的な課題とともに、IRL問題を正式に紹介しています。この記事では、現在の手法がこれらの課題をどのように軽減しているかを詳しく説明しています。さらに、不正確で不完全な認識、不完全なモデル、複数の報酬関数、非線形の報酬関数を扱うための伝統的なIRL手法の拡張についても説明する。最後に、この研究分野における大まかな進歩と、現在の未解決の研究課題について議論する。
本論文では、アーキテクチャ探索のスケーラビリティの課題を解決するために、タスクを微分可能な方法で定式化しています。離散的で微分不可能な探索空間上で進化や強化学習を適用する従来のアプローチとは異なり、本手法はアーキテクチャ表現の連続的な緩和に基づいており、勾配降下法を用いた効率的なアーキテクチャの探索が可能である。CIFAR-10, ImageNet, Penn Treebank, WikiText-2を用いた大規模な実験により、我々のアルゴリズムが、画像分類のための高性能な畳み込みアーキテクチャや、言語モデリングのためのリカレントアーキテクチャの発見に優れていること、また、最先端の非可分な手法よりも数桁速いことが示された。効率的なアーキテクチャ探索アルゴリズムの研究を促進するために、我々の実装は一般に公開されている。
本研究では、効果的かつ効率的なニューラルシーケンスラベリングシステムを構築するための設計上の課題を、最先端の構造のほとんどを含む12のニューラルシーケンスラベリングモデルを再現し、3つのベンチマーク（NER、Chunking、POS tagging）で系統的なモデル比較を行うことで明らかにしました。既存の文献にある誤解や矛盾した結論は、統計的実験の下で検証され、明らかにされる。比較・分析の過程で、実務者にとって有用ないくつかの実用的な結論を得ることができた。
人間や動物は、他の人がその技術を行うのを一度だけ見て、新しい行動を学ぶことができます。我々は、ロボットと観察された人間との間に、視点、環境、体格などの大幅な領域のずれがある場合でも、ロボットが同じように、人間の生のビデオピクセルから学習できるようにするという問題を考えます。この問題に対する従来のアプローチでは、人間とロボットの動作がどのように対応するかを手動で指定したり、明示的な人間のポーズ検出システムに依存することが多かった。本研究では、過去の様々なタスクで得られた人間とロボットのデモンストレーションデータを用いて、メタ学習により事前知識を蓄積することで、人間の映像からワンショットで学習するアプローチを提示します。そして、この事前知識と、人間からのたった一度の実演映像を組み合わせることで、人間が実演したタスクをロボットが実行することができる。PR2アームとSawyerアームを用いて実験を行い、メタ学習の後、人間が操作している1つのビデオだけで、ロボットが新しい物体の配置、押し出し、ピックアンドプレースを学習できることを示した。
我々は、中国語の単語埋め込みを学習する新しい手法であるcw2vecを提案する。この手法は、ストロークレベルの情報を利用することが、中国語の単語埋め込みの学習を向上させるために重要であるという我々の観察に基づいています。具体的には、中国語の単語の意味および形態素レベルの情報をキャプチャするストロークNグラムを使用して、そのような特徴を利用するための最小限のアプローチを設計します。定性的な分析を通して、我々のモデルが既存の手法では捉えることができない意味的な情報を抽出できることを示す。単語の類似性、単語の類推、テキスト分類、名前付き実体認識の各タスクにおける実証実験の結果、提案手法は、単語ベースのword2vecやGloVe、文字ベースのCWE、コンポーネントベースのJWE、ピクセルベースのGWEといった最先端の手法を一貫して凌駕することがわかった。
異なるニューラルネットワークの表現を比較し、表現が時間とともにどのように進化するかを決定することは、ニューラルネットワークの機能を理解する上で、依然として困難な未解決問題です。ニューラルネットワークの表現を比較することは、表現の構造が、同じタスクで学習されたネットワークのグループ間でも、また、学習の過程でも、大きく異なるため、基本的に困難です。ここでは、最近提案された手法であるSVCCAをベースにして、ニューラルネットワークを理解するためのツールとして投影加重CCA（Canonical Correlation Analysis）を開発する（Raghu et al.） まずコアとなる手法を改良し、信号とノイズを区別する方法を示し、この手法をCNN群全体の比較に適用し、一般化するネットワークは記憶するネットワークよりも類似した表現に収束すること、幅の広いネットワークは幅の狭いネットワークよりも類似した解に収束すること、トポロジーは同じだが学習率が異なる学習済みのネットワークは多様な表現を持つ異なるクラスタに収束することを実証します。また、RNNの表現ダイナミクスを学習時とシーケンス時の両方で調べたところ、RNNは学習時にボトムアップパターンで収束し、線形変換を考慮してもシーケンス時には隠れた状態が大きく変化することがわかった。これらの結果は、CNNとRNNの機能について新たな洞察を与え、CCAを使って表現を理解することの有用性を示している。
現代の深層伝達学習アプローチは、あるタスクから他のタスクに伝達可能な一般的な特徴ベクトルを学習することに主眼を置いてきた。例えば、言語における単語埋め込みや視覚における事前学習済みの畳み込み特徴などである。しかし、これらのアプローチは通常、単項の特徴を転送し、より構造化されたグラフィカルな表現をほとんど無視している。本研究では、大規模なラベルなしデータから、単語やピクセルなどのデータ単位のペア間の依存関係をキャプチャする一般的な潜在的関係グラフを学習し、下流のタスクにグラフを転送する可能性を探る。我々が提案する転移学習フレームワークは、質問応答、自然言語推論、感情分析、画像分類などの様々なタスクにおいて性能を向上させる。また、学習されたグラフは、グラフが学習されていない異なる埋め込み（GloVe埋め込み、ELMo埋め込み、タスク固有のRNN隠れユニットを含む）や、画像ピクセルのような埋め込みのないユニットに転送するのに十分な汎用性があることを示す。
本論文では、Self-Imitation Learning (SIL)を提案する。これは、エージェントの過去の良い決定を再現するように学習する、シンプルなオフポリシーのアクター批判アルゴリズムである。このアルゴリズムは、過去の良い経験を利用することで、間接的に深い探索を促すことができるという我々の仮説を検証するために設計されている。実証実験の結果、SILは、いくつかの難しい探索ゲームであるAtariゲームにおいて、Advantage Actor-Critic (A2C)を大幅に改善し、最先端のカウントベースの探索手法に対抗できることがわかった。また、MuJoCoタスクにおいて、SILが近位政策最適化（PPO）を改善することも示しています。
新しい文の埋め込み手法が急速に開発されているにもかかわらず、これらの様々な手法の包括的な評価を見つけることは困難です。ここ数年、文の埋め込みの分野では、特に、さまざまな下流のタスクに帰納的に移行できる汎用的な文のエンコーダーの開発に向けて、大きな進歩が見られました。本研究では、様々な下流のタスクや言語的特徴を調べるタスクを用いて、最近の手法を総合的に評価しました。その結果、最近導入された深い文脈依存の単語埋め込み用の言語モデルを用いたbag-of-wordsを用いたシンプルなアプローチが、エンテリジェントデータセットで学習した文エンコーダと比較して、多くのタスクで優れた結果をもたらすことがわかった。しかし、下流のいくつかのタスクで一貫した性能を発揮できる万能なエンコーダーには、まだ程遠いことも示された。
ニューラルネットワークを用いた単語埋め込みの計算が成功したことで、文や段落などの長いテキストの意味的埋め込みを生成する方法が生まれた。驚くべきことに、Wietingら（ICLR'16）は、このような複雑な手法が、特にアウトオブドメイン（伝達学習）の設定において、単語埋め込みのマイルドな再学習と基本的な線形回帰を含むより単純な手法に勝ることを示した。Wietingらの手法では、Paraphrase Database (Ganitkevitch et al., 2013)のような実質的なラベル付きデータセットを用いた再学習が必要である。  今回の論文では、さらに進んで、次のような完全に教師なしの文の埋め込みが、手ごわいベースラインであることを示している。Wikipediaのようなラベルのないコーパスで一般的な手法の1つを用いて計算した単語埋め込みを使用し，単語ベクトルの加重平均で文を表現し，PCA/SVDを用いてそれらを少し修正する．この重み付けにより、テキストの類似性タスクにおいて10%から30%程度性能が向上し、RNNやLSTMなどの洗練された教師付き手法を打ち負かすことができます。また、Wietingらのエンベッディングも改善されました。  このシンプルな手法は、ラベル付きの学習データが少ない、あるいは存在しない場合には、今後のベースラインとして使用されるべきである。  この論文は、Aroraら（TACL'16）のモデルを単純に拡張したもので、文脈から外れて発生する単語や、すべての文脈ではないandのような単語の高い確率を許容する新しい「平滑化」項を加えた、文の潜在変数生成モデルを用いて、上記の教師なし手法の成功を理論的に説明しています。
我々は、複数の語義、サブワード構造、不確実性情報を捉えることができる単語埋め込みの新しいモデルであるProbabilistic FastTextを紹介する。具体的には、各単語をガウス混合密度で表現し、混合成分の平均はn-gramの総和で与えられる。この表現により、モデルはサブワード構造（ラテン語の語根など）間で統計的な強さを共有することができ、希少な単語、スペルミスのある単語、さらには見たことのない単語の正確な表現が可能になります。さらに、混合物の各コンポーネントは、異なる語義を捉えることができます。確率論的FastTextは、確率論的モデルを持たないFastTextと、サブワード構造を取り込まない辞書レベルの確率論的埋め込みの両方を、英語のRareWordや外国語のデータセットを含むいくつかの単語類似性のベンチマークで上回りました。また，異なる意味を識別する能力を測定するベンチマークにおいても，最先端の性能を達成した．このように、提案モデルは、希少な単語のセマンティクスを強化しつつ、マルチセンス表現を実現した初めてのモデルです。
深層学習は、多くの自然言語処理（NLP）タスクの性能を個別に向上させてきた。しかし、一般的なNLPモデルは、単一のメトリック、データセット、およびタスクの特殊性に焦点を当てたパラダイムの中では生まれません。ここでは、質問応答、機械翻訳、要約、自然言語推論、感情分析、意味的役割のラベリング、ゼロショット関係抽出、目標指向型対話、意味的構文解析、常識的代名詞の解決という10のタスクを対象とした「自然言語十種競技」（デカNLP）を紹介する。また、すべてのタスクを文脈上の質問応答とみなします。さらに、新しいマルチタスク質問応答ネットワーク(MQAN)は、マルチタスク設定において、タスク固有のモジュールやパラメータなしに、decaNLPのすべてのタスクを共同で学習する。MQANは、機械翻訳と名前付き実体認識のための伝達学習、感情分析と自然言語推論のためのドメイン適応、テキスト分類のためのゼロショット能力の向上を示す。我々は、MQANのマルチポインター生成デコーダがこの成功の鍵であることを実証し、アンチカリキュラムトレーニング戦略によって性能がさらに向上することを示した。DecaNLP用に設計されたMQANは、シングルタスク設定のWikiSQL意味解析タスクでも最先端の結果を達成しています。また、データの調達と処理、モデルの学習と評価、およびDecaNLPのすべての実験を再現するためのコードも公開しています。
有限マルコフ決定過程（MDP）における遅延報酬のための新しい強化学習アプローチであるRUDDERを提案しています。MDPでは、Q値は期待される即時の報酬に期待される将来の報酬を加えたものになります。後者は、時間差（TD）学習におけるバイアスの問題や、モンテカルロ（MC）学習における高分散の問題に関連する。どちらの問題も、報酬が遅れるとさらに深刻になります。RUDDERは、将来の期待報酬をゼロにすることで、Q値の推定を当面の報酬の平均値の計算に単純化することを目的としています。私たちは、期待される将来の報酬をゼロにするために、以下の2つの新しい概念を提案します。(i) 報酬の再分配は、同じ最適政策を持つリターン同等の決定プロセスをもたらし、最適な場合には、期待される将来の報酬をゼロにする。(ii)強化学習タスクを深層学習が得意とする回帰タスクに変換する貢献度分析による報酬分解。報酬が遅延する人工的なタスクにおいて、RUDDERはMCよりも有意に速く、モンテカルロ木探索（MCTS）、TD（{lambda}）、報酬整形アプローチよりも指数関数的に速い。また、RUDDERをProximal Policy Optimization (PPO)のベースラインに乗せることで、スコアが向上しました（報酬が遅延するゲームで顕著）。ソースコードは ˶ˆ꒳ˆ˵ ) デモ映像は ˶ˆ꒳ˆ˵ )
視覚的タスクには関係があるのでしょうか、それとも関係がないのでしょうか。例えば、サーフェイスの法線があれば、画像の奥行きを簡単に推定できるのではないか？直感はこれらの質問に肯定的に答え、視覚的タスクの間に構造が存在することを示唆しています。この構造を知ることは、伝達学習の基礎となる概念であり、タスク間の冗長性を識別するための原理的な方法を提供します。例えば、関連するタスク間で監督をシームレスに再利用したり、複雑さを積み重ねることなく1つのシステムで多くのタスクを解決したりすることができます。我々は、視覚タスクの空間の構造をモデル化するための完全な計算アプローチを提案します。これは、26個の2D、2.5D、3D、意味的タスクの辞書を使って、潜在的な空間における（1次および高次の）伝達学習の依存関係を見つけることによって行われる。その結果、タスク伝達学習のための計算機上の分類マップが完成します。我々は、この構造の結果（例えば、自明ではない出現した関係）を研究し、ラベル付きデータの需要を減らすためにそれらを利用する。例えば、10個のタスクを解決するために必要なラベル付きデータポイントの総数は、性能をほぼ維持したまま、（独立して学習する場合に比べて）約2/3に減らすことができることを示しています。また、この分類構造を計算して調べるためのツールを提供しており、ユーザーがユースケースに応じた効率的な監視ポリシーを考案するために利用できるソルバーも備えています。
深層ニューラルネットワークは、様々なアプリケーションの進歩を可能にしてきました。ニューラルネットワークのサイズを大きくすると、一般的に精度が向上します。しかし、モデルのサイズが大きくなると、これらのモデルをトレーニングするために必要なメモリと計算量も増加します。本研究では、半精度浮動小数点数を用いてディープニューラルネットワークを学習する手法を紹介します。この手法では、重み、活性化、勾配をIEEEの半精度フォーマットで保存します。半精度浮動小数点数は、単精度浮動小数点数に比べて数値範囲が限られています。この情報の損失を処理するために、2つの技術を提案します。まず，オプティマイザの各ステップの後に，勾配を蓄積した重みの単精度コピーを維持することを推奨します．この単精度コピーは、学習時に半精度フォーマットに丸められます。次に，半精度の勾配による情報の損失を処理するために，損失を適切にスケーリングすることを提案します．この手法は、畳み込みニューラルネットワーク、リカレントニューラルネットワーク、生成的逆説ネットワークなど、さまざまなモデルで動作することを実証しました。この手法は、大規模なデータセットで学習した1億個以上のパラメータを持つ大規模なモデルに対しても有効です。この手法を用いることで、深層学習モデルのメモリ消費量を2倍近くまで削減することができます。また、将来のプロセッサでは、半精度のハードウェアユニットを使用することで、大幅な計算速度の向上が期待できます」と述べています。
音楽は、言葉が足りないときに感情を伝えるためによく使われる、表現力豊かなコミュニケーション手段です。音楽は、言葉が足りないときに感情を伝えるための表現手段であり、その情報の一部は、明確な言語が存在する楽曲の中にあります。しかし、演奏中には、音楽家が曲を解釈することによって、かなりの量の情報が追加されます。演奏者は、ダイナミクスやテンポなどの異なる音楽的特性を変化させることで、書かれたスコアに表現力を加えます。本論文では、楽譜の演奏を学習するモデルについて説明します。我々の研究では、生成された演奏は人間の演奏と区別がつかず、「音楽的チューリングテスト」の精神に基づいたテストに合格すると結論づけている。
ポジティブなサンプルとネガティブなサンプルを対比させて学習する方法は、多くの手法で採用されている一般的な戦略です。単語埋め込みのためのNoise contrastive estimation (NCE)や知識グラフのための埋め込みの翻訳は、このアプローチを採用したNLPの例です。本研究では、コントラスト学習をこのような手法の抽象化と捉え、ネガティブサンプラーを、敵対的に学習されたサンプラーを含む混合分布に増強する。結果として得られる適応的サンプラーは、より困難な負の例を見つけ、主要モデルにデータのより良い表現を学習させる。我々の提案を、単語埋め込み、順序埋め込み、知識グラフ埋め込みの学習で評価したところ、収束の速さと、複数の指標での結果の改善が見られた。
本研究では、専門家のフィードバックを効果的に活用して、逐次的な意思決定方針を学習する方法を研究する。本研究では、強化学習において重要な課題である、報酬が疎で時間軸が長い問題に焦点を当てる。本研究では、階層型ガイダンスと呼ばれるアルゴリズムフレームワークを提案する。これは、基礎となる問題の階層構造を利用して、専門家の様々な相互作用を統合するものである。このフレームワークは、異なるレベルの模倣学習（IL）と強化学習（RL）の異なる組み合わせを組み込むことができ、専門家の労力と探索コストの両方を劇的に削減することができる。Montezuma's Revengeなどの長期的なベンチマークを用いて、我々のアプローチは階層的なRLよりも大幅に速く学習でき、標準的なILよりも大幅にラベル効率が良いことを実証した。また、我々のフレームワークの特定のインスタンスに対するラベリングコストを理論的に分析した。
シーン表現（視覚的な感覚データを簡潔な記述に変換するプロセス）は、知的な行動のための必要条件である。最近の研究では、大規模なラベル付きデータセットを用いた場合、ニューラルネットワークがこのタスクに優れていることが示されている。しかし、人間によるラベル付けへの依存を排除することは、依然として重要な未解決問題である。そこで本研究では、機械が自分のセンサーだけを使ってシーンを表現することを学習するフレームワーク「Generative Query Network（GQN）」を紹介する。GQNは、さまざまな視点から撮影されたシーンの画像を入力とし、内部表現を構築し、この表現を用いて、以前に観察されなかった視点からのシーンの外観を予測することができる。GQNは、人間のラベルやドメイン知識を必要としない表現学習を実証しており、周囲の世界を理解するために自律的に学習する機械への道を開いている。
セマンティックセグメンテーションは、ロボット関連のアプリケーション、特に自律走行に役立ちます。セマンティックセグメンテーションに関する研究のほとんどは、セグメンテーションモデルの精度を高めることにのみ重点が置かれており、計算効率の高いソリューションについてはほとんど注目されていません。また、セマンティックセグメンテーションに関する研究では、セマンティックセグメンテーションの様々な設計上の選択を評価するための原理的な方法が提供されていない。本論文では、このギャップを解消するために、特徴抽出とデコーディングの手法を分離したリアルタイムセマンティックセグメンテーションのベンチマークフレームワークを提案します。このフレームワークは、VGG16、Resnet18、MobileNet、ShuffleNetといった特徴抽出用の異なるネットワーク・アーキテクチャで構成されています。また、デコーディング手法を定義するセグメンテーション用の複数のメタ・アーキテクチャから構成されています。これらにはSkipNet、UNet、Dilation Frontendなどがあります。実験結果は、都市景観のデータセット「Cityscapes」で示されています。このベンチマークフレームワークは、"this https URL "で公開されています。
現実世界の視覚問題の多くは、固有の曖昧さに悩まされています。例えば、臨床分野では、CTスキャンだけでは、どの領域が癌組織であるかがわからない場合があります。そのため、採点者のグループは、多様ではあるがもっともらしいセグメンテーションのセットを作成するのが一般的である。我々は、入力が与えられたときに、セグメンテーションの分布を学習するという課題を考える。この目的のために、我々はU-Netと条件付き可変オートエンコーダーの組み合わせに基づいた生成セグメンテーションモデルを提案する。このモデルは、無制限にもっともらしい仮説を効率的に生成することができる。肺の異常のセグメンテーションタスクと都市景観のセグメンテーションタスクにおいて、我々のモデルは、可能性のあるセグメンテーションのバリエーションとそれらが発生する頻度を再現し、既存のアプローチよりもはるかに優れていることを示した。これらのモデルは、複数のもっともらしいセマンティックセグメンテーション仮説を考慮して、可能性のある診断を提供し、現在の曖昧さを解決するための更なる行動を推奨する臨床意思決定アルゴリズムとして使用されるなど、実世界のアプリケーションに大きな影響を与える可能性があります。
畳み込みニューラルネットワークは、複雑な学習課題に取り組むために必要な、強力な表現空間を学習することができます。畳み込みニューラルネットワークは、複雑な学習課題に取り組むために必要な強力な表現空間を学習することができるが、このような表現を取り込むために必要なモデルの容量が大きいため、オーバーフィッティングの影響を受けやすく、一般化するためには適切な正則化が必要である。本論文では、学習時に入力の四角い領域をランダムにマスクするという単純な正則化手法（これをカットアウトと呼ぶ）を用いることで、畳み込みニューラルネットワークのロバスト性と全体的な性能を向上させることができることを示す。この手法は非常に簡単に実装できるだけでなく、既存のデータ補強や他の正則化手法と組み合わせて使用することで、モデルの性能をさらに向上させることができることを示している。CIFAR-10、CIFAR-100、SVHNの各データセットにおいて、この手法を現在の最先端のアーキテクチャに適用して評価したところ、テストエラーがそれぞれ2.56％、15.20％、1.30％という最先端の結果が得られました。コードはこのhttpsのURLから入手できます。
人間の3Dポーズシーケンスを予測・生成するための深層学習は、活発な研究分野です。これまでの研究では、関節の回転または関節の位置のいずれかを回帰していました。前者は、運動連鎖に沿って誤差が蓄積されやすく、オイラー角や指数マップのパラメータ化を用いた場合には不連続になりやすい。後者は、骨の伸縮や無効な構成を避けるために、スケルトンの制約に再投影する必要があります。本研究では、この2つの制限に対処しています。我々の再帰ネットワークであるQuaterNetは、回転を四元数で表現し、損失関数はスケルトン上でフォワードキネマティクスを実行して、角度誤差の代わりに絶対位置誤差をペナルティとして課す。短期的な予測では、QuaterNetは最先端の技術を定量的に改善します。長期的な生成においては、我々のアプローチは、グラフィックスの文献にある最近のニューラル戦略と同様に、質的に現実的であると判断される。
我々は、出力が入力要素のシーケンスとして表現される組み合わせ最適化問題を解くためのフレームワークを提案します。ポインタネットワークの代わりに，（グラフ）注目層のみに基づいたモデルで方針をパラメータ化し，学習中に見つかった最良の方針を決定論的に（貪欲に）展開するシンプルでロバストなベースラインを用いて，REINFORCEを用いて効率的に学習します。その結果，2次元ユークリッドTSPの学習アルゴリズムに関する最先端の結果を大幅に改善し，単一のツアー構築に対する最適性のギャップを，ノード数が20および50のインスタンスにおいて，それぞれ75％（0.33％）および50％（2.28％）以上低減することができた．
顕著性マップを抽出する現在の方法は、特定の固定された分類器にとって最も重要な入力の部分を特定します。我々は，このような分類器への強い依存性が，手法の性能を低下させることを示します．この問題を解決するために，我々は分類器に依存しない saliency map 抽出を提案する．この方法では，事前に与えられた分類器だけでなく，どの分類器でも使用できる画像のすべての部分を見つける．提案手法は、概念的にシンプルで実装が容易でありながら、先行研究よりも高品質な saliency map を抽出することが観察された。提案手法は、ImageNetデータのローカライズタスクにおいて、推論時にグランドトゥルースラベルを使用していないにもかかわらず、既存の弱教師付きローカライズ手法を凌駕するという新しい結果を得ました。この結果を再現したコードは、このhttpsのURLで公開されています。
近年、グラフ構造を持つデータに対する深層ニューラルネットワークの進歩により、推薦システムのベンチマークにおいて最先端の性能を発揮するようになりました。しかし，これらの手法を実用化し，数十億のアイテムと数億のユーザを持つウェブスケールの推薦タスクにスケーラブルに対応させることは，依然として困難である．ここでは、私たちが開発し、Pinterestに導入した大規模なディープ・レコメンデーション・エンジンについて説明します。我々は、データ効率の良いグラフ畳み込みネットワーク（GCN）アルゴリズムPinSageを開発した。PinSageは、効率的なランダムウォークとグラフ畳み込みを組み合わせて、ノード（アイテム）の埋め込みを生成し、グラフ構造とノードの特徴情報の両方を組み込む。従来のGCNアルゴリズムと比較して、高効率なランダムウォークに基づいて畳み込みを構成する新しい手法を開発し、モデルのロバスト性と収束性を向上させるために、より困難なトレーニング例に依存する新しいトレーニング戦略を設計している。また、学習されたモデルを用いてエンベッディングを生成するために、効率的なMapReduceモデル推論アルゴリズムを開発した。PinSageはPinterestに導入され、ピンとボードを表す30億のノードと180億のエッジを持つグラフ上の75億の例で学習されます。オフラインメトリクス、ユーザー調査、A/Bテストによると、PinSageは同等の深層学習やグラフベースの代替モデルよりも高品質なリコメンデーションを生成します。我々の知る限り、これはグラフ埋め込みの最大の応用例であり、グラフ畳み込みアーキテクチャに基づく新世代のウェブスケール推薦システムへの道を開くものです。
コモンセンス推論は、深層学習の長年の課題です。例えば、ニューラルネットワークを用いてWinograd Schemaデータセットに取り組むことは困難である(Levesque et al., 2011)。本論文では、教師なし学習を用いて、ニューラルネットワークでコモンセンス推論を行うための簡単な手法を紹介する。この手法では、大量の教師なしデータで学習した言語モデルを用いて、常識的推論テストの多肢選択問題を採点することが重要である。Pronoun DisambiguationとWinograd Schemaの両方の課題において、我々のモデルは、高価な注釈付きの知識ベースや手作業で作成した特徴を使用せずに、これまでの最先端の手法を大差で凌駕した。我々は、LM-1-Billion、CommonCrawl、SQuAD、Gutenberg Books、およびこの課題のためにカスタマイズされたコーパスを用いて、単語または文字レベルで動作する大規模なRNN言語モデルの配列を学習し、学習データの多様性がテスト性能に重要な役割を果たすことを示した。また、本システムは、正解を決定する文脈の重要な特徴を発見することに成功しており、常識的な知識をよく理解していることを示しています。
自然言語理解には、含意関係、質問応答、意味的類似性評価、文書分類などの多様なタスクがあります。ラベルのない大規模なテキストコーパスは豊富にありますが、これらのタスクを学習するためのラベル付きデータは少なく、識別的に学習されたモデルが十分な性能を発揮することは困難です。本研究では、ラベルなしテキストの多様なコーパスを用いて言語モデルを生成的に事前学習した後、各タスクについて識別的に微調整することで、これらのタスクで大きな成果を上げることができることを示した。これまでのアプローチとは異なり，我々は微調整の際にタスクを意識した入力変換を行うことで，モデルアーキテクチャの変更を最小限に抑えながら効果的な伝達を実現する．本研究では、自然言語理解のための広範なベンチマークを用いて、本アプローチの有効性を実証した。タスクに依存しない一般的なモデルは，各タスクに特化したアーキテクチャを用いて識別的に学習されたモデルよりも優れており，研究対象となった12のタスクのうち9つのタスクで技術水準を大幅に向上させることができた．例えば、常識的な推論（Stories Cloze Test）では8.9％、質問応答（RACE）では5.7％、テキストの含意関係（MultiNLI）では1.5％の絶対値の向上を達成した。
現実世界の逐次的な意思決定問題の多くは、もともと部分的に観測可能であり、環境モデルは通常未知である。そのため、不完全でノイズの多い観測データのみが与えられた場合でも、このような問題に取り組むことができる強化学習手法が必要とされている。本論文では、エージェントが環境の生成モデルを学習し、利用可能な情報を効果的に集約するためにそのモデルで推論を行うことを可能にする帰納的バイアスを導入した深層可変強化学習（DVRL）を提案する。本研究では、モデルを政策と一緒に学習させることで、n-ステップの近似式であるEvidence lower bound (ELBO)を開発しました。これにより、潜在的な状態の表現が制御タスクに適していることが保証される。Mountain HikeとFlickering Atariを用いた実験では、我々の手法が、過去をエンコードするためにリカレント・ニューラル・ネットワークに依存していた従来のアプローチよりも優れていることを示した。
畳み込みニューラルネットワークは、コンピュータビジョンシステムに広く採用されており、さまざまな視覚認識タスクに応用されています。このような進歩は、畳み込み層の基本的な考え方が変わっていないにもかかわらず、畳み込みニューラルネットワークのアーキテクチャや学習アルゴリズムが進歩したことによってもたらされています。本論文では、最新の視覚認識モデルの主力となっている畳み込み層を再検討します。畳み込み層の代わりに、「摂動層」と呼ばれる非常にシンプルで効果的なモジュールを導入します。摂動層は、伝統的な意味での畳み込みを行わず、その代わりに、非線形活性化された加法性雑音による摂動入力の重み付き線形結合として応答を計算する。我々は、この摂動層が標準的な畳み込み層の効果的な代替となることを分析的および経験的に示した。経験的に、畳み込み層の代わりに摂動層を持つ深層ニューラルネットワークは、PNN（Perturbative Neural Networks）と呼ばれ、様々な視覚データセット（MNIST、CIFAR-10、PASCAL VOC、ImageNet）において、少ないパラメータで標準的なCNNと同等の性能を発揮する。
逆問題学習は，教師付き学習アルゴリズムを正則化する手段であり，仮想逆問題学習は，教師付き学習アルゴリズムを半教師付きの設定に拡張することができる．しかし、どちらの方法も、入力ベクトルの多数のエントリに小さな摂動を加える必要があり、ワンショットの単語表現のような疎な高次元の入力には不適切である。本研究では，敵対的学習および仮想敵対的学習をテキスト領域に拡張し，元の入力そのものではなく，リカレントニューラルネットワーク内の単語埋め込みに摂動を加えることで，敵対的学習および仮想敵対的学習を実現する．提案手法は、半教師付きおよび純粋教師付きの複数のベンチマークタスクにおいて、最先端の結果を達成した。また、学習した単語埋め込みの品質が向上したこと、学習中にモデルがオーバーフィッティングしにくくなったことを視覚化して分析しています。
深層強化学習は、アタリゲームのような視覚ベースの問題に適用され、ピクセルをアクションに直接マッピングします。深層ニューラルネットワークは、有用な情報を抽出し、それに基づいて意思決定を行う責任を内部で負っています。画像処理と意思決定を分離することで、それぞれのタスクの複雑さをよりよく理解することができます。また、人間にとって理解しやすく、より一般化しやすい小さな政策表現を見つけることができる可能性があります。この目的のために、我々は強化学習における政策近似のために、政策とコンパクトな状態表現を別々に、かつ同時に学習する新しい方法を提案する。状態表現は、2つの新しいアルゴリズムに基づいたエンコーダによって生成される。直接残差スパースコーディングは、再構成誤差の最小化を無視し、代わりに最高の情報包含を目指して観測値を符号化する。エンコーダーは、コードのスパース性を最大化するために、オンラインで学習する観測値を自律的に選択します。辞書サイズが大きくなると、エンコーダーはニューラルネットワークの入力をどんどん大きくしていきます。これは、Exponential Natural Evolution Strategiesアルゴリズムのバリエーションで対応しており、実行中に確率分布の次元を適応させていきます。6〜18個のニューロンを持つ小さなニューラルネットワークを使って、Atari社のゲームでこのシステムをテストしました。その結果、2桁以上のニューロンを使用した最先端の技術に匹敵する、時にはそれ以上の結果を得ることができました。
記憶型ニューラルネットワークは、情報を長期間記憶する能力を利用して、時間的なデータをモデル化する。しかし、記憶した情報に対して複雑な関係推論を行う能力があるかどうかは不明である。ここではまず、標準的な記憶アーキテクチャが、実体のつながりを理解することが重要な課題、すなわち関係推論を伴う課題に苦戦する可能性があるという直観を確認した。次に、このような問題を改善するために、新しいメモリモジュールであるRMC（Relational Memory Core）を使用します。(RMCは、多頭式ドットプロダクトを用いて、記憶の相互作用を可能にします。その結果、RL領域（Mini PacManなど）、プログラム評価、言語モデルなどで大きな成果が得られ、WikiText-103、Project Gutenberg、GigaWordの各データセットで最先端の結果を得ることができました。
近年、人工知能（AI）はルネッサンスを迎え、視覚、言語、制御、意思決定などの主要な領域で大きな進歩を遂げています。これは、安価なデータと安価な計算資源が、深層学習の本来の強みに合致したことが一因となっています。しかし、人間の知能を定義する多くの特性は、はるかに異なる圧力の下で発達したものであり、現在のアプローチでは手が届かない。特に、自分の経験を超えて一般化することは、人間の知能が幼少期から持っていた特徴であり、現代のAIにとって手ごわい課題です。以下は、ポジションペーパー、レビュー、そして統一の部分です。私たちは、AIが人間のような能力を獲得するためには、組み合わせによる一般化が最優先されるべきであり、構造化された表現と計算がこの目的を実現する鍵となると主張します。生物学では自然と育成が協調して行われるように、我々は「手によるエンジニアリング」と「エンド・ツー・エンド」の学習の間の誤った選択を否定し、代わりに両者の補完的な強みを生かしたアプローチを提唱している。私たちは、深層学習アーキテクチャで関係性の帰納的バイアスを使用することで、エンティティ、関係性、およびそれらを合成するためのルールについての学習を促進する方法を探ります。これは、グラフ上で動作するニューラルネットワークに対する様々なアプローチを一般化・拡張したものであり、構造化された知識を操作し、構造化された行動を生み出すための分かりやすいインターフェースを提供する。本論文では、グラフネットワークがどのようにして関係推論と組み合わせ的な一般化をサポートし、より洗練された、解釈可能で柔軟な推論パターンの基礎を築くことができるかについて述べています。また、この論文に付随して、グラフネットワークを構築するためのオープンソースのソフトウェアライブラリを公開し、実際の使用方法のデモを行っています。
現在、機械学習は、いくつかの重要なタスクの改善に焦点を当てた実験的な研究が中心となっています。しかし、同じテストセットを使用して複数年前からモデルを選択しているため、最高性能のモデルの印象的な精度の数字には疑問が残ります。オーバーフィッティングの危険性を理解するために，本当に見たことのない画像からなる新しいテストセットを作成して，CIFAR-10分類器の精度を測定した．新しいテストセットは元のデータ分布にできるだけ近くなるようにしていますが、幅広い種類の深層学習モデルで精度が大きく低下することがわかりました（4～10％）。しかし、元々の精度が高い最近のモデルでは、落ち込みが小さく、全体的な性能も向上していることから、この落ち込みは適応性に基づくオーバーフィッティングによるものではないと考えられる。むしろ、今回の結果は、現在の精度の数値は脆く、データ分布の微細な自然変動にも影響を受けやすいという証拠であると考えています。
本論文では、教師なしの方法で単語間の文体の類似性を捉えることを目的とした最初の研究を紹介する。本研究では，continuous bag of words (CBOW) モデル (Mikolov et al., 2013) を拡張し，発話中のすべての単語のスタイルが一貫しているという仮定のもと，より広い文脈窓を用いてスタイルに敏感な単語ベクトルを学習することを提案する．さらに，語彙の文体の類似性を予測するという新しいタスクを導入し，このタスクのためのベンチマークデータセットを作成した。このデータセットを用いた実験では、我々の仮定を支持し、提案する拡張機能がスタイルに敏感な単語埋め込みの獲得に貢献することを実証した。
分類器の予測がいつ信頼できるかを知ることは、多くのアプリケーションで有用であり、AIを安全に使用するためにも重要である。機械学習の研究では、分類器の性能向上に力が注がれてきましたが、分類器の予測を信頼すべき場合と信頼すべきでない場合を理解することは、あまり注目されていません。標準的なアプローチは、分類器の判別スコアや信頼スコアを使用することですが、多くの状況でより効果的な代替手段が存在することを示します。本論文では，信頼度スコアと呼ばれる新しいスコアを提案する．このスコアは，テスト例に対する分類器と修正最近傍分類器の間の一致度を測定する．信頼度の高い（低い）スコアは，正しく分類された（誤って分類された）例を識別する際に驚くほど高い精度を示し，分類器の信頼度スコアや他の多くのベースラインを一貫して上回ることを経験的に示した．さらに、穏やかな分布の仮定の下で、ある例の信頼スコアが高い（低い）場合、分類器はベイズ最適分類器と一致する（一致しない）可能性が高いことを示します。我々の保証は、様々なノンパラメトリック設定の下での統計的整合性の非漸近率からなり、トポロジーデータ解析の最近の発展に基づいている。
人間は最新の強化学習（RL）アルゴリズムよりも大幅に速くビデオゲームのプレイを学習します。人間は、計画や戦略的な探索を支援するために、学習しやすい単純なモデルを構築するようだ。これに触発されて、我々はモデルベースのRLをサンプル効率のために活用する際の2つの問題を調査する。まず、厳密な計画が不可能な場合に戦略的な探索を行う方法を調査し、楽観的なモンテカルロ木探索が事後サンプリング法よりも優れていることを経験的に示す。第二に、オブジェクト表現を用いた高速学習をサポートするために、単純な決定論的モデルを学習する方法を示します。これらのアイデアの利点を、「Strategic Object Oriented Reinforcement Learning (SOORL)」という新しいアルゴリズムを紹介することで明らかにする。このアルゴリズムは、「Pitfall!
画像分類のデータセットはしばしば不均衡であり、これは深層学習の分類法の精度に悪影響を与える特徴です。本研究では、不均衡なデータセットのバランスを回復するための拡張ツールとして、バランシングGAN（BAGAN）を提案します。これは、少数の少数クラスの画像がGANを訓練するのに十分でない可能性があるため、挑戦的である。我々はこの問題を解決するために、多数派と少数派のクラスのすべての利用可能な画像を、敵対的学習の際に含めることにした。生成モデルは、多数派クラスから有用な特徴を学習し、それを用いて少数派クラスの画像を生成する。潜在空間にクラスの条件付けを行うことで、生成プロセスをターゲットクラスに向けて進めます。GANの生成器は、オートエンコーダーのエンコーダーモジュールで初期化されており、潜在空間における正確なクラスコンディショニングを学習することができる。提案手法を最先端のGANと比較し、BAGANは、不均衡なデータセットで学習した場合に、優れた品質の画像を生成することを実証する。
本論文では、InfoGANについて説明する。InfoGANは、完全に教師なしの方法で分離された表現を学習することができるGenerative Adversarial Networkの情報理論的な拡張である。InfoGANは、潜在変数の小さなサブセットと観測値との間の相互情報を最大化する生成的アドバーサリア・ネットワークでもある。我々は、効率的に最適化できる相互情報目的の下界を導出し、我々の学習手順がWake-Sleepアルゴリズムのバリエーションとして解釈できることを示す。具体的には、InfoGANは、MNISTデータセットの数字の形から書き方を、3Dレンダリング画像の照明からポーズを、SVHNデータセットの中央の数字から背景の数字を分離することに成功した。また、CelebA顔データセットでは、ヘアスタイル、眼鏡の有無、感情などの視覚的概念を発見しています。InfoGANは、既存の完全教師付き手法で学習された表現と競合する、解釈可能な表現を学習することが実験で示された。
DeepProbLogは、ニューラル述語による深層学習を組み込んだ確率論的論理プログラミング言語である。本論文では、既存の推論・学習技術を新しい言語に適用する方法を示す。我々の実験により、DeepProbLogは、記号的な表現とサブ記号的な表現の両方をサポートし、推論、1)プログラムの誘導、2)確率的（論理）プログラミング、3)例からの（深い）学習を行うことができることを示した。我々の知る限り、本研究は、汎用のニューラルネットワークと表現力豊かな確率論的なモデリングと推論を、両世界の表現力と強みをフルに活用する形で統合し、例題に基づいてエンド・ツー・エンドで学習できるフレームワークを提案した初めての研究です。
強化学習を実世界で実用化するための大きな課題は、タスクを正しく定義するオラクル報酬関数を指定する必要があることです。逆強化学習（IRL）では、この課題を回避するために、エキスパートの行動から報酬関数を推測します。魅力的ではあるが、現実世界でよく見られるバリエーション（例えば、あらゆるタイプのドアを開ける）をカバーするデモンストレーションのデータセットを集めるのは、実用的ではない場合がある。したがって、実際には、IRLは限られたデモのセットのみで実行されなければならず、報酬関数を明確に復元することは非常に困難である。本研究では、限られた数の実演から表現力のある報酬関数を推論できるように特別に最適化された「事前」を学習することで、他のタスクからの実演を利用して可能な報酬関数のセットを制約することができるという洞察を利用する。我々の手法は、新規タスクの画像から報酬を効率的に復元できることを実証し、我々のアプローチが事前の学習とどのように類似しているかについて直観的に説明する。
モデルベースの強化学習(RL)アルゴリズムは、サンプル効率は優れているが、漸近的な性能ではモデルフリーのアルゴリズムに劣ることが多い。これは特に、ディープネットワークのような高容量のパラメトリック関数近似器で顕著である。本論文では、不確実性を考慮したダイナミクスモデルを採用することで、このギャップを埋める方法を研究しています。不確実性を考慮したディープネットワークのダイナミクスモデルとサンプリングベースの不確実性伝播を組み合わせたPETS（Probabilistic ensembles with trajectory sampling）という新しいアルゴリズムを提案する。最先端のモデルベースおよびモデルフリーの深層RLアルゴリズムと比較した結果、我々のアプローチは、いくつかの困難なベンチマークタスクにおいて、モデルフリーのアルゴリズムの漸近的な性能に匹敵する一方で、必要なサンプル数は大幅に少ないことがわかった（例えば、half-heetahタスクにおいて、Soft Actor CriticおよびProximal Policy Optimizationと比較して、それぞれ8倍および125倍少ないサンプル数）。
グラフ構造を持つデータのための深い生成モデルは、化学合成の問題に新たな角度を提供します。分子グラフを直接生成する微分可能なモデルを最適化することで、離散的で広大な化学構造の空間において、高価な探索手順を回避することが可能になります。MolGANは、小さな分子グラフを対象とした暗黙的な尤度フリーの生成モデルであり、従来の尤度ベースの手法で用いられていた高価なグラフマッチング手順やノード順序付けヒューリスティックの必要性を回避することができます。この手法は、GAN（generative adversarial network）をグラフ構造を持つデータに直接適用したものです。この手法と強化学習の目的を組み合わせることで、特定の望ましい化学的特性を持つ分子の生成を促すことができる。QM9化学データベースを用いた実験では、我々のモデルがほぼ100％有効な化合物を生成できることを実証しました。MolGANは、分子の文字列ベース（SMILES）の表現を使用する最近の提案や、モード崩壊の影響を受けやすいものの、グラフを直接生成する尤度ベースの手法と比較しても、良好な結果が得られています。
チャンネルプルーニングは、ディープモデルの推論を高速化するための重要な手法の一つです。これまでのフィルタプルーニングアルゴリズムは、チャネルプルーニングとモデルの微調整を2つの独立したステップとみなしていた。本論文では、これらを単一のエンドツーエンドの学習可能なシステムに組み合わせることで、より良い結果が得られると主張する。我々は、効率的なチャネル選択層であるAutoPrunerを提案し、共同学習の方法で重要度の低いフィルタを自動的に見つける。我々のAutoPrunerは、過去の活性化反応を入力として受け取り、枝刈りのための真のバイナリ・インデックス・コードを生成する。したがって、ゼロのインデックス値に対応するすべてのフィルタは、トレーニング後に安全に除去することができる。このチャネル選択層の勾配情報は、モデル全体の学習にも役立つことを経験的に示しています。いくつかの弱いフィルターを徐々に消去することで、モデルの精度が過度に低下するのを防ぐことができる。これまでの最先端のプルーニングアルゴリズム（ゼロからのトレーニングを含む）と比較して、AutoPrunerは著しく優れた性能を達成している。さらに、アブレーションの実験では、提案された新しいミニバッチプーリングと2値化の操作が、フィルタプルーニングの成功に不可欠であることが示された。
バッチ正規化（BatchNorm）は、ディープニューラルネットワーク（DNN）のトレーニングをより高速かつ安定的に行うために広く採用されている技術です。BatchNormが広く普及しているにもかかわらず、その効果の正確な理由はまだよくわかっていません。一般的には、この効果は、学習中の層の入力分布の変化を制御して、いわゆる「内部共変量シフト」を減らすことに起因すると考えられている。本研究では、このような層の入力の分布の安定性は、BatchNormの成功にはほとんど関係がないことを実証しました。その代わりに、BatchNormが学習プロセスに与えるより根本的な影響を明らかにしました。それは、BatchNormが最適化ランドスケープを著しく滑らかにするということです。この滑らかさにより、勾配の予測性と安定性が向上し、より高速な学習が可能になります。
深層強化学習法は、環境報酬が特に疎なタスクでは従来から苦戦しています。このような領域では、人間のデモンストレーターが提供する軌道を模倣することで、探索を誘導する方法が成功している。しかし、これらのデモンストレーションは通常、エージェントの正確な環境設定や、デモンストレーターの行動や報酬の軌跡にアクセスできるような、人工的な条件下で収集されます。ここでは、そのようなデータにアクセスすることなく、ノイズの多い不整列映像に頼ることで、これらの制限を克服する2段階の方法を提案する。まず，複数のソースから得られた位置合わせされていない映像を，時間とモダリティ（視覚と聴覚）の両方で構築された自己教師付き目的語を用いて，共通の表現にマッピングすることを学習する．次に、この表現にYouTubeの動画を埋め込み、人間のゲームプレイを模倣するようエージェントに促す報酬関数を構築します。このようにして一発で真似をすることで、悪名高い難度の高い探索ゲーム「Montezuma's Revenge」、「Pitfall！」、「Private Eye」では、エージェントに環境報酬が与えられていなくても、初めて人間レベルのパフォーマンスを超えることができました。
離散的な潜在変数を持つディープニューラルネットワークは、より優れた記号的推論を可能にし、新たなタスクに役立つ抽象化を学習することが期待されています。離散潜在変数モデルへの関心は高まっていますが、最近のいくつかの改良にもかかわらず、離散潜在変数モデルの学習は依然として困難であり、その性能は連続モデルに匹敵するものではありませんでした。最近のベクトル量子化オートエンコーダ(VQ-VAE)の研究では，CIFAR-10などのデータセットにおいてVAEとほぼ同等のパープレキシティが得られるなど，この方向で大きな進展があった．本研究では，期待値最大化（EM）アルゴリズムとの関連性にヒントを得て，VQ-VAEの別の学習手法を調査した．EMを用いて離散的なボトルネックを学習することで、CIFAR-10においてより良い画像生成結果を得ることができ、知識の蒸留と合わせて、非自動回帰機械翻訳モデルを開発することができました。このモデルの精度は、強い貪欲な自動回帰ベースラインTransformerにほぼ匹敵しますが、推論は3.3倍高速です。
広大な画像の中から小さな物体を検出することは、衛星画像解析における主要な問題の1つです。地上画像における物体検出は、新しい深層学習アプローチの研究によって恩恵を受けていますが、そのような技術を俯瞰画像に移行することは容易ではありません。例えば、DigitalGlobe社の衛星画像の場合、1枚の画像に含まれるピクセル数は64km2以上、ピクセル数は2億5000万以上です。もう一つの課題は、対象となる物体が非常に小さい（多くの場合、範囲はわずか10ピクセル程度）ため、従来のコンピュータビジョン技術が複雑になることです。これらの問題を解決するために、私たちは、任意のサイズの衛星画像を0.5 km2/s以上の速度で評価するパイプライン（You Only Look Twice, YOLT）を提案します。提案されたアプローチは、複数のセンサー上で比較的少ないトレーニングデータで、非常に異なるスケールのオブジェクトを迅速に検出することができます。大規模なテスト画像をネイティブな解像度で評価したところ，車両の位置特定においてF1 > 0.8のスコアが得られた．さらに、解像度を下げてパイプラインを系統的にテストすることで、解像度と対象物の大きさの要件を検討し、わずか5ピクセルの大きさの対象物でも高い信頼性で位置を特定できると結論付けました。コードはこちらのhttpsのURLから入手できます。
報酬関数の設計は、強化学習の実世界での応用において、しばしば大きな実用的な課題となります。逆強化学習のようなアプローチは、この課題を克服しようとするものであるが、専門家によるデモンストレーションが必要であり、実際には入手が困難であったり、高価であったりする。我々は、イベント付き変分逆制御(VICE)を提案する。VICEは、完全なデモンストレーションが必要ない場合、例えば望ましいゴールの状態のサンプルしか得られない場合などに、逆強化学習法を一般化する。本手法は、制御と強化学習に関する別の視点に基づいており、エージェントの目標は、累積報酬を最大化するのではなく、1つ以上のイベントが将来のある時点で起こる確率を最大化することである。本研究では、報酬を特定することが難しい、あるいは不可能な画像などの高次元観測に焦点を当て、連続的な制御タスクにおいて本手法の有効性を実証する。
転移学習はコンピュータビジョンの基礎となるものですが、アーキテクチャと転移の関係を評価する研究はほとんど行われていません。現代のコンピュータビジョン研究における暗黙の仮説は、ImageNetで優れた性能を発揮するモデルは、他のビジョンタスクでも優れた性能を発揮するというものです。しかし、この仮説はこれまで体系的に検証されたことがありませんでした。ここでは、12の画像分類データセットにおいて、16の分類ネットワークの性能を比較した。その結果、ネットワークを固定的な特徴抽出器として用いた場合と、微調整を行った場合とで、ImageNetの精度と転送精度との間に強い相関関係があることがわかった（それぞれ$r = 0.99$と$0.96$とした）。前者の場合、この関係は、ImageNet上でのネットワークの学習方法に非常に敏感であることが分かりました。一般的な正則化の多くは、ImageNetの精度をわずかに向上させますが、転送学習には非常に不利な最終層の特徴をもたらします。さらに、2つの小さな画像分類データセットでは、ImageNetでの事前学習の効果はほとんどなく、ImageNetで学習した特徴は、細かいタスクにはうまく移行しないことがわかりました。これらの結果から、ImageNetのアーキテクチャはデータセット間でよく一般化されるが、ImageNetの特徴は以前に提案されたよりも一般的ではないことが示された。
本研究では、ハイパーボリック・アテンション・ネットワークを導入し、ニューラルネットワークに、階層構造やパワーロー構造を持つデータの複雑さに対応できるだけの能力を持たせる。最近のいくつかのアプローチでは、浅いネットワークのパラメータに双曲幾何学を課すことの利点をうまく実証しています。私たちは、この研究を拡張し、ニューラルネットワークの活性化に双曲幾何学を適用します。これにより、双曲幾何学を利用して、深層ネットワークが生成する埋め込みを推論することができます。これは、ソフトアテンションというユビキタスなメカニズムを、双曲面モデルとクラインモデルで定義された操作で再表現することで実現しています。我々の手法は、神経表現をコンパクトに保ちながら、神経機械翻訳、グラフ上の学習、視覚的質問応答タスクの一般化の点で改善を示した。
データ補強は、最新の画像分類器の精度を向上させるための効果的な手法です。しかし、現在のデータ補強の実装は手動で設計されている。本論文では、改良されたデータ補強ポリシーを自動的に検索するAutoAugmentと呼ばれる簡単な手順について説明する。我々の実装では、1つのポリシーが多くのサブポリシーから構成され、そのうちの1つが各ミニバッチの各画像に対してランダムに選択されるような探索空間を設計した。サブポリシーは2つの操作で構成され，各操作は平行移動，回転，剪断などの画像処理機能と，それらの機能を適用する確率と大きさである．探索アルゴリズムを用いて，対象となるデータセットにおいてニューラルネットワークが最高の検証精度を得られるような最適なポリシーを見つける．我々の手法は，CIFAR-10，CIFAR-100，SVHN，およびImageNet（追加データなし）において，最先端の精度を達成した．ImageNetでは、従来の記録である83.1%を0.4%上回る83.5%というトップ1精度を達成しました。CIFAR-10では、1.5%のエラーレートを達成し、これは従来の最先端技術よりも0.6%優れています。私たちが見つけた拡張政策は、データセット間で移行可能です。例えば、Oxford Flowers、Caltech-101、Oxford-IIT Pets、FGVC Aircraft、Stanford Carsなどである。
最近の視覚認識の進歩は、深層畳み込みネットワーク（DCN）に注意メカニズムを組み込んだことに端を発している。これらのネットワークは物体認識に最適化されているため、画像のクラスラベルから得られる弱い形式の監視だけで、どこに注意を向けるべきかを学習する。今回、我々は、人間が物体認識に重要だと考える画像領域に注目するようDCNを教育することで、より強い監視信号を用いることの利点を示した。まず、大規模なオンライン実験（ClickMe）を行い、ImageNetに50万個近い人間由来の「トップダウン」注意マップを追加した。人間の心理物理学を用いて、ClickMeで同定されたトップダウン特徴が、ボトムアップの saliency 特徴よりも、迅速な画像分類のための診断効果が高いことを確認した。概念実証として、最先端の注意ネットワークを拡張し、ClickMeの監視を加えることで、その精度が大幅に向上し、より解釈しやすく、人間の観察者が使用するものに近い視覚的特徴が得られることを実証しました。
人間の指示を理解し、それに従うことで、ロボットは未知の状況でも効率的に行動することができます。本研究では、マルチモーダル・ナビゲーション・ポリシーを学習するためのエンド・ツー・エンドの微分可能なニューラル・アーキテクチャであるFollowNetを紹介します。FollowNetは、自然言語による指示に加えて、視覚および深度の入力を運動プリミティブにマッピングします。フォローネットは、視覚と奥行きの入力を条件とした注意メカニズムを用いて命令を処理し、ナビゲーションタスクを実行しながら命令の関連部分に焦点を当てます。強化学習(RL)では、状態表現、注意機能、制御方針を同時に学習する。本研究では、複雑な自然言語による指示のデータセットを用いてFollowNetエージェントを評価しました。FollowNetエージェントは、似たような語彙で記述された以前に見たことのない指示を実行することを学習し、トレーニング中に遭遇しなかった経路をうまくナビゲートすることを示している。このエージェントは、注目メカニズムを持たないベースラインモデルと比較して30%の改善を示し、新規の指示に対して52%の成功率を示した。
楽器、ジャンル、スタイルを超えて音楽を翻訳する手法を紹介しています。この手法は、マルチドメイン波動オートエンコーダーに基づいており、エンコーダーを共有し、潜在的な空間を分離して、エンドツーエンドで波形の学習を行う。多様な学習データセットと大きなネットキャパシティを採用し、ドメインに依存しないエンコーダにより、学習時に見られなかった音楽ドメインからの翻訳を可能にしています。この手法は教師なしで行われ、ドメイン間でマッチしたサンプルや音楽のトランスクリプションという形での監督には依存しない。NSynthおよびプロの音楽家から収集したデータセットを用いて本手法を評価したところ，口笛を翻訳する場合でも納得のいく翻訳が得られ，訓練を受けていない人間でも器楽演奏が可能になる可能性がある．
本論文では、画像生成タスクのための注意駆動型の長距離依存性モデリングを可能にするSelf-Attention Generative Adversarial Network (SAGAN)を提案しています。従来の畳み込みGANは、高解像度の詳細を、低解像度の特徴マップにおける空間的に局所的な点のみの関数として生成するものであった。SAGANでは、すべての特徴位置からの手掛かりを用いて詳細を生成することができます。さらに、識別器は、画像の離れた部分にある高精細な特徴が互いに一致していることを確認することができます。さらに、最近の研究では、生成器の条件付けがGANの性能に影響することが示されている。この知見を利用して、GANジェネレータにスペクトル正規化を適用し、これにより学習ダイナミクスが改善されることを見出した。提案されたSAGANは、ImageNetデータセットにおいて、公表されている最高のInceptionスコアを36.8から52.52に向上させ、Frechet Inception距離を27.62から18.65に短縮するなど、最先端の結果を達成した。注目層を視覚化することで、この生成器が、固定された形状の局所領域ではなく、オブジェクトの形状に対応する近傍領域を活用していることがわかる。
本研究では、ロボットが世界を観察するだけで世界について学ぶことができる新しいアプローチを模索しています。特に、連続的な制御タスクのために、タスクに依存しない表現を学習することの有効性を調査する。本研究では、単一のフレームではなく、複数のフレームを合同で埋め込み空間に埋め込むことで、視覚的観察から学習するTime-Contrastive Networks（TCN）を拡張する。これにより、位置と速度の両方の属性をより正確にエンコードできるようになったことを示す。さらに、この自己教師付きアプローチの有用性を強化学習の設定で検証した。エージェントがランダムな行動をとったり、他のエージェントがタスクを成功させたりするのを観察することで学習された表現は、学習された埋め込みだけを入力として、近位政策最適化（PPO）のようなアルゴリズムを用いた連続的な制御政策の学習を可能にすることを示している。
ニューラル言語モデル（LM）が事前の言語的コンテキストをどのように利用するかについては、ほとんど分かっていない。本論文では、LSTM LMにおける文脈の役割を、アブレーションの研究を通して調査します。具体的には、先行する文脈の単語をシャッフルしたり、置き換えたり、削除したりしたときのパープレキシティの増加を分析する。Penn TreebankとWikiText-2という2つの標準的なデータセットにおいて、モデルは平均して約200トークンの文脈を利用することができるが、近くの文脈（最近の50トークン）と遠くの履歴を明確に区別することがわかった。このモデルは、直近の文の中の単語の順番には非常に敏感ですが、遠距離の文脈（50トークン以上）の中の単語の順番は無視しています。さらに、神経キャッシングモデル（Grave et al., 2017b）は、LSTMがこの遠い文脈内から単語をコピーするのに特に役立つことがわかりました。全体として、私たちの分析は、ニューラルLMがそのコンテキストをどのように使用するかについての理解を深めるだけでなく、キャッシュベースのモデルからの最近の成功にも光を当てています。
ディープラーニングでは、その効率の良さから、通常、学習手法としてStochastic Gradient Descent（SGD）が選択されますが、最近、SGDの問題が研究の関心を集めています。すなわち、ディープニューラルネットワーク（DNN）のシャープミニマムは、一般化に乏しく、特に、大規模バッチのSGDは、シャープミニマムに収束する傾向があります。特に、ラージバッチSGDはシャープミニマムに収束する傾向がある。シャープミニマムを回避することで、一般化を改善できるかどうかは未解決の問題である。この問題に答えるために、我々はDNNの鋭いミニマムを平滑化し、それによって一般化を改善するSmoothOutフレームワークを提案する。具体的には、SmoothOutはDNNの複数のコピーにノイズを注入し、それらのコピーを平均化する。SGDにノイズを注入する方法は広く知られていますが、SmoothOutは様々な点で異なります。(1)パラメータ更新の前にノイズ除去処理を行っていること、(2)ノイズの強さをフィルタノルムに合わせていること、(3)ノイズ注入の利点をシャープネスと汎化の観点から別の解釈をしていること、(4)ガウスノイズの代わりに一様なノイズを使っていること、などです。SmoothOutがシャープな最小値を除去できることを証明します。複数のDNNコピーを学習することは非効率的であるため、バッチごとにノイズ注入とノイズ除去のオーバーヘッドを導入するだけの不偏的なstochastic SmoothOutをさらに提案する。また、SmoothOutの適応型であるAdaSmoothOutを提案し、汎用性を高める。様々な実験において、SmoothOutとAdaSmoothOutは、スモールバッチとラージバッチの両方のトレーニングにおいて、最先端のソリューションに比べて一貫して一般化を改善しています。
教師なし学習におけるGAN（generative adversarial network）と強化学習（reinforcement learning）におけるRL（actor-critic）の手法は、どちらも最適化が難しいという評価を受けています。両分野の実務者は、これらの不安定さを軽減し、学習を改善するための戦略を数多く蓄積してきた。ここでは、アクターが報酬に影響を与えられない環境では、GANはアクター批判的な手法と見なすことができることを示す。モデルのクラスごとに学習を安定化させるための戦略を、2つのクラス間で一般化するものと、そのモデルに特有のものの両方をレビューする。また、より複雑な情報の流れを持つGANやRLアルゴリズムの拡張についても紹介します。この形式的なつながりを強調することで、GANとRLの両コミュニティが、ディープネットワークを用いたマルチレベル最適化のための一般的でスケーラブルかつ安定したアルゴリズムを開発し、コミュニティを超えたインスピレーションを引き出すことを期待しています。
Variational Auto-Encoder（VAE）は、最も使われている教師なしの機械学習モデルの一つです。しかし、事前と事後の両方にガウス分布をデフォルトで選択することは、数学的に便利な分布であり、しばしば競争力のある結果をもたらしますが、このパラメータ化は潜在的な超球状構造を持つデータのモデル化に失敗することを示しています。この問題を解決するために、我々は代わりにvon Mises-Fisher (vMF)分布を使用することを提案し、潜在的な超球状の空間を導き出す。一連の実験を通して、このような超球状のVAE（-VAE）が、超球状の潜在構造を持つデータを取り込むのに適していることを示す一方で、他のデータタイプでは低次元で通常のVAE（-VAE）よりも優れていることを示した。
アルゴリズムに対して、その結果を説明することが求められています。これまでのところ、ランキングアルゴリズムによって生成されたランキングを説明する方法はありません。このギャップを解決するために、我々は、ランキングアルゴリズムによって生成されたランキングを説明するLISTwise ExplaiNerであるLISTENを提案する。LISTENを効率的に利用するために、ニューラルネットワークを学習し、LISTENが生成する説明空間を学習する。LISTENは忠実な説明を生成し、Q-LISTENはこれらの説明を学習できることを示す。さらに、LISTENが実世界の環境で安全に使用できることを示す。ニュース推薦システムのユーザーは、手動で生成された説明ではなく、LISTENによって生成された説明に接しても、大きく異なる行動を取らない。
過去数年にわたり、分散型意味表現は、下流のアプリケーションに統合するための事前知識を効果的かつ柔軟に保持するものであることが証明されてきた。本調査では、意味の表現に焦点を当てます。まず、単語ベクトル空間モデルの理論的背景を説明し、その主な限界の1つである「意味混同の欠陥」に注目する。次に、曖昧さのない語彙の意味をモデル化する方法として、単語レベルから、より細かい語義レベルへの移行によって、この欠陥をどのように解決できるかを説明する。この調査では、感覚表現の2つの主要な分野、すなわち教師なしと知識ベースの分野における幅広い技術の包括的な概要を示します。最後に、この調査では、このタイプの表現の主な評価手順とアプリケーションをカバーし、その重要な4つの側面（解釈可能性、意味の粒度、異なるドメインへの適応性、構成性）の分析を行います。
帰納的伝達学習はコンピュータビジョンに大きな影響を与えてきましたが、NLPにおける既存のアプローチは、タスクに応じた修正やゼロからのトレーニングを必要とします。我々は、NLPのあらゆるタスクに適用可能な効果的な伝達学習法であるUniversal Language Model Fin-tuning (ULMFiT)を提案し、言語モデルを微調整する上で鍵となる技術を紹介する。我々の手法は、6つのテキスト分類タスクにおいて、大多数のデータセットで誤差を18-24%削減し、最先端の手法を大幅に上回った。さらに，わずか100個のラベル付き例文で，100倍のデータを用いてゼロから学習した場合と同等の性能を実現しています．我々は、事前に学習したモデルとコードをオープンソースで提供しています。
正確な分類器を学習するには多くのラベルが必要ですが，各ラベルは限られた情報（2値分類では1ビット）しか提供しません．本研究では、BabbleLabbleを提案する。これは、分類器を学習するためのフレームワークであり、アノテーターが各ラベル付けの決定に対して自然言語による説明を提供する。本研究では、BabbleLabbleを用いて、分類器の学習を行う。3つの関係性抽出タスクにおいて、ユーザはラベルの代わりに説明を提供することで、同等のF1スコアを持つ分類器を5～100倍速く学習できることがわかった。さらに、ラベル付け機能が本質的に不完全であることを考慮すると、単純なルールベースのセマンティックパーサーで十分であることがわかった。
実際のウェブデータを対象とした機械読解（MRC）では、通常、検索エンジンで検索された複数の文章を分析して質問に答えることが求められます。1つの文章を対象としたMRCに比べて、複数の文章を対象としたMRCは、異なる文章から複数の紛らわしい回答候補を得る可能性があるため、より困難である。この問題を解決するために、本研究では、異なる文章から得られた回答候補を、その内容表現に基づいて相互に検証することができるエンド・ツー・エンドのニューラルモデルを提案する。具体的には，最終的な回答を予測する3つのモジュールを共同で学習する．これらのモジュールは，回答の境界，回答の内容，およびパッセージ間の回答検証という3つの要素に基づいている．実験の結果、我々の手法はベースラインを大きく上回り、実環境でのMRCのために設計された英語のMS-MARCOデータセットと中国語のDuReaderデータセットにおいて、最先端の性能を達成することができた。
四足歩行ロボットの俊敏な運動を設計するには、多くの場合、広範な専門知識と面倒な手動チューニングが必要です。本論文では、深層強化学習技術を活用して、このプロセスを自動化するシステムを紹介します。本システムは、単純な報酬信号を用いて四足歩行をゼロから学習することができる。さらに、学習した歩行をより制御する必要がある場合には、ユーザーは学習プロセスを導くためのオープンループ参照を提供することができる。この制御方針は物理シミュレータで学習された後、実際のロボットに導入されます。ロボット工学では、シミュレーションで学習した方針が現実世界に移行しないことがよくあります。私たちは、物理シミュレータを改良し、ロバストな政策を学習することで、この現実とのギャップを縮めます。システム同定、正確なアクチュエータモデルの開発、レイテンシーのシミュレーションにより、シミュレーションを改善します。また、物理環境のランダム化、摂動の追加、コンパクトな観測空間の設計により、ロバストなコントローラを学習します。このシステムを、俊敏な動きをする2つの歩容（trottingとgalloping）で評価しました。シミュレーションで学習した後、四足歩行ロボットは実世界で両方の歩容を成功させることができる。
文レベルのラベルのみで学習したネットワークを用いて、注意や勾配に基づいた視覚化技術を用いて、二値配列タグ付け問題のトークンレベルのラベルを推論することができるか？我々は、ソフトアテンションに基づいたニューラルネットワークアーキテクチャを構築し、それを二分文分類器として訓練し、4つの異なるデータセットのトークンレベルのアノテーションに対して評価した。ネットワークからトークンラベルを推定することで、モデルが学習している内容を定量的に評価する方法が得られ、支援システムに有用なフィードバックを生成することができます。その結果、アテンションベースの手法は、勾配ベースの手法と比較して、トークンレベルのラベルをより正確に予測することができ、場合によっては教師付きオラクルネットワークに匹敵することがわかった。
LSTMやGRUのような洗練されたゲーテッドリカレントニューラルネットワークアーキテクチャは、無数のアプリケーションで非常に効果的であることが示されています。我々は、統計の移動平均を保持するだけで、データの長期的な依存性を学習することができる非ゲートユニット、統計リカレントユニット（SRU）を開発しました。SRUのアーキテクチャはシンプルで、ゲートを持たず、LSTMと同等の数のパラメータを含んでいますが、SRUは、より洗練されたLSTMやGRUと比較しても遜色のない性能を発揮し、様々なタスクにおいて一方または両方を凌駕します。我々は、合成タスクと実世界タスクの両方に対して、ベイズ最適化スキームを用いてそれぞれのアーキテクチャのハイパーパラメータを最適化することで、LSTMやGRUと比較してSRUの有効性を公平に示します。
最近、事前に学習したソースエンベディングから正確なメタエンベディングを作成することが注目されています。これまでに、大域的・局所的な線形変換や連結に基づく手法が、正確なメタエンベッディングを生成することが示されてきた。本論文では，2つの異なる単語埋め込みセットの算術平均によって，より複雑なメタ埋め込み学習法と同等以上の性能を持つメタ埋め込みが得られることを示す．この結果は、異なるソース埋め込みのベクトル空間が比較できず、単純に平均化できないことを考えると、直観的ではないように思える。本論文では、元のベクトル空間が比較できないにもかかわらず、平均化によって正確なメタ埋め込みができる理由について考察する。
依存関係解析のための新しいアーキテクチャを紹介します。\スタックポインターネットワーク (˶‾᷄ -̫ ‾᷅˵)です。pointer networks~citep{vinyals2015pointer} を内部スタックと組み合わせることで、提案されたモデルはまず文全体を読み込んで符号化し、次に依存関係ツリーをトップダウンで（根から葉へ）深さ優先で構築します。スタックは深さ優先探索の状況を追跡し、ポインタネットワークは各ステップでスタックの一番上にある単語に対して1つの子を選択する。¶Textsc{StackPtr}パーサーは文全体の情報と以前に派生した全てのサブツリー構造から恩恵を受け、古典的な遷移ベースのパーサーにおける左から右への制限を取り除きます。しかし、任意の（非投影的なものを含む）解析ツリーを構築するためのステップ数は、他の遷移ベースのパーサーと同様に文の長さに線形であり、O(n^2)の時間複雑性を持つ効率的なデコーディングアルゴリズムをもたらします。本研究では，20の言語と異なる依存関係注釈スキーマからなる29のツリーバンクを用いてモデルを評価し，そのうち21のツリーバンクで最先端の性能を達成した．
双方向性LSTMは、テキスト表現のための強力なツールです。その一方で、LSTMは逐次的な性質を持っているため、様々な制限を受けることがわかっています。本研究では、テキストを符号化するための別のLSTM構造を調査する。この構造は、各単語の並列状態からなる。リカレントステップは、単語のシーケンスを段階的に読み取るのではなく、単語間のローカルおよびグローバルな情報交換を同時に行うために使用されます。様々な分類および配列ラベリングのベンチマークの結果から、提案モデルは強力な表現力を持ち、同様のパラメータ数を持つスタック型BiLSTMモデルと比較して、非常に競争力のある性能を発揮することがわかった。
人は誰でも、話す内容、性別、社会的地位、出身地など、さまざまな要因の影響を受けて、自分の母国語を話したり書いたりしています。機械翻訳（MT）を行おうとする場合、これらのバリエーションは、システムがどのように翻訳を行うべきかに大きな影響を与えるが、標準的な画一的なモデルではうまく捉えられない。本論文では、シンプルでパラメータ効率の良い適応手法を提案します。この手法では、出力ソフトマックスのバイアスを、機械翻訳システムの各ユーザーに直接または因数分解された近似値を用いて適応させるだけです。3言語のTEDトークを対象とした実験では、翻訳精度が向上し、ターゲットテキストに話者の特徴がよりよく反映されていることが実証された。
敵対的な学習によって得られた深層生成モデルは、自然な画像の質感を生成する能力があることから、ますます人気が高まっています。しかし、物体の見た目は、その質感の他に、形状の幾何学的性質にも大きく影響されますが、既存の生成モデルでは考慮されていません。本論文では、幾何学的情報を画像生成プロセスに取り入れるためのGeometry-Aware Generative Adversarial Networks (GAGAN)を紹介する。具体的には、GAGANでは、生成器が統計的形状モデルの確率空間から潜在的な変数をサンプリングする。生成器の出力を微分可能な幾何学的変換によって正準座標フレームにマッピングすることで、オブジェクトの幾何学性を強化し、事前から生成されたオブジェクトへの暗黙の接続を追加します。顔の生成に関する実験結果によると、GAGANは、表情、ポーズ、形態などの任意の顔属性を持つ顔のリアルな画像を、現在のGANベースの手法よりも高い品質で生成できることがわかった。私たちの手法は、既存のあらゆるGANアーキテクチャを補強し、生成される画像の品質を向上させるために使用することができます。
読解は難しいタスクであり、特に、回答が再発する可能性が高い、より長い、あるいは複数の証拠文書に渡って実行される場合には、困難を伴います。既存のニューラルアーキテクチャーは、一般的に、証拠文書全体に対応できないため、（切り捨てなどの方法で）文書内の1つの通路を選択し、その通路内で注意深く答えを探すという方法に頼っています。しかし、場合によっては、この戦略は最適ではありません。なぜなら、特定の文章に焦点を当てることで、文書中の同じ答えについての複数の言及を利用することが困難になるからです。本研究では、回答を見つけるためにカスケード接続される軽量モデルを構築することで、異なるアプローチを取っています。各サブモデルは、注目メカニズムを備えたフィードフォワードネットワークのみで構成されており、些細なことですが並列化が可能です。我々のアプローチは、約1桁の大きさの証拠文書に対応でき、文書中の各回答候補に関する複数の言及から表現レベルで情報を集約できることを示す。経験的には、TriviaQAデータセットのWikipediaドメインとWebドメインの両方において、我々のアプローチは、より複雑なリカレント・アーキテクチャを上回る最先端の性能を達成している。
今回の技術報告では、データ増強法を適用することで、自然言語のオーバーフィッティング問題を軽減することを目的としています。具体的には、ガウスノイズ、ベルヌーイノイズ、敵対的なノイズなど、入力された単語の埋め込みを乱すいくつかのタイプのノイズを試みます。また、ノイズの種類に応じていくつかの制約を設けている。これらの提案されたデータ補強法を実装することで、ベースラインモデルは、いくつかの文分類タスクにおいて改善を得ることができる。
最近学習された多くのニューラルネットワークは、良好な性能を得るために多数のパラメータを採用している。直感的には、必要なパラメータの数が問題の難易度の目安になるかもしれません。しかし、そのような考え方はどれほど正確なのでしょうか？実際にはどれくらいの数のパラメータが必要なのでしょうか？この論文では、ネットワークを本来のパラメータ空間ではなく、より小さく、ランダムに方向づけられた部分空間で訓練することで、この疑問に答えようとしています。この部分空間の次元をゆっくりと増加させ、どの次元で初めて解が現れるかを記録し、これを目的ランドスケープの本質的な次元と定義します。このアプローチは実装が簡単で、計算が容易であり、いくつかの示唆に富む結論が得られました。多くの問題は、人が疑うよりも小さな固有次元を持っており、与えられたデータセットの固有次元は、サイズが大きく異なるモデル群の間でほとんど変化しません。後者の結果は，問題を解決するのに十分な大きさのパラメータ空間があれば，追加のパラメータは直接，解の多様性の次元を増加させるという重大な意味を持っています．例えば、倒立振子問題を解くことは、MNISTの数字の分類よりも100倍簡単であり、ピクセルからAtari Pongをプレイすることは、CIFAR-10を分類するのと同じくらい難しいと結論づけています。この方法は、パラメータ化されたモデルが彷徨う目的地の新しい地図を提供することに加えて、解の最小記述長の上界を建設的に得るための簡単な手法です。この方法の副産物として、ネットワークを圧縮するための簡単なアプローチがあり、場合によっては100倍以上の圧縮が可能です。
半教師付き学習（SSL）は、ラベルが限られていたり、入手が困難な場合に、ラベルのないデータを活用するための強力なフレームワークです。最近では，ディープニューラルネットワークを用いたSSLアルゴリズムが，標準的なベンチマークタスクで成功を収めている．しかし、これらのベンチマークは、これらのアルゴリズムが実世界のアプリケーションで直面する多くの問題に対応していないと我々は主張する。我々は、広く使われている様々なSSL技術を統一的に再実装した後、これらの問題を解決するために設計された一連の実験でそれらをテストした。その結果，ラベルなしデータを使用しない単純なベースラインの性能は，しばしば過小評価されていること，SSL手法はラベル付きデータとラベルなしデータの量に対する感度が異なること，ラベルなしデータセットにクラス外の例が含まれている場合には性能が大幅に低下することがわかった．SSLの研究を実社会への適用に導くために，我々は統一された再実装と評価のプラットフォームを公開している．
文体変換とは、文脈の中で意図や影響を変えずに、特定の文体を含むように文章を言い換える作業のことである。本論文では、自動スタイル変換のための新しい手法を紹介する。まず、入力文の潜在的な表現を学習し、それを言語翻訳モデルに基づかせることで、文の意味をよりよく保持しつつ文体の特性を減らす。次に、敵対的生成技術を用いて、出力が望ましいスタイルに一致するようにする。この手法を、感情、性別、政治的傾向という3つの異なるスタイル変換で評価した。最新の2つのスタイル変換モデル技術と比較して、スタイル変換の自動評価と、意味の保持と流暢性の手動評価の両方で改善を示した。
スタイル変換とは、文脈の中で意図や影響を変えることなく、特定のスタイル特性を含むようにテキストを言い換える作業である。本論文では、自動スタイル変換のための新しい手法を紹介する。まず、入力文の潜在的な表現を学習し、それを言語翻訳モデルに基づかせることで、文の意味をよりよく保持しつつ文体の特性を減らす。次に、敵対的生成技術を用いて、出力が望ましいスタイルに一致するようにする。この手法を、感情、性別、政治的傾向という3つの異なるスタイル変換で評価した。最新の2つのスタイル変換モデル技術と比較して、スタイル変換の自動評価と、意味の保持と流暢性の手動評価の両方で改善を示した。
現在のエンド・ツー・エンドの機械読解・質問応答（Q˶ˆ꒳ˆ˵）モデルは、主に注目のリカレントニューラルネットワーク（RNN）に基づいています。しかし，これらのモデルは成功しているにもかかわらず，RNNの逐次的な性質のために，学習と推論の両方に時間がかかることが多い．我々は，リカレントネットワークを必要としない QANet と呼ばれる新しい Q\&A アーキテクチャを提案する．QANetのエンコーダは，畳み込みと自己注意のみで構成されており，畳み込みは局所的な相互作用を，自己注意は大域的な相互作用をモデル化する．SQuADデータセットにおいて，我々のモデルは，リカレントモデルと同等の精度を達成しながら，学習が3倍から13倍，推論が4倍から9倍高速化した．この高速化により、より多くのデータでモデルを学習することができるようになりました。そこで、ニューラル機械翻訳モデルからの逆翻訳によって生成されたデータとこのモデルを組み合わせました。SQuADデータセットにおいて、増強されたデータで訓練された我々の単一モデルは、テストセットで84.6のF1スコアを達成し、公表されている最高のF1スコアである81.8を大幅に上回りました。
共同訓練は，少量のラベル付きデータに加えて大量のラベルなしデータを利用する半教師付き学習のフレームワークとしてよく知られている．共同訓練法は、ラベルのないデータに予測されたラベルを利用し、予測の信頼性に基づいてサンプルを選択して訓練を補強します。しかし、既存の共同訓練法におけるサンプルの選択は、事前に設定されたポリシーに基づいており、ラベルなしのサブセットとラベル付きのサブセットの間のサンプリングバイアスを無視しており、データ空間を探索することができない。本論文では、高品質なラベルなしのサンプルを選択して、より良い共同訓練を行うための新しい手法、Reinforced Co-Trainingを提案する。具体的には、Q-learningを用いて、少量のラベル付きデータセットを用いてデータ選択ポリシーを学習し、このポリシーを利用して共同訓練分類器を自動的に訓練するというものである。クリックベイト検出と一般的なテキスト分類タスクの実験結果から、我々の提案手法がより正確なテキスト分類結果を得られることを実証した。
最近では、例の集合から分布を推定するニューラルネットワークモデルの設計に関心が集まっています。本論文では、強力な生成モデルを生み出すオートエンコーダー・ニューラルネットワークの簡単な改良法を紹介する。この手法では、自己回帰制約を考慮してオートエンコーダーのパラメータをマスクします。この制約により、オートエンコーダーの出力は、条件付き確率のセットと、その積である完全な結合確率と解釈することができます。また、複数の異なる順序で結合確率を分解することができる単一のネットワークを訓練することもできます。このシンプルなフレームワークは、深層アーキテクチャを含む複数のアーキテクチャに適用できます。GPUのようなベクトル化された実装は、シンプルで高速です。実験では、この手法が最先端の扱いやすい分布推定法と競合することを実証しました。また、テスト時には、この手法は他の自己回帰推定量よりも大幅に高速で、スケーリングも良好です。
ここでは，テキストの属性変換というタスクを考える．これは，属性に依存しない内容を維持したまま，特定の属性（例えば，感情）を変更するために文章を変換するものである（例えば，「screen is just the right size」を「screen is too small」に変更する）．我々の学習データには、ポジティブかネガティブかなどの属性でラベル付けされた文だけが含まれているが、属性だけが異なる文のペアは含まれていないため、教師なしで属性と属性に依存しない内容を切り離すことを学習する必要がある。敵対的手法を用いたこれまでの研究では、高品質な出力を得るのに苦労した。本論文では、テキストの属性がしばしば特徴的なフレーズ（例："too small"）によって示されるという観察に基づいて、より単純な手法を提案する。我々の最も強力な手法は、文の元の属性値に関連するフレーズを削除することでコンテンツの単語を抽出し、ターゲットの属性に関連する新しいフレーズを取得し、ニューラルモデルを用いてこれらを流暢に組み合わせて最終的な出力を生成する。人間による評価では、Yelpのレビューのセンチメントを変更する、Amazonのレビューのセンチメントを変更する、画像のキャプションをロマンチックまたはユーモラスに変更する、という3つの属性変換データセットにおいて、我々の最良の手法は、従来の最良のシステムよりも22%多い入力に対して、文法的に適切な応答を生成する。
本論文では、Non-Autonomous Input-Output Stable Network（NAIS-Net）を紹介します。NAIS-Netは、非常に深いアーキテクチャであり、各スタック処理ブロックは時不変の非自律的な動的システムから派生しています。非自律性は、ブロックの入力から展開された各処理段階へのスキップ接続によって実装されており、パターンに依存した処理の深さに適応的にブロックを展開できるように、安定性を確保することができます。NAIS-Netは、無限のアンロール長であっても、非自明なLipschitzの入出力マップを誘導する。NAIS-Netは大域的に漸近的に安定であり、すべての初期条件に対して$tanh$個の入力に依存した平衡が正確に1つ存在し、ReL個の入力に対して増分的に安定であることを証明する。また、完全連結層と畳み込み層の両方について、導出された条件の下で安定性を確保する効率的な実装も示されています。実験結果は、NAIS-Netが実際にどのように安定性を発揮するかを示しており、ResNetsと比較して、一般化ギャップを大幅に削減することができた。
物体検出では、陽性と陰性を定義するために、IoU（intersection over union）閾値が必要である。低いIoU閾値（例：0.5）で学習した物体検出器は、通常、ノイズの多い検出結果を得ることができます。しかし、IoU閾値を大きくすると、検出性能が低下する傾向にあります。これには主に2つの要因があります。1）指数関数的に消滅する正のサンプルによる学習時のオーバーフィッティング，2）検出器が最適なIoUと入力仮説のIoUとの間の推論時のミスマッチ．これらの問題を解決するために，多段式物体検出アーキテクチャであるCascade R-CNNを提案する．カスケードR-CNNは，IoUの閾値を増加させながら学習された一連の検出器で構成されており，近い偽陽性に対して順次選択性を高めていく．検出器は段階的に学習され，ある検出器の出力が次の高品質な検出器の学習に適した分布であるという観察結果を利用している．段階的に改善された仮説をリサンプリングすることで，すべての検出器が同等の大きさの正の例を持つことが保証され，オーバーフィッティングの問題が軽減される．推論でも同じカスケード手順が適用され、各ステージの仮説と検出器の品質をより緊密に一致させることができます。カスケードR-CNNの簡単な実装は、難易度の高いCOCOデータセットにおいて、単一モデルの物体検出器を上回ることが示されました。また，Cascade R-CNNは，検出器のアーキテクチャを問わず広く適用可能であり，ベースラインの検出器の強さによらず一貫した利益を得ることができることが実験で示された．コードは、このhttpsのURLで公開されます。
これまで、ニューラル抽象化要約法は、単一文書要約（SDS）において大きな成功を収めてきました。しかし，大規模なマルチドキュメントの要約が存在しないため，このような手法はマルチドキュメント要約(MDS)にはほとんど適用できない．本論文では、SDSのための最先端のニューラル抽象化要約モデルを適応することで、MDSのためのニューラル抽象化手法を調査する。SDSの大規模データで学習したニューラル抽象化モデルをMDSタスクに拡張するアプローチを提案する。本アプローチでは、微調整のために少数のマルチドキュメントサマリーを利用するのみである。2つのベンチマークであるDUCデータセットでの実験結果により、我々のアプローチが様々なベースラインのニューラルモデルを凌駕できることを実証する。
本論文では、エージェントが教師なしで環境を学習することができるシンプルなスキームを説明する。この方式では、同じエージェントの2つのバージョン、AliceとBobが互いに対戦します。アリスはボブにタスクを提案し、ボブはそのタスクを完了しようとする。この研究では、2種類の環境に焦点を当てます。(ほぼ)可逆的な環境と、リセット可能な環境です。アリスは一連の行動をすることでタスクを「提案」し、ボブはそれを元に戻すか、繰り返すかしなければなりません。適切な報酬構造を介して、アリスとボブは自動的に探索のカリキュラムを生成し、エージェントの教師なしのトレーニングを可能にします。ボブが環境内のRLタスクに配置されると、この教師なしの学習により、学習に必要な教師付きエピソードの数が減り、場合によってはより高い報酬に収束する。
我々は、勾配ベースの強化学習(RL)アルゴリズムを学習するための金属学習アプローチを提案する。このアイデアは、微分可能な損失関数を進化させることで、この損失を最小化するように政策を最適化するエージェントが高い報酬を得られるようにするものである。この損失は、エージェントの経験に対する時間的な畳み込みによってパラメータ化されます。この損失は、エージェントの履歴を考慮に入れることができる柔軟性の高いものであるため、高速なタスク学習が可能である。実証実験の結果、我々の進化型政策勾配アルゴリズム(EPG)は、既製の政策勾配法と比較して、いくつかのランダム化された環境でより高速な学習を達成した。また、EPGの学習した損失は、分布外のテスト時間のタスクに一般化することができ、他の一般的な金属学習アルゴリズムとは質的に異なる挙動を示すことを実証した。
潜在木学習モデルは、構文監視なしで文を解析することを学習し、その解析結果を用いて文の表現を構築します。このようなモデルに関する既存の研究では、文の分類などのタスクでは良好な性能を発揮するものの、もっともらしい意味論や構文論のフォーマリズムに準拠した文法を学習しないことが明らかになっている（Williams et al.） このようなモデルの解析能力を自然言語で研究することは、1つの文に対していくつかの有効な解析があるような自然言語の固有の複雑さのために困難です。本論文では、潜在木モデルの解析能力を研究するために作成されたトイデータセットであるListOpsを紹介します。ListOpsの配列は、接頭辞の算術のスタイルになっています。このデータセットは、システムがタスクを成功させるために学習する必要がある、単一の正しい解析戦略を持つように設計されています。現在の主要な潜在木モデルは、ListOpsの解析を学習して成功させることができないことを示しています。これらのモデルは、純粋なシーケンシャルRNNよりも悪い精度を達成しています。
ゲート付きリカレントユニットの成功を考えると、長短期記憶（LSTM）ネットワークのすべてのゲートが必要なのかという自然な疑問が出てくる。これまでの研究では、忘却ゲートがLSTMの中で最も重要なゲートの一つであることがわかっている。本研究では、クロノ初期化されたバイアスを持つLSTMの忘却ゲートのみのバージョンが、計算量を削減するだけでなく、複数のベンチマークデータセットにおいて標準的なLSTMよりも優れた性能を発揮し、現代の最高モデルのいくつかと競合することを示す。我々の提案するネットワークJANETは、MNISTおよびpMNISTデータセットにおいて99%および92.5%の精度を達成し、98.5%および91%の精度を得た標準的なLSTMを上回りました。
BPEmbは、BPE（Byte-Pair Encoding）に基づいて275の言語で事前に学習されたサブワードユニットエンベッディングのコレクションである。細かいエンティティタイピングをテストベッドとして使用した評価では、BPEmbは競争力のある性能を発揮し、いくつかの言語では他のサブワードアプローチよりも優れた性能を発揮しました。BPEmb は以下の https URL から入手できます。
自然言語で記述されたシーンを、エンティティのリアルなレイアウトと外観で想像することは、空間的、視覚的、意味的な世界知識の究極のテストである。この目的のために、我々は、ビデオキャプションデータからこれらの知識を学習し、新しいキャプションからビデオを生成する際にそれを適用することができるモデル、CRAFT（Composition, Retrieval, and Fusion Network）を発表する。CRAFTは、言及されたエンティティ（キャラクターやオブジェクト）の時間的レイアウトを明示的に予測し、ビデオデータベースから時空間的なエンティティセグメントを検索し、それらを融合してシーンビデオを生成する。本研究では、CRAFTの構成要素を順次学習させながら、レイアウトと見た目を共同でモデル化し、検索のための構成表現の学習を促す損失を与えた。CRAFTは、キャプションへの意味的な忠実性、構成の一貫性、および視覚的な品質について評価します。CRAFTは、直接ピクセルを生成するアプローチよりも優れており、見たことのないキャプションや、テキストアノテーションのないビデオデータベースにも十分に一般化することができます。CRAFTは、25,000本以上のビデオを含む、豊富なアノテーションを持つ新しいビデオキャプションデータセットであるFLINTSTONESで実証されています。CRAFTによって生成されたビデオの一部は、こちらのhttps URLをご覧ください。
モデルフリー強化学習では、政策のパラメータ空間でのランダム探索に基づく手法は、行動の空間を探索する手法よりもサンプルの複雑さが著しく劣るというのが一般的な考え方です。本論文では、連続制御問題に対する静的な線形政策を学習するためのランダム探索法を紹介し、ベンチマークであるMuJoCoロコモーションタスクにおいて最先端のサンプル効率を実現することで、このような通説を払拭する。また、制御理論の古典的な問題である「線形二次レギュレータ」の困難なインスタンスに対して、ダイナミクスがわからない場合に、ほぼ最適なコントローラを見つけることができます。このランダム探索アルゴリズムは、これらのベンチマークにおいて、競合する最速のモデルフリー手法と比較して、少なくとも15倍の計算効率を実現しています。この計算効率の良さを利用して，各ベンチマーク課題について，何百ものランダムシードと多数の異なるハイパーパラメータ設定に対する本手法の性能を評価した．シミュレーションの結果，これらのベンチマークタスクにおける性能の高いばらつきが浮き彫りになり，一般的に用いられているサンプル効率の推定値ではRLアルゴリズムの性能を適切に評価できないことが示唆された．
教師なしの画像間変換は，コンピュータビジョンにおける重要かつ挑戦的な問題である．ソース領域の画像が与えられたとき、対応する画像のペアを見ることなく、ターゲット領域の対応する画像の条件付き分布を学習することが目的である。この条件付き分布は、本来マルチモーダルなものですが、既存のアプローチでは、決定論的な一対一のマッピングとしてモデル化するという単純すぎる仮定をしています。その結果，与えられたソースドメイン画像から多様な出力を生成することができない．この問題を解決するために、我々は、Multimodal Unsupervised Image-to-image Translation (MUNIT)フレームワークを提案する。画像表現は、ドメイン不変のコンテンツコードと、ドメイン固有の特性を表すスタイルコードに分解できると仮定する。画像を別のドメインに翻訳するためには，そのコンテンツコードを，ターゲットドメインのスタイル空間からサンプリングしたランダムなスタイルコードと再結合する．提案されたフレームワークを分析し、いくつかの理論的な結果を確立する。大規模な実験を行い，最先端のアプローチと比較することで，提案フレームワークの優位性をさらに実証する．さらに、我々のフレームワークでは、スタイル画像の例を提供することで、ユーザーが翻訳出力のスタイルを制御することができる。コードおよび事前学習済みモデルは、このhttps URLから入手できます。
自動テキスト要約は、文書の主要なアイデアを保持しながらテキストを短縮する自動プロセスであり、自然言語処理の重要な研究分野である。この文献レビューの目的は、自動テキスト要約におけるニューラルベースのモデルに関する最近の研究を調査することである。最新のニューラルベースの要約器10種（抽象的モデル5種、抽出的モデル5種）について詳細に検討する。さらに、要約タスクに適用可能な関連技術を議論し、ニューラルベースの要約における将来の研究のための有望な道を提示する。
本論文では、マグニチュード・スペクトログラムから時間領域の信号（または位相スペクトログラム）を単独で再構成する問題に取り組む。マグニチュード・スペクトログラムには位相情報が含まれていないため、時間領域の信号を再構成するためには、位相情報を復元または推論する必要がある。この信号再構成問題に対処する方法として、GriffinとLimが提案した方法が広く使われている。この方法では、通常、信号再構成処理に多くの反復処理を必要とし、入力によっては、必ずしも高品質な音声信号を生成できないことがある。これらの欠点を克服するために、我々は、ディープニューラルネットワークを用いて信号再構成プロセスをモデル化し、生成的逆説ネットワークのアイデアを用いてそれを学習することにより、信号再構成問題に学習ベースのアプローチを適用した。実験評価の結果、我々の手法はGriffin-Lim法よりも高速かつ高品質に信号を再構成できることが明らかになった。
新しいデータセットから洞察を引き出す能力は、意思決定に不可欠です。視覚的な対話ツールは、技術者ではないユーザーが視覚的にクエリを作成し、その結果を理解するための効果的な方法を提供するため、データ探索において重要な役割を果たします。近年、自然言語は、データベースの代替的な検索インターフェースとして注目を集めており、専門家ではないユーザーが複雑な質問や情報ニーズを効率的かつ効果的に表現できる可能性を秘めています。しかし、自然言語の質問を理解し、SQLに正確に変換することは困難な作業であるため、データベースのための自然言語インターフェース（NLIDB）は、実用的なツールや商用製品にはまだ浸透していません。本論文では、自然言語インターフェースを備えた新しいデータ探索ツールであるDBPalを紹介します。DBPalは、深層モデルの最近の進歩を活用して、以下の方法でクエリ理解をよりロバストにする。第一に、DBPalは、言い換えや他の言語的変動に対して翻訳プロセスをよりロバストにする、SQLに自然言語文を翻訳するために深いモデルを使用しています。第二に、データベース スキーマおよびクエリ機能を知らずに質問をフレーズする際にユーザーをサポートするために、DBPalは、クエリの策定中にユーザーに部分的なクエリ拡張を提案する学習された自動補完モデルを提供し、その結果、複雑なクエリを書くのに役立ちます。
分布データは、人がキャンディを飲み込むことができることを教えてくれますが、人がペイントボールを飲み込むことができることは証明されていないので、教えてくれません。しかし、どちらも物理的には妥当な事象です。本論文では、意味的妥当性のタスクを紹介する。つまり、妥当だが、おそらく新規性のある事象を認識する。本論文では、"man swallow paintball "のような単一の事象の意味的妥当性を判断した新しいクラウドソースのデータセットを紹介する。分布表現に基づいた単純なモデルは、選択優先度では良い結果が得られたものの、このタスクではあまり良い結果が得られなかったが、手動で抽出したエンティティプロパティに関する知識を注入することで、大幅に性能が向上した。我々のエラー分析は、我々の新しいデータセットが意味論的妥当性モデルの優れたテストベッドであることを示しています。
深層ネットワークのようなブラックボックス分類器を解釈することで、分析者は分類器を高リスクの設定で展開する前に検証することができます。そのためには、ディープネットワークの表現を可視化して、「ネットワークが見ているものを見る」ということが必要です。本論文では、このような環境における標準的な次元削減手法では、情報が得られない、あるいは誤解を招くような可視化が行われる可能性があることを示しています。その代わりに、ダークナレッジの概念に触発された方法で分類器の予測を視覚的に要約するDarkSightを紹介します。DarkSightは、データポイントを低次元空間に埋め込むことで、深層分類器をより単純なものに圧縮することを容易にし、基本的にモデル圧縮と次元削減を組み合わせたものである。DarkSightとt-SNEを定性的、定量的に比較したところ、DarkSightによる可視化の方が情報量が多いことがわかった。また、この手法では、与えられた予測のベクトルがどれだけ珍しいかを定量化することで、暗黙知に基づいた新しい信頼性指標を得ることができる。
抽象的な言語生成モデルの教師付きトレーニングでは，教師付きトレーニング信号に基づいて，言語シーケンスに対する条件付き確率を学習する．訓練信号に様々な文体が含まれている場合、このようなモデルは、訓練データのメイクアップに直接影響され、アプリケーションのニーズによって制御できない「平均的な」文体を学習してしまう可能性がある。本論文では、共有モデルパラメータによる一般的な言語特性と、プライベートモデルパラメータによる特定のスタイル特性の両方を捉えることができるモデルアーキテクチャのファミリーについて説明する。このようなモデルは、一般的な言語現象をモデル化する力を利用しつつ、特定の学習スタイルに応じた言語を生成することができる。さらに，学習したすべてのスタイルの出力分布の混合物を用いて，テキスト入力のみに基づいてオンザフライでスタイル適応を行う拡張機能について説明する．実験の結果、提案したモデルは、単一のスタイルや平均的なスタイルの言語生成機能を内包するモデルよりも一貫して優れていることがわかった。
視覚世界を真に理解するためには、モデルは画像を認識するだけでなく、画像を生成することもできなければなりません。この目的のために、最近、自然言語の記述から画像を生成する方法が進歩しています。これらの手法は、鳥や花の説明のような限られた領域では素晴らしい結果が得られるが、多くのオブジェクトや関係性を持つ複雑な文章を忠実に再現することは困難である。この限界を克服するために、我々はシーングラフから画像を生成する手法を提案する。これにより、オブジェクトとその関係を明示的に推論できるようになる。我々のモデルは、グラフ畳み込みを用いて入力グラフを処理し、オブジェクトのバウンディングボックスとセグメンテーションマスクを予測することでシーンレイアウトを計算し、カスケード接続された洗練されたネットワークを用いてレイアウトを画像に変換する。このネットワークは、現実的な出力を確保するために、一対の識別器に対して敵対的に学習されます。Visual GenomeとCOCO-Stuffを用いて本手法を検証したところ、定性的な結果、アブレーション、ユーザスタディにより、本手法が複数のオブジェクトを含む複雑な画像を生成できることが示された。
学習した微分可能なフォワードモデルを用いたアクションプランニングは、モデルフリーのRL手法に比べてサンプルの複雑さが改善されていること、異なるタスク間で学習したモデルを再利用できること、連続的なアクション空間で効率的な勾配ベースの最適化を実行できることなど、多くの望ましい特性を持つ一般的なアプローチである。しかし、この手法は、行動空間が離散的である場合には、簡単には適用できない。本研究では、離散的な行動空間においてバックプロップによるプランニングを効果的に行うことが可能であることを示す。フォワードモデルを学習する際に、シンプレックス上の行動ベクトルの単純なパラメータ化と入力ノイズを組み合わせる。我々の実験によると、この手法は、グリッドワールドのナビゲーションタスクにおいて、限られた環境でのインタラクションを利用しながら、モデルフリーRLや離散的な計画手法と性能や計画時間の点で同等かそれ以上の性能を発揮することができる。また、アクション空間が離散的なアクションと連続的なアクションを組み合わせた難しい新しいタスクにおいても、モデルベース制御を行うことができる。さらに、推論時に使用できる高速なポリシーネットワークを生成するポリシー蒸留アプローチを提案し、反復的な計画手順の必要性を排除します。
新しいデータに素早く適応し、そのようなサンプルを生成するエンド・ツー・エンドの学習済み記憶システムを提案する。Kanervaのスパース分散メモリにヒントを得て、ロバストな分散読み書き機構を備えています。このメモリは解析的に扱いやすく、ベイズ式更新ルールによる最適なオンライン圧縮が可能です。我々はこのモデルを、メモリが豊富なデータ依存の事前分布を提供する、階層的な条件付き生成モデルとして定式化しました。その結果、トップダウンの記憶とボトムアップの知覚が組み合わされて、観測を表すコードが生成される。経験的には、OmniglotとCIFARの両方のデータセットで学習した生成モデルが、適応メモリによって大幅に改善されることを実証しています。微分可能なニューラルコンピュータ（DNC）やその改良型と比較して、我々のメモリモデルはより大きな容量を持ち、訓練が非常に簡単である。
現代の多くのアプリケーションでは、遺伝子の機能分類、画像のラベリング、テキストの分類など、複数のラベルを持つデータを扱っています。多数のラベルとラベル間の潜在的な依存関係を持つこのようなデータの分類は困難な作業であり、データがオンラインでチャンクで受信される場合にはさらに困難になります。現在のマルチラベル分類法の多くは、多くの時間とメモリを必要とするため、実用的な実世界のアプリケーションでは実現不可能である。本論文では、ラベルを縮小された符号化空間に変換し、得られた疑似ラベル上でモデルを学習する高速な線形ラベル空間次元削減法を提案する。さらに、ラベルを元の空間にマッピングする復号化行列を更新する解析手法を提供し、テスト段階で使用する。実験結果は、実行時間と様々な尺度での予測性能の観点から、このアプローチの有効性を示しています。
構造化されていない環境をナビゲートすることは、知的生物の基本的な能力であり、したがって、人工知能の研究と開発において基本的な関心事である。長距離のナビゲーションは、複雑な認知タスクであり、認識可能なランドマークとロバストな視覚処理に基づいた空間の内部表現を開発することに依存しています。迷路ナビゲーション問題に深層強化学習を適用した最近の研究を基に、都市規模で適用可能なエンドツーエンドの深層強化学習アプローチを提示します。ナビゲーションを成功させるには、一般的な政策と地域固有の知識を統合することが重要であることを認識し、地域固有の特徴をカプセル化しつつ、複数の都市への転送を可能にするデュアルパスウェイアーキテクチャを提案する。この学習法により、エージェントは複数の都市のナビゲーションを学習し、数キロメートル離れた目的地への移動を可能にすることを実証しています。プロジェクトのウェブページ（http）には、研究内容を要約したビデオや、学習したエージェントが多様な都市環境や移動タスクで活躍する様子、StreetLearnデータセットを請求するためのフォーム、その他のリソースへのリンクなどが掲載されています。StreetLearnの環境コードはこちらのhttpsのURLから入手できます。
この記事では、最近のTensor2TensorフレームワークとTransformer sequence-to-sequenceモデル（Vaswani et al.、2017）を使用したニューラル機械翻訳の実験について説明します。最終的な翻訳品質、メモリ使用量、トレーニングの安定性、トレーニング時間に影響を与える重要なパラメータのいくつかを検証し、各実験を仲間の研究者への推奨事項で締めくくります。より多くのデータとより大きなモデル」という一般的なマントラを確認することに加え、複数のGPUへのスケーリングを取り上げ、バッチサイズ、学習率、ウォームアップステップ、最大文の長さ、チェックポイントの平均化に関して、トレーニングを改善するための実践的なヒントを提供しています。また、バッチサイズ、学習率、ウォームアップステップ、最大文の長さ、チェックポイントの平均化など、実用的なヒントも紹介しています。
教師なし学習の主な目的は、学習中に教師ありのラベルにアクセスすることなく、後続のタスクに有用なデータ表現を発見することです。一般的には、生成モデルの負の対数尤度のような代理目的を最小化することで、後続のタスクに有用な表現が副次的に生じることを期待して、この目的に近づいている。本研究では、その代わりに、教師なし学習ルールをメタ学習することで、後の目的のタスクを直接ターゲットとし、そのタスクに有用な表現を導くことを提案する。ここでは、望ましいタスク(メタ目的)を半教師付き分類における表現の性能とし、このメタ目的の下で良好な性能を示す表現を生成するアルゴリズム(教師なしの重み更新規則)をメタ学習する。さらに、この教師なし更新規則を、生物学的に動機づけられたニューロンローカルな関数とすることで、新しいニューラルネットワークアーキテクチャに一般化することができるようにした。メタ学習された更新規則は、有用な特徴を生み出し、時には既存の教師なし学習技術よりも優れた性能を発揮することを示します。メタ学習された教師なし更新規則は、異なる幅、深さ、および非線形性を持つネットワークの学習に一般化することを示す。また、ランダムに配列された入力次元を持つデータに対する学習も一般化され、さらには画像データセットからテキストタスクへの一般化も可能である。
我々は、強化学習からのアクター・クリティック・アプローチに基づいた、ニューラル抽象的要約のための学習フレームワークを提示する。従来のニューラルネットワークを用いた手法では、予測された要約の尤度を最大化することのみを目的としており、他の評価制約は考慮されていないため、低品質の要約や誤った文章が生成される可能性がある。この問題を軽減するために、我々はアクター批判のフレームワークを採用し、学習手順を強化します。アクターには、要約生成のためのポリシーネットワークとして、典型的な注意ベースのsequence-to-sequence (seq2seq)フレームワークを採用する。批評家については、最尤推定法と、ニューラルネットワークベースの二値分類器であるグローバル要約品質推定法を組み合わせることで、生成された要約を人間が書いた要約と区別できないようにする。政策勾配法を用いてパラメータ学習を行う。また，アクターモデルと批評家モデルの共同学習を行うために，交互学習戦略を提案する．様々な言語のベンチマークデータを用いた大規模な実験により、我々のフレームワークが最先端の手法よりも向上することが示された。
本論文では、ニューラルテキスト生成モデルの最近の開発状況を系統的に調査した。具体的には、従来の最尤推定学習スキームを用いたリカレントニューラルネットワーク言語モデルから始め、そのテキスト生成における欠点を指摘する。そこで、強化学習、再パラメトリック化トリック、GAN(Generative Adversarial Nets)技術に基づいて、最近提案されたテキスト生成方法を紹介する。これらのモデルの異なる特性と、勾配消失や生成の多様性といった共通の問題を処理するための対応技術を比較する。最後に、2つのよく知られたデータセットを用いて、異なるタイプのニューラルテキスト生成モデルのベンチマーク実験を行い、前述のモデルの特性とともに経験的な結果を議論する。
文章を埋め込みベクトルにエンコードするモデルを発表し、特に他のNLPタスクへの転移学習を目標とする。このモデルは効率的であり、多様な伝達タスクにおいて正確な性能を発揮する。符号化モデルの2つのバリエーションは、精度と計算資源の間のトレードオフを可能にする。両方のモデルについて、モデルの複雑さ、リソースの消費、転送タスクのトレーニングデータの利用可能性、およびタスクのパフォーマンスの関係を調査し、報告する。また、事前に学習した単語埋め込みを用いて単語レベルの伝達学習を行うベースラインと、伝達学習を行わないベースラインとの比較を行った。その結果，文埋め込みを用いた伝達学習は，単語レベルの伝達学習を上回る傾向にあることがわかった．文章埋め込みを用いた伝達学習では、伝達タスクのための最小限の教師付き訓練データで、驚くほど良い性能が得られることがわかった。また、モデルの偏りを検出することを目的とした単語埋め込み連想テスト（WEAT）において、有望な結果が得られた。事前に学習した文の符号化モデルは、TF Hubで自由にダウンロードして利用することができます。
畳み込みニューラルネットワーク（CNN）は、その構築モジュールの幾何学的構造が固定されているため、幾何学的変換のモデル化には本質的に限界があります。本研究では、CNNの変換モデリング能力を高めるために、変形可能な畳み込みと変形可能なRoIプーリングという2つの新しいモジュールを導入する。この2つのモジュールは、モジュール内の空間サンプリング位置を追加のオフセットで補強し、追加の監視なしにターゲットタスクからオフセットを学習するというアイデアに基づいています。この新しいモジュールは、既存のCNNにおけるプレーンなモジュールと容易に置き換えることができ、標準的なバックプロパゲーションによってエンドツーエンドで容易に学習することができ、変形可能な畳み込みネットワークを生み出すことができます。大規模な実験により、物体検出やセマンティック・セグメンテーションなどの高度なビジョン・タスクにおける本アプローチの有効性が検証されました。コードを公開します。
自然言語から色付きの3D形状を生成する手法を紹介します。この目的のために、まず、自由形式のテキスト記述と着色された3D形状の共同埋め込みを学習する。我々のモデルは、連想学習とメトリック学習のアプローチを組み合わせて拡張することで、暗黙的なクロスモーダル接続を学習し、言語と、色や形などの3D形状の物理的特性との間の多対多の関係を捉える共同表現を生成するものである。我々のアプローチを評価するために、物理的な3Dオブジェクトに対する自然言語記述の大規模なデータセットをShapeNetデータセットとして収集した。この学習された共同埋め込みを用いて、テキストから形状の検索を行い、ベースラインのアプローチを上回る結果を得た。さらに、この埋め込みを、新しい条件付きWasserstein GANフレームワークと組み合わせて、テキストから色付きの3D形状を生成します。この手法は、自然言語のテキストと、色、質感、形状の詳細なバリエーションを持つ現実的な3Dオブジェクトを結びつける世界初の手法です。このhttpsのURLでビデオを見る
単一文書の要約は、文書の主要な情報内容を保持しつつ、より短いバージョンを作成するタスクです。本論文では、抽出型要約を文のランキングタスクとして概念化し、強化学習目的でROUGE評価指標をグローバルに最適化する新しい学習アルゴリズムを提案する。このアルゴリズムを用いて、CNNおよびDailyMailデータセット上でニューラル要約モデルを学習し、自動評価および人間による評価において、最先端の抽出型および抽象型システムを上回ることを実験的に示した。
YOLO！のアップデートを発表しました。YOLO! をより良くするために、たくさんの小さな設計変更を行いました。また、新しいネットワークを学習させましたが、これがなかなかいい感じです。前回よりも少し大きくなりましたが、より正確になりました。でも、まだ速いですよ、心配しないでください。320x320の場合、YOLOv3は28.2mAPで22msで動作します。これはSSDと同じ精度ですが、3倍速いです。従来の0.5IOUのmap検出基準で見てみると、YOLOv3はかなり優秀です。RetinaNetが57.5 mAP@50で198msであるのに対し、YOLOv3はTitan Xで57.9 mAP@50を51msで達成しており、同等の性能でありながら3.8倍高速です。なお、すべてのコードはhttpsのURLで公開されています。
バッチ正規化（BN）は、ディープラーニングの開発においてマイルストーンとなる技術であり、様々なネットワークの学習を可能にします。しかし、バッチ次元での正規化には問題があります。バッチサイズが小さくなると、バッチ統計の推定が不正確になるため、BNのエラーが急激に増加します。このため、BNは、より大きなモデルの学習や、メモリ消費量に制約のある小さなバッチを必要とする検出、セグメンテーション、ビデオなどのコンピュータビジョンタスクへの特徴の移行には使用できない。本論文では、BNに代わるシンプルな手法として、グループ正規化（GN）を紹介します。GNは、チャンネルをグループに分割し、各グループ内で正規化のための平均値と分散値を計算します。GNの計算はバッチサイズに依存せず、またその精度は幅広いバッチサイズで安定しています。ImageNet で訓練された ResNet-50 において、GN はバッチサイズ 2 の場合に BN と比較して 10.6% 低いエラーを示しました。一般的なバッチサイズを使用した場合、GN は BN と同等に優れており、他の正規化手法よりも優れています。さらに、GNは事前学習から微調整へと自然に移行することができます。GN は、COCO におけるオブジェクトの検出とセグメンテーション、および Kinetics におけるビデオの分類において、BN をベースにした同等の手法よりも優れており、GN が様々なタスクにおいて強力な BN を効果的に置き換えることができることを示しています。GNは、最新のライブラリに数行のコードで簡単に実装することができます。
我々は、抽象的な要約のために長い文書を表現するという課題に対処するために、エンコーダー・デコーダー・アーキテクチャーにおける深層コミュニケーション・エージェントを提示する。深層コミュニケーションエージェントを用いることで、長いテキストを符号化するタスクは、複数の協力するエージェントに分割され、それぞれが入力テキストのサブセクションを担当する。これらの符号化器は、強化学習を用いてエンド・ツー・エンドで学習された1つの復号器に接続され、焦点の合った首尾一貫した要約を生成する。実証実験の結果、複数の通信可能なエンコーダーは、単一のエンコーダーや複数の非通信可能なエンコーダーを含むいくつかの強力なベースラインと比較して、より高品質な要約をもたらすことが明らかになった。
従来の質問応答モデルでは、クロスエントロピー損失を用いて最適化を行っていたが、これは正確な回答を促す一方で、近くにある回答や重複する回答が同じくらい正確である場合にはペナルティを課すというものであった。我々は、クロスエントロピー損失と自己批判的ポリシー学習を組み合わせた混合目的を提案する。この目的は、評価指標と最適化目的の間のミスアライメントを解決するために、単語の重複から得られる報酬を使用する。混合目的に加えて、我々は、深層自己注意と残差ネットワークの最近の研究に触発された深層残差コーテンションエンコーダを用いて、動的コーテンションネットワーク（DCN）を改善する。我々の提案は、質問の種類や入力の長さに関わらず、モデルの性能を向上させ、特に長期的な依存関係を捉える能力を必要とする長文の質問に対して有効である。Stanford Question Answering Datasetにおいて，我々のモデルは，75.1%の完全一致精度と83.1%のF1という最先端の結果を達成し，アンサンブルは78.9%の完全一致精度と86.0%のF1を達成した．
ここでは、ゼロショット認識の問題を考えます。つまり、学習例がゼロのカテゴリに対して、視覚データが提供されているカテゴリの単語埋め込みと他のカテゴリとの関係だけを使って、視覚的な分類器を学習します。馴染みのないカテゴリや新規のカテゴリに対応するには、馴染みのあるクラスから得られた知識を、馴染みのないクラスの記述に移すことが重要である。本論文では、最近導入されたグラフ畳み込みネットワーク（Graph Convolutional Network: GCN）をベースに、意味的な埋め込みとカテゴリーの関係性の両方を用いて分類器を予測するアプローチを提案する。学習された知識グラフ(KG)が与えられたとき、我々のアプローチは、各ノード(視覚的なカテゴリーを表す)の意味的な埋め込みを入力として受け取る。一連のグラフ畳み込みの後、各カテゴリの視覚的分類器を予測します。学習時には，いくつかのカテゴリの視覚的分類器を与え，GCNパラメータを学習する．テスト時には，これらのフィルタを用いて，見たことのないカテゴリの視覚的分類器を予測する．我々のアプローチは、KGのノイズに強いことを示している。さらに重要なことに，我々のアプローチは，現在の最先端の結果と比較して，性能を大幅に向上させることができる（いくつかの指標では2～3％，いくつかの指標では20％という驚異的な値）．
私たちは、一般的な強化学習環境の生成ニューラルネットワークモデルを構築することを検討しています。我々のワールドモデルは、環境の圧縮された空間的・時間的表現を学習するために、教師なしの方法で素早く学習することができます。ワールドモデルから抽出された特徴をエージェントの入力として使用することで、必要なタスクを解決できる非常にコンパクトでシンプルなポリシーを学習することができます。さらに、ワールドモデルによって生成された幻覚の中でエージェントを学習し、このポリシーを実際の環境に戻すこともできます。この論文のインタラクティブ版はこちらのhttps URLでご覧いただけます。
深層ニューラルネットワークは、大規模なデータセットを記憶する能力があるにもかかわらず、しばしば良好な一般化性能を達成します。しかし、汎化するネットワークと汎化しないネットワークの学習解の違いは、まだ明らかになっていません。また、単一方向のチューニング特性（ある入力に対する単一ユニットまたはユニットの線形結合の活性化と定義）が注目されていますが、その重要性は評価されていません。本研究では、これらの研究を統合し、ラベルの破損率が異なるデータセットで学習されたネットワーク、ラベルが修正されていないデータセットで学習されたネットワークのアンサンブル、異なるハイパーパラメータ、および学習期間において、単一方向への依存度がネットワークの汎化性能の良い予測因子であることを実証した。dropoutはこの量をある時点までしか正則化しませんが、バッチ正則化は、個々のユニットのクラス選択性を低下させることによって、暗黙のうちに単一方向の信頼性を失わせます。最後に、クラス選択性はタスクの重要性を予測するのに不十分であることがわかりました。これは、よく汎化するネットワークは、選択性を低下させることで個々のユニットへの依存性を最小化するだけでなく、強力なネットワーク性能には個々の選択性を持つユニットは必要ないかもしれないことを示唆しています。
QFS（Query Focused Summarization）は、これまで主に抽出型の手法で取り組まれてきました。しかし、このような手法では、まとまりのないテキストになってしまいます。本研究では、このような限界を克服するために、抽象的な手法をQFSに適用する方法を検討します。最近、神経注意に基づいたsequence-to-sequenceモデルが開発され、一般的な単一文書の抽象的な要約のタスクにおいて最先端の結果が得られた。このようなモデルは、大量の学習データを用いてEnd to Endの方法で学習される。我々は、抽象的な要約をQFSに適用するために、3つの側面に取り組んでいる。(a)学習データがないため、クエリの関連性を事前に学習した抽象化モデルに組み込む。(b)既存の抽象化モデルは単一文書の設定で学習されているため、抽象化モデルをQFSの複数文書の要件に組み込むための反復手法を設計する。(c)我々が適用する抽象化モデルは、特定の長さ（約100ワード）のテキストを生成するように学習されているが、我々は異なるサイズ（約250ワード）の出力を生成することを目的としている。我々の手法(Relevance Sensitive Attention for QFS)を、抽出型のベースラインや、抽象化モデルを組み合わせる様々な方法と、DUC QFSデータセットで比較し、ROUGEの性能が確実に向上することを実証した。
本論文では、大規模な敵対的事例を防御するための改良技術を開発しました。まず、ImageNet上で前例のない規模で敵対的なトレーニングの最先端バージョンを実装し、この設定で効果を維持しているかどうかを調査します-重要な未解決の科学的疑問です（Athalye et al.2018）。次に、私たちがlogit pairingと呼ぶ、例のペアのlogitが似ていることを奨励する手法を用いて、強化された防御を導入します。クリーンな例とその敵対的な例に適用すると、ロジットペアリングはバニラの敵対的なトレーニングよりも敵対的な例の精度を向上させます。また、クリーンな例のみのロジットペアリングは、2つのデータセットでの精度において敵対的なトレーニングと競合することがわかりました。最後に、敵対的ロジットペアリングは、PGDホワイトボックス攻撃に対してImageNet上で最先端の防御を達成し、精度が1.5%から27.9%に向上したことを示す。また、Adversarial logit pairingは、ImageNetにおけるブラックボックス攻撃に対する現在の最先端の防御にダメージを与えることに成功し(Tramer et al., 2018)、その精度は66.6%から47.1%に低下しました。この新たな精度低下により、Adversarial logit pairingは、ImageNet上のブラックボックス攻撃に対するState of the artとして、Tramerら(2018)と肩を並べることになりました。
本論文では、壊滅的な忘却を回避しつつ、単一の深層ニューラルネットワークに複数のタスクを追加する方法を紹介します。ネットワーク・プルーニング技術にヒントを得て、大規模な深層ネットワークの冗長性を利用して、新しいタスクを学習するために採用できるパラメータを解放します。反復的な刈り込みとネットワークの再トレーニングを行うことで、パフォーマンスの低下とストレージのオーバーヘッドを最小限に抑えながら、複数のタスクを1つのネットワークに順次「パック」することができます。古いタスクの精度を維持するためにプロキシの損失を利用する先行研究とは異なり、我々は常に現在のタスクに最適化します。様々なネットワークアーキテクチャと大規模データセットを用いて大規模な実験を行い、先行研究と比較して、壊滅的な忘却に対するロバスト性が非常に高いことを確認しました。特に、ImageNetで学習したVGG-16ネットワークに3つの細かい分類タスクを追加し、それぞれのタスクで個別に学習したネットワークに近い精度を達成することができた。コードはこのhttpsのURLから入手できます。
単語ベクトルは大量のメモリとストレージを必要とするため、携帯電話やGPUなどのリソースが限られたデバイスでは問題となります。本論文では，Word2Vecに量子化関数を導入することで，パラメータあたり1〜2ビットの量子化された高品質な単語ベクトルを学習できることを示す．さらに、量子化関数を用いた学習が正則化の役割を果たすことを示す。英語版Wikipedia（2017年版）で単語ベクトルを学習し、標準的な単語の類似性や類推タスク、質問応答（SQuAD）で評価した。我々の量子化された単語ベクトルは、フルプレシジョン（32ビット）の単語ベクトルに比べて8～16倍のスペースを必要とするだけでなく、単語の類似性タスクと質問応答においてそれらを上回る結果となった。
コピーメカニズムを備えた注意ベースの神経抽象的要約システムは、有望な結果を示している。しかし、このようなシステムでは、入力パラグラフのフレーズやセンテンス、場合によっては複数の連続したセンテンスをコピーして要約を生成し、効果的に抽出型要約を行っていることが注目されている。本論文では、最新のニューラル抽象化要約システムであるポインタ生成ネットワークを用いて、この動作を検証する。我々は、再トレーニングを行わずにコピーの量を制御できる簡単なベースライン手法を提案する。実験によると、この方法は、元の記事との重複を最小限に抑えながら高いROUGEスコアを得ようとする抽象化システムに強力なベースラインを提供し、元のモデルのROUGEスコアを2ポイント以内に抑えながら、元の記事とのn-gramの重複を大幅に減らすことができた。
ダーティなデータがデータマイニングや機械学習の結果に悪影響を与えることから、データ品質の問題が広く注目されています。データ品質と結果の精度の関係は、データ品質を考慮した適切なアルゴリズムの選択や、クリーニングするデータシェアの決定に応用できる。しかし、このような関係を探ることに焦点を当てた研究は少ない。そこで本稿では，データの欠落，不整合，矛盾が分類・クラスタリングアルゴリズムに与える影響を実験的に比較した。この実験結果に基づいて、アルゴリズムの選択とデータクリーニングのガイドラインを提供する。
視覚的な質問に答えるためには、画像に関する高次の推論が必要であり、これは機械システムが複雑な指示に従うために必要な基本的な能力である。近年、モジュラーネットワークは、視覚的な推論タスクを実行するための効果的なフレームワークであることが示されている。モジュラーネットワークは当初、モデルの透明性を考慮して設計されていたが、複雑な視覚的推論のベンチマークにおける性能は不十分であった。現在の最先端のアプローチは、推論プロセスを理解するための効果的なメカニズムを提供していない。本論文では、解釈可能なモデルと最新の視覚的推論手法との間のパフォーマンスギャップを解消する。本論文では、複雑な推論タスクを明示的に解釈可能な方法で実行できるモデルとして現れる、一連の視覚的推論プリミティブを提案する。プリミティブの出力の忠実さと解釈可能性は、結果として得られるモデルの長所と短所を診断するための比類ない能力を可能にします。CLEVRデータセットにおいて99.1%という最先端の精度を達成し、これらのプリミティブが高いパフォーマンスを発揮することを示しています。また、このモデルは、新規のオブジェクト属性を含む少量のデータが与えられた場合に、一般化された表現を効果的に学習できることを示しています。CoGenTの一般化タスクを用いて、現在の技術水準に比べて20%ポイント以上の改善を示しています。
Variational Autoencoder（VAE）は、自然データに対して意味的に意味のある潜在的な表現を生成するための効果的なモデルであることが証明されています。しかし、これまでのところ、連続したデータへの適用は限られており、既存のリカレントVAEモデルでは、長期的な構造を持つ連続したデータをモデル化することが困難であることが示されています。この問題を解決するために、我々は階層型デコーダの使用を提案する。このデコーダは、まず入力の部分配列に対する埋め込みを出力し、次にこの埋め込みを使って各部分配列を独立に生成する。この構造は、モデルが潜在的なコードを利用することを促すことで、リカレントVAEの問題点である「事後崩壊」問題を回避することができる。このアーキテクチャを音符のシーケンスのモデル化に適用したところ、「フラット」なベースラインモデルに比べて、サンプリング、補間、再構成のパフォーマンスが劇的に向上することがわかった。この "MusicVAE "の実装は、このhttpのURLからオンラインで見ることができます。
ニューラルネットワークのプルーニング技術は、学習したネットワークのパラメータ数を90%以上削減することができ、精度を落とすことなくストレージの必要性や推論の計算性能を向上させることができます。しかし、現代の経験では、プルーニングによって生成された疎なアーキテクチャは、最初から学習することが難しく、同様に学習性能を向上させることができません。我々は、標準的なプルーニング技術によって、初期化によって効果的な学習が可能になったサブネットワークが自然に発見されることを発見した。これらの結果に基づき、我々は「宝くじ仮説」を明らかにした。すなわち、高密度でランダムに初期化されたフィードフォワードネットワークには、サブネットワーク（「ウィニングチケット」）が含まれており、これらのサブネットワークを単独で訓練すると、同程度の反復回数で元のネットワークと同等のテスト精度に達する。このウィニングチケットは、初期化の宝くじに当たったようなもので、接続の初期重みがあるため、学習が特に効果的に行われる。我々は、当選チケットを特定するためのアルゴリズムと、宝くじ仮説とこれらの偶然の初期化の重要性を支持する一連の実験を提示する。MNISTおよびCIFAR10において、完全結合型および畳み込み型のフィードフォワードアーキテクチャのサイズの10-20%以下のウィニングチケットを一貫して見つけることができた。このサイズを超えると，我々が見つけたウイニングチケットは，元のネットワークよりも高速に学習し，テストの精度も高くなる．
これまでに開発された最も精度の高い物体検出器は，R-CNNによって普及した2段階アプローチに基づいており，物体位置の候補の疎なセットに分類器を適用している．これに対して、物体の位置の可能性がある規則的で高密度なサンプリングに適用される1段階の検出器は、より高速でシンプルになる可能性があるが、これまでのところ2段階の検出器の精度には及ばない。この論文では、その理由を調べました。その結果，密な検出器の学習時に発生する極端な前景と背景のクラスの不均衡が原因であることがわかりました。このクラスの不均衡に対処するために，標準的なクロスエントロピー損失の形を変えて，よく分類された例に割り当てられる損失の重みを下げることを提案する．我々の新しいFocal Lossは、学習を難しい例の疎なセットに集中させ、膨大な数の易しい否定例が学習中に検出器を圧倒するのを防ぐ。この損失の有効性を評価するために，「RetinaNet」と呼ぶ単純な密な検出器を設計し，学習しました．その結果，焦点損失を用いて学習した場合，RetinaNetはこれまでの1段検出器の速度に匹敵すると同時に，既存の最先端の2段検出器の精度を上回ることがわかった．コードは、このhttpsのURLにあります。
本論文では、タスクの分布が存在し、この分布からサンプリングされた以前に見たことのないタスクを提示されたときに、良い性能を発揮する（すなわち、素早く学習する）エージェントを得たいというメタリング問題を考える。我々はReptileと呼ばれる非常に単純なメタラーニングアルゴリズムを提案する。このアルゴリズムは、新しいタスクで素早く微調整できるパラメータ初期化を学習する。Reptileは、タスクを繰り返しサンプリングし、そのタスクで学習し、初期化をそのタスクで学習した重みに近づけることで動作する。同じく初期化を学習するMAMLとは異なり、Reptileは最適化プロセスを通じて微分する必要がないため、多くの更新ステップが必要な最適化問題に適しています。我々は、Reptileが数ショットの分類のためのいくつかの確立されたベンチマークで良好な性能を示すことを示す。また、なぜReptileが有効なのかを理解するために、いくつかの理論的な分析を行った。
RNNsを正則化するための新しい手法であるzoneoutを提案する。各タイムステップにおいて、zoneoutはいくつかの隠れユニットに以前の値を維持するように確率的に強制する。ドロップアウトと同様に、ゾーンアウトはランダムなノイズを用いて擬似的なアンサンブルを訓練し、汎化を向上させる。しかし、隠れユニットをドロップする代わりに保持することで、フィードフォワードの確率的深さネットワークのように、勾配情報と状態情報が時間を通じてより容易に伝搬される。様々なRNN正則化を経験的に調査した結果、zoneoutはタスク間で大幅な性能向上をもたらすことがわかった。比較的単純なモデルで、Penn TreebankおよびText8データセットにおける文字レベルおよび単語レベルの言語モデリングにおいて、競争力のある結果を得ることができた。また、リカレントバッチ正規化と組み合わせることで、パーミュート・シーケンシャル・MNISTにおいて最先端の結果を得ることができた。
線虫の発生初期における細胞の移動は、一連のルールと接続が異なるスケールで形成される非常に複雑なプロセスによって制御されています。これまでの研究で、エージェントベースのマルチスケールモデリングシステムは、物理学的なルールと生物学的なルールを統合し、発生システムを研究するための新たな手段を提供できることが示されてきた。しかし、細胞の動きをモデル化するためにこれらのシステムを適用することは依然として困難であり、適切なスケールでの制御ネットワークの包括的な理解が必要である。最近の深層学習と強化学習の発展は、3Dタイムラプス画像を用いて細胞の動きを探るという前例のない機会を提供する。我々は、線虫の胚発生における細胞の動きを特徴づけるために、ABMシステム内での深層強化学習アプローチを紹介する。我々のモデリングシステムは、胚における細胞の動きのパターンの複雑さを捉え、貪欲なアルゴリズムを使用する従来のルールベースのABMが直面していた局所最適化の問題を克服している。我々のモデルを2つの実在する発生過程、すなわち、インターカレーションによるCpaaa細胞の前方移動と、左右非対称性の再編成を用いて検証した。最初のケースでは、モデルの結果、Cpaaaのインターカレーションは、隣の細胞の動きによる受動的な動きではなく、より長い距離からの継続的な影響による能動的な方向性を持った細胞の動きであることがわかった。これは、学習型シミュレーションによって、受動的な移動モデルではCpaaaをあらかじめ設定された目的地に導くことができないことがわかったからである。2つ目のケースでは、リーダー・フォロワーのメカニズムが集団的な細胞の動きのパターンをうまく説明した。これらの結果から、ABMに深層強化学習を導入する我々のアプローチは、リバースエンジニアリングの観点から細胞の移動経路を探索することで、制御メカニズムを検証できることがわかりました。このモデルは、ライブイメージングで生成された大規模なデータセットを探索するための新しい扉を開きます。
ネットワークの障害や悪意のある攻撃など、ネットワークのセキュリティ問題は深刻です。ネットワークのセキュリティを確保するためには、ネットワークトラフィックを監視し、その異常を検知することが有効な手段の一つである。本論文では，ネットワークトラフィックの予測と異常検知のためのハイブリッド手法を提案する．具体的には，元のネットワークトラフィックデータを高周波数成分と低周波数成分に分解する．そして、非線形モデルであるRVM(Relevance Vector Machine)モデルとARMA(Auto Regressive Moving Average)モデルをそれぞれ採用して予測を行う。予測結果を組み合わせた後、異常検知のために、中心極限定理（LCT）に基づく自己適応型の閾値法を導入します。さらに、広範な実験により、提案手法の効率性を評価している。
深層強化学習（RL）は近年多くの成功を収めていますが、実験のターンアラウンドタイムは研究および実践において重要なボトルネックとなっています。我々は、既存の深層強化学習アルゴリズムを最新のコンピュータ、特にCPUとGPUの組み合わせに最適化する方法を調査した。その結果、政策勾配学習アルゴリズムとQ値学習アルゴリズムの両方が、多数の並列シミュレータインスタンスを用いた学習に適応できることを確認した。さらに、サンプルの複雑さや最終的な性能に悪影響を与えることなく、標準よりもかなり大きなバッチサイズを使用して学習することが可能であることがわかりました。これらの事実を利用して、並列化のための統一されたフレームワークを構築し、両クラスのアルゴリズムの実験を劇的に高速化しました。ニューラルネットワークの計算にはすべてGPUを使用し、データ収集とトレーニングの両方を高速化しています。その結果、DGX-1全体を使って、同期・非同期の両方のアルゴリズムを用いて、Atariゲームの成功戦略をわずか数分で学習することができました。
少数ショット分類では、ほんの一握りのラベル付き例から分類器を学習するアルゴリズムに興味があります。最近の少数ショット分類では，学習アルゴリズムのパラメータ化されたモデルが定義され，異なる分類問題を表すエピソード（それぞれが少量のラベル付きトレーニングセットとそれに対応するテストセット）で学習されるというメタ学習が注目されている．本研究では、この少数ショット分類のパラダイムを、各エピソード内でラベルのない例も利用可能なシナリオへと発展させる。ここでは、全てのラベル無し例が、そのエピソードのラベル付き例と同じクラスセットに属すると仮定する場合と、他のディストラクタクラスの例も提供されるという、より困難な状況の2つを考慮する。このパラダイムに対処するために、我々はプロトタイプを生成する際にラベルのない例を使用する能力で増強されたPrototypical Networks（Snellら、2017）の新しい拡張を提案する。これらのモデルは、ラベルのない例をうまく活用することを学ぶために、エピソード上でエンド・ツー・エンドの方法で訓練される。これらの手法を、OmniglotおよびminiImageNetベンチマークを、ラベルのない例を使って拡張された新しいフレームワークに適合させて評価します。また、ImageNetの新しい分割版を提案します。これは、階層構造を持つ大規模なクラスのセットから構成されます。実験の結果、我々のプロトタイプ・ネットワークは、半教師付きアルゴリズムのように、ラベルのない例を使って予測値を向上させることができることが確認された。
ナレッジグラフは、質問応答や情報検索など、さまざまな用途に利用されています。ナレッジグラフの作成と維持には多大な努力が払われているが、大規模なもの（例：Yago、DBPedia、Wikidata）でさえも不完全なままである。我々は、関係グラフ畳み込みネットワーク(R-GCN)を導入し、2つの標準的な知識ベース補完タスクに適用する。R-GCNは、リンク予測（欠落した事実、すなわち、主語-予測-目的語のトリプルの復元）と、エンティティ分類（欠落したエンティティ属性の復元）の2つの標準的な知識ベース補完タスクに適用する。R-GCNは、グラフ上で動作する最近のニューラルネットワークに関連しており、現実的な知識ベースの特徴である高度に多元的なデータを扱うために特別に開発されたものである。本研究では、R-GCNが単独でエンティティ分類モデルとして有効であることを示す。さらに、DistMultのようなリンク予測のための因子分解モデルを、関係グラフの複数の推論ステップにわたって証拠を蓄積するエンコーダモデルで強化することで、大幅に改善できることを示し、FB15k-237において、デコーダのみのベースラインに比べて29.8%の大幅な改善を実証した。
自然言語推論のための大規模データセットは、クラウドワーカーに文章（前提）を提示し、その文章が包含する、矛盾する、または論理的に中立である3つの新しい文章（仮説）を生成するように求めることで作成される。このようなデータのかなりの部分において、このプロトコルは、前提条件を見ずに仮説だけを見てラベルを特定できるような手がかりを残していることを示します。具体的には、SNLI（Bowman et. al, 2015）の約67％、MultiNLI（Williams et. al, 2017）の約53％において、単純なテキスト分類モデルが仮説のみを正しく分類できることを示している。我々の分析では、否定や曖昧さなどの特定の言語現象が、特定の推論クラスと高い相関関係にあることが明らかになりました。我々の発見は、これまでの自然言語推論モデルの成功は過大評価されており、このタスクは依然として難しい未解決問題であることを示唆している。
セマンティック・ウェブの発展により、多くの新しい構造化データが知識ベース（KB）の形でウェブ上で利用できるようになりました。この貴重なデータにアクセスし、エンドユーザが利用できるようにすることが、KBを利用した質問応答（QA）の主な目的の1つです。現在のほとんどのQAシステムは、1つの言語（すなわち英語）で、1つのKBに問い合わせを行います。既存のアプローチは、新しいKBや言語に簡単に適応できるようには設計されていません。我々はまず、自然言語による質問をSPARQLクエリに変換するための新しいアプローチを紹介します。このアプローチは、複数のKBに同時に、異なる言語で問い合わせを行うことができ、他のKBや言語にも簡単に移植することができる。評価では、5つのよく知られた大規模なKBを使用して、我々のアプローチの影響を証明しました。評価では、Wikidata、DBpedia、MusicBrainz、DBLP、Freebaseという5つの有名な大規模KBと、英語、ドイツ語、フランス語、イタリア語、スペイン語という5つの異なる言語を用いて、我々のアプローチの影響を証明します。次に、研究コミュニティやエンドユーザが簡単にアクセスできるように、我々のアプローチをどのように統合したかを示します。要約すると、我々はセマンティックウェブ上での多言語、KBに依存しない質問応答のための概念的なソリューションを提供した。提供された第一近似値は、この概念を検証します。
ほとんどの深層学習の実践者にとって、シーケンスモデリングはリカレントネットワークと同義です。しかし、最近の結果では、音声合成や機械翻訳などのタスクにおいて、畳み込みアーキテクチャがリカレントネットワークよりも優れていることが示されています。新しいシーケンスモデリングのタスクやデータセットが与えられたとき、どのアーキテクチャを使うべきでしょうか？本研究では，シーケンスモデリングのための一般的な畳み込みネットワークとリカレントネットワークのアーキテクチャを系統的に評価した．モデルの評価は、リカレントネットワークのベンチマークによく用いられる標準的なタスクを幅広く用いて行われた。その結果、単純な畳み込みアーキテクチャは、様々なタスクやデータセットにおいて、LSTMなどの一般的なリカレントネットワークよりも優れており、有効メモリも長いことが分かりました。我々は、シーケンスモデリングとリカレントネットワークの間の一般的な関連性を再考すべきであり、畳み込みネットワークはシーケンスモデリングタスクの自然な出発点とみなされるべきであると結論付けた。関連する研究を支援するために、コードをこのhttpのURLで公開しています。
近年、リカレント・ニューラル・ネットワーク（RNN）の学習方法が進歩しているにもかかわらず、シーケンスの長期的な依存性を捉えることは基本的な課題となっています。ほとんどのアプローチでは、時間によるバックプロパゲーション（BPTT）を使用していますが、これは非常に長いシーケンスに対応することが困難です。本論文では、教師なしの補助損失を元の目的に追加することで、RNNの長期依存性を捉える能力を向上させる簡単な方法を提案する。この補助損失により、RNNはシーケンス内の前のイベントを再構築するか、次のイベントを予測することになり、長いシーケンスに対して切断型バックプロパゲーションが実行可能となり、また完全なBPTTも改善される。本研究では、最大16,000までのシーケンス長を持つピクセル単位の画像分類や、実際の文書分類のベンチマークなど、さまざまな設定で本手法を評価しました。その結果、他のリカレントモデルや同程度のサイズのTransformerを含む競合ベースラインと比較して、本手法が優れた性能とリソース効率を持つことが明らかになりました。さらに、最適化と正則化における補助損失の有益な効果や、バックプロパゲーションがほとんどない極端なケースも明らかになりました。
このモデルは、sequence-to-sequenceフレームワークを拡張したもので、自然言語の生成を、高レベルの粗いトークンのシーケンスと、自然言語のトークンのシーケンスという、2つの並行した離散的な確率過程としてモデル化します。高レベルの粗いトークンを推定または学習する方法は数多くありますが、我々は、高レベルの談話セマンティクスを豊富に取り込むには、単純な抽出手順で十分であると主張します。このような手順により、両方の配列に対する正確な合同対数尤度を最大化することで、マルチレゾリューション・リカレント・ニューラル・ネットワークを学習することができる。自然言語トークンに対する標準的な対数尤度の目的（単語の複雑さ）とは対照的に、共同対数尤度を最適化することで、モデルは高レベルの抽象度をモデル化する方向に偏る。提案したモデルを，UbuntuのテクニカルサポートとTwitterの会話という2つの困難なドメインにおける対話応答生成タスクに適用した．Ubuntuでは、提案モデルは、自動評価指標と人間による評価の両方で最先端の結果を得て、競合するアプローチよりもかなりのマージンで優れていた。また，Twitterでは，自動評価指標により，より適切で話題性のある応答を生成することができた．最後に、提案モデルは、自然言語のスパース性を克服し、長期的な構造をよりよく捉えることができることを実験で示しました。
逐次モデルは、オーディオ、ビジュアル、テキストの各領域において、データ分布の推定と高品質なサンプルの生成の両面で、最先端の結果を達成しています。しかし、このクラスのモデルを効率的にサンプリングすることは、これまで困難な課題でした。本論文では、音声合成に焦点を当て、高品質な出力を維持しながらサンプリング時間を短縮するための一般的な手法を紹介します。まず、最新のWaveNetモデルと同等の品質を持つデュアルソフトマックス層を備えた単層のリカレントニューラルネットワーク、WaveRNNについて説明します。このネットワークはコンパクトな形状であるため、24kHzの16ビットオーディオをGPU上で実時間よりも4倍高速に生成することが可能です。次に、WaveRNNの重みの数を減らすために、重みの刈り込み技術を適用しました。その結果、パラメータ数が一定の場合、大きな疎なネットワークは小さな密なネットワークよりも優れた性能を発揮し、この関係は96％を超える疎性レベルでも維持されることが分かりました。スパースなWaveRNNでは重みの数が少ないため、モバイルCPUで高忠実度のオーディオをリアルタイムにサンプリングすることが可能になります。最後に、長いシーケンスを短いシーケンスのバッチに折り畳み、一度に複数のサンプルを生成することができるサブスケールに基づく新しい生成方式を提案します。サブスケールWaveRNNは、品質を損なうことなく1ステップあたり16個のサンプルを生成し、サンプリング効率を高めるための直交的な方法を提供します。
マルチタスク学習と半教師付き学習を組み合わせて、異なるラベル空間間の共同埋め込み空間を誘導し、ラベル埋め込み間の伝達関数を学習することで、ラベルのないデータと補助的な注釈付きデータセットを共同で活用することができます。本研究では，ラベル空間が異なる様々なシーケンス分類タスクを対象に，本手法を評価した．その結果、シングルタスクおよびマルチタスクのベースラインを上回り、トピックベースのセンチメント分析の最先端を達成した。
論理的な表現の構造を捉えて活用するモデルの能力を測定するために、新たに論理的な関連性のデータセットを導入し、関連性の予測タスクを実施した。このタスクを用いて、シーケンス処理の文献でよく見られる一連のアーキテクチャと、「可能世界の畳み込み」として関連性を計算する新しいモデルクラス（PossibleWorldNets）とを比較した。その結果、畳み込みネットワークは、LSTM RNNと比較して、このクラスの問題に対して誤った帰納的バイアスを持つこと、ツリー構造ニューラルネットワークは、論理のシンタックスを利用する能力が向上しているため、LSTM RNNよりも優れていること、PossibleWorldNetsはすべてのベンチマークよりも優れていることがわかりました。
Evolution Strategies（ES）は、AtariゲームやMuJoCoヒューマノイド・ロコモーション・ベンチマークなどの難易度の高いディープRL問題において、強化学習（RL）アルゴリズムに代わる有効なアルゴリズムであることが最近実証されました。その際、ESアルゴリズムは自然進化戦略という特殊なクラスに属していましたが（REINFORCEなどの近似勾配RLアルゴリズムに似ている）、本研究では、非常に基本的な正統的ESアルゴリズムであっても、同等またはそれ以上の性能を達成できることを実証しました。このような基本的なESアルゴリズムの成功は，過去数十年間にESの分野で得られた多くの進歩を統合することで，最先端の技術をさらに発展させることができることを示唆している．また、ESアルゴリズムは、従来のRLアルゴリズムとは大きく異なる性能特性を持つことを定性的に示しています。あるゲームでは、環境を利用することを学習してはるかに優れた性能を発揮しますが、他のゲームでは、最適ではないローカルミニマムに陥ることがあります。そのため、ESアルゴリズムと従来のRLアルゴリズムの長所を組み合わせることで、新たな技術の進歩が期待できます。
近年、人間や機械によって生成される噂のニュースが広く増加しています。そのため、風評被害を調査するツールが急務となっている。そのようなツールの有用な機能の1つは、複数のソースからの異なる視点を提示することで、特定のトピックやイベントがどのように表現されているかを確認することです。本論文では、噂のニュースを調査するための新規の合意考慮型検索フレームワークであるMaesterを提案します。調査のための質問が与えられると、Maesterはその質問に関連する記事を検索し、賛成、反対、議論の各カテゴリから上位の記事を割り当ててユーザに表示する。結果をこの3つのカテゴリに分けることで、ユーザは調査対象の質問に対する全体的な視点を得ることができます。私たちは、以下の2つの重要な見解に基づいてMaesterを構築しました。(1)関連性は、質問と記事の両方に出現するキーワードやエンティティによって一般的に判断できる。そこで、関連性の検出には、キーワードと実体のマッチング機能を持つ勾配ブースティング木モデルを用い、一致度の推定にはリカレントニューラルネットワークを活用します。FNC（Fake News Challenge）データセットを用いた実験では、一致度を考慮した検索において、MaesterがFNCで優勝したオリジナルのソリューションよりも最大で1桁向上したことが実証された。
我々は、単一の深層ニューラルネットワークを用いて画像中の物体を検出する手法を発表する。SSDと名付けられた我々のアプローチは、バウンディングボックスの出力空間を、特徴マップの位置ごとに異なるアスペクト比とスケールにわたるデフォルトボックスのセットに離散化する。予測時には、ネットワークは各デフォルトボックス内の各オブジェクトカテゴリの存在に対するスコアを生成し、オブジェクトの形状とより一致するようにボックスを調整します。さらに、解像度の異なる複数の特徴量マップからの予測値を組み合わせることで、様々なサイズの物体を自然に扱うことができます。SSDのモデルは、物体の提案を必要とする手法に比べてシンプルです。なぜなら、提案の生成とそれに続くピクセルまたは特徴のリサンプリング段階を完全に排除し、すべての計算を単一のネットワークにカプセル化しているからです。これにより、SSDは学習しやすく、検出コンポーネントを必要とするシステムに簡単に組み込むことができます。PASCAL VOC、MS COCO、ILSVRCのデータセットを用いた実験の結果、SSDは追加の物体提案段階を利用する手法と同等の精度を持ち、学習と推論の両方に統一されたフレームワークを提供しながら、はるかに高速であることが確認されました。他のシングルステージの手法と比較して、SSDは入力画像サイズが小さくても、はるかに優れた精度を持っています。300枚の入力画像では、SSDはVOC2007テストにおいて72.1%のmAPを達成しました。また、500枚の入力画像では、SSDは75.1%のmAPを達成し、同等の最新モデルであるFaster R-CNNを上回りました。コードはこちらのhttpsのURLから入手できます。
コンピュータビジョンや自然言語処理の分野で深層学習の導入が成功していることに触発され、この学習パラダイムは音楽情報検索の分野にも応用されています。深層学習を効果的かつ効率的に利用するために、深層伝達学習が一般的なアプローチとなっています。このアプローチでは、事前に学習したニューラルネットワークの出力を、新たな学習タスクの基礎として再利用することができます。最初の学習タスクと新しい学習タスクに共通点があり、同じ種類の入力データ（音楽音声など）に適用された場合、生成されたデータの深層表現は新しいタスクにとっても有益である、というのが基本的な仮説である。しかし、深層表現を生成するために使用されるネットワークの多くは、単一の初期学習ソースを用いて学習されるため、その表現は将来起こりうるすべてのタスクに対して情報的であるとは考えにくい。本論文では、音楽領域のデータと学習タスクに対して、深層表現を生成するために最も重要な要素は何かを調査した結果を発表する。この調査は、音楽表現を学習するために、複数の学習ソースと、ソース間の情報共有レベルを変えた複数の深層学習アーキテクチャを用いた大規模な実証研究によって行われました。そして、複数のデータセットを評価対象として、これらの表現を検証しました。これらの実験結果は、音楽領域で広く展開可能な深層データ表現を学習するための手法を設計する上で、いくつかの示唆を与えてくれます。
知的な生物は、監督なしで自分の環境を探索し、有用なスキルを学ぶことができる。本論文では、DIAYN ('Diversity is All You Need')という、報酬関数なしで有用なスキルを学習する手法を提案する。提案手法では，最大エントロピー政策を用いて情報理論的な目的を最大化することでスキルを学習する．様々なロボットタスクをシミュレーションした結果、この単純な目的によって、歩行やジャンプなどの多様なスキルが教師なしで出現することを示しています。多くの強化学習ベンチマーク環境において、我々の手法は、真のタスク報酬を受け取らないにもかかわらず、ベンチマークタスクを解決するスキルを学習することができる。我々は、事前に学習されたスキルが、下流のタスクのための良いパラメータ初期化を提供し、複雑で疎な報酬タスクを解決するために階層的に構成することができることを示す。この結果は、教師なしでスキルを発見することが、強化学習における探索とデータ効率の課題を克服するための効果的な事前学習メカニズムとして役立つことを示唆している。
我々は、勾配ベースの強化学習(RL)アルゴリズムを学習するための金属学習アプローチを提案する。このアイデアは、微分可能な損失関数を進化させることで、この損失を最小化するように政策を最適化するエージェントが高い報酬を得られるようにするものである。この損失は、エージェントの経験に対する時間的な畳み込みによってパラメータ化されます。この損失は、エージェントの履歴を考慮に入れることができる柔軟性の高いものであるため、高速なタスク学習が可能である。実証実験の結果、我々の進化型政策勾配アルゴリズム(EPG)は、既製の政策勾配法と比較して、いくつかのランダム化された環境でより高速な学習を達成した。また、EPGの学習した損失は、分布外のテスト時間のタスクに一般化することができ、他の一般的な金属学習アルゴリズムとは質的に異なる挙動を示すことを実証した。
我々は、(1)単語使用の複雑な特性（構文や意味論など）と、(2)これらの使用が言語的文脈によってどのように変化するか（すなわち、多義性をモデル化する）の両方をモデル化する、新しいタイプの深い文脈を持つ単語表現を導入した。単語ベクトルは、大規模なテキストコーパスで事前に学習された深層双方向言語モデル（biLM）の内部状態の関数として学習されています。これらの表現は、既存のモデルに簡単に追加することができ、質問応答、テキストの含意関係、感情分析などの6つの困難なNLP問題において、技術水準を大幅に向上させることができることを示します。また、事前に学習したネットワークの深い内部を公開することが重要であることを示す分析結果を示し、下流のモデルが異なる種類の半教師信号を混合できるようにします。
機械学習アルゴリズムの性能は、優れたハイパーパラメータのセットを特定することに決定的に依存します。最近のアプローチでは、ベイジアン最適化を用いて設定を適応的に選択していますが、我々は適応的なリソース配分と早期停止によってランダム検索を高速化することに焦点を当てています。ハイパーパラメータの最適化を、純粋探索型の非ストキャスティック無限腕バンディット問題として定式化し、反復、データサンプル、特徴などの事前に定義されたリソースを、ランダムにサンプリングされた構成に割り当てます。このフレームワークのための新しいアルゴリズムHyperbandを紹介し、その理論的特性を分析して、いくつかの望ましい保証を提供します。さらに、一連のハイパーパラメータ最適化問題において、Hyperbandを一般的なベイジアン最適化手法と比較します。その結果、Hyperbandは、様々な深層学習やカーネルベースの学習問題において、競合他社の手法と比較して1桁以上の高速化を実現できることがわかった。
最近の多くの論文（多くのNIPS論文を含む）では、標準的なリカレントネットが、関連する入力信号と教師信号の間の長いタイムラグに対応できないことに注目しています。むしろ洗練された代替手法が提案されている。我々はまず、過去の多くの論文で特定のアルゴリズムを宣伝するために使われた問題が、ランダムな重みの推測によって、提案されたアルゴリズムよりも早く解決できることを示す。これは、推測が良いアルゴリズムであることを意味するものではありません。これは、推測が良いアルゴリズムであることを意味するものではなく、他のアルゴリズムが良いアルゴリズムであるかどうか、あるいは選ばれた問題が意味のあるものであるかどうかに疑問を投げかけるものである。次に、我々が最近開発したアルゴリズムであるLong Short Term Memory (LSTM)を用いて、random weight guessingでも我々が知っている他のリカレントネットアルゴリズムでもすぐには解けない難しい問題を解く。
私たちは、モデルを自動的に設計するための高速で安価なアプローチであるEfficient Neural Architecture Search (ENAS)を提案します。ENASでは、コントローラは、大規模な計算グラフ内の最適なサブグラフを探索することで、ニューラルネットワークアーキテクチャを発見することを学習します。コントローラは政策勾配を用いて学習され、検証セットにおける期待報酬を最大化する部分グラフを選択します。一方、選択されたサブグラフに対応するモデルは、カノニカルクロスエントロピー損失を最小化するように学習されます。子モデル間でパラメータを共有することで、ENASは高速に動作します。既存の自動モデル設計アプローチよりも少ないGPU時間で強力な経験的性能を実現し、特に標準的なNeural Architecture Searchよりも1,000倍少ないコストで実現します。Penn Treebankデータセットにおいて、ENASはテストパープレキシティ55.8を達成する新しいアーキテクチャを発見し、ポストトレーニング処理を行わない全ての手法の中で最先端を確立しました。CIFAR-10データセットでは、ENASはテスト誤差2.89%を達成する新規アーキテクチャを設計し、これはテスト誤差が2.65%のNASNet（Zoph et al.2018）と同等です。
ディープニューラルネットワークのトレーニングには多くのトレーニングサンプルが必要ですが、実際にはトレーニングラベルの入手にはコストがかかり、信頼できる専門家のラベラーによるものもあれば、ヒューリスティックやクラウドソーシングのような弱い監督のソースによるものもあり、品質が異なる場合があります。これは、学習プロセスにおける基本的な質と量のトレードオフになります。少量の高品質なデータから学習するのか、それとも潜在的に大量の弱いラベル付けのデータから学習するのか。我々は、もし学習者がデータ表現を学習する際にラベルの質を知り、それを考慮に入れることができれば、両方の長所を得ることができると主張する。そこで我々は、弱いラベル付きデータを用いてディープニューラルネットワークを学習するための、半教師付き学生・教師アプローチである「忠実度重み付け学習」（FWL）を提案する。FWLは、（高品質なラベルにアクセスできる）教師が推定したラベル品質の事後信頼度に応じて、（我々が関心を持つタスクで訓練された）学生ネットワークのパラメータ更新をサンプルごとに変更する。生徒も教師もデータから学習します。FWLは、情報検索と自然言語処理の2つのタスクで評価され、最先端の半教師付き手法を上回る結果を得た。これは、FWLのアプローチが、強いラベルと弱いラベルをうまく利用し、タスクに依存したデータ表現を改善することを示している。
音声信号は高い時間分解能でサンプリングされており、音声合成を学習するには、様々な時間スケールの構造を捉える必要があります。GAN（Generative Adversarial Network）は、局所的にも大域的にもコヒーレントな画像を生成することに成功しているが、オーディオの生成にはほとんど適用されていない。本論文では、生の波形オーディオの教師なし合成にGANを適用する最初の試みであるWaveGANを紹介する。WaveGANは、効果音の生成に適した、大域的なコヒーレンスを持つ1秒間のオーディオ波形のスライスを合成することができる。我々の実験では、語彙数の少ない音声データセットで学習させた場合、ラベルなしでWaveGANは分かりやすい単語を生成することを学習し、ドラム、鳥の鳴き声、ピアノなどの他のドメインの音声も合成できることを示した。WaveGANは、画像生成用に設計されたGANを画像のような音声特徴表現に適用した手法と比較し、どちらのアプローチも有望であることがわかった。
RMSProp、Adam、Adadelta、Nadamなど、最近提案された確率的最適化手法は、過去の勾配の二乗の指数的移動平均の平方根でスケールされた勾配の更新を使用することに基づいています。しかし、大きな出力空間での学習など、多くのアプリケーションにおいて、これらのアルゴリズムが最適解（非凸設定では臨界点）に収束しないことが経験的に観察されています。我々は、このような失敗の原因の一つが、アルゴリズムで使用されている指数移動平均であることを示す。アダムが最適解に収束しない単純な凸最適化の設定の明示的な例を提供し、アダム・アルゴリズムのこれまでの分析の正確な問題点を説明する。また、収束の問題を解決するだけでなく、しばしば経験的な性能を向上させるアダムアルゴリズムの新しいバリエーションを提案する。
雑談モデルにはいくつかの問題点があることが知られている：具体性に欠け、一貫した性格を示さず、あまり人を惹きつけないことが多い。本研究では、プロフィール情報を条件として、雑談をより魅力的にするという課題を提示する。我々はデータを収集し、(i)与えられたプロフィール情報と、(ii)話している相手に関する情報を条件とするモデルを学習し、その結果、次の発話の予測によって測定されるように、対話が改善される。(ii)は最初は未知であるため、我々のモデルは相手に個人的な話題を提供するように訓練されており、その結果得られた対話を用いて対話者のプロファイル情報を予測できることを示している。
今日、世界に関する構造化データ（ウィキデータなど）や非構造化データが豊富に存在することは、将来の人工知能にとって大きなチャンスとなります。これまでのところ、これらの2つの異なるモダリティの統合は、情報をどのように表現するのが最善であるかに関する多くの決定を伴う困難なプロセスであり、情報の取得や有用性の確保、大量のデータの手作業によるラベル付けなどが必要でした。DeepTypeは、型システムを用いてニューラルネットワークの推論プロセスに記号情報を明示的に統合することで、この課題を克服します。まず、型システムを構築し、次にそれを用いてニューラルネットワークの出力が記号構造を尊重するように制約します。これを実現するために、設計問題を「型システムを構築し、それを用いてニューラルネットワークを訓練する」という混合整数問題に再構成します。この再構成では、離散変数はオントロジーのどの親子関係が型システム内の型であるかを選択し、連続変数は型システムに適合する分類器を制御します。元の問題は厳密には解けないので、2段階のアルゴリズムを提案する。1) Oracle と Learnability heuristic から得られる型システムを定義する離散変数に対するヒューリスティック探索または確率的最適化，2) 分類器のパラメータを適合させるための勾配降下．DeepTypeを3つの標準的なデータセット（WikiDisamb30, CoNLL (YAGO), TAC KBP 2010）のEntity Linking問題に適用したところ、人間が設計した型システムや最近の深層学習に基づく実体埋め込みに依存するアプローチを含め、既存のすべての解決策を大差で上回ることがわかった。また、記号情報を明示的に利用することで、再学習なしに新しい実体を統合することができる。
Deceptive Game（欺瞞的ゲーム）とは、報酬構造やゲームのその他の側面が、エージェントを大域的に最適な政策から遠ざけるように設計されたゲームのことです。多くのゲームはある程度の欺瞞性を備えているが，我々は認知的バイアスを利用して特定のタイプの欺瞞性を実装した一連のゲームをビデオゲーム記述言語（VGDL）でデザインした．このVGDLゲームはGVGAI（General Video Game Artificial Intelligence）フレームワークで実行可能であり、GVGAIコンペティションに応募された様々な既存のAIエージェントをこれらの欺瞞的ゲームでテストすることが可能である。その結果、テストされたすべてのエージェントは、いくつかの種類の欺瞞に対して脆弱であり、エージェントによって弱点が異なることがわかりました。これは、ゲームプレーイング・アルゴリズムの能力を理解するために欺瞞を利用できること、またゲームプレーイング・アルゴリズムが、ゲームが見せる欺瞞を特徴づけるために利用できることを示唆しています。
ニューラルネットワークの画像分類器を手作業で作ることに労力が割かれているため、それを自動的に発見するためのアーキテクチャ検索の使用が動機付けられている。ニューラルネットワークのトポロジーには進化論的アルゴリズムが繰り返し適用されてきたが、発見された画像分類器は人間が作ったものよりも劣っていた。ここでは、画像分類器AmoebaNet-Aを進化させることで、初めて人手による分類器を超えることに成功した。そのために、トーナメント選択進化アルゴリズムに年齢特性を導入して、若い遺伝子型が有利になるように改良しました。サイズを合わせたAmoebaNet-Aは、より複雑なアーキテクチャ探索法で発見された現在の最先端のImageNetモデルと同等の精度を持っています。より大きなサイズに拡大したAmoebaNet-Aは、最新の83.9% / 96.6%のImageNetトップ5の精度を実現しています。よく知られている強化学習アルゴリズムとの比較では、同じハードウェアでも、特に探索の初期段階では、進化の方が速く結果を得ることができるという証拠を示しています。これは、利用可能な計算機資源が少ない場合に有効です。このようにevolutionは、高品質なアーキテクチャを効果的に発見するためのシンプルな手法であると言えます。
本研究では、単一の強化学習エージェントと単一のパラメータセットを用いて、大量のタスクを解決することを目的としています。主な課題は、増加したデータ量と拡張した学習時間を処理することです。私たちは、新しい分散型エージェントIMPALA（Importance Weighted Actor-Learner Architecture）を開発しました。このエージェントは、単一マシンでの学習においてリソースをより効率的に使用するだけでなく、データ効率やリソース利用を犠牲にすることなく、数千台のマシンにまで拡張することができます。IMPALAは、アクターと学習を分離し、V-traceと呼ばれる新しいオフポリシー補正法を組み合わせることで、高いスループットで安定した学習を実現します。DMLab-30（DeepMind Lab環境の30のタスクセット(Beattie et al., 2016)）とAtari-57（Arcade Learning Environmentのすべての利用可能なAtariゲーム(Bellemare et al., 2013a)）で、マルチタスク強化学習に対するIMPALAの有効性を実証する。その結果、IMPALAは、より少ないデータで従来のエージェントよりも優れた性能を達成することができ、重要なことに、マルチタスクアプローチの結果としてタスク間の積極的な移行を示すことがわかった。
本論文では、ニューラルネットワークの表現を理解し、解釈可能な/分離された中間層の表現を持つニューラルネットワークを学習するための最近の研究をレビューする。深層ニューラルネットワークは様々なタスクで優れた性能を発揮しているが、解釈可能性は常に深層ニューラルネットワークのアキレス腱である。現在のところ、深層ニューラルネットワークは、ブラックボックス表現の解釈可能性の低さを犠牲にして、高い識別力を得ています。私たちは、モデルの解釈可能性が高ければ、非常に少ないアノテーションからの学習、意味レベルでの人間とコンピュータのコミュニケーションによる学習、ネットワーク表現の意味的なデバッグなど、深層学習のいくつかのボトルネックを打破できると考えています。ここでは、畳み込みニューラルネットワーク（CNN）に焦点を当て、CNN表現の可視化、学習済みCNNの表現を診断する方法、学習済みCNNの表現を切り離す方法、切り離された表現を持つCNNの学習、モデルの解釈可能性に基づくミドル・ツー・エンドの学習について再考します。最後に、説明可能な人工知能の今後の動向について述べます。
電子カルテ（EHR）データを用いた予測モデリングは、個別化医療を推進し、医療の質を向上させると期待されている。予測統計モデルを構築するためには、通常、正規化されたEHRデータから精選された予測変数を抽出する必要があります。私たちは、FHIR（Fast Healthcare Interoperability Resources）フォーマットに基づいて、患者の生のEHR記録全体を表現することを提案します。この表現を用いた深層学習手法は，複数の医療機関で発生する複数の医療イベントを，医療機関ごとにデータを統一することなく正確に予測できることを実証している．本研究では，米国の2つのアカデミックメディカルセンター（24時間以上入院している成人患者216,221人）の非識別EHRデータを用いて，この手法を検証した．我々が提案する逐次フォーマットでは、この大量のEHRデータは、臨床ノートを含む合計46,864,534,945個のデータポイントに展開されます。深層学習モデルは，院内死亡率（サイト間のAUROC 0.93～0.94），30日以内の予定外再入院（AUROC 0.75～0.76），入院期間の延長（AUROC 0.85～0.86），患者の最終的な退院診断のすべて（頻度加重AUROC 0.90）を予測するなどのタスクで高い精度を達成した．これらのモデルは、すべてのケースにおいて、最先端の従来の予測モデルよりも優れていました。また、ニューラルネットワークを用いたアトリビューションシステムのケーススタディを紹介し、臨床医が予測結果をどのようにして透明化できるかを示しました。このアプローチは、様々な臨床シナリオに対して、患者のカルテに記載された証拠を直接強調した説明とともに、正確でスケーラブルな予測を行うために使用できると考えています。
近年、機械学習システムにおいて、予測や判断の根拠を人間が理解できるように説明することが注目されています。しかし、どのような説明が真に人間が理解できる説明なのかは、まだ十分に理解されていません。本研究では、検証という特殊な文脈において、説明を解釈可能にするものについての理解を深めています。例えば、Xを予測する機械学習システムがあり、その予測Xに根拠を与えているとします。一連のユーザースタディを通して、どのような複雑さの増加が、人間が根拠を検証する時間に最も大きな影響を与え、どのようなものが比較的影響を受けにくいかを明らかにしました。
本研究では，RGB画像と人体の表面ベースの表現との間の密な対応関係を確立する．これは，密な人体ポーズ推定と呼ばれるタスクである．まず、効率的なアノテーション・パイプラインを導入することで、COCOデータセットに含まれる5万人の人物の密な対応関係を収集します。次に、このデータセットを用いて、背景、オクルージョン、スケールの変化があっても、密な対応関係を実現するCNNベースのシステムを訓練する。さらに、欠損しているグランドトゥルース値を補うことができる「インペインティング」ネットワークを学習することで、学習セットの有効性を向上させ、過去に達成可能だった最良の結果と比較して明らかな改善を報告している。また、完全畳み込みネットワークとリージョンベースのモデルを試したところ、後者の方が優れていることが分かりました。さらに、カスケード接続によって精度を向上させ、リアルタイムで高精度な結果を得ることができました。補足資料とビデオはプロジェクトページに掲載されています（http URL
英語版ウィキペディアの記事を作成することは、ソース文書の多文書要約としてアプローチできることを示しています。顕著な情報を粗く特定するために抽出型要約を用い、記事を生成するために神経抽象化モデルを用います。抽象化モデルでは、デコーダのみのアーキテクチャを導入し、配列変換に用いられる典型的なエンコーダ-デコーダアーキテクチャよりもはるかに長い配列に対応できるようにした。このモデルでは、流暢でまとまりのある複数文の段落や、Wikipediaの記事全体を生成できることを示しています。また、参照文書が与えられた場合、パープレキシティ、ROUGEスコア、人間の評価に反映されるように、関連する事実情報を抽出できることを示す。
本論文では、リカレントニューラルネットワーク(RNN)における様々なタイプのリカレントユニットを比較しています。特に、長短期記憶(LSTM)ユニットや、最近提案されたゲーテッドリカレントユニット(GRU)など、ゲーティングメカニズムを実装した、より洗練されたユニットに注目します。これらのリカレントユニットを、ポリフォニック・ミュージック・モデリングとスピーチ・シグナル・モデリングのタスクで評価した。実験の結果、これらの高度なリカレントユニットは、tanhユニットのような従来のリカレントユニットよりも実際に優れていることがわかりました。また、GRUはLSTMと比較しても遜色ないことがわかりました。
近年、自然言語処理（NLP）の分野では、大量のテキストを用いて教師なしで学習した単語の分散ベクトル表現が成功を収めています。これらの表現は、様々なNLP問題において、単語の汎用的な特徴として使用されています。しかし、この成功を、文などの単語の並びの表現の学習に拡張することは、まだ未解決の問題である。最近の研究では、汎用的な固定長の文表現を学習するために、異なる学習目的を持つ教師なしおよび教師ありの学習技術が検討されている。本研究では、文表現のためのシンプルで効果的なマルチタスク学習フレームワークを提示する。これは、多様な学習目的の帰納的バイアスを単一のモデルにまとめるものである。 このモデルを、複数の学習目的を持つ複数のデータソースを用いて、1億文以上の文で学習する。大規模な実験により、単一のリカレント文エンコーダーを、関連性の低いタスクで共有することで、従来の手法よりも一貫した改善が得られることを実証した。また、学習した汎用的な表現を用いることで、伝達学習や低リソース環境での大幅な改善を実現しています。
リカレントニューラルネットワーク（RNN）、コンボリューショナルニューラルネットワーク（CNN）、セルフアテンションネットワーク（SAN）は、文脈を考慮した表現を生成するためによく用いられる。RNNは長距離の依存性を捉えることができるが、並列化が難しく、時間効率が悪い。また，CNNは局所的な依存性に着目するが，タスクによってはうまくいかないこともある．一方、SANは、並列化可能な計算により、これらの依存性をモデル化することができるが、必要なメモリ量は、配列の長さに応じて急激に増加する。本論文では、RNN/CNNを用いずにシーケンスを符号化するためのモデルとして、「Bi-Directional Block Self-attention Network (Bi-BloSAN)」を提案する。Bi-BloSANは、RNNと同程度のメモリしか必要としないが、SANの利点をすべて備えている。Bi-BloSANは，シーケンス全体をブロックに分割し，ブロック内SANを各ブロックに適用して局所的な文脈をモデル化し，ブロック間SANを全ブロックの出力に適用して長距離依存性を捉える．このように，各SANは短いシーケンスを処理するだけでよく，少量のメモリしか必要としない．さらに，同じ単語の前後の文脈の変化を扱うために，特徴レベルの注目を使用し，時間的順序情報を符号化するためにforward/backwardマスクを使用している．異なるNLPタスクの9つのベンチマークデータセットにおいて、Bi-BloSANは最先端の精度を達成または改善し、既存のRNN/CNN/SANよりも効率とメモリのトレードオフが良いことを示した。
私たちは、複数のメモリレベルを持つ新しいRNNアーキテクチャであるNested LSTM（NLSTM）を提案します。Nested LSTMは、スタッキングではなくネスティングによってLSTMに深さを加えます。NLSTMのメモリセルの値は、内部にメモリセルを持つLSTMセルによって計算されます。具体的には、（外側の）メモリセルの値をcoutert=ft⊙ct-1+it⊙gtとして計算する代わりに、NLSTMのメモリセルは、連結（ft⊙ct-1,it⊙gt）を内側のLSTM（またはNLSTM）のメモリセルへの入力として使用し、coutert=hinnertを設定します。また、LSTMの内部メモリは、スタック型LSTMの上位ユニットと比較して、より長期的な依存関係を学習します。
これは、質問と文章を入力とし、主語、述語、引数のリストからなる半構造化されたアサーションを出力する、オープンドメインの質問応答タスクである。アサーションは、読解における短い回答スパンよりも多くの証拠を伝えることができ、パッセージベースのQAにおける退屈なパッセージよりも簡潔である。これらの利点により、ABQAは音声制御されたスピーカーなどの人間とコンピュータの対話シナリオに適している。ABQAの改良に向けてさらに前進するには、より豊富な教師付きデータセットと強力なテキスト理解モデルが必要である。そこで、WebAssertionsという新しいデータセットを導入することにした。このデータセットには、55,960のWeb文章に含まれる358,427のアサーションに対する手書きのQAラベルが含まれている。ABQAを解決するために、我々は生成的アプローチと抽出的アプローチの両方を開発した。生成的アプローチのバックボーンは、sequence to sequence learningである。出力されたアサーションの構造を把握するために、まずアサーションの構造を生成し、次に各フィールドの単語を生成する階層的なデコーダを導入する。抽出アプローチは、Learning to rankに基づいている。質問とアサーションの間の意味的な関連性を測定するために、粒度の異なるレベルの特徴が設計されている。実験の結果、我々のアプローチは、質問を考慮したアサーションを文章から推論する能力があることを示した。さらに、ABQAの結果をパッセージ・ベースのQAの追加機能として組み込むことで、我々のアプローチを評価した。2つのデータセットを用いた結果、ABQAの特徴は、パッセージベースのQAの精度を大幅に向上させることがわかった。
機械翻訳は、近年の深層学習の進歩と大規模な並列コーパスの利用により、素晴らしい性能を達成している。これらの成果をローリソース言語ペアにも適用しようとする試みが数多くなされているが、そのためには何万もの並列文が必要となる。本研究では、この研究の方向性を極端にして、並列データがなくても翻訳学習が可能かどうかを調査する。本研究では、2つの異なる言語の単言語コーパスから文を受け取り、それらを同じ潜在空間にマッピングするモデルを提案する。このモデルは、この共有された特徴空間から両言語の再構成を学習することで、ラベル付きデータを使わずに効果的に翻訳を学習する。このモデルを、広く使われている2つのデータセットと2つの言語ペアで実証したところ、Multi30kとWMTの英語-フランス語データセットにおいて、BLEUスコアが32.8と15.1となり、学習時に平行文を1つも使わずに学習することができました。
言語間の単語埋め込みを学習する最新の手法は、対訳辞書やパラレルコーパスに依存していました。最近の研究では、文字レベルの情報を用いることで、並列データの監督の必要性を軽減できることが示された。しかし，これらの手法は，文字レベルの情報を用いた場合には，監視下のデータと同等の結果を得ることができず，また，共通のアルファベットを持つ言語のペアに限られていた．本研究では，並列コーパスを用いることなく，単言語の単語埋め込み空間を教師なしで整列させることで，2言語間の対訳辞書を構築できることを示す．文字情報を一切使用せずに、我々のモデルは、いくつかの言語ペアのクロスリンガルタスクにおいて、既存の教師ありの手法よりも優れている。我々の実験では、英語-ロシア語や英語-中国語のような離れた言語ペアでも、我々の手法が非常によく機能することを示している。最後に、限られた量の並列データしか存在しない英語-エスペラント語の低リソース言語ペアの実験について説明し、完全に教師なしの機械翻訳における本手法の潜在的な影響を示します。我々のコード、エンベッディング、辞書は公開されています。
機械学習の中心となる2つの問題を考察しています。最小値がテストセットに一般化するかどうかをどのようにして予測できるのか、また、確率的勾配降下法はなぜよく一般化する最小値を見つけるのか。我々の研究は、深層ニューラルネットワークが、同じ入力の実際のラベルでよく一般化するにもかかわらず、ランダムにラベル付けされた訓練データを簡単に記憶できることを示したZhangら（2016）に応えるものです。我々は、同じ現象が小線形モデルでも起こることを示しています。これらの観察結果は、急激な最小値にペナルティを課すがモデルのパラメータ化には不変であるベイズ証拠によって説明される。また、学習率を固定した場合、テストセットの精度を最大化する最適なバッチサイズが存在することを示す。また、学習率を固定した場合、テストセットの精度を最大化する最適なバッチサイズが存在することを示した。確率的勾配降下法を確率的微分方程式として解釈すると、「ノイズスケール」g = ˶ˆ꒳ˆ˵ (˶frac{N}{B} - 1) ˶ˆ꒳ˆ˵ (˶frac{N}{B} - 1) ˶ˆ꒳ˆ˵ (˶frac{N}{B} - 1) ˶ˆ꒳ˆ˵ (˶frac{N}{B} - 1) ˶ˆ꒳ˆ˵ (˶frac{N}{B} - 1) ˶ˆ꒳ˆ˵ (˵ ) その結果、最適なバッチサイズは、学習率とトレーニングセットのサイズの両方に比例し、B_{opt}となります。\これらの予測を経験的に検証します。
インスタンスセグメンテーションのようなピクセルレベルのグルーピング問題を解決するために、微分可能でエンドツーエンドの学習可能なフレームワークを紹介する。まず、ピクセルを超球面埋め込み空間に回帰させ、同じグループのピクセルは高い余弦類似性を持ち、異なるグループのピクセルは指定されたマージン以下の類似性を持つようにする。埋め込み次元とマージンの選択については、球体上に点を一様に分布させる問題の理論的な結果と関連づけて分析しています。第二に，インスタンスをグループ化するために，Mean-Shift Clusteringの一種である，カーネルバンド幅でパラメータ化されたリカレントニューラルネットワークとして実装されたものを利用する．このリカレント・グルーピング・モジュールは微分可能で、収束的なダイナミクスと確率的な解釈が可能です。このモジュールを介してグループ加重損失をバックプロパゲーションすることで、その後のクラスタリングでは解決されない埋め込みエラーの修正のみに焦点を当てて学習することができる。我々のフレームワークは、概念的にはシンプルで理論的には豊富であるが、実際には効果的で計算効率も高い。本研究では、オブジェクトプロポーザル生成のための最新のインスタンスセグメンテーションを大幅に改善するとともに、境界検出やセマンティックセグメンテーションなどの分類タスクにおけるグルーピングロスの利点を実証しています。
疾患の進行や治療のモニタリングに関連する画像マーカーを捕捉するモデルを得ることは困難です。一般的にモデルは、検出の自動化を目的とした既知のマーカーの注釈付き例を含む大量のデータに基づいています。しかし、アノテーションには多大な労力が必要であり、また既知のマーカーの語彙に限定されるため、このようなアプローチには限界がある。ここでは、画像データの異常をマーカーの候補として識別するために、教師なし学習を行います。AnoGANは、正常な解剖学的変化の多様性を学習する深層畳み込み生成敵対ネットワークであり、画像空間から潜在空間へのマッピングに基づく新しい異常スコアリングスキームを伴う。このモデルを新しいデータに適用すると、異常をラベル付けし、学習した分布への適合性を示す画像パッチをスコアリングします。網膜の光コヒーレンス・トモグラフィー画像を用いた結果、この手法は、網膜液や反射率の高い病巣を含む画像などの異常画像を正しく識別することができる。
人工ニューラルネットワークは、教師あり、教師なしを問わず、さまざまな問題の解決策をモデル化できる強力な関数近似器です。人工ニューラルネットワークのサイズや表現力が大きくなると、モデルの分散も大きくなり、ほとんどどこにでもあるオーバーフィッティング問題が発生します。様々なモデルの正則化手法によって緩和されますが、一般的な対処法は、テストしたいドメインのデータ分布を十分に近似した大量のトレーニングデータ（必ずしも容易には入手できません）を求めることです。これに対して、帰納論理プログラミングに代表される論理プログラミング手法は、データを非常に効率的に利用して、記号的な領域を推論するモデルを学習することができる。しかし、これらの手法は、ニューラルネットワークが適用可能な様々なドメインに対応することができない。ニューラルネットワークは、入力のノイズやミスラベルに対してロバストではなく、さらに重要なことに、生のピクセルに対する操作のようにデータが曖昧な非記号的ドメインに適用することができない。本論文では、微分可能な帰納論理フレームワークを提案する。このフレームワークは、従来のILPシステムが適しているタスクを解決できるだけでなく、ILPでは対処できない学習データのノイズやエラーに対する頑健性を示す。さらに、このフレームワークは尤度目的に対してバックプロパゲーションにより学習されるため、曖昧なデータに対してニューラルネットワークと接続することでハイブリッド化することができ、ILPが対応できない領域にも適用することができ、ニューラルネットワーク単体では達成できないデータ効率と汎用性を提供することができる。
本研究では、意味的なレイアウトを推論することで、テキストと画像を合成する新しい階層的なアプローチを提案する。本アルゴリズムは、テキストから画像への直接的なマッピングを学習するのではなく、生成プロセスを複数のステップに分解し、まずレイアウト生成器によってテキストから意味的なレイアウトを構築し、画像生成器によってレイアウトを画像に変換します。レイアウト生成部では，オブジェクトの境界ボックスを生成し，ボックス内のオブジェクトの形状を推定することで，各ボックスを精緻化することで，セマンティックレイアウトを粗いものから細かいものへと段階的に構築する．画像生成部は、推測された意味的レイアウトに基づいて画像を合成することで、テキストの説明と一致する画像の有用な意味的構造を提供する。提案モデルは，意味的に意味のある画像を生成するだけでなく，生成された画像に自動的にアノテーションを施したり，生成されたシーンレイアウトをユーザが変更して生成プロセスを制御することも可能である．提案モデルの能力を、難易度の高いMS-COCOデータセットで実証し、既存のアプローチに比べて、画像の品質、出力の解釈性、入力テキストとの意味的な整合性を大幅に改善できることを示した。
本論文では、GAN（Generative Adversarial Network）とIEC（Interactive evolutionary Computation）を組み合わせたアプローチについて述べています。GANは生き生きとした画像を生成するように学習することができるが、通常は学習した分布からランダムにサンプリングされるため、結果として得られる出力の制御には限界がある。一方、インタラクティブ進化は、画像、音楽、3Dオブジェクトなどの様々な人工物を作り出すことができると期待されているが、伝統的に、ターゲットドメインの進化可能な表現を手で設計することに依存している。本論文の主な洞察は、特定のターゲットドメインで訓練されたGANが、コンパクトでロバストな遺伝子型-表現型マッピングとして機能するということである（すなわち、生成された表現型のほとんどが有効なドメインの人工物に似ている）。このようなGANを学習すると、GANの生成ネットワークへの入力として与えられた潜在的なベクトルを進化的に制御することができ、制御可能で高品質な画像生成が可能になる。本論文では、この新しいアプローチの利点を、参加者が特定のターゲット画像に強く類似した画像を進化させることができたというユーザー研究を通して示します。
医用画像解析やコンピュータ支援介入の問題は、深層学習を用いたソリューションで解決されることが多くなっています。既存の深層学習プラットフォームは柔軟性があるものの、医用画像解析に特化した機能は提供されておらず、この用途に適応させるにはかなりの導入努力が必要です。そのため、多くの研究グループで重複した取り組みや互換性のないインフラが開発されています。本研究では、医用画像における深層学習のためのオープンソースのNiftyNetプラットフォームを紹介します。NiftyNetの目的は、これらのソリューションの開発を加速して簡素化し、コミュニティが使用、適応、構築できるように研究成果を普及させるための共通のメカニズムを提供することです。NiftyNetは、セグメンテーション、回帰、画像生成、表現学習など、さまざまな医療用画像アプリケーションに対応したモジュール式の深層学習パイプラインを提供します。データローディング、データ補強、ネットワークアーキテクチャ、損失関数、評価指標など、NiftyNetパイプラインの構成要素は、医用画像解析やコンピュータ支援介入の特殊性に合わせて調整されており、その利点を活かしています。NiftyNetはTensorFlow上に構築されており、2D、3D画像や計算グラフのTensorBoardによる可視化をデフォルトでサポートしています。NiftyNetを用いて構築された3つの例示的な医用画像解析アプリケーションを紹介する。(1）コンピュータ断層撮影からの複数の腹部臓器のセグメンテーション、（2）脳磁気共鳴画像からコンピュータ断層撮影の減衰マップを予測する画像回帰、（3）指定された解剖学的ポーズのシミュレーション超音波画像の生成。NiftyNetは、セグメンテーション、回帰、画像生成、表現学習などの深層学習ソリューションを迅速に開発・配布したり、新しいアプリケーションにプラットフォームを拡張することができます。
腫瘍の成長は、細胞の浸潤と質量効果に関連しており、これらは伝統的に反応拡散方程式やバイオメカニクスといった数学的モデルによって定式化されています。このようなモデルは、腫瘍成長の予測モデルを構築するために、臨床的な測定値に基づいてパーソナライズすることができます。本論文では、深層畳み込みニューラルネットワーク（ConvNets）を用いて、細胞の浸潤と質量効果を直接表現して学習し、その後の腫瘍の関与領域を予測する可能性を検討する。侵襲ネットワークは、マルチモーダル画像データから得られる代謝率、細胞密度、腫瘍境界に関連する情報から細胞の侵襲を学習します。膨張ネットワークは、腫瘍塊の成長する動きから質量効果をモデル化する。また、侵襲ネットワークと膨張ネットワークを融合させることで、両者の間に内在する相関関係を利用するためのさまざまなアーキテクチャを研究しています。本研究で開発したネットワークは，母集団データを用いて容易に学習でき，対象となる患者に合わせて個別化することができる．膵臓腫瘍のデータセットを用いた定量的な実験により、提案手法は精度と効率の両面で最先端の数理モデルに基づくアプローチを大幅に上回り、2つのサブネットワークのそれぞれが捉える情報は補完的であることが示された。
人体の骨格のダイナミクスは、人間の行動認識に重要な情報をもたらします。従来のモデル化手法では、人の手で作られたパーツや移動ルールに頼っていたため、表現力が乏しく、一般化が困難でした。本研究では、空間的パターンと時間的パターンの両方をデータから自動的に学習することで、これまでの手法の限界を超えた、動的スケルトンの新しいモデル「Spatial-Temporal Graph Convolutional Networks (ST-GCN)」を提案する。この手法は、従来の手法の限界を超え、データから空間的パターンと時間的パターンの両方を自動的に学習することで、表現力を高めるだけでなく、より強力な一般化能力をもたらします。KineticsとNTU-RGBDという2つの大規模データセットにおいて、本手法は主流の手法よりも大幅な改善を達成した。
本論文では、半教師付きビデオオブジェクトセグメンテーション、すなわち、最初のフレームのマスクを与えて、ビデオの背景からオブジェクトを分離するというタスクに取り組む。OSVOSは、ImageNetで学習された一般的な意味情報を、前景セグメンテーションのタスクに次々と転送し、最終的にテストシーケンスの単一のアノテーションされたオブジェクトの外観を学習することができる、完全な畳み込みニューラルネットワークアーキテクチャに基づいています（したがって、ワンショット）。すべてのフレームは独立して処理されますが、結果は時間的に一貫していて安定しています。2つのアノテーション付きビデオ・セグメンテーション・データベースを用いて実験を行い、OSVOSが高速であり、技術水準を大幅に向上させることを示している（79.8% vs 68.0%）。
構造化されていないドメインにおける対話応答の品質を自動的に評価することは、困難な問題です。残念ながら、既存の自動評価指標には偏りがあり、人間による応答品質の判断との相関性は非常に低い。しかし、正確な自動評価手順を持つことは、対話研究にとって非常に重要である。なぜならば、人間による評価を少なくして、新しいモデルを迅速に試作・テストできるからである。この課題に対応するために、我々は対話の自動評価を学習問題として定式化した。我々は、人間の応答スコアの新しいデータセットを用いて、入力された応答に対する人間のようなスコアの予測を学習する評価モデル(ADEM)を発表する。ADEMモデルの予測値は、BLEUなどの単語オーバーラップ指標よりもはるかに高いレベルで、発話レベルとシステムレベルの両方で人間の判断と有意な相関があることを示す。また、ADEMは、学習時に見られなかった対話モデルの評価にも一般化できることを示しています。これは、自動対話評価にとって重要なステップです。
最近のニューラルネットワークは、入力のどこに注目すべきかを指示するアテンションメカニズムで補強されていることが多い。本論文では、平滑化された最大演算子を用いて、スパースで構造化された注目のための新しいフレームワークを提案する。この演算子の勾配は、実値から確率へのマッピングを定義し、注目メカニズムとして適していることを示す。我々のフレームワークには、特別なケースとしてsoftmaxと、最近提案されたsparsemaxのわずかな一般化が含まれる。しかし、我々のフレームワークは、最新の構造化されたペナルティをどのように組み込むことができるかを示し、その結果、入力のセグメントまたはグループ全体に焦点を当てる、より解釈可能な注意メカニズムが得られる。我々は、注目メカニズムのフォワードパスとバックワードパスを計算するための効率的なアルゴリズムを導き出し、バックプロパゲーションで学習されたニューラルネットワークでの使用を可能にする。本研究では、既存のニューラルネットワークを置き換えるための注意メカニズムの可能性を示すために、テキストの含意、機械翻訳、文の要約という3つの大規模タスクで評価した。その結果、我々の注目メカニズムは、性能を犠牲にすることなく、解釈可能性を向上させることができた。特に、テキストの含意と要約については、ソフトマックスとスパースマックスに基づく標準的な注目メカニズムよりも優れた性能を示した。
民間のドローンは、空中からの監視、配送、既存の建築物の監視など、様々なタスクに利用されることが期待されています。しかし、都市環境におけるドローンの展開は、これまでのところ限られています。実際、構造化されていない非常にダイナミックなシナリオでは、ドローンは、実現可能で安全な方法で自律的にナビゲートするという多くの課題に直面しています。本論文では、従来の地図-位置-計画の手法とは対照的に、上記の課題に対処するためのデータ駆動型のアプローチを検討します。そのために、都市の街路でドローンを安全に走らせることができる畳み込みニューラルネットワーク、DroNetを提案します。DroNetは、高速な8層の残差ネットワークとして設計されており、1つの入力画像に対して、2つの出力を生成します。すなわち、障害物を避けながらドローンをナビゲートするためのステアリング角度と、危険な状況を認識して迅速に対応するための衝突確率です。しかし、街中のような構造化されていない屋外環境で、十分なデータを収集するにはどうすればよいのでしょうか。熟練したパイロットが訓練用の軌道を提供することは、大量のデータを必要とすることや、何よりも路上を移動する他の車両や歩行者に対するリスクを考えると、明らかに選択肢ではありません。そこで私たちは、すでに都市環境に溶け込んでいる自動車や自転車が収集したデータからUAVを訓練することを提案します。自動車や自転車は、他の自動車や歩行者を危険にさらすことはありません。市街地で学習したとはいえ、都市部の車両の視点から見ると、DroNetが学習したナビゲーション・ポリシーは非常に一般化しています。実際、DroNetは、UAVが比較的高い高度を飛行したり、駐車場や廊下などの屋内環境でもうまく飛行できるようにします。
ニューラルテキスト生成モデルは、自己回帰型言語モデルやseq2seqモデルが多い。これらのモデルは、各単語が前の単語を条件として、単語を順次サンプリングしてテキストを生成するものであり、いくつかの機械翻訳や要約のベンチマークにおいて最先端のモデルである。これらのベンチマークは、生成されたテキストの品質を直接測定するものではないにもかかわらず、検証パープレキシティによって定義されることが多い。また、これらのモデルは通常、最大尤度と教師強制によって学習されます。これらの方法はperplexityを最適化するのに適しているが、テキストを生成するには、学習時には観測されなかった可能性のある単語のシーケンスを条件付けする必要があるため、サンプル品質が低くなる可能性がある。本研究では、Generative Adversarial Networks (GAN)を用いてサンプル品質を向上させることを提案する。GANは、高品質なサンプルを生成するように生成器を明示的に訓練し、画像生成で多くの成功を収めてきた。GANはもともと微分可能な値を出力するように設計されているため、離散的な言語の生成は困難です。我々は、検証パープレキシティだけでは、モデルによって生成されたテキストの品質を示すことができないと主張する。本研究では、周囲の文脈を条件として欠落したテキストを埋める、アクター批判型条件付きGANを導入する。これにより、最尤学習モデルと比較して、より現実的な条件付きおよび無条件のテキストサンプルが生成されることを、定性的および定量的に示すことができる。
表現学習は、テキストやグラフなどの記号的なデータから学習するための貴重なアプローチとなっている。しかし、複雑な記号データは潜在的な階層構造を示すことが多いが、最新の手法では、この特性を考慮していないユークリッド・ベクトル空間の埋め込みを学習するのが一般的である。この目的のために、我々は、双曲空間、より正確にはn次元のポアンカレ球に埋め込むことで、記号データの階層的表現を学習する新しいアプローチを導入する。この双曲幾何学により、階層性と類似性を同時に捉えることで、記号データの解析的な表現を学習することができる。本研究では、リーマン最適化に基づいて埋め込みを学習する効率的なアルゴリズムを導入し、ポアンカレ埋め込みが、潜在的な階層を持つデータに対して、表現能力と一般化能力の両面でユークリッド埋め込みを大幅に上回ることを実験的に示した。
深層人工ニューラルネットワーク（DNN）は、通常、勾配ベースの学習アルゴリズム、すなわちバックプロパゲーションによって学習されます。進化戦略（ES）は、難易度の高い深層強化学習（RL）問題において、Q-learningや政策勾配などのバックプロップベースのアルゴリズムに対抗することができる。しかし、ESは、勾配の有限差分近似に似た操作を介して確率的な勾配降下を行うため、勾配ベースのアルゴリズムと考えることができる。そのため、勾配ベースではない進化的アルゴリズムがDNNの規模で機能するかどうかという疑問が生じる。勾配のないシンプルな集団ベースの遺伝的アルゴリズム（GA）を用いてDNNの重みを進化させると、Atariやヒューマノイドのロコモーションなどの難しいディープRL問題でも良い結果が得られることを実証した。Deep GAは、400万以上の自由パラメータを持つネットワークを進化させることに成功し、従来の進化アルゴリズムで進化させたニューラルネットワークの中で最大規模となった。これらの結果は、(1)GAが動作可能な規模の感覚を拡大し、(2)性能を最適化するためには、勾配に従うことが最良の選択ではない場合があることを興味深く示唆し、(3)性能を向上させる多数の神経進化技術をすぐに利用できるようにしている。後者については、DNNとノベルティ探索を組み合わせることで、報酬関数が欺瞞的または疎な課題での探索を促し、報酬最大化アルゴリズム（DQN、A3C、ES、GAなど）が失敗する高次元問題を解決できることを示しています。さらに、Deep GAはES、A3C、DQNよりも高速であり（1つのデスクトップで約4時間、720コアに分散させて約1時間でAtariを学習できる）、最先端の10,000倍までのコンパクトなエンコーディング技術を可能にします。
EFM（Elementary Flux Mode）とは、定常状態の制約空間で機能する最小の反応セットを持つ経路のことです。EFMの計算は非常に複雑であるため、これらのフラックスバランスのとれたパスウェイを見つけるための様々なアプローチが提案されている。本論文では、グラフデータモデルに基づいて、EFMのサブセットを見つけるアプローチを提案する。与えられた代謝ネットワークをグラフモデルにマッピングし、代謝物とそれに関連する反応に基づいて、反応を含めるかどうかを決定することができる。この概念により、このアプローチは出力経路を分類するのに便利である。提案手法の代謝ネットワークへの影響について議論する。
本論文では、一般的な2段階の領域ベースのConvNet検出システム（すなわち、R-CNN）を用いた物体検出において、質的に解釈可能なモデルを学習する方法を紹介する。R-CNNは領域提案ネットワークとRoI(Region-of-Interest)予測から構成されており、このhttpの解釈可能モデルでは、弱教師付きの抽出的根拠生成、すなわち、物体インスタンスの潜在的な識別可能な部品構成を、部品構成に対する教師を使わずに自動的に検出と同時に展開する学習に焦点を当てている。本研究では、有向非環状AND-ORグラフ(AOG)に埋め込まれたトップダウンの階層的・構成的な文法モデルを利用して、RoIの潜在的な部品構成の空間を探索し、展開する。我々は、R-CNNで広く使用されているRoIPooling演算子の代わりにAOGParsing演算子を提案し、提案手法は多くの最新のConvNetベースの検出システムに適用可能である。AOGParsing演算子は、トップダウンの階層的・構成的な文法モデルの説明可能な厳密さと、ボトムアップのディープニューラルネットワークの識別力の両方をエンドツーエンドの学習によって利用することを目的としています。検出においては、バウンディングボックスは、オンザフライでAOGから得られる最適なパースツリーによって解釈され、これは解釈検出のために生成された抽出根拠として扱われます。学習では、AOGとConvNetをエンド・ツー・エンドで学習するために、フォールディング・アンフォールディング法を提案します。実験では、R-FCNの上に構築し、PASCAL VOC 2007および2012データセットで提案手法をテストしたところ、最先端の手法と同等の性能を得ることができた。
模倣学習は、学習者が専門家の行動を模倣して最高のパフォーマンスを達成しようとする逐次的なタスクである。近年、この課題に対していくつかのアルゴリズムが提案されています。本プロジェクトでは、これらのアルゴリズムを幅広くレビューし、その主な特徴を示し、性能と後悔限界について比較することを目的としています。
帰納的伝達学習はコンピュータビジョンに大きな影響を与えましたが、NLPにおける既存のアプローチは、タスクに応じた修正やゼロからのトレーニングを必要とします。我々は、NLPのあらゆるタスクに適用可能な効果的な伝達学習法であるUniversal Language Model Fine-tuning (ULMFiT)を提案し、言語モデルを微調整する上で鍵となる技術を紹介する。我々の手法は、6つのテキスト分類タスクにおいて、大多数のデータセットで誤差を18-24%削減し、最先端の手法を大幅に上回った。さらに，わずか100個のラベル付き例文で，100倍のデータを用いてゼロから学習した場合と同等の性能を実現しています．我々は、事前に学習したモデルとコードをオープンソースで提供しています。
遺伝子発現データは、膨大な量の特徴量（p）に比べてサンプル数（n）が少ないため、予測モデルの構築においてユニークな課題となっています。この "n<<p "という特性は、病気の結果を分類するための深層学習技術の適用を妨げている。外部の遺伝子ネットワーク情報を取り込んだスパース学習は、この問題を解決する可能性がある。しかし、(1)数万の特徴量があり、数百の学習サンプルしかないこと、(2)遺伝子ネットワークのスケールフリー構造は、畳み込みニューラルネットワークのセットアップには不向きであることなどから、この問題は非常に困難である。これらの問題を解決し、ロバストな分類モデルを構築するために、我々は、グラフ埋め込み型深層フィードフォワードネットワーク（GEDFN）を提案します。この手法は、オーバーフィッティングを防ぐために、ネットワーク層間の接続を疎にすることができます。この手法の能力を検証するために、The Cancer Genome Atlas (TCGA)の乳がんRNA-seqデータセットを用いて、シミュレーション実験と実データ解析を行いました。その結果，高い分類精度と解釈しやすい特徴選択の結果が得られたことから，この手法は，現在の分類モデルや特徴選択手順に加えて有用な手法であると考えられる．この手法は、こちらのhttpsのURLで公開されています。
本論文ではまず、「なぜDropoutとBN（Batch Normalization）という2つの最も強力な技術を組み合わせると、性能が悪くなることが多いのか」という疑問に、理論的・統計的な側面から答えています。理論的には、Dropoutは、特定の神経ユニットの状態を訓練からテストに移す際に、その分散をシフトさせることがわかりました。しかし、BNは、学習過程で蓄積された統計的な分散をテストの段階でも維持します。BNの前にDropoutを適用した場合、この分散の不整合（我々はこの方式を「分散シフト」と呼んでいます）が、推論における不安定な数値行動の原因となり、最終的に誤った予測をしてしまうことになります。DenseNet、ResNet、ResNeXt、Wide ResNetを用いた徹底的な実験により、我々の発見が確認されました。次に、解明されたメカニズムに基づいて、Dropoutを修正するいくつかの戦略を検討し、分散シフトのリスクを回避することで、その組み合わせの限界を克服しようとしています。
機械学習アルゴリズムは、医療診断や自律走行など、インパクトが大きくリスクの高いタスクへの適用が増えているため、研究者はそのようなアルゴリズムがどのようにして予測に至ったのかを説明することが重要です。近年、高度に複雑なニューラルネットワークが予測の根拠を得るために画像内のどこを「見る」のかを要約するために、多くの画像サレンシー法が開発されてきました。しかし、これらの手法は、そのヒューリスティックな性質やアーキテクチャ上の制約により、限界があります。本論文では、2つの主要な貢献をしています。1つ目は、あらゆるブラックボックス・アルゴリズムに対する様々な種類の説明を学習するための一般的なフレームワークを提案することである。第二に、このフレームワークを分類器の決定に最も影響を与える画像の部分を見つけることに特化します。これまでの研究とは異なり、本研究の手法はモデルに依存せず、画像の摂動を明示的かつ解釈可能にすることで検証可能なものとなっている。
本研究では、2人口の非対称ゲームに関する新たな理論的洞察を導入し、2つの単一人口の対称ゲームへのエレガントな対称分解を可能にする。具体的には、非対称ゲームを構成するペイオフテーブル（AとB）を、2つの独立した単一人口の対称ゲームとして想定し、調査することで、非対称のバイマトリックスゲーム（A,B）を対称ゲームに分解できることを示します。我々は、非対称2人口ゲームとその対称1人口ゲームの間のいくつかの驚くべき形式的関係を明らかにし、分解による次元の減少により、元の非対称ゲームの便利な分析を容易にする。主な発見は、(x,y)が非対称ゲーム(A,B)のナッシュ均衡である場合、yはペイオフテーブルAで決定される対称対局のナッシュ均衡であり、xはペイオフテーブルBで決定される対称対局のナッシュ均衡であることを意味することである。また、その逆も成り立ち、対局のナッシュ均衡の組み合わせが非対称ゲームのナッシュ均衡を形成する。このような形式的な関係が、非対称ゲームのナッシュ構造の特定と分析にどのように役立つかを、いくつかの典型的な例で、より単純な対局ゲームの進化的なダイナミクスを検証することで説明する。
近年のLSTMの成功の原動力は、複雑で非線形な関係を学習する能力にあります。その結果、これらの関係を記述することができないため、LSTMはブラックボックスとして特徴づけられてきた。そこで、標準的なLSTMによる個々の予測を、基礎となるモデルに変更を加えることなく分析するための解釈アルゴリズム、Contextual Decomposition (CD)を紹介します。CDは、LSTMの出力を分解することで、LSTMの最終的な予測に対する単語や変数の組み合わせの貢献度を把握します。YelpデータセットとSSTデータセットを用いたセンチメント分析のタスクでは、CDが対照的なセンチメントの単語やフレーズを確実に識別し、それらがどのように組み合わされてLSTMの最終予測をもたらすかを示しています。また、SSTのフレーズレベルのラベルを用いて、CDがLSTMからポジティブとネガティブの否定をうまく抽出できることを示しています。
最近提案されたTemporal Ensemblingは、いくつかの半教師付き学習ベンチマークで最先端の結果を達成しました。これは、各学習例におけるラベル予測の指数関数的移動平均を維持し、このターゲットと矛盾する予測にペナルティを課すものである。しかし、Temporal Ensemblingはエポック毎に一度しかターゲットが変化しないため、大規模なデータセットを学習する際には扱いにくくなる。この問題を解決するために，我々はラベル予測の代わりにモデルの重みを平均化する手法であるMean Teacherを提案する．さらに、Mean Teacherはテスト精度を向上させ、Temporal Ensemblingよりも少ないラベルでの学習を可能にします。ネットワークアーキテクチャを変更せずに、Mean Teacherは250ラベルのSVHで4.35%のエラーレートを達成し、1000ラベルで学習したTemporal Ensemblingよりも優れています。また、優れたネットワーク・アーキテクチャが性能を左右することも示している。Mean TeacherとResidual Networksを組み合わせることで，CIFAR-10では4000個のラベルを用いた場合に10.55%から6.28%に，ImageNet 2012では10%のラベルを用いた場合に35.24%から9.11%に，それぞれ改善することができました．
音声による自然言語の理解は，ロボットが人間と効果的にコミュニケーションをとるために不可欠な要素である．しかし，制約のない音声指示を扱うことは，(1)音声言語で使用される多様な表現を含む複雑な構造，(2)人間の指示を解釈する際の本質的な曖昧さ，などの理由から困難である．本論文では、制約のない音声言語を扱うことができ、音声指示の曖昧さを効果的に解決することができる初めての包括的なシステムを提案する。具体的には、深層学習を用いた物体検出技術と自然言語処理技術を統合し、ロボットが対話を通じて指示の曖昧さを解消する方法を提案する。模擬環境および実際の産業用ロボットアームを用いた実験により、本システムが人間のオペレータからの自然な指示を効果的に理解する能力があること、また、対話的な説明プロセスによって物体のピッキング作業の成功率を高めることができることを実証した。
本論文では、多変量の依存関係を表現するためのグラフィカルモデルを用いたミッシングデータ研究の最近の進歩をレビューします。まず、従来のフレームワークの限界を3つの異なる視点から検証します。\まず、従来のフレームワークの限界を3つの視点から検証する。次に、グラフィカルモデルに基づく手続きがこれらの限界を克服し、データがMNAR（Missing Not At Random）の場合でも意味のある性能保証を提供できることを示す。特に、幅広いカテゴリーのデータ欠損問題において、一貫した推定を保証する条件を明らかにし、この推定を実施するための手順を導き出す。最後に、MAR(Missing At Random)とMNARの両方のカテゴリーの欠落データモデルに対して、テスト可能な意味を導き出す。
テキストベースのクエリに関連する画像領域を選択することで、視覚的な質問への回答を学習する手法を紹介する。我々の手法は、特定の場所を評価する必要がある "what color "や、情報のある画像領域を選択的に識別する "what room "のような質問への回答において、大幅な改善を示した。我々のモデルは、我々の知る限り最大の人間による注釈付き視覚的質問応答データセットであるVQAデータセットでテストされた。
自然な社交場では、人間はいわゆる自由な会話をするグループを作る傾向がある。このような状況では、ロバストな頭部と胴体のポーズを推定することで、進行中の会話の高レベルの記述を容易にすることができます。しかし、一般的な分散型カメラネットワークで得られる視覚情報だけでは、ロバスト性を実現するには不十分な場合があります。このような観点から、最近のウェアラブルセンシング技術の進歩は、マルチモーダルでリッチな情報の流れを可能にします。本論文では、頭部と胴体の姿勢推定問題を行列補完タスクに変換することを提案します。本論文では、分散したウェアラブルセンサの組み合わせから発せられるマルチモーダルデータを、時間的な一貫性、頭と体の結合、シナリオに固有のノイズを考慮して融合することができるフレームワークを紹介する。このデータセットには、通常の屋内環境で対話する18人の視覚、聴覚、赤外線の記録が含まれています。提案された手法の健全性を示すとともに，F形の検出や社会的注目を集める要因の発見など，より高度なタスクへの利用可能性を示した．
コールセンターで働く9人の従業員が，皮膚コンダクタンスセンサを手首に装着して1週間仕事をし，各通話のストレスレベルを報告した．全員が同じ職務内容であるにもかかわらず、ストレスレベルの報告の仕方には個人差が大きく、同じ参加者の中でも日によって似通ったものがある一方で、参加者によって大きな違いがあることがわかりました。この個人差に対応して，ストレスのある通話とない通話のクラスを自動的に認識する方法として，サポート・ベクトル・マシン（SVM）の損失関数を変更して，さまざまなプライオ-ルに適応させる方法と，皮膚コンダクタンスの変動の点で最も似ている人からの学習サンプルをより重視する方法の2つを検討した．1500件の通話を対象にこの手法をテストしたところ、同じ人の異なる日にトレーニングとテストを行った場合は78.03％、提案されたSVMの適応策を用いて異なる人のトレーニングとテストを行った場合は73.41％の精度を参加者全体で達成しました。
サイズと密度の異なるスケールの構造を含むマルチスケールデータは，スペクトルクラスタリングにとって大きな課題である．局所的にスケーリングされた適切な親和性行列が与えられても、そのような行列の最初のk個の固有ベクトルでは、クラスターをうまく分離できない。そこで、本論文では、より良いクラスタリング結果を得るために、すべての固有ベクトルからのクラスタ分離情報の融合を利用する。我々の手法 FUll Spectral ClustEring (FUSE) は，Power Iteration (PI) と Independent Component Analysis (ICA) に基づいている．PIは，すべての固有ベクトルを1つの疑似固有ベクトルに融合するために用いられる．クラスタ衝突問題を解決するために，PIを用いてp（p＞k）個の疑似固有ベクトルを生成する．これらの擬似固有ベクトルは冗長であり，クラスター分離情報はノイズに汚染されているため，ICAを用いて擬似固有ベクトルを回転させ，一対の統計的独立性を持たせます．ICAが局所最適を克服して探索プロセスを高速化するために，自己適応的で自己学習的なグリーディ探索法を開発した．最終的に、回転させた擬似固有ベクトル（独立成分）のうち、尖り具合で測定したクラスタ分離情報が多いk個の擬似固有ベクトルを選択し、クラスタリングを行う。様々な合成データや実世界のデータにより、我々のFUSE法の有効性と効率性が検証された。
放射線画像から腫瘍のリスク層別化（特徴付け）を行うには，コンピュータ支援診断（CAD）ツールを用いると，より正確かつ迅速に行うことができる．このようなツールによる腫瘍の特徴づけは、非侵襲的ながんの病期診断や予後診断を可能にし、精密医療の一環として個別化された治療計画を促進することにもつながります。本研究では、腫瘍の特性評価を向上させるために、教師付きおよび教師なしの機械学習戦略を提案する。最初のアプローチは教師あり学習に基づくもので、深層学習アルゴリズム、特に3D Convolutional Neural NetworkとTransfer Learningを利用することで大きな成果を上げています。また、放射線科医によるスキャンの解釈をヒントに、グラフ正則化されたスパースマルチタスクラーニング（MTL）フレームワークを用いて、タスクに依存した特徴表現をCADシステムに組み込む方法を示します。2つ目のアプローチでは，医用画像処理アプリケーションに共通する問題である，ラベル付きの学習データが限られていることに対処するため，教師なし学習アルゴリズムを検討する．コンピュータビジョンにおけるラベルプロポーションからの学習（LLP）アプローチにヒントを得て，プロポーションSVMを腫瘍の特徴付けに用いることを提案する。また、教師なしの腫瘍分類のための「深い特徴」の良さについての基本的な疑問に対する答えを求めている。我々が提案する教師付き学習アルゴリズムと教師なし学習アルゴリズムを、肺と膵臓という2つの異なる腫瘍診断の課題（それぞれ1018枚のCTスキャンと171枚のMRIスキャン）で評価し、どちらの問題でも最先端の感度と特異度の結果を得た。
本研究では、大規模なナレッジグラフ（KG）における推論学習の問題を研究する。具体的には、マルチホップ関係の経路を学習するための新しい強化学習フレームワークについて説明する。本研究では、知識グラフの埋め込みに基づいた連続的な状態を持つポリシーベースのエージェントを用い、経路を拡張するために最も有望な関係をサンプリングすることで、KGベクトル空間内で推論する。先行研究とは対照的に、我々のアプローチは、精度、多様性、効率を考慮した報酬関数を含む。実験的には、FreebaseおよびNever-Ending Language Learningデータセットにおいて、提案手法がパスランキングに基づくアルゴリズムおよび知識グラフ埋め込み手法を上回ることを示す。
最先端のコンピュータビジョンモデルは、入力の小さな敵対的摂動に対して脆弱であることが示されている。言い換えれば、データ分布に含まれるほとんどの画像は、モデルによって正しく分類されると同時に、視覚的に類似した誤分類された画像に非常に近いものとなります。多くの研究者が関心を寄せているにもかかわらず、この現象の原因はまだよく理解されておらず、未解決のままです。私たちは、このような直感に反する挙動は、データ多様体の高次元の幾何学的形状に起因する自然現象であるという仮説を立てました。この仮説を検証するための第一歩として、同心円状の高次元の球体を2つに分類するという単純な合成データセットを研究した。このデータセットでは、テストエラーの量と最近接エラーまでの平均距離の間に基本的なトレードオフがあることを示す。特に、球体の小さな一定の割合を誤分類するモデルは、サイズO(1/sqrt{d})の敵対的な摂動に対して脆弱であることを証明した。驚くべきことに、このデータセットでいくつかの異なるアーキテクチャを訓練すると、すべてのエラーセットが自然にこの理論的な境界に近づきます。この理論の結果、ニューラルネットワークの小さな敵対的摂動に対する脆弱性は、観察されたテストエラーの量の論理的帰結であることがわかりました。我々は、この非常に単純なケースの理論的分析が、複雑な実世界のデータセットの幾何学的形状がどのようにして敵対的な例につながるのかを探るための道筋を示すことになると期待している。
本論文では、最新の話者認識システムに対するなりすまし攻撃を合成する生成的敵対ネットワーク（GAN）の能力を調査します。まず、SampleRNNとWaveNetで生成したサンプルは、CNNベースの話者認識システムを騙せないことを示す。また、Wasserstein GANの目的関数を修正して、学習対象のクラスではない実在のデータを利用することを提案する。我々の半教師付き学習法は、標的を絞った攻撃とそうでない攻撃の両方を行うことができ、話者認証システムのセキュリティに関する問題を提起する。
速読の原理にヒントを得て、比較的重要でない入力トークンに対して、隠れた状態のごく一部のみを更新することを動的に決定するリカレントニューラルネットワーク（RNN）であるSkim-RNNを紹介します。Skim-RNNは、常に隠れた状態全体を更新するRNNよりも計算上の利点があります。Skim-RNNは、標準的なRNNと同じ入出力インターフェースを使用しており、既存のモデルでRNNの代わりに簡単に使用することができます。実験では、Skim-RNNが、5つの異なる自然言語タスクにおいて、標準的なRNNと比較して、精度を落とすことなく、大幅な計算コストの削減を達成できることを示しました。さらに、Skim-RNNの精度と速度のトレードオフを、推論時間中に安定して動的に制御できることを実証しました。また、シングルCPU上で動作するSkim-RNNは、GPU上で動作する標準的なRNNと比較して低遅延であることを示しています。
コンピュータに自転車に乗らせようとする過去の試みは、膨大な学習時間を必要としたり（強化学習アプローチでは1700回の練習走行を行ったが[1]、直線走行ができなかった）、制御したい特定の自転車の正確な運動方程式を代数的に解析する必要があった[2, 3]。不思議なことに、人間は自転車の乗り方を学ぶときに、これらのいずれも必要としない。ここでは，希望する方向（例えば，希望する目標に向かって，あるいは希望する経路に沿って）に自転車を走らせることができる2ニューロンネットワーク1を紹介する．人が自転車に乗るときと同じように、このネットワークは長距離の目標に対しては非常に正確ですが、短距離では安定性の問題が行動を支配します。これは、明示的な設計によるものではなく、ネットワークが自転車をどのように制御するかという自然な結果として発生します。
教師あり、教師なしを問わず、既存の機械学習アルゴリズムの多くは、優れたモデルを生成するために、入力特性の質に依存しています。そのため、よりコンパクトで高レベルな特徴セットを生成できる特徴融合技術が注目されています。元の変数を融合して新たな変数を生成する手法は、過去数十年の間に数多く開発されてきた。最も基本的なものは、PCA（Principal Component Analysis）やLDA（Linear Discriminant Analysis）のように、元の変数の線形結合を用いるものであるが、IsomapやLLE（Linear Locally Embedding）のように、非線形結合に基づいて低次元の多様な埋め込みを見つけるものもある。さらに最近では，非線形特徴融合を行うためのマニフォールド学習に代わる手法として，オートエンコーダー（AE）が登場している．最近では，AEのモデルが何十種類も提案されており，それぞれが固有の特徴を持っています。これらのモデルの多くは，元の特徴量を融合して縮小した特徴量セットを生成するために使用できますが，他の用途を考慮して設計されたAEもあります．本論文の目的は，AE とは何か，AE をどのように特徴融合に利用するか，幅広いモデルを集めた分類法，および他の古典的な技術との関連性について，読者に広く理解してもらうことである．さらに，与えられた課題に対して適切な AE を選択する方法に関する一連の教訓的なガイドラインと，利用可能なソフ トウェアツールについても説明している．最後に，手書きの数字と乳がんのデータセットを用いて，AEの使用方法を示す2つのケーススタディを行う．
我々は、パンオプティックセグメンテーション（PS）と呼ぶタスクを提案し、研究しています。パノプティックセグメンテーションは、セマンティックセグメンテーション（各画素にクラスラベルを付与する）とインスタンスセグメンテーション（各物体のインスタンスを検出してセグメンテーションする）という一般的に異なるタスクを統合したものである。提案されたタスクでは、豊かで完全な一貫性のあるシーン・セグメンテーションを生成する必要があります。コンピュータビジョンの初期の研究では、関連する画像/シーンの解析タスクが扱われていたが、適切な測定基準がないことや、関連する認識の課題があることから、現在では一般的ではない。この問題を解決するために、我々は、すべてのクラス（ものとこと）の性能を解釈可能かつ統一的な方法で把握する、新しい汎視的品質（PQ）メトリックを提案する。提案した指標を用いて、3つの既存データセットにおけるPSの人間と機械のパフォーマンスを厳密に調査し、タスクに関する興味深い洞察を得た。本研究の目的は、画像のセグメンテーションをより統一的に捉えることで、コミュニティの関心を呼び起こすことです。
リカレントニューラルネットワーク（RNN）は、逐次データや時系列データから特徴や長期的な依存関係を学習することができます。RNNは、ユニット間の少なくとも1つの接続が有向サイクルを形成する非線形ユニットのスタックを持っています。よく訓練されたRNNは、あらゆる力学系をモデル化することができるが、RNNの訓練は、長期依存性の学習に関する問題に悩まされることが多い。この論文では、RNNの初心者や専門家のために、RNNに関する調査といくつかの新しい進歩を紹介します。RNNの基礎と最近の進歩について説明し、研究課題を紹介する。
リカレントニューラルネットワークは、テキスト、音声、画像処理から推薦システムに至るまで、今日では多くのアプリケーションで成功しています。バックプロパゲーションは、これらのネットワークを特定のタスクで学習させるために一般的に使用されるアルゴリズムです。多くの深層学習フレームワークは、リカレントニューラルネットワークのトレーニングとサンプリングの手順を独自に実装していますが、実際には他にも複数の可能性があり、調整すべきパラメータもあります。既存の文献では、この点が見落とされたり無視されたりすることが非常に多い。そこで本稿では、与えられたシーケンスの次のトークンを予測するというタスクを解決するために、キャラクターレベルのリカレントニューラルネットワークのための可能なトレーニングおよびサンプリングスキームの概要を説明する。様々なデータセット、ニューラルネットワークアーキテクチャ、パラメータ設定でこれらの異なるスキームをテストし、いくつかの持ち帰り推奨事項を策定する。学習方式とサンプリング方式の選択は，学習の安定性，サンプリング時間，モデルの性能，実装の手間など，多くのトレードオフに左右されるが，データにはほとんど依存しないことがわかった．最も驚くべき結果は、サブシーケンスでモデルを正しく初期化するために隠れた状態を転送すると、データセットによっては不安定な学習動作になることが多いということである。
Visual Dialogというタスクを紹介します。このタスクでは、AIエージェントに、視覚的コンテンツについて自然な会話言語で人間と意味のある対話を行うことを求めます。具体的には、画像、対話履歴、および画像に関する質問が与えられた場合、エージェントは質問を画像に基づかせ、履歴から文脈を推測し、質問に正確に答えなければならない。Visual Dialogは、機械知能の一般的なテストとして機能するように、特定の下流のタスクから十分に切り離されていますが、個々の応答やベンチマークの進捗を客観的に評価できるように、視覚に基づいています。我々は、大規模なVisual Dialogデータセット（VisDial）を作成するために、新しい2人用のチャットデータ収集プロトコルを開発しました。VisDial v0.9がリリースされ、COCOからの約12万枚の画像に対する1つのダイアログと10の質問-回答ペア、合計約120万のダイアログの質問-回答ペアが含まれている。Visual Dialogのためのニューラルエンコーダー・デコーダーモデルのファミリーを紹介する。3つのエンコーダー（Late Fusion, Hierarchical Recurrent Encoder, Memory Network）と2つのデコーダー（Generative and discriminative）を持ち、多くの洗練されたベースラインを凌駕する。ビジュアル対話のための検索ベースの評価プロトコルを提案する。AIエージェントは、回答候補のセットをソートするように求められ、人間の回答の平均-逆数ランクなどの指標で評価される。また、Visual Dialogタスクにおける機械と人間のパフォーマンスのギャップを人間の研究によって定量化する。これらすべてをまとめて、初の「ビジュアル・チャットボット」を実演します。データセット、コード、学習済みモデル、ビジュアル・チャットボットは、こちらのhttps URLから入手できます。
機械学習を実世界の生産システムで使用することは、小さな玩具の例や大規模なオフラインの研究実験では見られない多くの問題によって複雑になります。テストとモニタリングは、機械学習システムが実運用に適しているかどうかを評価するための重要な検討事項です。しかし、どの程度のテストとモニタリングで十分なのでしょうか？私たちは、これらの問題を定量化するために、実用的なテストのセットに基づいたMLテストスコアのルーブリックを提示します。
ディープニューラルネットワーク（DNN）は、近年、多くの視覚認識タスクで大きな成功を収めています。しかし、既存のディープニューラルネットワークモデルは、計算コストやメモリ使用量が高いため、メモリリソースの少ないデバイスや、レイテンシー要件の厳しいアプリケーションへの導入を妨げています。そこで、モデルの性能を大幅に低下させることなく、モデルの圧縮と高速化を行うことが考えられています。この分野では、過去5年間で飛躍的な進歩があった。本論文では、DNNモデルを圧縮・高速化するための最近の技術をレビューする。一般的に、これらの技術は、パラメータの刈り込みと量子化、低ランクの因数分解、転送された/コンパクトな畳み込みフィルタ、および知識の蒸留の4つのカテゴリに分類される。まず、パラメータの刈り込みと量子化の手法を説明し、その後、その他の手法を紹介する。また、それぞれのカテゴリーについて、性能、関連するアプリケーション、利点、欠点に関する洞察的な分析を行います。次に、ダイナミックキャパシティネットワークやストキャスティックデプスネットワークなど、ごく最近成功した手法を紹介する。その後、評価マトリクス、モデル性能の評価に使用される主なデータセット、および最近のベンチマークの取り組みについて調査する。最後に、本稿を締めくくり、残された課題と今後の可能な方向性について議論します。
深層学習の歴史は数十年前にさかのぼりますが、わずか5年前には、「深層学習」という言葉もアプローチも一般的ではありませんでした。その後の5年間で、この分野は何を発見したのでしょうか？音声認識、画像認識、ゲームなどの分野でかなりの進歩があり、一般紙でもかなり熱狂的に取り上げられていることを背景に、私は深層学習に対する10の懸念を提示し、人工的な一般知能に到達するためには、深層学習を他の技術で補う必要があることを提案します。
ニューラルネットワークの学習は、非凸性の高い損失関数の「良い」最小化子を見つける能力に依存しています。ある種のネットワークアーキテクチャ設計（スキップ接続など）では、学習しやすい損失関数が得られ、選択された学習パラメータ（バッチサイズ、学習率、オプティマイザ）では、一般化しやすい最小化器が得られることはよく知られています。しかし、これらの違いの理由や、損失関数の構造への影響についてはよくわかっていません。本論文では、さまざまな可視化手法を用いて、ニューラル損失関数の構造と、損失ランドスケープが汎化に与える影響を調べた。まず、損失関数の曲率を視覚化し、損失関数を横に並べて比較するのに役立つ単純な「フィルタ正規化」手法を紹介します。次に、様々な視覚化を用いて、ネットワークアーキテクチャが損失地形にどのように影響するか、また、学習パラメータが最小化器の形状にどのように影響するかを調べます。
畳み込みニューラルネットワーク（CNN）は、音声、画像、テキストの学習において独自の優位性を発揮してきました。最近では、長短期記憶セル（LSTM）を持つリカレント・ニューラルネットワーク（RNN）のシーケンス・ツー・シーケンス学習にも挑戦しています。これは、CNNでは並列化が容易であるのに対し、RNNではほとんどがシーケンシャルであるため、パフォーマンスのボトルネックになるからです。しかし、RNNとは異なり、ネイティブCNNはシーケンス変換に必要な履歴感度を欠いている。したがって、シーケンス順序の認識、すなわち位置感度を強化することが、CNNを一般的な深層学習モデルにするための鍵となる。本研究では、PoseNetと呼ばれる、位置感を強化した拡張CNNモデルを紹介する。PoseNetの特徴は、エンコーダとデコーダで位置情報を非対称に扱うことです。実験によると、PoseNetはCNNベースのsequence-to-sequence学習の精度を大幅に向上させることができ、WMT2014の英独翻訳タスクでは約33-36BLEUスコア、英仏翻訳タスクでは約44-46BLEUスコアを達成しました。
優れた学習結果にもかかわらず、Adam、Adagrad、RMSpropなどの適応型最適化手法は、Stochastic gradient descent (SGD)と比較して一般化が不十分であることがわかっています。これらの手法は、学習の初期段階では良好な結果が得られるが、学習の後期段階ではSGDに劣る傾向がある。本研究では、適応的な手法で学習を開始し、必要に応じてSGDに切り替えるハイブリッド戦略を検討する。具体的には、ある条件が満たされたときにAdamからSGDに切り替えるシンプルな戦略であるSWATSを提案する。我々が提案する条件は、Adamステップの勾配部分空間への投影に関するものである。この条件を監視するプロセスは、オーバーヘッドがほとんどなく、オプティマイザのハイパーパラメータの数を増やさないように設計されている。我々は、以下のようないくつかの標準的なベンチマークでの実験を報告します。CIFAR-10およびCIFAR-100データセットのResNet、SENet、DenseNetおよびPyramidNet、tiny-ImageNetデータセットのResNet、PTBおよびWT2データセットのリカレントネットワークによる言語モデリングなど、いくつかの標準的なベンチマークでの実験を報告します。その結果、我々の戦略は、大部分のタスクにおいて、SGDとAdamの間の汎化のギャップを埋めることができることを示している。
近年、深層学習は、音声認識や画像分類などの多くのアプリケーションで採用されています。本研究では、グラフクラスタリングに深層学習を採用する可能性を探ります。本研究では，まず，元のグラフの非線形埋め込みをstacked autoencoderによって学習し，次にその埋め込みに対してk -meansアルゴリズムを実行してクラスタリング結果を得るというシンプルな手法を提案する．オートエンコーダーとスペクトル・クラスタリングが実際に最適化するものという点で類似していることから、この単純な方法がしっかりとした理論的根拠を持っていることを示す。そして、提案した方法がスペクトル・クラスタリングよりも効率的で柔軟性があることを示す。まず、オートエンコーダーの計算量は、スペクトル・クラスタリングよりもはるかに低い。前者はスパース・グラフのノード数に線形であるのに対し、後者は固有値分解のために超二次的である。第二に、スパース性の制約が追加された場合、深層学習の文献で開発されたスパース・オートエンコーダーを単純に採用することができるが、スパース・スペクトル法を実装するのは容易ではない。様々なグラフデータセットを用いた実験結果は、提案手法が従来のスペクトルクラスタリングを大幅に上回ることを示しており、グラフクラスタリングにおける深層学習の有効性を明確に示している。
長いテキスト列から潜在的な表現を学習することは、多くの自然言語処理アプリケーションにおいて重要な最初のステップである。リカレントニューラルネットワーク（RNN）は、この困難なタスクの礎となっています。しかし、RNNを用いたデコーディング（再構成）の際の文の質は、テキストの長さに応じて低下する。我々は、上記の問題から解放され、かつ計算効率の良い、シーケンス間、純粋な畳み込みおよびデコンボリューショナルオートエンコーディングフレームワークを提案する。提案手法はシンプルで実装が容易であり、多くのアプリケーションのビルディングブロックとして活用することができる。RNNと比較して、我々のフレームワークは長いパラグラフの再構築と修正に優れていることを経験的に示す。また、半教師付きのテキスト分類や要約タスクでの定量的な評価により、ラベルのない長いテキストデータをより有効に活用できる可能性を示した。
構造に基づくリガンド探索は、創薬プロセスを強化するための最も成功したアプローチの一つである。現在、このようなプロセスを支援する機械学習（ML）手法への移行が顕著になっています。その中でも、最近注目されているのがディープラーニング（深層学習）です。ディープラーニングでは、モデルが「学習」することで、課題に関連する特徴を抽出することができます。私たちは、リガンドと受容体の複合体の結合親和性を推定する新しいディープニューラルネットワークを開発しました。複合体は3次元のグリッドで表現され、モデルは3次元の畳み込みを利用してこの表現の特徴マップを作成し、タンパク質とリガンドの両方の原子を同じように扱います。私たちのネットワークは、CASF "scoring power" benchmarkとAstex Diverse Setでテストされ、古典的なスコアリング関数よりも優れた性能を示しました。このモデルは、使用方法やサンプルとともに、gitリポジトリとして以下のURLで公開されています。
ニューラルアーキテクチャの設計には、専門的な知識と広範な試行錯誤が必要です。自動化されたアーキテクチャ検索はこれらの要件を簡素化することができるが，既存の方法で生成されたリカレント・ニューラル・ネットワーク（RNN）アーキテクチャは，柔軟性とコンポーネントの両方に制限がある．本研究では、任意の深さと幅を持つ新しいRNNを生成することができる、自動アーキテクチャ検索に使用するドメイン固有言語（DSL）を提案する。このDSLは、Gated Recurrent UnitやLong Short Term Memoryなどの標準的なアーキテクチャを定義するのに十分な柔軟性を持ち、三角曲線や層の正規化などの非標準的なRNNコンポーネントの導入も可能である。ランキング関数を用いたランダム検索と強化学習という2つの異なる候補生成技術を用いて、言語モデリングや機械翻訳の領域において、RNN DSLが生成する新しいアーキテクチャを調査した。結果として得られたアーキテクチャは、人間の直感に従っていないにもかかわらず、対象とするタスクに対して高い性能を発揮しており、使用可能なRNNアーキテクチャの空間がこれまでの想定よりもはるかに大きいことを示唆している。
強化学習（RL）では、複数の異なるスキルを必要とする複雑なタスクに対するポリシーを学習することが大きな課題となっています。また、実世界のシナリオで展開するための要件でもある。本論文では、効率的なマルチタスク強化学習のための新しいフレームワークを提案する。このフレームワークでは、エージェントが、以前に学習したポリシーをいつ使用するか、新しいスキルをいつ学習するかを決定する階層的なポリシーを採用するよう学習する。これにより、エージェントは学習の異なる段階で継続的に新しいスキルを習得することができる。学習したタスクは、人間の言語による記述に対応しています。エージェントはこれらの記述を介してのみ以前に学習したスキルにアクセスできるため、エージェントは常に人間が解釈可能な選択肢の記述を提供することができる。階層化された政策に必要な複雑な時間的依存性をエージェントが学習するのを助けるために、我々は、以前に学習したスキルに頼るタイミングと新しいスキルを実行するタイミングを調整する確率的時間文法をエージェントに提供する。本研究では、過去に学習したスキルを再利用し、同時に新しいスキルを学習する能力を明示的にテストするように設計されたMinecraftゲームを用いて、本アプローチを検証する。
Zero-shot Learnerは、見たことのないクラスを予測できるモデルです。本研究では、テキストを分類するためのゼロショット学習法を提案する。本手法では、大規模な文のコーパスを用いてモデルを学習し、文と文のタグの埋め込みとの関係を学習する。このような関係を学習することで、モデルは見たことのない文章やタグ、さらには同じ埋め込み空間に入れることができる新しいデータセットにも一般化することができる。このモデルは、与えられた文がタグに関連しているかどうかを予測するように学習するが、他の分類器は文を可能なクラスの一つに分類するように学習する。我々は、このタスクのために3つの異なるニューラルネットワークを提案し、学習に用いたデータセットのテストセットと、再学習を行わなかった他の2つの標準的なデータセットでの精度を報告する。いずれの場合も、我々のモデルは、新たな未経験のクラスに対してよく汎化することが示された。このモデルは、最先端の教師付きモデルの精度には達していないが、自然言語処理における一般的な知能への一歩となることは明らかである。
本論文では、テキストから直接音声を合成するためのニューラルネットワークアーキテクチャであるTacotron 2について述べる。このシステムは、文字エンベッディングをメルスケールのスペクトログラムにマッピングするリカレント配列間特徴予測ネットワークと、それらのスペクトログラムから時間領域の波形を合成するボコーダとして機能する修正WaveNetモデルで構成されています。このモデルは、平均オピニオンスコア（MOS）4.53を達成し、プロが録音した音声のMOS 4.58と同等の結果を得た。我々のデザインを検証するために、システムの主要コンポーネントのアブレーション研究を行い、言語的特徴、持続時間、F0特徴の代わりに、WaveNetへの入力としてメル・スペクトログラムを使用した場合の影響を評価しました。さらに、コンパクトな音響中間表現を用いることで、WaveNetアーキテクチャを大幅に簡素化できることを実証しました。
自己ペース学習とハードサンプルマイニングは、学習精度を向上させるためにトレーニングインスタンスに再重み付けする。本論文では、確率的勾配降下法(SGD)におけるサンプルの不確実性の軽量推定値に基づいて、2つの改良された代替案を提示する。ミニバッチSGDの反復における正しいクラスの予測確率の分散と、正しいクラスの確率の決定閾値への近さである。6つのデータセットを用いた広範な実験の結果，我々の手法は，残差学習，モメンタム，ADAM，バッチ正規化，ドロップアウト，蒸留などの一般的な学習手法に加えて，様々なネットワークアーキテクチャにおいて確実に精度を向上させることがわかった．
Listen, Attend, and Spell (LAS)などのアテンションベースのエンコーダ・デコーダアーキテクチャは、従来の自動音声認識(ASR)システムの音響、発音、言語モデルのコンポーネントを1つのニューラルネットワークに統合したものです。これまでの研究では、このようなアーキテクチャが、音声入力タスクにおいて最先端のASRシステムに匹敵することを示してきましたが、このようなアーキテクチャが、音声検索のような難易度の高いタスクに実用的であるかどうかは明らかではありませんでした。本研究では、LASモデルの構造的および最適化的な改良を行い、性能を大幅に向上させました。構造面では、書記素の代わりに単語の断片モデルを使用できることを示しています。また、マルチヘッドアテンションアーキテクチャを導入し、一般的に使用されているシングルヘッドアテンションよりも改善されています。最適化の面では，同期学習，スケジュールされたサンプリング，ラベルの平滑化，最小単語エラーレートの最適化を検討し，これらすべてが精度を向上させることを示した．ストリーミング認識用の一方向性LSTMエンコーダを用いた結果を紹介します。12,500時間の音声検索タスクでは、従来のシステムが6.7%のWERを達成したのに対し、提案された変更は9.2%から5.6%に改善しました。
最近のディープネットワークは、ラベルが完全にランダムな場合でも、データ全体を記憶することができます。破損したラベルに対するオーバーフィッティングを克服するために、我々は、MentorNetと呼ばれる別のニューラルネットワークを学習して、ベースとなるディープネットワークであるStudentNetの学習を監視するという新しい手法を提案する。MentorNetは、StudentNetの学習中に、ラベルがおそらく正しいと思われるサンプルに焦点を当てるためのカリキュラム（サンプルの重み付けスキーム）を提供します。通常、人間の専門家によって事前に定義される既存のカリキュラムとは異なり、MentorNetはStudentNetとともにデータ駆動型のカリキュラムを動的に学習します。実験の結果、我々のアプローチは、破損した訓練データで訓練された深層ネットワークの一般化性能を大幅に向上させることができます。特に，我々の知る限りでは，実世界のノイズの多いラベルを含む220万枚の画像を含む大規模なベンチマークであるWebVisionにおいて，最高の結果を得ることができました．コードはこちらのhttpsのURLにあります。
知識の蒸留（KD）は，ある機械学習モデル（教師）から別の機械学習モデル（生徒）に知識を移すことである．） 一般的に，教師は強力な性能を持つ大容量のモデルであり，生徒はよりコンパクトなモデルである．知識を移すことで、生徒のコンパクトさから利益を得たいと考えます。私たちは、先生に近い性能を持つコンパクトなモデルを望みます。モデルを圧縮するのではなく、教師と同じパラメータで生徒を訓練するのです。驚くべきことに、これらの｛Born-Again Networks（BAN）｝は、コンピュータビジョンと言語モデリングの両方のタスクにおいて、教師を大幅に凌駕する。DenseNetsに基づくBANを用いた実験では、CIFAR-10（3.5％）およびCIFAR-100（15.5％）のデータセットにおいて、検証誤差により最先端の性能を示した。さらに、2つの蒸留目的についても実験を行った。(i) Confidence-Weighted by Teacher Max (CWTM) と (ii) Dark Knowledge with Permuted Predictions (DKPP) です。どちらの方法もKDの本質的な構成要素を解明し、予測されたクラスと予測されないクラスの両方で教師の出力が役割を果たすことを示した。我々は様々な能力の学生を使った実験を行い、学生が教師を圧倒するという、あまり検討されていないケースに焦点を当てています。この実験では、DenseNetsとResNetsの間で知識を転送することで、どちらの方向にも大きな利点があることを示しています。
既存の学習済みのニューラルネットワークがある場合、既に学習した機能のパフォーマンスを妨げることなく、新たな機能を学習することが望まれることが多い。既存のアプローチでは、最適ではない解を学習したり、共同学習を必要としたり、追加されたドメインごとにパラメータ数が大幅に増加し、通常は元のネットワークと同じくらいの数になってしまう。我々は、Deep Adaptation Networks (DAN)と呼ばれる手法を提案する。(DAN）と呼ばれる方法を提案します。これは、新しく学習されたフィルタが既存のフィルタの線形結合であることを制約するものです。DANは、元の領域での性能を正確に維持し、標準的な微調整手順と比較して数分の1（ネットワークアーキテクチャに依存）のパラメータ数を必要とし、より少ない学習サイクルで同等以上の性能に収束します。さらに、標準的なネットワークの量子化技術と組み合わせることで、パラメータのコストを元の値の約3％にまで削減し、精度の低下を最小限に抑えることに成功しました。学習されたアーキテクチャは、様々な学習された表現を切り替えるように制御することができ、1つのネットワークで複数の異なるドメインのタスクを解決することができます。本研究では、さまざまな画像分類タスクにおいて本手法の有効性を示す広範な実験を行い、その動作のさまざまな側面を探っている。
本論文では、非言語的な入力からテキストや音声を生成するタスクとして定義される、自然言語生成（Natural Language Generation: NLG）に関する技術の現状を調査しています。NLGの調査は、この分野が過去10年ほどの間に、特に新しい（通常はデータ駆動の）手法やNLG技術の新しい応用に関連して変化してきたことを考えると、時宜を得たものである。そこで本調査では、(a)NLGの中核的なタスクと、そのようなタスクを組織化するために採用されたアーキテクチャに関する研究の最新の統合を行うこと、(b)NLGと人工知能の他の分野との間で相乗効果が高まった結果として一部発生した、比較的最近の数多くの研究トピックに焦点を当てること、(c)NLGの評価における課題に注目し、異なる評価方法とそれらの間の関係に重点を置いて、自然言語処理の他の分野で直面している同様の課題と関連付けることを目的としています。
人間の伝統的な五感（視覚、聴覚、味覚、嗅覚、触覚）のうち、視覚と聴覚は、人間が世界を理解するための基本的な情報源です。自然現象の中では、この2つのモダリティはしばしば相関し、人間の知覚に共同で影響を与えます。本論文では、視覚的な入力から音を生成するという課題を提起します。このような機能は、バーチャルリアリティへの応用（バーチャルシーンのためのサウンドを自動的に生成する）や、視覚障害者が画像やビデオにアクセスする際の利便性を高めるのに役立ちます。この方向性への第一歩として、我々は学習ベースの手法を用いて、入力ビデオフレームから生の波形サンプルを生成する。我々のモデルを、様々な音（周囲の音や人や動物の音など）を含むビデオのデータセットで評価した。実験の結果、生成された音はかなりリアルで、視覚的な入力と時間的にうまく同期していることがわかりました。
近年、深層学習の分野では、畳み込みニューラルネットワーク（CNN）が重要な役割を果たしています。CNNのバリエーションは、さまざまなドメインの分類タスクで大きな成功を収めていることが証明されています。しかし、CNNには2つの大きな欠点があります。特徴間の重要な空間的階層を考慮していないことと、回転不変性がないことです。CNNは、テストデータに物体の重要な特徴がある限り、特徴の相対的な空間的向きを無視して、テストデータを物体として分類する。これが偽陽性の原因となる。また、CNNには回転不変性がないため、ネットワークが誤ってオブジェクトに別のラベルを付けてしまい、偽陰性の原因となる。この問題を解決するために、Hintonらは最近の論文で、カプセルの概念を用いた新しいタイプのニューラルネットワークを提案している。ダイナミックルーティングと再構成正則化を用いることで、カプセルネットワークモデルは、回転不変かつ空間的に認識できるようになる。このカプセルネットワークは、MNISTにおいて、回転やスケーリングなどのデータ拡張を行わない場合のテストエラーが0.25%という、これまでのベースラインである0.39%を上回る最先端の結果を達成し、その可能性を示しました。さらに、より高次元のデータへのカプセルネットワークの適用を検証するために、CIFAR10データセットで最適なテスト誤差をもたらす最適な構成セットを見つけることを試みる。
我々は、非常に計算効率の高いCNNアーキテクチャ「ShuffleNet」を導入しました。このアーキテクチャは、非常に限られた計算能力（例：10～150MFLOPs）のモバイルデバイス用に特別に設計されています。このアーキテクチャでは、ポイントワイズグループコンボリューションとチャネルシャッフルという2つの新しい演算を用いることで、精度を維持しながら計算コストを大幅に削減しています。例えば，ImageNetの分類タスクでは，40MFLOPsの計算量で，最近のMobileNetよりもトップ1エラーが少ない（絶対値で7.8%）．ARMベースのモバイル機器では，ShuffleNetはAlexNetと同等の精度を維持しながら，実際には約13倍の高速化を達成している．
ニューラルネットワークは最近、多くのタスクで成功を収めています。しかし、優れた性能を発揮するニューラルネットワークのアーキテクチャは、いまだに専門家が手作業で設計し、面倒な試行錯誤を繰り返しているのが一般的です。本研究では、CNNアーキテクチャを自動的に探索する新しい手法を提案する。この手法では、演算子にネットワーク形態素を適用し、コサインアニーリングによる短時間の最適化を行うというシンプルなヒルクライミング手順を採用している。驚くべきことに、このシンプルな手法は、1つのネットワークを学習するのと同じオーダーのリソースしか必要としないにもかかわらず、競争力のある結果をもたらす。例えば、CIFAR-10において、我々の手法は単一のGPUを用いてわずか12時間で6%以下のエラーレートでネットワークを設計・学習し、1日の学習ではさらに5%近くまでエラーを減らすことができました。
我々は、効率的な文書表現学習フレームワーク「Document Vector through Corruption (Doc2VecC)」を発表しました。Doc2VecCは、各文書を単語埋め込みの単純な平均値として表現します。このようにして生成された表現は、学習中の文書の意味を確実に捉えます。このモデルは、データに依存した正則化を導入しており、情報量の多い単語や希少な単語を優遇する一方で、一般的な単語や差別的でない単語の埋め込みをゼロに近づけるようにしています。Doc2VecCはWord2Vecよりも有意に優れた単語埋め込みを生成します。我々は、Doc2VecCをいくつかの最新の文書表現学習アルゴリズムと比較しました。Doc2VecCが導入したシンプルなモデルアーキテクチャは、感情分析、文書分類、および意味的関連性タスクのための高品質な文書表現を生成する上で、最先端のモデルと一致、または凌駕しました。モデルがシンプルなので、1台のマシンで1時間に数十億語の学習が可能です。同時に、このモデルは、テスト時に未見の文書の表現を非常に効率的に生成します。
インデックスはモデルであり、B-Tree-Indexはソートされた配列内のレコードの位置とキーを対応付けるモデル、Hash-Indexはソートされていない配列内のレコードの位置とキーを対応付けるモデル、BitMap-Indexはデータレコードが存在するかどうかを示すモデルと見なすことができる。この探索的な研究論文では、この前提から出発し、既存のすべてのインデックス構造は、深層学習モデルを含む他のタイプのモデルに置き換えることができると仮定し、これを学習済みインデックスと呼んでいます。モデルはルックアップキーのソート順や構造を学習し、この信号を使ってレコードの位置や存在を効果的に予測することができるというのが重要なアイデアである。我々は、学習済みインデックスが従来のインデックス構造よりも優れている条件を理論的に分析し、学習済みインデックス構造を設計する上での主な課題を説明する。初期の結果では、ニューラルネットを使用することで、いくつかの実世界のデータセットにおいて、キャッシュに最適化されたB-Treeを最大70％の速度で凌駕し、メモリを桁違いに節約できることがわかりました。さらに重要なことは、データ管理システムのコアコンポーネントを学習モデルで置き換えるというアイデアは、将来のシステム設計に大きな影響を与えるものであり、今回の研究はその可能性を垣間見せてくれるものだと信じています。
タンパク質は、生物学において最も多様な機能を担っています。タンパク質の配列から情報を抽出したり、突然変異の影響を予測したりする能力は、生物学や医学の多くの分野で非常に有用です。しかし、タンパク質の配列と機能の間のマッピングは複雑で、あまり理解されていない。本研究では、変分法自動符号化器を用いて天然のタンパク質配列を埋め込み、それを用いて突然変異がタンパク質の機能にどのように影響するかを予測する。この教師なしのアプローチを用いて、自然の変異をクラスタリングし、タンパク質内の位置のセット間の相互作用を学習します。このアプローチは、一般的に、配列内の相互作用を考慮しないベースラインの手法よりも優れており、場合によっては、逆Pottsモデルを使用する最先端のアプローチよりも優れています。この生成モデルは、タンパク質配列空間の探索を計算的に導き、合理的で自動化されたタンパク質設計への情報提供を強化するために利用できる。
オープンドメインの社会対話は、人工知能の長年の目標の一つです。今年は、世界中の一流大学が開発したシステムを実際のお客様に評価してもらう「Amazon Alexa Prize」というチャレンジが初めて発表されました。このチャレンジの目的は、「20分間、人気のあるトピックについて人間と首尾一貫して魅力的な会話をする」ことです。私たちは、ルールベースのシステムと機械学習システムを組み合わせたボットのアンサンブルからなるAlexa Prizeシステム（「Alana」と呼ばれる）について説明し、文脈に応じたランカーの仕組みを使ってシステムの応答を選択しました。ランカーは、コンテスト中に受け取った実際のユーザーのフィードバックで学習されましたが、ここでは、コンテスト中に得られたノイズの多い、まばらなフィードバックをどのように学習するかという問題に取り組みました。
我々は、Deep Q Network (DQN)における価値関数パラメータの確率分布に直接取り組むフレームワークを提案し、パラメータの事後を近似する強力な変分推論サブルーチンを用いる。我々の提案するサロゲート目的と変分推論損失の間の等価性を確立する。我々の新しいアルゴリズムは、効率的な探索を実現し、大規模な連鎖マルコフ決定過程（MDP）においても良好な性能を発揮します。
木構造ニューラルネットワークは、文の意味を解釈する際に貴重な構文解析情報を利用します。しかし、木構造ニューラルネットワークには、大規模なNLPタスクでは遅くて扱いにくいという2つの重要な技術的問題があります。SPINNは、構文解析と解釈を1つの木構造ハイブリッドモデルに統合したもので、木構造の文解釈をシフト・リダス・パーサーの線形逐次構造に統合することで、これらの問題を解決します。このモデルは、他の木構造モデルに比べて最大25倍の速度でバッチ計算をサポートしており、統合されたパーサーは、精度をほとんど落とすことなく未解析データを処理することができます。このモデルをStanford NLI entailment taskで評価したところ、他の文エンコーディングモデルを大幅に上回る結果が得られました。
多変量時系列の後続クラスタリングは、時間データの中に繰り返されるパターンを発見するのに有効なツールである。これらのパターンが発見されると、一見複雑に見えるデータセットも、わずかな数の状態、すなわちクラスタからなる時間的シーケンスとして解釈することができる。例えば，フィットネストラッキングアプリケーションの生のセンサーデータは，いくつかの動作（歩く，座る，走るなど）のタイムラインとして表現できる．しかし、これらのパターンを発見するには、時系列のセグメンテーションとクラスタリングを同時に行う必要があるため、困難を伴います。さらに、得られたクラスターを解釈することは、特にデータが高次元である場合には困難である。ここでは、モデルベース・クラスタリングの新しい手法を提案する。この手法をTeplitz Inverse Covariance-based Clustering (TICC)と呼ぶ。TICC法の各クラスタは、そのクラスタの典型的なサブシーケンスにおける異なる観測値間の相互依存性を特徴づける相関ネットワーク、すなわちMarkov random field (MRF)によって定義される。このグラフ表示に基づいて、TICCは時系列データのセグメント化とクラスター化を同時に行う。期待値最大化（EM）アルゴリズムのバリエーションを用いて、交互最小化によってTICC問題を解く。その結果得られた2つの小問題を、それぞれ動的計画法とADMM（Alternating Direction Method of Multipliers）を用いて、スケーラブルに効率よく解くための閉形式解を導出した。一連の合成実験において、TICCといくつかの最先端のベースラインを比較することで、我々のアプローチを検証し、自動車センサーのデータセットを用いて、TICCがどのように実世界のシナリオで解釈可能なクラスタを学習することができるかを実証した。
畳み込みニューラルネットワーク（CNN）の構造を学習するための新しい手法を提案している。本手法では、モデルベース最適化（SMBO）戦略を用いており、複雑さが増す順に構造を探索すると同時に、構造空間を探索するための代理モデルを学習する。同じ探索空間の下で直接比較すると、我々の手法はZophら（2018）のRL法と比べて、評価されるモデルの数では最大5倍、総計算量では8倍高速であることがわかります。このようにして発見した構造は、CIFAR-10とImageNetで最先端の分類精度を達成しています。
本研究では、創薬や設計に重要な応用が期待されている、タンパク質間のインターフェースの予測を検討し、既存および新規に提案した空間グラフ畳み込み演算子の性能を調べた。注目するノードのローカルな近傍に対して畳み込みを行うことで、複数の層の畳み込みを重ね、グラフ全体の情報を統合して、注目するタンパク質の3次元構造を表す効果的な潜在表現を学習することができます。そして、学習した特徴をタンパク質のペアに渡って組み合わせるアーキテクチャを用いて、アミノ酸残基のペアがインターフェースの一部であるかどうかを分類する。実験では、いくつかのグラフ畳み込み演算子により、このタスクにおいて最先端のSVM法よりも優れた精度が得られました。
確率的勾配降下法を用いてディープニューラルネットワークを学習するには、学習率とバッチサイズの両方を慎重に選択する必要があります。バッチサイズを小さくすると、より少ない学習エポックで収束しますが、バッチサイズを大きくすると、並列性が高まり、計算効率が向上します。私たちは、すべてのエポックに対して単一のバッチサイズを静的に選択するのではなく、学習プロセス中にバッチサイズを適応的に増加させる新しい学習手法を開発しました。この手法では，小さなバッチサイズでも収束率が高く，大きなバッチサイズと同等の性能が得られる．CIFAR-10，CIFAR-100，ImageNetデータセット上で動作する標準的なAlexNet，ResNet，VGGネットワークを用いて，我々の手法を分析した．その結果，4つのNVIDIA Tesla P100 GPUにおいて，適応的なバッチサイズで学習することで，固定のバッチサイズで学習した場合に比べて精度を1％未満に抑えながら，性能を最大で6.25倍に向上させることができた．
また，バイトレベルのリカレント言語モデルの特性を調べました．十分な容量，学習データ，および計算時間が与えられた場合，これらのモデルが学習する表現には，高レベルの概念に対応する分離した特徴が含まれる．具体的には、感情分析を行う1つのユニットを発見しました。教師なしで学習されたこれらの表現は、Stanford Sentiment Treebankの2つのサブセットにおいて、最先端の技術を達成しています。また、データ効率も非常に良い。わずかな数のラベル付き例を使用するだけで、我々のアプローチは、完全なデータセットで学習した強力なベースラインと同等の性能を発揮します。また、センチメントユニットがモデルの生成プロセスに直接影響を与えることも実証しています。センチメントユニットの値を正または負に固定するだけで，対応する正または負のセンチメントを持つサンプルが生成される．
チェスのゲームは、人工知能の歴史の中で最も広く研究されている分野です。最強のプログラムは、洗練された探索技術、ドメイン固有の適応、そして人間の専門家が数十年かけて改良した手作りの評価関数の組み合わせに基づいています。一方、AlphaGo Zeroプログラムは、自己対戦ゲームからのタブララサ強化学習により、最近、囲碁ゲームで超人的なパフォーマンスを達成した。本論文では、このアプローチを一般化し、多くの挑戦的な領域で超人的なパフォーマンスをタブララサに達成できる単一のアルファゼロ・アルゴリズムを開発しました。AlphaZeroは、ゲームのルール以外の知識を持たず、ランダムにプレイすることから始めて、24時間以内にチェス、将棋、囲碁のゲームで超人的なレベルのプレイを達成し、いずれの場合も世界チャンピオンのプログラムに説得力を持って勝った。
先験的に未知の混乱した環境を動的システムが高速かつ安全にナビゲートすることは、自律システムの多くの応用に不可欠である。しかし、自律システムの軌道計画は計算量が多く、効率的な計画を立てるためには、安全性や動的実現性を犠牲にしてダイナミクスを単純化する必要があります。逆に、より洗練された力学モデルを用いて安全な軌道を計算することもできますが、これは通常、リアルタイム計画に使用するには遅すぎます。我々は、新しいアルゴリズムFaSTrackを提案する。Fast and Safe Tracking for High Dimensional systems（高次元システムのための高速かつ安全なトラッキング）」を提案する。簡略化されたダイナミクスを使用して迅速に計画するパスまたは軌道プランナーは、FaSTrackフレームワークに組み込むことができ、保証されたトラッキングエラー境界とともに車両に安全コントローラを提供します。この境界は、高次元のダイナミクスと外乱によるすべての可能な偏差を捉えます。なお、FaSTrackはモジュール式であり、現在のほとんどのパスプランナーや軌道プランナーと併用することができます。このフレームワークを、RRTプランナーから得られた3Dパスを追跡する10D非線形クアドローターモデルを用いて実証します。
新しいAIタスクであるEmbodied Question Answering (EmbodiedQA)では、エージェントが3D環境のランダムな場所で生成され、質問（「車の色は何色ですか」）をされます。この質問に答えるためには、エージェントはまず、知的に移動して環境を探索し、一人称（自分中心）の視覚によって情報を収集し、そして質問（「オレンジ」）に答えなければならない。この困難なタスクには、能動的な知覚、言語理解、目標に沿ったナビゲーション、常識的な推論、言語を行動に結びつけることなど、さまざまなAIスキルが必要となります。本研究では、EmbodiedQAのための環境、エンド・ツー・エンドで訓練された強化学習エージェント、および評価プロトコルを開発しました。
本研究では、条件付き生成逆説ネットワーク（conditional generative adversarial networks: Conditional GANs）を用いて、意味的ラベルマップから高解像度のフォトリアリスティック画像を合成する新しい手法を提案する。条件付きGANは様々な応用を可能にしてきたが、その結果は低解像度に限られることが多く、まだリアルには程遠いものである。本研究では、新たな逆問題を用いて、2048x1024の視覚的に魅力的な結果を生成するとともに、新たなマルチスケールの生成器と識別器のアーキテクチャを開発しました。さらに、2つの機能を追加することで、このフレームワークをインタラクティブな視覚操作に拡張しました。1つ目は、オブジェクトインスタンスのセグメンテーション情報を取り入れることで、オブジェクトの削除/追加やオブジェクトカテゴリの変更などのオブジェクト操作を可能にします。2つ目は、同じ入力に対して多様な結果を生成する方法を提案し、ユーザがオブジェクトの外観をインタラクティブに編集できるようにすることです。ヒューマン・オピニオン・スタディにより、本手法が既存の手法を大幅に上回り、深層画像の合成・編集の品質と解像度の両方を進歩させることが実証された。
本論文では、任意のポーズの人物画像を、その人物の画像と新規のポーズに基づいて合成することを可能にする、新規のPose Guided Person Generation Network (PG2)を提案する。我々の生成フレームワークであるPG2は、ポーズ情報を明示的に利用し、ポーズの統合と画像の洗練という2つの重要な段階から構成されています。第1段階では、条件となる画像と目標となるポーズがU-Netのようなネットワークに入力され、目標となるポーズを持つ人物の初期の粗い画像が生成されます。第2段階では、U-Netライクな生成器を敵対的に学習させることで、初期の粗い画像を改良します。128×64の再認識画像と256×256のファッション写真の両方を対象とした広範な実験結果により、我々のモデルが説得力のあるディテールを持つ高品質な人物画像を生成することが示された。
本研究では、機械学習タスクのモデルを設計する問題を研究しています。固定次元のベクトルを対象とする従来のアプローチとは対照的に、並べ替えに不変な集合で定義される目的関数を考慮します。このような問題は，人口統計の推定から，ダムのピエゾメータデータの異常検出，宇宙論まで幅広く存在します．我々の主な定理は、順列不変関数を特徴づけ、任意の順列不変目的関数が属するべき関数族を提供するものである。この関数族は特殊な構造を持っており、集合を扱うことのできる深層ネットワークアーキテクチャを設計することができ、教師なし・教師ありの両方の学習タスクを含む様々なシナリオに展開することができます。また、ディープモデルにおける順列等化の必要条件と十分条件を導き出しました。本研究では、母集団統計の推定、点群分類、集合の拡張、外れ値の検出などに本手法を適用して実証する。
現在の機械学習（ML）研究の多くは、科学や社会の大きな世界にとって重要な問題との関連性を失っています。この観点から見ると、調査するデータセット、評価のための指標、そして結果を元の領域に伝える度合いには明らかな限界があります。MLのインパクトを高めるためには、研究の進め方にどのような変化が必要なのでしょうか。私たちは、この分野のエネルギーと注意を明確に集中させるための6つのインパクトチャレンジを提示し、解決しなければならない既存の障害について議論します。私たちの目的は、継続的な議論を促し、重要なMLに焦点を当てることです。
モデルフリーの深層強化学習アルゴリズムは、幅広いロボットスキルを学習できることが示されていますが、良好な性能を得るためには非常に多くのサンプル数が必要となります。モデルベースのアルゴリズムは、原理的にはより効率的な学習が可能ですが、ディープニューラルネットワークのような表現力のある大容量モデルに拡張することは難しいことがわかっています。本研究では、中規模のニューラルネットワークモデルをモデル予測制御（MPC）と組み合わせることで、モデルベースの強化学習アルゴリズムにおいて優れたサンプルの複雑さを実現し、様々な複雑な運動課題を達成するための安定したもっともらしい歩容を作り出すことができることを実証しました。また、モデルフリー学習器の初期化にディープニューラルネットワークのダイナミクスモデルを用いることで、モデルベース手法のサンプル効率とモデルフリー手法の高いタスク特異性を両立させることを提案する。本研究では、MuJoCoロコモーションタスクにおいて、ランダムなアクションデータで学習した純粋なモデルベースアプローチが、優れたサンプル効率で任意の軌道をたどることができることを実証した。また、本ハイブリッドアルゴリズムは、高速ベンチマークタスクにおいてモデルフリー学習を加速することができ、スイマー、チーター、ホッパー、アリの各エージェントで3～5倍のサンプル効率を達成した。動画はこちらのhttpsのURLからご覧いただけます。
オブジェクトインスタンスのセグメンテーションを行う手法の多くは、すべての学習例にセグメンテーションマスクのラベルを付ける必要があります。この要求は、新しいカテゴリをアノテーションする際にコストがかかり、インスタンス・セグメンテーション・モデルは、よくアノテーションされた約100のクラスに制限されています。本論文の目的は、新しい部分教師付き学習パラダイムと、新しい重み伝達関数を提案することである。これにより、ボックスアノテーションが付与されているが、マスクアノテーションが付与されているのはごく一部である大規模なカテゴリセットに対して、インスタンスセグメンテーションモデルを学習することができる。これらの貢献により、Mask R-CNNを学習し、Visual GenomeデータセットのボックスアノテーションとCOCOデータセットの80クラスのマスクアノテーションを用いて、3000の視覚的概念を検出し、セグメント化することができた。また、COCOデータセットを用いた対照研究において、我々のアプローチを評価した。本研究は、視覚的世界を広く理解するインスタンスセグメンテーションモデルへの第一歩となる。
深層学習手法は、最近、機械翻訳、対話応答生成、要約、およびその他のテキスト生成タスクにおいて、経験的に大きな成功を収めている。この手法では、原文の隠れた表現を生成するエンコーダモデルと、原文を生成するデコーダモデルからなるエンドツーエンドのニューラルネットワークモデルを学習します。このようなモデルは、従来のシステムに比べて部品点数が大幅に削減されていますが、良好な性能を得るためには大幅なチューニングが必要です。特にテキスト生成モデルでは、デコーダが望ましくない動作をすることがあります。例えば、切り捨てられた出力や反復的な出力、当たり障りのない一般的な応答の出力、場合によっては文法的に意味のない言葉の出力などがあります。本論文は、このようなテキスト生成モデルの望ましくない振る舞いを解決するための実践的なガイドとして、実世界での応用を可能にすることを目的としています。
Generative Adversarial Network (GAN)は、生成モデルの強力なサブクラスです。非常に多くの興味深いGANアルゴリズムが研究されていますが、どのアルゴリズムが他のアルゴリズムよりも優れているかを評価することは非常に困難です。我々は、最先端のモデルと評価方法について、中立的かつ多面的な大規模実証研究を行った。その結果、ハイパーパラメータの最適化とランダムな再起動を十分に行うことで、ほとんどのモデルが同程度のスコアに達することが分かりました。これは、アルゴリズムの根本的な変更よりも、より高い計算予算とチューニングによって改善が可能であることを示唆しています。また、現在の評価基準の限界を克服するために、精度とリコールを計算できるいくつかのデータセットを提案しています。今回の実験結果から、今後のGAN研究は、より体系的で客観的な評価方法に基づいて行われるべきであることが示唆された。最後に、テストされたアルゴリズムのいずれもが、\{goodfellow2014generative}で紹介されたnon-saturating GANを一貫して上回っているという証拠を見つけることができませんでした。
私たちは、アフィン変換に不変で（異なる層やネットワーク間の比較が可能）、高速に計算できる（以前の方法よりも多くの比較を計算できる）方法で、2つの表現を素早く比較するツール、Singular Vector Canonical Correlation Analysis（SVCCA）という新しい手法を提案します。このツールを用いて、層の本質的な次元を測定し、必要のない過剰なパラメータ化があることを示した。また、学習中の学習ダイナミクスを調べ、ネットワークがボトムアップで最終的な表現に収束していくことを発見した。コード：このhttpsのURL
ディープニューラルネットワークは、分類タスクを実行する非常に効果的な方法であることが証明されています。入力データが高次元で、入力と出力の関係が複雑で、ラベル付けされた学習例の数が多い場合に優れています。しかし，学習したネットワークが特定のテストケースで特定の分類判断をする理由を説明するのは難しい．これは、分散した階層的な表現に依存しているためです。もし、ニューラルネットが獲得した知識を、代わりに階層的な決定に依存するモデルで同じ知識を表現することができれば、特定の決定を説明することはずっと簡単になる。本論文では、訓練されたニューラルネットを用いて、訓練データから直接学習したものよりも一般化しやすいタイプのソフト決定木を作成する方法を説明する。
入院患者の終末期医療の質を向上させることは、医療機関にとって優先事項である。研究によると、医師は予後を過大評価する傾向があり、それが治療の惰性と相まって、終末期における患者の希望と実際のケアとの間にミスマッチが生じている。我々は、Deep LearningとElectronic Health Record（EHR）データを用いてこの問題に対処する方法を説明し、現在、学術医療センターでInstitutional Review Boardの承認を得て試験的に実施している。入院患者のEHRデータは、アルゴリズムによって自動的に評価され、緩和ケアサービスの恩恵を受ける可能性が高い患者を緩和ケアチームに引き合わせます。このアルゴリズムは、過去数年間のEHRデータをもとに学習されたディープニューラルネットワークで、緩和ケアの恩恵を受ける可能性のある患者の代理として、患者の3～12カ月間の全原因死亡率を予測します。この予測により、緩和ケアチームは、治療中の医師からの紹介に頼ったり、時間のかかる全患者のチャートレビューを行ったりすることなく、そのような患者に積極的にアプローチすることができます。また、モデルの予測を説明するための新しい解釈方法も紹介しています。
従来の歩行者検出手法を向上させるためには、余分な機能を集約することが有効であると考えられている。しかし、CNNベースの歩行者検出器がこれらの追加機能から恩恵を受けられるかどうか、またどのように恩恵を受けられるかについては、まだ研究が不足しています。本論文の最初の貢献は、CNNベースの歩行者検出フレームワークに追加機能を集約することで、この問題を探ることである。広範な実験を通して、様々な種類の追加機能の効果を定量的に評価します。さらに、HyperLearnerという新しいネットワークアーキテクチャを提案し、歩行者検出と与えられた追加機能を共同で学習します。HyperLearnerは、マルチタスク学習により、与えられた特徴の情報を利用し、推論に余分な入力をすることなく検出性能を向上させることができる。複数の歩行者ベンチマークを用いた実験結果により、提案したHyperLearnerの有効性が検証された。
ニューラルネットワークは、現代の機械学習の主流となっていますが、その学習と成功は、モデルアーキテクチャ、損失関数、最適化アルゴリズムなどのハイパーパラメータの経験的な選択に依存しています。本研究では、シンプルな非同期最適化アルゴリズムである「Population Based Training (PBT)」を発表しました。重要なのは，PBTは，学習の全過程で使用する単一の固定セットを見つけようとするという，一般的には最適とは言えない戦略ではなく，ハイパーパラメータ設定のスケジュールを発見することです。典型的な分散型ハイパーパラメータ・トレーニング・フレームワークにわずかな変更を加えるだけで、我々の手法はモデルのロバストで信頼性の高いトレーニングを可能にする。我々は、深層強化学習問題においてPBTの有効性を実証し、一連のハイパーパラメータを最適化することで、ウォールクロック収束の高速化とエージェントの最終性能の向上を示した。さらに、同じ手法が機械翻訳の教師付き学習にも適用できることを示し、BLEUスコアを直接最大化するためにPBTを使用したり、生成された画像のInceptionスコアを最大化するためにGenerative Adversarial Networksの学習にPBTを使用したりします。いずれの場合も、PBTはハイパーパラメータのスケジュールとモデルの選択を自動的に発見し、安定したトレーニングと最終的なパフォーマンスの向上につながっています。
深層強化学習アルゴリズムは、非常に一般的なポリシークラスを使用して複雑なタスクを学習することが示されています。しかし、スパースな報酬問題は依然として大きな課題である。新規性検出に基づく探索手法は、このような環境で特に成功しているが、一般的には観測値の生成モデルまたは予測モデルを必要とし、生の画像の場合のように観測値が非常に高次元で複雑な場合には学習が困難になることがある。本研究では、識別的に学習された模範モデルに完全に基づいた探索のための新規性検出アルゴリズムを提案する。このアルゴリズムでは、訪問した各状態を他のすべての状態と識別するように分類器が学習される。直感的に、新規の状態は、学習中に見られた他の状態と区別するのが容易である。このような判別モデルは、暗黙的な密度推定に対応しており、カウントベースの探索と組み合わせることで、vizDoomベンチマークでのチャレンジングな自己中心的観測に関する最先端の結果を含む、様々な人気のあるベンチマークタスクで競争力のある結果を得ることができることを示している。
本論文では、アスペクトベースのセンチメント分析という課題を紹介します。このタスクの目的は，ユーザのコメントに含まれるエンティティに関するきめ細かな情報を抽出することです．本研究では、文書ごとに単一のエンティティを想定したアスペクトベースの感情分析と、ターゲットエンティティに対する単一の感情を想定したターゲット感情分析の両方を拡張する。特に、1つまたは複数のエンティティの各アスペクトに対するセンチメントを特定します。このタスクのテストベッドとして、SentiHoodデータセットを紹介します。このデータセットは、質問応答（QA）プラットフォームから抽出されたもので、都市の近隣がユーザーによって議論されます。SentiHoodデータセットは、質問応答プラットフォームから抽出したものです。これは、一般的なソーシャルメディアのプラットフォーム（この場合はQAプラットフォーム）を、きめ細かなオピニオンマイニングに使用した初めての例です。QAプラットフォームからのテキストは、現在のデータセットがベースとしているレビュー専用プラットフォームからのテキストに比べて、はるかに制約が少ない。本研究では、ロジスティック回帰と最新のリカレントニューラルネットワークを用いて、いくつかの強力なベースラインを開発しました。
単語のセンチメントは、その単語が使用されるドメインに依存します。そのため、計算社会科学研究では、研究対象のドメインに特化したセンチメント辞書が必要となる。本研究では、ドメイン固有の単語埋め込みとラベル伝搬フレームワークを組み合わせることで、小さなシードワードセットを用いて正確なドメイン固有のセンチメント辞書を生成し、手作業で収集したリソースに依存するアプローチと比較して、最先端の性能を達成する。このフレームワークを用いて、2つの大規模な実証研究を行い、時間とコミュニティの間でセンチメントがどの程度変化するかを定量化した。具体的には，150年分の英語の歴史的なセンチメント辞書と，ソーシャルメディアフォーラムRedditから250のオンラインコミュニティのコミュニティ固有のセンチメント辞書を作成し，公開した．歴史的語彙は、過去150年の間に、感情を持つ（中立ではない）英単語の5％以上が極性を完全に切り替えたことを示し、コミュニティ固有の語彙は、異なるコミュニティ間で感情がいかに大きく変化するかを強調する。
関連するタスクの多くは、エージェントが特定の状態に到達すること、あるいは物体を望ましい構成に操作することを必要とします。例えば、ロボットに、歯車を軸に合わせて組み立てることや、鍵を挿入して回すことを要求することがあります。このようなゴール指向のタスクは、強化学習にとって大きな課題である。なぜなら、自然な報酬関数は疎であり、ゴールに到達して何らかの学習信号を受け取るためには、膨大な量の探索が必要となるからである。これまでのアプローチでは、専門家のデモンストレーションを利用したり、学習エージェントを導くためにタスク固有の報酬形成関数を手動で設計したりすることで、これらの問題に取り組んできた。その代わりに、タスクが達成された1つの状態を得ること以外の事前知識を必要とせずに、これらのタスクを学習する方法を提案します。ロボットは逆に学習され、ゴールから徐々に離れたスタート状態のセットからゴールに到達することを徐々に学んでいきます。本手法は、エージェントのパフォーマンスに適応した開始状態のカリキュラムを自動的に生成し、ゴール指向のタスクを効率的に学習することができる。我々の手法は、最新の強化学習手法では解決できない、難しいナビゲーションや細かい操作の問題を模擬して実証しています。
最近開発されたWaveNetアーキテクチャは、現実的な音声合成における最先端の技術であり、様々な言語において、以前のどのシステムよりも自然な音声であると常に評価されています。しかし、WaveNetは、一度に1つの音声サンプルを連続的に生成するため、今日の超並列コンピュータには適しておらず、リアルタイムのプロダクション環境に導入することは困難です。本論文では，学習したWaveNetから並列フィードフォワードネットワークを，品質に大きな差をつけずに学習する新しい手法であるProbability Density Distillationを紹介する。その結果、リアルタイムの20倍以上の速度で高忠実度の音声サンプルを生成することができ、Googleアシスタントでオンライン展開され、英語と日本語の複数の音声を提供することも可能になりました。
模倣学習は、異なるタスクを単独で解決するために一般的に適用されてきました。そのためには、慎重な特徴量エンジニアリングが必要であったり、膨大な数のサンプルが必要であったりします。理想的には、ロボットは、与えられたタスクのごく少数のデモンストレーションから学習し、タスク固有のエンジニアリングを必要とせずに、同じタスクの新しい状況に即座に一般化できることが望ましい。本論文では、このような能力を実現するためのメタ学習フレームワークを提案する。具体的には、非常に大きなタスクのセットがあり、各タスクには多くのインスタンスがあるという設定を考える。例えば、テーブル上のすべてのブロックを1つのタワーに積み上げるタスクや、テーブル上のすべてのブロックを2つのブロックのタワーに配置するタスクなどが考えられます。いずれの場合も、タスクの異なるインスタンスは、異なる初期状態の異なるブロックのセットで構成されます。学習時に、アルゴリズムは、すべてのタスクのサブセットに対するデモンストレーションのペアを提示します。ニューラルネットが学習され、一方のデモンストレーションと現在の状態（最初はペアのもう一方のデモンストレーションの初期状態）を入力とし、結果として得られる状態とアクションのシーケンスが2つ目のデモンストレーションとできる限り一致することを目標にアクションを出力する。テスト時には、新しいタスクの1つのインスタンスのデモが提示され、ニューラルネットは、この新しいタスクの新しいインスタンスで良好な性能を発揮することが期待される。ソフトアテンションを用いることで、学習データでは見たことのない条件やタスクにモデルを一般化することができます。このモデルをより多くのタスクや環境で学習させることで、あらゆるデモンストレーションを、圧倒的に多様なタスクを達成するロバストなポリシーに変えることができる一般的なシステムを得ることができると期待しています。動画はこちらのhttpsのURLからご覧いただけます。
静止画像上での群集計数は、スケールの変化のために困難な問題です。最近では，ディープニューラルネットワークがこの問題に有効であることが示されている．しかし、既存のニューラルネットワークベースの手法は、スケールに関連した特徴を抽出するために、マルチカラムまたはマルチネットワークモデルを使用することが多く、最適化のために複雑になり、計算も無駄になります。このため、我々は単一画像の群集計数のための新しいマルチスケール畳み込みニューラルネットワーク（MSCNN）を提案する。このネットワークは、マルチスケールブロブに基づいて、より高い群集計数性能のためのスケール関連特徴を生成することができ、実用的なアプリケーションのための精度とコストの両方を兼ね備えたシングルカラムアーキテクチャである。補完的な結果として、我々の手法は、はるかに少ないパラメータ数で、精度とロバスト性の両方において、最先端の手法を上回ることが示された。
スタイル変換は、自然言語処理（NLP）における重要な問題です。しかし，並列データや原理的な評価指標がないことが主な理由で，言語スタイル変換の進歩はコンピュータビジョンなどの他の領域に比べて遅れている．本論文では、非並列データを用いてスタイル変換を学習することを提案する。この目的を達成するために、2つのモデルを検討する。提案モデルの主要なアイデアは、敵対的ネットワークを用いて、コンテンツ表現とスタイル表現を別々に学習することである。また、スタイル移転の2つの側面、すなわち移転強度とコンテンツ保存を測定する新しい評価指標を提案する。我々のモデルと評価指標を、論文-ニュースタイトルの転送と、ポジティブ-ネガティブレビューの転送という2つのタスクに適用した。その結果，提案した内容保存指標は人間の判断と高い相関性があり，提案モデルは自動符号化器と比較して，より高いスタイル伝達強度と同様の内容保存スコアを持つ文章を生成できることがわかった．
2D画像の背後にある3D世界をモデル化するためには、どのような3D表現が最も適切でしょうか？ポリゴンメッシュは、そのコンパクトさと幾何学的特性から、有望な候補です。しかし、2D画像からニューラルネットワークを用いてポリゴンメッシュをモデル化するのは簡単ではありません。なぜなら、メッシュから画像への変換（レンダリング）には、ラスタライズと呼ばれる離散的な操作が必要であり、バックプロパゲーションが妨げられるからです。そこで、本研究では、ニューラルネットワークにレンダリングを統合することを可能にする、ラスタライズのための近似勾配を提案する。このレンダラーを用いて、シルエット画像監視による単一画像の3Dメッシュ再構成を行い、本システムは既存のボクセルベースのアプローチを凌駕する。さらに、2Dから3Dへのスタイル変換や3D DeepDreamなどの勾配ベースの3Dメッシュ編集を、2Dの監視下で初めて実行しました。これらのアプリケーションは、ニューラルネットワークにメッシュレンダラーを統合することの可能性と、我々が提案するレンダラーの有効性を示している。
単純で低次元の連続制御タスクに対して、最適化を必要としない最近傍政策と呼ばれる新しい政策を設計する。この方針は、最適化を必要としないため、学習アルゴリズムの最適化の難しさに気を取られることなく、タスクの根本的な難しさを調べることができる。我々は、初期状態とゴール状態のペアに基づいて全体的な軌道を検索するものと、現在の状態とゴール状態のペアに基づいて部分的な軌道を検索するものの2つのバリエーションを提案する。提案した方針を、報酬が希薄な、広く使われている5つのベンチマーク連続制御タスクでテストした。提案した政策を、報酬の少ない、広く使われている5つの連続制御タスク（Reacher, Half Cheetah, Double Pendulum, Cart Pole, Mountain Car）でテストした。その結果、これまで難しいとされてきたこれらの課題の大半（最初の4つ）は、提案した方針によって高い成功率で容易に解決されることがわかった。これは、これまで難しかったとされてきた課題が、最適化の難しさに起因していた可能性を示している。今回の研究から、洗練された政策学習アルゴリズムの進歩を真に評価するためには、より困難な問題で評価することが必要であることが示唆された。
1枚の画像から、その画像が撮影された環境がどの程度わかるのか？この論文では、前景の物体と背景（環境の可視部分）を組み合わせることで、どれだけの情報を取り出すことができるかを調べています。完全に拡散していないと仮定すると、前景の物体は複雑な形をした、完璧とは言い難い鏡のような役割を果たします。さらに、その外観は、環境からの光と、それがどのような素材で作られているのかわからないという点で混乱をきたします。本研究では，近似表面法線から計算された複数の反射率マップから環境を予測する学習ベースのアプローチを提案する．提案手法では，環境の統計量と材料の特性を共同でモデル化することができる．本研究では，合成された学習データを用いてシステムを学習するが，実世界のデータにも適用できることを示す．興味深いことに、我々の分析によると、複数の材料で作られた物体から得られる情報は、しばしば補完的であり、より良いパフォーマンスをもたらすことが分かった。
本研究では、視覚的プリミティブの計数に基づく人工的な監視信号を用いた新しい表現学習法を紹介する。この監視信号は等変関係から得られるもので、手動での注釈を必要としない。我々は、画像の変換を表現の変換に関連付ける。より具体的には、与えられた表現にマッチする変換ではなく、このような関係を満たす表現を探します。本論文では、計数の文脈において、スケーリングとタイリングという2つの画像変換を使用します。1つ目の変換は、視覚的プリミティブの数がスケールに対して不変でなければならないという事実を利用しています。2つ目の変換は，各タイルの視覚的プリミティブの総数を，画像全体のそれと等しくすることを可能にします．この2つの変換を1つの制約にまとめ、コントラスト損失を用いたニューラルネットワークの学習に用いる。提案されたタスクは、伝達学習のベンチマークにおいて、最先端の技術と同等かそれ以上の性能を持つ表現を生成する。
グラフアテンションネットワーク（GAT）は、グラフ構造のデータを扱う新しいニューラルネットワークアーキテクチャであり、マスクされた自己注意層を活用することで、グラフ畳み込みやその近似に基づく先行手法の欠点を解決しています。ノードが近隣の特徴に注意を払うことができる層を積み重ねることで、（暗黙のうちに）近隣の異なるノードに異なる重みを指定することを可能にしています。このようにして、スペクトルベースのグラフニューラルネットワークのいくつかの重要な課題を同時に解決し、私たちのモデルを帰納的な問題だけでなく、帰納的な問題にも容易に適用できるようにしています。我々のGATモデルは、Cora、Citeseer、Pubmedの各引用ネットワークデータ、およびタンパク質-タンパク質相互作用データ（学習時にはテストグラフを見ない）という、4つの確立された帰納的・誘導的グラフベンチマークにおいて、最先端の結果を達成、またはそれに匹敵する結果を得ています。
ロボットの学習を多くのスキルや環境に適用するための重要な課題は、人間の監視を不要にすることです。これにより、ロボットは、人間からのフィードバックを求めるコストに制限されることなく、自らデータを収集し、自らのパフォーマンスを向上させることができます。モデルベースの強化学習は、エージェントが自分の行動の効果を予測することを学習することを可能にするという期待を持っています。これにより、人間による詳細な監視なしに、幅広いタスクや環境に対して柔軟な予測モデルを提供することができます。本研究では、行動を考慮したビデオ予測モデルとモデル予測制御を組み合わせる手法を開発した。この手法では、完全にラベル化されていない学習データを使用する。この手法では、キャリブレーションされたカメラや、計測されたトレーニングセットアップ、精密なセンシングやアクチュエーションは必要ありません。その結果，本手法により，実際のロボットが非伸縮性の操作（物体を押す操作）を行うことができ，訓練中に見られなかった新しい物体を扱うことができることがわかった．
このアルゴリズムは、勾配降下法で学習されたあらゆるモデルと互換性があり、分類、回帰、強化学習などの様々な学習問題に適用できるという意味で、モデルに依存しないメタ学習のアルゴリズムを提案する。メタ学習の目的は，様々な学習課題についてモデルを学習し，少数の学習サンプルだけで新しい学習課題を解決できるようにすることである．我々のアプローチでは、モデルのパラメータを明示的に学習し、新しいタスクの少量の学習データを用いて少ない数の勾配ステップを行うことで、そのタスクに対して良好な汎化性能を得ることができる。つまり、この手法では、モデルを簡単に微調整できるように訓練します。この手法は、2つの数ショット画像分類ベンチマークにおいて最先端の性能をもたらし、数ショット回帰においても良い結果をもたらし、ニューラルネットワークポリシーを用いたポリシー勾配強化学習の微調整を加速することを実証する。
ある人が経験していることをその人のフレームから理解することは、私たちの日常生活において必要不可欠です。そのため、このような能力を持つ機械があれば、人との対話がうまくいくと考えることができます。しかし、現在のところ、人の感情を詳細に理解できるシステムはありません。感情を認識するためのコンピュータビジョンに関するこれまでの研究では，主に顔の表情を分析することに焦点が当てられており，通常は6つの基本的な感情に分類されている[11]．しかし，感情認識においては，文脈が重要な役割を果たしており，文脈を取り入れることで，より多くの感情状態を推測することができる．本論文では，制御されていない環境で文脈の中にいる人物を含む画像のデータセットであるEmotions in Context Database (EMCO)を紹介する．これらの画像では，人物は26の感情カテゴリと，価 値，喚起，優位性という連続的な次元でアノテーションされて いる[21]．EMCOデータセットを用いて，畳み込みニューラルネットワークモデルを学習したところ，人物とシーン全体を共同で分析し，感情状態に関する豊富な情報を認識することができた．これにより，画像中の人物の感情を認識するためには，文脈を考慮することが重要であることを示し，視覚的文脈における感情認識タスクのベンチマークを提供している．
ネットワーク生物学は、病気、特にがんの複雑なメカニズムを明らかにするのに役立つと成功しています。一方で、ネットワーク生物学では、疾患に特化したネットワークを構築するための深い知識が必要ですが、近年のヒトのがん生物学の進歩をもってしても、現在の知識は非常に限られています。このような困難な状況に対処するために、深層学習は大きな可能性を示しています。しかし、深層学習技術は、従来、格子状に構造化されたデータを使用するため、ヒトの疾患サブタイプの分類への深層学習技術の適用はまだ検討されていない。最近では、グラフベースの深層学習技術が登場し、ネットワークバイオロジーにおける分析を活用する機会となっています。本論文では、2つの重要なコンポーネント1）グラフ畳み込みニューラルネットワーク（グラフCNN）と2）リレーションネットワーク（RN）を統合したハイブリッドモデルを提案しました。グラフCNNは、協調的な遺伝子コミュニティの発現パターンを学習するコンポーネントとして利用し、RNは学習したパターン間の関連性を学習するコンポーネントとして利用する。提案モデルを、臨床的に有用な標準的な乳がんのサブタイプ分類であるPAM50乳がんサブタイプ分類タスクに適用した。サブタイプ分類と患者の生存率分析の両方の実験において，提案した手法は既存の手法よりも有意に優れた性能を達成した．本研究は，来るべき個別化医療を実現するための重要な出発点になると確信している．
L2正則化とweight decay正則化は、標準的な確率的勾配降下法では（学習率でスケールを変えた場合）同等ですが、Adamのような適応的勾配アルゴリズムではそうではないことを示しています。これらのアルゴリズムの一般的な実装では、L2正則化を採用していますが（我々が明らかにした不等価性のために誤解を招く可能性があるため、しばしば「重み減衰」と呼ばれます）、我々は、重み減衰を損失関数に対して行われる最適化ステップから分離することにより、重み減衰正則化の元の定式化を回復するための簡単な修正を提案します。我々の提案する修正は、(i)標準的なSGDとAdamの両方において、重み減衰係数の最適な選択を学習率の設定から切り離すこと、(ii)Adamの汎化性能を大幅に向上させ、画像分類データセットにおいてSGDと勢いよく競合できるようにすること、を実証的に示している。私たちが提案した非結合型の重み減衰は、すでに多くの研究者に採用されており、コミュニティではTensorFlowとPyTorchに実装されています。私たちの実験の完全なソースコードは、以下のhttps URLから入手できます。
データセット増強は、ドメイン固有の変換を幅広く適用してトレーニングセットを合成的に拡張することであり、教師付き学習の標準的なツールである。しかし，視覚認識のようなタスクでは，変換セットは新しい領域ごとに慎重に設計，実装，テストしなければならず，再利用や汎用性に限界がある．本論文では、データセット増強のために、より単純でドメインにとらわれないアプローチを採用している。既存のデータポイントから始めて、それらの間にノイズを加えたり、補間したり、外挿したりするような単純な変換を適用する。私たちの主な洞察は、入力空間ではなく、学習した特徴空間で変換を行うことです。教師なし表現学習への関心が再燃していることから、この手法はタイムリーでより効果的なものとなっています。これは単純な提案ですが、これまで経験的にテストされていませんでした。我々は、sequence-to-sequenceモデルによって生成された文脈ベクトルの空間で作業を行い、静的データと逐次データの両方に効果的な手法を実証する。
言語モデリングを行列分解問題として定式化し、Softmaxベースのモデル（大多数のニューラル言語モデルを含む）の表現力がSoftmaxのボトルネックによって制限されることを示します。自然言語は文脈に大きく依存しているため、実際には分散した単語埋め込みを持つSoftmaxでは自然言語をモデル化するのに十分な能力がないことをさらに示唆しています。本研究では、この問題を解決するために、シンプルで効果的な手法を提案し、Penn TreebankとWikiText-2におけるパープレクシティをそれぞれ47.69と40.68に改善しました。また、提案手法は、大規模な1B Wordデータセットにおいても優れており、パープレキシティにおいてベースラインを5.6ポイント以上上回る結果を得た。
文章符号化のための木構造ニューラルネットワークアーキテクチャは、形式言語学で一般的に見られる意味構成のアプローチからヒントを得たものであり、これにより、同等のシーケンスモデルよりも経験的に優れた結果を示した。さらに、これらのモデルの構成関数に乗法的な相互作用項を加えることで、さらに大きな改善が得られる。しかし、このような強力な合成関数を採用した既存の合成アプローチでは、モデルの次元や語彙のサイズが大きくなるとパラメータ数が爆発的に増加してしまい、スケールが小さくなってしまう。本研究では、Lifted Matrix-Spaceモデルを紹介する。このモデルは、グローバルな変換を用いて、ベクトルの単語埋め込みを行列にマッピングし、行列と行列の乗算に基づいた演算によって合成することができる。この合成機能は、比較的少ないモデルパラメータで、より多くの活性化を層間で効果的に伝達することができる。本モデルをStanford NLIコーパス、Multi-Genre NLIコーパス、Stanford Sentiment Treebankで評価したところ、木構造モデルのための従来の最もよく知られた合成関数であるTreeLSTM (Tai et al., 2015)を一貫して上回ることがわかりました。
深層学習の研究論文が豊富にある中で、既存の作品の再現性や採用が課題となっています。これは、著者が提供するオープンソースの実装がないことが原因である。さらに、研究論文を別のライブラリに再実装することは、困難な作業です。これらの課題を解決するために、私たちはDLPaper2Codeという新しい拡張可能なアプローチを提案します。これは、研究論文で利用可能な深層学習の設計フロー図や表を抽出して理解し、抽象的な計算グラフに変換するものです。抽出された計算グラフは、KerasとCaffeの両方で、リアルタイムに実行可能なソースコードに変換されます。arXivのようなウェブサイトを作成し、5,000の研究論文に対して自動生成された設計を公開します。生成されたデザインは、直感的なドラッグ・アンド・ドロップのUIフレームワークを用いて、クラウドソース方式で評価・編集することができます。我々のアプローチを評価するために、手動で定義した文法を用いて、216,000以上の有効なデザインビジュアライゼーションを含むシミュレーションデータセットを作成した。模擬データセットを用いた実験では、提案フレームワークがフローダイアグラムのコンテンツ抽出において93%以上の精度を実現することが示された。
現在の文書要約モデルは、希望する長さ、スタイル、ユーザが興味を持ちそうなエンティティ、ユーザが既に読んだ文書の量などのユーザの好みを無視している。我々は、ユーザーがこれらの高レベルの属性を指定し、最終的な要約の形状をユーザーのニーズに合うように制御することを可能にする、シンプルで効果的なメカニズムを持つニューラル要約モデルを提案する。ユーザーの入力があれば、我々のシステムはユーザーの好みに沿った高品質の要約を作成することができる。ユーザーが入力しない場合は、自動的に制御変数を設定する。フルテキストのCNN-Dailymailデータセットでは、F1-ROUGE1 40.38対39.53と人間の評価の両方で、最新の抽象化システムを上回る結果を得ました。
9000以上のオブジェクトカテゴリを検出できる、最先端のリアルタイムオブジェクト検出システムであるYOLO9000を紹介します。YOLO9000は、9000以上の物体カテゴリを検出できる最先端のリアルタイム物体検出システムです。まず最初に、YOLOの検出方法に様々な改良を加えます。改良されたモデル「YOLOv2」は、PASCAL VOCやCOCOなどの標準的な検出タスクで最先端の性能を発揮します。67 FPSでは、YOLOv2はVOC 2007で76.8 mAPを達成しました。40 FPSでは、YOLOv2は78.6 mAPを達成し、Faster RCNN with ResNetやSSDなどの最先端の手法を上回り、しかも大幅に高速化されています。最後に、物体検出と分類を共同で学習する方法を提案します。この方法では、COCO検出データセットとImageNet分類データセットを用いて、YOLO9000を同時に学習します。この共同学習により、YOLO9000はラベル付けされた検出データを持たないオブジェクトクラスの検出を予測することができます。この手法をImageNetの検出タスクで検証しました。YOLO9000は、ImageNetの検出検証セットにおいて、200クラスのうち44クラスの検出データしかないにもかかわらず、19.7 mAPを獲得しました。COCOに含まれていない156のクラスでは、YOLO9000は16.0 mAPを獲得しました。しかし、YOLOは200クラスだけではなく、9000以上の異なるオブジェクトカテゴリの検出を予測します。しかも、リアルタイムで動作します。
畳み込みニューラルネットワーク（CNN）は、NLPタスクで広く使われています。この論文では、テキスト分類のためのCNNを改良するために、新しい重み初期化法を紹介しています。畳み込みフィルターをランダムに初期化するのではなく、意味的特徴を畳み込みフィルターにエンコードすることで、モデルが学習の初期段階で有用な特徴の学習に集中できるようにする。実験では、センチメント分析やトピック分類を含む7つのテキスト分類タスクにおいて、初期化技術の有効性を実証した。
人の頭部に設置された一人称視点のカメラは、カメラを装着した人にとってどの物体が重要であるかを撮影します。このタスクに対する先行研究の多くは、手動でラベル付けされた一人称データから、教師ありの方法で重要なオブジェクトを検出することを学習している。しかし、重要なオブジェクトは、カメラを装着している人の意図や注意などの内部状態と強く関連しているため、カメラを装着している人だけが重要性ラベルを提供することができます。このような制約は、アノテーション処理にコストがかかり、スケーラビリティにも限界がある。本研究では、カメラを装着している人や第三者のラベラーによる監視がなくても、一人称視点の画像から重要なオブジェクトを検出できることを示す。我々は、重要物体の検出問題を、1)セグメンテーションエージェントと2)認識エージェントの相互作用として定式化する。セグメンテーションエージェントは、まず各画像に対して重要物体のセグメンテーションマスクの可能性を提案し、それを認識エージェントに与える。認識エージェントは、視覚的セマンティクスと空間的特徴を用いて重要物体マスクの予測を学習する。このような両エージェント間の相互作用を、我々が提案する視覚空間ネットワーク（VSN）内の交互のクロスパスウェイ監視スキームによって実現しています。VSNは空間経路（「どこで」）と視覚経路（「何を」）で構成されており、一方の経路は共通の視覚的意味を学習し、もう一方の経路は空間的な位置の手がかりに焦点を当てています。一方の経路はその予測値をセグメンテーションエージェントに与え、セグメンテーションエージェントは重要なオブジェクトのセグメンテーションマスクの候補を提案し、もう一方の経路はそれを監視信号として使用する。2つの異なる重要物体データセットにおいて、本手法の成功を示す。本手法は、スーパーバイズ手法と同等以上の結果を得ることができる。
知識グラフのリンク予測は、エンティティ間の欠落した関係を予測するタスクである。リンク予測に関するこれまでの研究は、大規模な知識グラフに対応できる浅くて高速なモデルに焦点を当てていた。しかし、これらのモデルは、深い多層モデルに比べて表現力の低い特徴を学習するため、性能が制限される可能性がある。本研究では、リンク予測のための多層畳み込みネットワークモデルであるConvEを紹介し、いくつかの確立されたデータセットにおける最先端の結果を報告する。また，このモデルはパラメータ効率が高く，DistMultやR-GCNと同等の性能を8倍，17倍の少ないパラメータで実現できることを示した．このモデルは、FreebaseやYAGO3のような、高度に連結された複雑な知識グラフによく見られる、高いindegreeを持つノードをモデル化するのに特に有効であることが示唆されている。また、WN18およびFB15kデータセットでは、トレーニングセットからの逆関係がテストセットに存在することにより、テストセットのリークに悩まされていることが指摘されていますが、この問題の程度はこれまで定量化されていませんでした。単純なルールベースのモデルであれば、WN18とFB15kの両方で最先端の結果を得ることができますが、この問題は深刻であると考えています。逆相関を利用するだけでは競争力のある結果が得られないデータセットでモデルを評価するために、一般的に使用されているいくつかのデータセットを調査・検証し、必要に応じてロバストなバリエーションを導き出す。その結果、ConvEはほとんどのデータセットで最先端の平均逆数ランクを達成することができました。
エンジン、車両、航空機などの機械装置には、通常、機械の動作や状態を把握するために多数のセンサーが取り付けられています。しかし、センサーでは捕捉できない外部要因や変数が存在することが多く、本質的に予測不可能な時系列データになってしまいます。例えば、手動による制御や、監視されていない環境条件や負荷によって、本質的に予測できない時系列が発生することがあります。このような場合、定常性に依存した数理モデルや、予測誤差を利用した予測モデルに基づく標準的なアプローチでは、異常を検知することが困難になります。本研究では、時系列の「正常な」振る舞いを再構成することを学習し、その再構成誤差を利用して異常を検知する、長短期記憶ネットワークに基づく異常検知用エンコーダ・デコーダ方式（EncDec-AD）を提案する。本研究では、電力需要、スペースシャトル、心電図という、一般に公開されている3つの準予測可能な時系列データと、予測可能な挙動と予測不可能な挙動の両方を持つ2つの実世界のエンジンデータを用いて実験を行った。EncDec-ADはロバストであり、予測可能な時系列、予測不可能な時系列、周期的な時系列、非周期的な時系列、準周期的な時系列から異常を検出できることを示しています。さらに、EncDec-ADは、短い時系列（長さ30）と長い時系列（長さ500）の両方から異常を検出できることを示しています。
ノイズ抑制は信号処理の中でも成熟した分野であるにもかかわらず、推定器のアルゴリズムやパラメータの微調整に大きく依存している。本論文では、DSPと深層学習のハイブリッドによるノイズ抑制手法を紹介します。4つの隠れ層を持つディープニューラルネットワークを用いて、理想的な臨界帯域のゲインを推定し、伝統的なピッチフィルターでピッチハーモニクス間のノイズを減衰させています。このアプローチは、従来の最小平均二乗誤差スペクトル推定器よりも大幅に高い品質を達成する一方で、低消費電力のプロセッサで48kHzのリアルタイム動作が可能なほど複雑さを抑えています。
Saliency法は、ディープニューラルネットワークの予測を説明することを目的としています。これらの手法は、説明がモデルの予測に寄与しない要因に敏感な場合、信頼性に欠けます。本研究では、入力データに一定のシフトを加えるという単純で一般的な前処理ステップを用いて、モデルに影響を与えない変換が多数の手法の誤った属性を引き起こすことを示す。信頼性を保証するためには、入力不変性を満たす必要がある。これは、入力の変換に対するモデルの感度を顕著に反映させることを意味する。我々は、いくつかの例を挙げて、入力不変性を満たさない saliency 法は、誤解を招くような帰属をもたらすことを示す。
自然言語処理（NLP）モデルでは、単語埋め込みのために膨大な数のパラメータを必要とすることが多く、その結果、ストレージやメモリの使用量が大きくなります。ニューラルNLPモデルをモバイル機器に展開するためには，性能を大きく犠牲にすることなく単語埋め込みを圧縮する必要がある．この目的のために、我々は少数の基底ベクトルで埋め込みを構成することを提案する。各単語に対して、基底ベクトルの構成は、ハッシュコードによって決定される。また，圧縮率を最大化するために，二値化方式ではなく，マルチコードブック量子化方式を採用している．各コードは、(3, 2, 1, 8)のような複数の離散的な数値で構成され、各成分の値は一定の範囲に制限されています。我々は、エンド・ツー・エンドのニューラルネットワークにおいて、ガンベル・ソフトマックス・トリックを適用することで、離散的なコードを直接学習することを提案する。実験によると，性能を落とすことなく，感情分析タスクで98%の圧縮率を達成し，機械翻訳タスクでは94%～99%の圧縮率を達成した．いずれのタスクにおいても，提案手法は圧縮率をわずかに下げることでモデルの性能を向上させることができる．文字レベルのセグメンテーションなどの他のアプローチと比較して、提案手法は言語に依存せず、ネットワークアーキテクチャを変更する必要もありません。
ニューラルネットワーク用の敵対例を生成する標準的な手法は、視点移動、カメラノイズ、その他の自然な変換の組み合わせにより、物理的な世界ではニューラルネットワーク分類器を一貫して騙すことができず、実世界のシステムとの関連性が制限されている。本研究では、ロバストな3次元の敵対的オブジェクトの存在を実証し、選択された変換の分布にわたって敵対的である例を合成するための最初のアルゴリズムを提示します。また、ノイズ、歪み、アフィン変換に強い2次元の敵対的画像を合成する。さらに、このアルゴリズムを複雑な三次元物体に適用し、3Dプリントを用いて初めて物理的な敵対的物体を製造した。その結果、物理的な世界に3Dの敵対的オブジェクトが存在することを実証した。
ニューラル機械翻訳の既存のアプローチでは、各出力語は以前に生成された出力に基づいて条件付けられています。本研究では、この自己回帰的な特性を回避し、出力を並列に生成することで、推論時のレイテンシーを一桁下げることができるモデルを導入しました。知識の抽出、潜在変数としての入力トークンの多さの使用、およびポリシー勾配の微調整により、教師として使用される自己回帰的なTransformerネットワークと比較して、わずか2.0BLEUポイントのコストでこれを達成しました。本研究では、学習戦略の3つの側面に関連した実質的な累積的改善を実証し、IWSLT 2016の英語-ドイツ語および2つのWMT言語ペアで本アプローチを検証した。推論時にフェルタリティを並列にサンプリングすることで、我々の非自動回帰モデルは、WMT 2016英語-ルーマニア語において29.8BLEUという最先端に近い性能を達成した。
本論文では、バスケットボール選手の一人称映像から、選手全体の未来の動き（位置と視線方向）を予測する手法を紹介しています。予測された行動は、共同注意に関与することで社会的行動に適合しつつ、次の行動を取ることを可能にする個人の物理的空間を反映している。我々の重要な革新は、複数の一人称カメラの3D再構成を利用して、社会的構成の互いの視覚的セマンティクスを自動的に注釈することです。私たちは、一人称視点の動画に埋め込まれたユニークな2つの学習信号を利用しています。個々の一人称映像は、人の周りの空間的・社会的レイアウトの視覚的セマンティクスを記録しており、過去の類似した状況と関連付けることができます。集合的には、一人称ビデオは個人をグループに結びつけることができる共同注意を追跡する。シャムニューラルネットワークを用いて、グループの動きの自己中心的な視覚的セマンティクスを学習し、未来の軌道を検索する。このとき、社会的適合性の指標である、社会的形成によって予測される共同注意への視線の配置を最大化することで、全プレイヤーから取得した軌跡を統合します。これにより、どちらの社会的構成がより確からしいかを特徴づけ、将来のグループの軌跡を予測することができる。
監督なしで有用な表現を学習することは、機械学習における重要な課題である。本論文では、このような離散的な表現を学習する、シンプルかつ強力な生成モデルを提案する。我々のモデル、VQ-VAE（Vector Quantised-Variational AutoEncoder）は、2つの重要な点でVAEとは異なる。すなわち、エンコーダネットワークは、連続的ではなく離散的なコードを出力する。離散的な潜在表現を学習するために，ベクトル量子化（VQ）の考え方を取り入れている．VQ法を用いることで、VAEフレームワークで一般的に見られる、強力な自己回帰デコーダとペアになったときに潜在表現が無視されてしまう「事後崩壊」の問題を回避することができる。これらの表現を自己回帰的な事前処理と組み合わせることで、このモデルは高品質の画像、動画、音声を生成することができ、さらに高品質の話者変換や音素の教師なし学習も行うことができ、学習した表現の有用性がさらに実証されました。
1億3,100万USドルはいくらですか？1億3100万ドルは、テキサス州の全員をランチタイムに雇用するためのコストである」というように、数字の意味を理解しやすくするために、パースペクティブと呼ばれる短い説明文を自動生成する新しいタスクを提案します。まず、ニュース記事中の数字に関する言及のデータセットを収集し、各言及には評価された視点のセットが付けられている。次に、これらの記述を生成するシステムを提案する。これは、式の構築と記述の生成という2つのステップからなる。式の構築では、知識ベースの数値的な事実から式を構成し、得られた式を親しみやすさ、数値的な近さ、意味的な互換性に基づいてランク付けする。説明文の生成では，sequence-to-sequence recurrent neural network を用いて，数式を自然言語に変換します．我々のシステムは、数式構築において、非合成ベースラインと比較して15.2%のF1向上を達成し、ベースラインの記述生成と比較して12.5BLEUポイントの向上を達成した。
カプセルとは，物体や物体の一部など，特定の種類の実体のインスタンス化パラメータをアクティビティ・ベクトルで表現するニューロンのグループである．活動ベクトルの長さは、そのエンティティが存在する確率を表し、その向きはインスタンス化パラメータを表します。あるレベルのアクティブなカプセルは、上位のカプセルのインスタンス化パラメータを、変換マトリクスを介して予測する。複数の予測が一致した場合，より高いレベルのカプセルがアクティブになる．我々は、識別的に学習された多層カプセルシステムが、MNISTにおいて最先端の性能を達成し、重複度の高い数字の認識においては、畳み込みネットよりもかなり優れていることを示す。これらの結果を得るために、我々は反復的なRouting-by-agreementメカニズムを使用する。下位レベルのカプセルは、アクティビティ・ベクトルが下位レベルのカプセルから来る予測と大きなスカラー積を持つ上位レベルのカプセルに、その出力を送ることを好む。
転移学習は、ソースドメインでの貴重な知識を利用して、ターゲットドメインでのパフォーマンスをモデル化することを目的としています。特に、オーバーフィッティングの可能性が高いニューラルネットワークでは、重要な意味を持ちます。画像処理などの分野では、ニューラルネットワークを用いた転移学習の有効性が多くの研究で示されています。しかし、ニューラルNLPについては、既存の研究では転移学習を何気なく適用しているだけで、結論は一貫していません。本論文では、体系的なケーススタディを行い、ニューラルネットワークのNLPへの転移性について明らかにします。
本論文では、深層リカレント生成デコーダ（DRGN）を備えた配列-配列指向のエンコーダ-デコーダモデルに基づいた、抽象的なテキスト要約のための新しいフレームワークを提案する。本研究では、要約の品質を向上させるために、対象となる要約に含まれる潜在的な構造情報をリカレント潜在的ランダムモデルに基づいて学習する。また，再帰潜在変数の事後推論が困難であるため，ニューラル変分推論を採用した．また，生成的な潜在変数と識別的な決定論的状態の両方に基づいて，抽象的な要約を生成する．さまざまな言語のベンチマークデータを用いた大規模な実験により、DRGNが最先端の手法よりも優れていることが示されました。
ほとんどの人はセマンティックウェブのデータを直接扱うことはありません。基本的な技術を理解するための専門知識を持っていない限り、データを理解するためのテキストやビジュアルのインターフェースが必要です。私たちは、セマンティックウェブデータのための自然言語要約を生成するという問題を探究しています。これは、特にオープンドメインの状況では、自明のことではありません。この問題を解決するために、ニューラルネットワークの利用を検討しています。我々のシステムは、一連のトリプルからの情報を固定次元のベクトルにエンコードし、エンコードされたベクトルに出力を合わせることで、テキスト要約を生成する。本研究では、WikipediaのスニペットとDBpediaおよびWikidataのトリプルを組み合わせた2つのコーパスを用いてモデルを学習・評価し、有望な結果を得た。
モデルフリーの深層強化学習とオンラインプランニングを組み合わせることは、深層RLの成功例を基にした有望なアプローチである。先行ツリーを用いたオンラインプランニングは、遷移モデルが事前に分かっている環境では成功している。しかし、データから遷移モデルを学習する必要がある複雑な環境では、学習したモデルの欠陥により、計画のための実用性が制限されている。これらの課題を解決するために、我々はTreeQNを提案する。TreeQNは微分可能な再帰的な木構造モデルであり、離散的なアクションを持つ深層RLにおける価値関数ネットワークの代替として機能する。TreeQNは、学習した抽象的な状態空間に遷移モデルを再帰的に適用して木を動的に構築し、木のバックアップを用いて予測された報酬と状態値を集約してQ値を推定する。また、TreeQNにソフトマックス層を追加して確率的ポリシーネットワークを形成する、アクター批判型のATreeCも提案している。どちらのアプローチもエンド・ツー・エンドで学習され、学習されたモデルが実際にツリーで使用される際に最適化されるようになっています。我々は、TreeQNとATreeCが箱押しタスクでn-step DQNとA2Cを、また複数のAtariゲームでn-step DQNと価値予測ネットワーク（Oh et al. さらに、異なる補助的な損失が学習遷移モデルに与える影響を示すアブレーション研究を紹介します。
深層学習法は通常、その能力を最大限に発揮するために膨大な量の学習データを必要とし、しばしば高価な手動ラベリングを必要とします。したがって、合成画像を使用することは、ラベリングが無料で得られるため、物体検出器を訓練する上で非常に魅力的であり、合成画像と実画像を組み合わせて訓練するためのいくつかのアプローチが提案されている。
本論文では，ある簡単な方法を用いるだけで，最新の物体検出器を合成画像のみで効率的に学習できることを示す．特徴抽出を行う層を実画像で事前に学習した一般的な層に固定し、残りの層のみをOpenGLレンダリングで学習するのです。オブジェクト認識用の最新のディープアーキテクチャ（Faster-RCNN、R-FCN、Mask-RCNN）および画像特徴抽出用のディープアーキテクチャ（InceptionResnet、Resnet）を用いた実験では、このシンプルなアプローチが驚くほどの性能を発揮することが示された。
リカレントニューラルネットワーク（RNN）は、さまざまな自然言語処理（NLP）タスクへの適用に成功し、従来の手法よりも優れた結果を得ている。しかし、RNNの有効性の背後にあるメカニズムが理解されていないため、RNNのアーキテクチャのさらなる改善が制限されています。本論文では、NLPタスクのためのRNNモデルを理解し、比較するためのビジュアル分析手法を紹介します。我々は、入力テキストに対する予想される応答に基づいて、個々の隠れた状態のユニットの機能を説明する手法を提案する。そして、期待される反応に基づいて、隠れた状態のユニットと単語を共クラスタ化し、共クラスタ化の結果をメモリチップやワードクラウドとして視覚化することで、RNNの隠れた状態に関するより構造的な知識を提供する。また、文レベルでのRNNの隠れた状態の振る舞いを分析するために、集約情報に基づいたグリフベースのシーケンスの可視化を提案する。我々の手法の有用性と有効性を、ケーススタディとドメインエキスパートからのレビューによって実証する。
大規模な深層ニューラルネットワークは強力ですが、記憶や敵対的な例に対する感度など、望ましくない挙動を示します。本研究では、これらの問題を軽減するためのシンプルな学習原理であるmixupを提案する。mixupは、例とそのラベルのペアの凸型の組み合わせでニューラルネットワークを学習する。そうすることで，mixupはニューラルネットワークを正則化し，学習例の間で単純な線形動作を好むようにする．ImageNet-2012，CIFAR-10，CIFAR-100，Google commands，UCIの各データセットを用いた実験の結果，mixupは最先端のニューラルネットワークアーキテクチャの一般化を向上させることがわかった．また、Mixupは、不正なラベルの記憶を減らし、敵対的な例に対するロバスト性を高め、生成的な敵対的ネットワークの学習を安定させることがわかった。
本論文では、生成的逆問題ネットワークの新しい学習方法について述べる。その鍵となるアイデアは、生成器と識別器の両方を段階的に成長させることである。低解像度から始めて、学習が進むにつれて、より細かい詳細をモデル化する新しい層を追加する。これにより、学習の高速化と安定化が図られ、1024²のCelebA画像など、これまでにない品質の画像を生成することができます。また、生成された画像のバリエーションを増やす簡単な方法を提案し、教師なしのCIFAR10で8.80という記録的なインセプションスコアを達成しました。さらに、生成器と識別器の間の不健全な競争を抑制するために重要な、いくつかの実装の詳細について説明します。最後に、GANの結果を画質とバリエーションの両面から評価するための新しい指標を提案します。さらに、CelebAデータセットのより高品質なバージョンを構築する。
DeConvNet、Guided BackProp、LRPは、ディープニューラルネットワークの理解を深めるために考案されました。これらの手法は、線形モデルに対して、理論的に正しい説明をしないことを示しています。しかし、これらの手法は何百万ものパラメータを持つ多層ネットワークで使用されています。線形モデルは単純なニューラルネットワークであるため、これは懸念すべきことである。我々は、ニューラルネットの説明法は、単純さの限界である線形モデルで確実に機能すべきであると主張する。線形モデルの分析に基づいて、線形モデルでは理論的に健全であり、深層ネットワークでは改善された説明をもたらす2つの説明技法（PatternNetとPatternAttribution）を生み出す一般化を提案する。
概念空間とは、概念的な知識を幾何学的に表現したもので、実体は点に、自然な性質は凸領域に、空間の次元は顕著な特徴に対応しています。概念空間は、様々な認知現象をエレガントにモデル化することができる一方で、このような表現を自動的に構築する方法がないため、これまで人工知能への応用は限られていました。この問題を解決するために、我々は、ウィキペディアからエンティティのベクトル空間埋め込みを学習し、同じ意味的タイプのエンティティがある低次元部分空間に位置するように、この埋め込みを制約する方法を提案する。この方法では、重要な特徴が方向としてモデル化できることや、自然な性質が凸領域に対応する傾向があることなどを示すことで、これらの部分空間が（近似的な）概念空間表現として有用であることを実験的に示している。
最近の研究では、入力ベクトルに比較的小さな摂動を加えることで、ディープニューラルネットワーク（DNN）の出力を容易に変化させることができることが明らかになっている。本論文では、1つのピクセルしか変更できないという極めて限定されたシナリオでの攻撃を分析する。そのために、微分進化（DE）に基づいて、1ピクセルの敵対的摂動を生成する新しい方法を提案します。この方法は、より少ない敵対的情報（ブラックボックス攻撃）を必要とし、DEの本質的な特徴により、より多くの種類のネットワークを騙すことができます。その結果，Kaggle CIFAR-10テストデータセットに含まれる自然画像の67.97%とImageNet (ILSVRC 2012)テスト画像の16.04%が，平均で74.03%と22.91%の信頼度で，たった1つのピクセルを修正するだけで，少なくとも1つのターゲットクラスに摂動できることがわかりました．また，オリジナルのCIFAR-10データセットでも同様の脆弱性を示した．このように、提案された攻撃は、極端に限定されたシナリオにおいて、敵対的機械学習の異なる方法を模索し、現在のDNNがこのような低次元の攻撃に対しても脆弱であることを示しています。さらに、敵対的機械学習の分野におけるDE（または広義には進化的計算）の重要な応用例として、ロバスト性を評価するためにニューラルネットワークに対する低コストの敵対的攻撃を効果的に生成できるツールの作成についても説明しています。
機械学習されたモデルは、しばしば「ブラックボックス」と表現されます。しかし、多くの実世界のアプリケーションでは、人間が解釈しやすいように、モデルの予測能力を犠牲にしなければならない場合があります。このような場合、特徴量エンジニアリングは重要なタスクとなり、人間の多大な努力と時間を必要とします。特徴の中には、本質的に静的で、影響を受けない特性を表すもの（例：個人の年齢）もあれば、調整可能な特性を表すもの（例：1日に摂取する炭水化物の量）もあります。しかし、一度データからモデルを学習すると、新しいインスタンスに対するモデルの予測は不可逆であり、すべてのインスタンスが選択した特徴空間に位置する静的な点であると仮定します。しかし、(i)なぜモデルがあるインスタンスに対してある予測を出力するのか、(ii)そのインスタンスのどの調整可能な特徴を修正すべきか、そして最後に(iii)修正されたインスタンスがモデルに入力されたときにその予測をどのように変更するのかを理解することが重要となる状況が多くあります。本論文では、ツリーベースのアンサンブル分類器の内部を利用して、真のネガティブなインスタンスをポジティブな予測に変換するための推奨事項を提示する手法を紹介します。この手法の有効性を、オンライン広告アプリケーションを用いて実証します。まず、ランダムフォレスト分類器を用いて、広告の品質が低いもの（ネガティブ）と高いもの（ポジティブ）の2種類の広告（インスタンス）を効果的に分離します。次に、低品質の広告（ネガティブ・インスタンス）を高品質の広告（ポジティブ・インスタンス）に変換することを目的としたレコメンデーションを提供するアルゴリズムを紹介します。最後に、大規模なアドネットワークであるYahoo Geminiのアクティブなインベントリのサブセットを用いて、我々のアプローチを評価する。
Generative Adversarial Network (GAN)は、広範囲に渡って注釈されたトレーニングデータがなくても、深い表現を学習する方法を提供します。GANは、2つのネットワークが競合してバックプロパゲーション信号を生成することで、学習を実現します。GANによって学習される表現は、画像合成、セマンティック画像編集、スタイル変換、画像の超解像、分類など、さまざまな用途に利用できる。このレビュー論文の目的は、信号処理コミュニティにGANの概要を提供することであり、可能な限り身近な類推や概念を利用している。また、GANを学習・構築するためのさまざまな手法を明らかにするとともに、その理論と応用に残された課題についても指摘しています。
視覚における深層学習の成功は、次のような理由によるものです。視覚分野における深層学習の成功は、(a)高い能力を持つモデル、(b)計算能力の向上、(c)大規模なラベル付きデータの利用可能性、に起因する。2012年以降、モデルの表現能力やGPUの計算能力は大きく進歩している。しかし、最大のデータセットのサイズは、意外にも一定しています。データセットのサイズを10倍、100倍にしたらどうなるのか？本論文は、「巨大なデータ」と「視覚的深層学習」の関係にまつわる謎の雲を取り除くための一歩となる。3億枚の画像に対して3億7500万以上のノイズのあるラベルを持つJFT-300Mデータセットを利用して、このデータを表現学習に使用した場合、現在の視覚タスクのパフォーマンスがどのように変化するかを調査します。本論文では、いくつかの驚くべき（そしていくつかの予想される）結果が得られた。第一に、視覚タスクの性能は、学習データの量に応じて対数的に増加することがわかった。第二に、表現学習（または事前学習）はまだ多くの可能性を秘めていることを示している。より良いベースモデルを学習するだけで、多くの視覚タスクのパフォーマンスを向上させることができる。最後に、予想通り、画像分類、物体検出、セマンティックセグメンテーション、人間の姿勢推定など、さまざまなビジョンタスクにおける最新の結果を紹介します。私たちの願いは、この結果がビジョン・コミュニティに刺激を与え、データを過小評価せず、より大きなデータセットを構築するための共同作業を発展させることです。
人工知能の長年の目標は、困難な領域において超人的な熟練度をタブラ・ラサで学習するアルゴリズムです。最近では、AlphaGoが囲碁の世界チャンピオンを破った初めてのプログラムとなりました。AlphaGoの木探索は、深層ニューラルネットワークを用いて局面の評価と手の選択を行います。これらのニューラルネットワークは、人間の熟練した手からの教師付き学習と、自分自身のプレイからの強化学習によって学習されました。ここでは、強化学習のみに基づいたアルゴリズムを紹介します。人間のデータやガイダンス、ゲームルール以外の領域の知識は必要ありません。AlphaGoは自分自身の先生になります。ニューラルネットワークが学習され、AlphaGo自身の手の選択やAlphaGoのゲームの勝敗を予測します。このニューラルネットワークは、木探索の強度を向上させ、その結果、より質の高い手の選択が可能となり、次の反復ではより強力なセルフプレイが可能となります。タブラ・ラサからスタートした私たちの新しいプログラム「AlphaGo Zero」は、過去に発表されたチャンピオンに敗れたAlphaGoに対して100-0で勝利し、超人的なパフォーマンスを達成しました。
自然言語を意味的フレームに解析するフレームワークであるSLINGについて説明します。SLINGは、双方向のLSTM入力エンコーディングと、出力デコーディングのためのTransition Based Recurrent Unit (TBRU)を備えた、一般的な遷移ベースのニューラルネットワーク解析をサポートしています。解析モデルは、テキストのトークンのみを入力として、エンドツーエンドで学習されます。遷移システムは、記号的な表現を介さずにフレームグラフを直接出力するように設計されています。SLINGフレームワークには、効率的でスケーラブルなフレームストアの実装と、解析中の高速な推論のためのニューラルネットワークJITコンパイラが含まれています。SLINGはC++で実装されており、GitHubからダウンロードすることができます。
意味レベルでの文の表現は、自然言語処理や人工知能にとって困難な課題です。単語の埋め込み（すなわち、単語のベクトル表現）が進歩したにもかかわらず、単語間の意味的な相互作用が複雑であるため、文の意味を捉えることは未解決の問題である。本論文では、ラベルのないテキストから教師なしの文表現を学習することを目的とした埋め込み手法を提案する。本論文では、教師なしで文をモデル化する手法を提案する。この手法では、文を、重み付けされた一連の単語埋め込みとしてモデル化する。単語埋め込みの重みは、Term Frequency--Inverse Document Frequency (TF--IDF)変換によって得られるShannonの単語エントロピーを用いてフィッティングされる。モデルのハイパーパラメータは、データの特性（例：文の長さやテキストの性別）に応じて選択することができます。ハイパーパラメータの選択には、単語の埋め込み方法と次元数、および重み付けのスキームが含まれます。我々の手法は、既存の手法と比較して、識別可能なモジュール、短期間のトレーニング、（見たことのない）文表現のオンライン推論、ドメイン、外部知識、言語リソースからの独立性などの利点がある。その結果、我々のモデルは、よく知られている意味的文章類似度（STS）ベンチマークにおいて、最新の技術を上回る性能を示した。さらに、我々のモデルは、教師付きシステムや知識ベースのSTSシステムと比較して、最先端の性能を達成しました。
単語の言語横断的な表現は、多言語の文脈で単語の意味を推論することを可能にし、低リソース言語のための自然言語処理モデルを開発する際に、言語横断的な伝達を促進する鍵となります。この調査では、多言語の単語埋め込みモデルの包括的な類型化を行います。また、それぞれのデータ要件と目的関数を比較する。この調査の繰り返しのテーマは、文献に掲載されているモデルの多くは、同じ目的に対して最適化されており、一見異なるモデルでも、最適化戦略やハイパーパラメータなどを調整することで、同等になることが多いということです。また、多言語の単語埋め込みの評価方法の違いや、今後の課題や研究の方向性についても議論します。
深層ネットワークにおける活性化関数の選択は、学習ダイナミクスとタスクパフォーマンスに大きな影響を与えます。現在、最も成功し、広く使用されている活性化関数はRectified Linear Unit (ReLU)です。ReLUの代替となるものは様々なものが提案されているが、利得が安定していないため、ReLUに取って代わるものはない。そこで本研究では、自動探索技術を用いて新しい活性化関数を発見することを提案する。網羅的探索と強化学習ベースの探索を組み合わせて、複数の新しい活性化関数を発見する。そして、発見された最適な活性化関数を用いて経験的な評価を行うことで、探索の有効性を検証する。実験の結果、最もよく発見された活性化関数である$f(x) = x ˶ˆ꒳ˆ˵ (˶ˆ꒳ˆ˵) $ (Swishと名付けた)は、多くの困難なデータセットにおいて、より深いモデルでReLUよりもよく機能する傾向があることがわかった。例えば、ReLUをSwishユニットに置き換えるだけで、ImageNetのトップ1分類精度が、Mobile NASNet-Aでは0.9％、Inception-ResNet-v2では0.6％向上します。SwishのシンプルさとReLUとの類似性により、実践者はどのようなニューラルネットワークでもReLUをSwishユニットに置き換えることが容易になります。
近年のディープニューラルネットワーク（DNN）の進歩により、カメラやLiDARなどのセンサーを利用して、人間の手を借りずに走行できるDNN駆動の自律走行車が開発されています。テスラ、GM、フォード、BMW、Waymo/Googleなど、ほとんどの主要メーカーがさまざまなタイプの自律走行車の製造とテストに取り組んでいます。また、カリフォルニア州、テキサス州、ニューヨーク州など、米国のいくつかの州の議員は、自律走行車のテストと道路への配備のプロセスを迅速に進めるための新しい法律を可決しました。しかし、DNNはその目覚ましい進歩にもかかわらず、従来のソフトウェアと同様に、致命的な衝突につながる可能性のある誤った動作や予期しないコーナーケースの動作を示すことがよくあります。このような自律走行車の事故は、死亡事故を含めて既にいくつか発生している。既存のDNN駆動車両のテスト技術の多くは、様々な走行条件でのテストデータを手動で収集することに大きく依存しており、テスト条件の数が増えれば増えるほど、膨大なコストがかかってしまいます。本論文では、死亡事故につながる可能性のあるDNN駆動車両の誤った動作を自動的に検出するための体系的なテストツールDeepTestを設計、実装、評価した。まず、本ツールは、雨、霧、照明条件などの実世界の走行条件の変化を活用して、テストケースを自動的に生成するように設計されています。DeepTestは、活性化されたニューロンの数を最大化するテスト入力を生成することで、DNNロジックのさまざまな部分を体系的に探索します。DeepTestは、Udacityの自動運転車チャレンジでトップの成績を収めた3つのDNNにおいて、致命的な事故につながる可能性のある、さまざまな現実的な運転条件（ぼやけ、雨、霧など）下での数千の誤った動作を発見しました。
リカレント・ニューラル・ネットワーク（RNN）を使って長いシーケンスを学習することは、非常に難しい課題です。3つの大きな課題があります。1) 複雑な依存関係、2) 消えたり爆発したりする勾配、3) 効率的な並列化。本論文では、これらの課題すべてに同時に取り組む、シンプルかつ効果的なRNN接続構造「DilatedRNN」を紹介する。提案したアーキテクチャは、多解像度のDilated Recurrent skip接続を特徴とし、多様なRNNセルと柔軟に組み合わせることができる。さらに，DilatedRNNは，必要なパラメータの数を減らし，学習効率を大幅に向上させるとともに，非常に長期的な依存関係を含むタスクにおいて，（標準的なRNNセルを用いた場合でも）最先端の性能を発揮することができます。このアーキテクチャの利点を理論的に定量化するために，平均再帰長という記憶容量の測定法を導入しました．そして、DilatedRNNが他のリカレント・ニューラル・アーキテクチャよりも優れていることを厳密に証明する。本手法のコードは、以下のURLで公開されています。
オプションとは、状態空間の特定の領域に対する制御方針と、その領域からの離脱を認識する終了条件からなる短期的なスキルのことです。先行研究では、アタリゲームの強化学習を高速化するために、オプションを発見するDeep Discovery of Options (DDO)というアルゴリズムを提案しました。本論文では、ロボットの模倣学習を拡張して、深層ニューラルネットワークでパラメータ化された低レベルの連続制御スキルを実演から学習するDiscovery of Deep Continuous Options (DDCO)を研究しています。我々はDDOを次のように拡張する。(1)連続的な制御動作だけでなく離散的なオプションを呼び出すことができる高レベルのポリシーをパラメトリックに表現するための、カテゴリーと連続のハイブリッド分布モデル、および(2)DDOの要件である、発見されるオプションの数をユーザが指定することを緩和するクロスバリデーション法。DDCOの評価は，3リンクロボットが垂直面内で摩擦と重力を利用してブロックを押すシミュレーションと，da Vinci手術ロボットを用いた2つの物理実験，すなわち針を把持してシリコン組織ファントムに挿入する針挿入実験と，針やピンを山から把持してビンに分類する針ビンピッキング実験で行った．3リンクアームのシミュレーションでは、DDCOはベースラインの模倣学習アプローチと比較して、同じ報酬を得るために必要なデモンストレーションの回数を3倍に減らすことができるという結果が得られた。針を刺すタスクでは、模倣学習が6/10だったのに対し、DDCOは8/10で成功しました。また、手術用の箱を取るタスクでは、99回の把持試行のうち66回の把持に成功し、1回を除くすべてのケースで、失敗した把持から2回目の試行で回復することができた。
文章の抽象的な要約のためのsequence-to-sequenceフレームワークを拡張するために、選択的符号化モデルを提案する。このモデルは、文エンコーダ、選択的ゲートネットワーク、注意力を備えたデコーダから構成される。文章エンコーダーとデコーダーはリカレントニューラルネットワークで構成されている。選択ゲートネットワークは、エンコーダからデコーダへの情報の流れを制御することで、第2レベルの文表現を構築する。この第2レベルの表現は、文の要約タスクに合わせて調整されており、より良い性能が得られる。我々のモデルを、英語のGigaword、DUC 2004、MSR抽象文要約データセットを用いて評価した。実験結果は、提案した選択的符号化モデルが、最先端のベースラインモデルよりも優れていることを示している。
マルチクラス分類では，クラスの基礎となる構造情報を無視するのが常套手段である．本論文では，ラベルの基礎となる既知のグラフ構造を利用するグラフ畳み込みネットワーク（GCN）拡張ニューラルネットワーク分類器を提案する．提案手法は，例えば条件付き乱数場(CRF)における(近似的な)推論手順に似ている．提案手法を文書分類と物体認識で評価し，精度とモデルの予測の一貫性に対応するグラフ理論的な指標を報告する．実験の結果，提案モデルは，ラベル空間のグラフ構造を無視したベースライン手法を，グラフ理論的な指標の観点から凌駕することが明らかになった．
オンラインの学術データが大量に増加していることは、知識発見を強化するための課題と機会の両方を提示している。そのような課題の1つは、文書の内容を正確に記述し、高速な情報処理を促進することができる小さなキーフレーズのセットを、文書から自動的に抽出することである。本論文では、PositionRankを提案する。PositionRankは、学術的な文書からキーフレーズを抽出するための教師なしモデルであり、単語の出現位置すべてからの情報を、偏ったPageRankに組み込む。我々のモデルは、単語の位置を考慮していないPageRankモデルや、このタスクの強力なベースラインと比較して、顕著な性能向上を実現している。具体的には、研究論文のいくつかのデータセットにおいて、PositionRankは29.09%もの改善を達成しています。
テキスト要約は、ユーザーが必要とする情報をコンパクトな形で提示するという問題を解決します。適切な形式の要約を作成するには、さまざまなアプローチがある。最新の手法の一つとして、Latent Semantic Analysis（LSA）がある。本論文では、LSAに基づく様々な要約アルゴリズムを説明し、そのうちの2つは本論文の著者が提案したものである。これらのアルゴリズムをトルコ語と英語の文書で評価し、その性能をROUGEスコアを用いて比較した。我々のアルゴリズムの1つが最高のスコアを出し、トルコ語と英語の文書セットでは2つのアルゴリズムが同等の性能を発揮する。
自然言語処理において、テキスト単位の相対的重要度を計算するための確率的グラフベースの手法を紹介する。この手法を、テキスト要約（TS）の問題でテストした。抽出型TSは、文書や文書集合の中で最も重要な文を特定するために、文の重要度（sentence salience）の概念に依存している。サリエンスは通常、特定の重要な単語の存在、またはセントロイド疑似文との類似性の観点から定義される。我々は、文のグラフ表現における固有ベクトル中心性の概念に基づいて文の重要性を計算する新しいアプローチ、LexRankを検討する。このモデルでは、文のグラフ表現の隣接行列として、文内コサイン類似度に基づく接続性行列が用いられる。LexRankに基づいた我々のシステムは、最近のDUC2004の評価において、複数のタスクで1位を獲得した。本論文では、我々のアプローチの詳細な分析を行い、以前のDUC評価からのデータを含むより大きなデータセットに適用した。類似性グラフを用いて中心性を計算するいくつかの方法について議論します。その結果、LexRankを含むdegreeベースの手法は、ほとんどのケースでcentroidベースの手法とDUCに参加している他のシステムの両方を凌駕することがわかりました。さらに、LexRank with threshold法は、continuous LexRankを含む他の度数ベースの手法よりも優れています。また、我々のアプローチは、文書の不完全な局所的クラスタリングに起因するデータのノイズに非常に敏感ではないことを示している。
本論文では、テキスト処理のためのグラフベースのランキングモデルであるTextRankを紹介し、このモデルが自然言語のアプリケーションでどのようにうまく利用できるかを示しています。特に、キーワードと文の抽出のための2つの革新的な教師なしの手法を提案し、得られた結果は、確立されたベンチマークで以前に発表された結果と比較して良好であることを示す。
映像中の物体カテゴリーを高精度に検出・追跡するための最近のアプローチは、年々煩雑になってきている複雑な多段階のソリューションで構成されている。本論文では、検出と追跡を同時に行うConvNetアーキテクチャを提案し、シンプルで効果的な方法でタスクを解決します。我々の貢献は3つあります。(フレームベースのオブジェクト検出とフレーム間のトラック回帰のためのマルチタスク目的を用いて、検出と追跡を同時に行うConvNetアーキテクチャを構築します。時空間物体検出のための我々のConvNetアーキテクチャは、大規模なImageNet VIDデータセットで評価され、最先端の結果を達成しました。我々のアプローチは、前回のImageNetチャレンジで優勝した手法よりも優れた単一モデル性能を提供しますが、概念的にははるかに単純です。最後に、時間的なストライドを大きくすることで、トラッカーの速度を劇的に向上させることができることを示しています。
ウェブ上の文書数が指数関数的に増加しているため、文書セットの主要なアイデアを短時間で提供できるマルチ文書要約の重要性が高まっている。本論文では、分散型単語袋モデルを用いた教師なしセントロイドベースの文書レベル再構成フレームワークを提案する。具体的には、要約と文書の間の再構成誤差を最小化するために、要約文を選択するアプローチである。本研究では、文の選択とビームサーチを適用することで、モデルの性能をさらに向上させる。2つの異なるデータセットを用いた実験結果は、最先端のベースラインと比較して大幅な性能向上を示した。
本研究では、自然の中での人物検索の問題を調査する。本研究では、クエリブラインド方式で生成されたすべての候補領域とクエリを比較するのではなく、再帰的に検索領域を画像全体から縮小し、各再帰的検索ステップでクエリと文脈上の手がかりからの情報を完全に利用することで、ターゲットとなる人物の正確な定位を実現することを提案する。本研究では、このような再帰的な人物検索を実現するために、Neural Person Search Machines (NPSM)を開発しました。NPSMは、ニューラルサーチの仕組みを利用して、ターゲットを含む緩い領域からタイトな領域へと、選択的にフォーカスを縮めることができます。このプロセスでは、NPSMは内部のプリミティブ・メモリ・コンポーネントを用いてクエリ表現を記憶し、注意を調整して他の気を散らす領域に対するロバスト性を高めている。CUHK-SYSU Person Search datasetとPRW datasetという2つのベンチマークデータを用いた評価では、mAPとtop-1の両方の評価プロトコルにおいて、本手法が現在の技術を上回ることが実証された。
深層学習（DL）システムは、自動運転車やマルウェア検知など、安全・安心に関わる領域で導入が進んでおり、コーナーケースの入力に対するシステムの動作の正しさと予測可能性が非常に重要になっています。既存のDLテストは、手動でラベル付けされたデータに大きく依存しているため、まれな入力に対する誤った動作を明らかにできないことが多い。我々は、実世界のDLシステムを体系的にテストするための初のホワイトボックスフレームワークであるDeepXploreを設計、実装、評価した。まず、テスト入力によって動作するDLシステムの部分を系統的に測定するために、ニューロンカバレッジを導入します。次に、類似した機能を持つ複数のDLシステムを相互参照オアクルとして活用することで、手動によるチェックを回避します。最後に、多くの差分行動を引き起こし、かつ高いニューロンカバレッジを達成するDLシステムの入力を見つけることが、共同最適化問題として表現され、勾配ベースの探索技術を用いて効率的に解決できることを示します。DeepXploreは、ImageNetおよびUdacity自動運転チャレンジデータを含む5つの一般的なデータセットでトレーニングされた数千のニューロンを持つ最先端のDLモデルにおいて、何千もの誤ったコーナーケース行動（自動運転車がガードレールに衝突したり、良性のソフトウェアを装ったマルウェアなど）を効率的に発見しました。テストしたすべてのDLモデルについて、DeepXploreは、コモディティラップトップのみで動作しながら、平均して1秒以内に不正な動作を示すテスト入力を1つ生成しました。さらに、DeepXploreが生成したテスト入力は、対応するDLモデルの再学習にも使用でき、モデルの精度を最大3%向上させることができることを示しています。
本論文では、単眼のRGB画像から部屋のレイアウトを推定するタスクに注目しています。先行研究では、この問題を2つのサブタスクに分割している。すなわち、床、壁、天井の意味的なセグメンテーションを行ってレイアウト仮説を作成し、続いて、これらの仮説をランク付けする反復的な最適化ステップを行う。一方、我々はこの問題を、部屋のレイアウトキーポイントの順序付けされたセットを推定するという、より直接的な定式化を採用しています。部屋のレイアウトとそれに対応するセグメンテーションは、これらの順序付けられたキーポイントの位置があれば完全に特定されます。我々は，エンド・ツー・エンドで学習可能なエンコーダ・デコーダネットワークであるRoomNetを用いて，部屋のレイアウトのキーポイントの位置を予測する．難易度の高いベンチマークデータであるHedauおよびLSUNにおいて，最新の性能を達成するとともに，最新の研究と比較して200倍から600倍の高速化を実現した．さらに、同じパラメトリック容量の下でキーポイントの位置を改良するために、リカレント計算やメモリユニットを追加するなど、RoomNetアーキテクチャのオプション拡張についても紹介します。
実際の機械学習アプリケーションでは、高速な評価時間や解釈可能性など、精度以外の要求があるかもしれません。特に、一部の入力に対する学習関数の単調性を保証することは、ユーザーの信頼を得るために重要である。我々は、低次元の機械学習問題に対して、校正された補間ルックアップテーブルを用いて柔軟な単調関数を学習することで、これらの目標を達成することを提案する。我々は、線形不等式制約を追加することにより、格子回帰の構造的リスク最小化フレームワークを単調関数に拡張する。さらに、連続的な特徴を正規化し、カテゴリーデータや欠落データを扱うために、各特徴の解釈可能な較正を共同で学習することを提案するが、その代償として目的が非凸になる。並列化、ミニバッチ処理、付加的正則化項のランダムサンプリングにより、大規模な学習に対応している。最大16の特徴と数億の学習サンプルを持つ実世界の問題に関するケーススタディでは、提案された単調関数が、ユーザーに高い透明性を提供しながら、実際に最先端の精度を達成できることが示された。
強化学習アルゴリズムは、複雑で興味深い環境下で問題を解決するエージェントを訓練することができます。通常、訓練されたエージェントの複雑さは、環境の複雑さと密接に関係している。これは、高い能力を持つエージェントには、複雑な環境での訓練が必要であることを示唆している。本論文では、セルフプレイで訓練された競争的なマルチエージェント環境が、環境そのものよりもはるかに複雑な行動を生み出すことを指摘します。また、このような環境には、自然なカリキュラムが用意されており、どのようなスキルレベルであっても、そのレベルのエージェントが集まった環境は、適切な難易度を持つことになるからであると指摘する。本研究では、エージェントが物理シミュレーションされた3Dの世界で競争するマルチエージェント環境をいくつか紹介している。訓練されたエージェントは、環境自体は比較的単純であるにもかかわらず、複雑で興味深い様々なスキルを習得する。そのスキルとは、走る、ブロックする、ダッキングする、タックルする、相手を欺く、キックする、両手両足を使って防御するなどの行動である。学習された行動のハイライトは、こちらのhttps URLをご覧ください。
本研究では、デモンストレーションからの数撃ちゃ当たる学習と、ニューラルプログラムの誘導とを橋渡しする、ニューラルタスクプログラミング（NTP）という新しいロボット学習フレームワークを提案しています。NTPは、タスクの仕様（例：タスクのビデオデモンストレーション）を入力とし、それを再帰的に細かいサブタスクの仕様に分解します。これらの仕様は、最下層のプログラムが環境と相互作用する呼び出し可能なサブルーチンである、階層的なニューラルプログラムに供給されます。この手法を、3つのロボット操作タスクで検証しました。NTPは、階層的な構造や構成的な構造を持つ連続的なタスクに対して、強力な一般化を達成しました。実験結果は、NTPが、長さが増加し、トポロジーが変化し、目的が変化するような未経験のタスクに対しても、うまく一般化することを示している。
本論文では、バスケットボール選手の一人称映像から、その選手のパフォーマンスを評価する手法を紹介します。評価指標は主観的であり、評価者に依存することが課題である。この課題を解決するために，一人称視点のカメラを活用する．一人称視点からの時空間的な視覚的セマンティクスにより，カメラを装着した人が台本のないバスケットボールの試合に参加している間の行動を推論することができます．我々の手法は，プレイヤーの一人称視点の映像を用いて，評価者の好みに応じたプレイヤーのパフォーマンス指標を提供するものである．この目標を達成するために，まず，畳み込みLSTMネットワークを用いて，一人称映像からアトミックなバスケットボールイベントを検出します．このネットワークは，顕著な領域にズームインすることができるため，カメラを装着した人の頭の動きが激しい一人称映像の問題を解決することができます．次に、検出されたアトミックイベントをガウス混合に通して、高度に非線形な視覚的時空間的バスケットボール評価特徴を構築する。最後に，この特徴を用いて，ラベル付けされた一人称視点のバスケットボールビデオのペアから，バスケットボールの専門家が2人の選手のうちどちらが優れているかを示すバスケットボール評価モデルを学習する．我々のモデルは、バスケットボールの評価者の基準を知らないにもかかわらず、実世界のゲームで選手を正確に評価するように学習することを実証した。さらに、我々のモデルは、選手のパフォーマンスにプラスまたはマイナスの影響を与えるバスケットボールのイベントを発見することもできます。
動画内の人の視線を追うことは、人とその行動を理解するための重要な信号である。本論文では、対象物が別のフレームにある場合でも、（ビデオ内の）人がどこを見ているかを予測することで、ビデオ内の視線を追跡するアプローチを紹介します。本論文では、VideoGazeという新しいデータセットを収集し、モデルの学習と評価の両方のベンチマークとして使用しています。人が映っている1つのフレームが与えられると、我々のモデルは、すべてのフレームにおける注視位置の密度と、人がその特定のフレームを見ている確率を推定する。我々のアプローチの重要な点は、視線を監視としてのみ使用しながら、注目度、視線のポーズ、ビュー間の幾何学的関係を共同で推定するエンド・ツー・エンドのモデルです。このモデルは、追加の監視なしにこれらの中間タスクを自動的に解決することを内部で学習することを視覚化しています。実験によると、我々のアプローチは、既存のアプローチよりもビデオ内の視線によく追従し、ビデオ内の人間の活動をより豊かに理解することができる。
悪意のあるクラウドソーシングフォーラムは、オンライン上で誤った情報を拡散するソースとして人気を集めていますが、人間の労働者を雇用して管理するコストには限界があります。本論文では、ディープラーニング言語モデル（Recurrent Neural Networks：RNN）を利用して、製品やサービスの偽オンラインレビューを自動生成する新しいクラスの攻撃を発見しました。この攻撃は、安価で拡張性が高いだけでなく、コンテンツの出力速度を制御することで、クラウドソースキャンペーンを検出しやすくする特徴的なバースト性を排除することができます。Yelpのレビューを例に、レビューの生成とカスタマイズの2段階の攻撃によって、最先端の統計的検出器では区別できないレビューが生成されることを示します。また、このようなレビューは、人間による検知を回避するだけでなく、ユーザーによる「有用性」の評価でも高得点を得ることができることを、調査に基づいたユーザー調査で示します。最後に、RNNの学習・生成サイクルによって導入される非可逆的な変換を利用して、これらの攻撃に対する新しい自動化された防御策を開発します。さらに、我々が開発したメカニズムへの対策を検討し、攻撃者にとって魅力的ではないコスト・ベネフィット・トレードオフをもたらすこと、そして、オンラインサービスプロバイダが課す簡単な制約によってさらに抑制できることを示す。
知覚的に類似した意味構造を持つ画像間の色変換のための新しいアルゴリズムを提案します。我々は、画像間の意味的に意味のある密な対応関係を利用して、より正確な色転送を実現することを目指している。これを達成するために、我々のアルゴリズムはマッチングに神経表現を使用します。さらに、色の伝達は、空間的に変化し、大域的にコヒーレントである必要があります。このため，我々のアルゴリズムは，ローカルな制約とグローバルな制約の両方を満たす色転送のローカルな線形モデルを最適化する．提案手法は，マッチングと色変換を共同で最適化するもので，粗いものから細かいものへの戦略を採用している．提案手法は，1対1の色転送から1対多の色転送への拡張に成功した．後者では，入力画像の要素が不一致であるという問題にさらに対処することができる．提案手法を様々な画像コンテンツでテストすることで検証した。
深層強化学習コミュニティは，DQNアルゴリズムにいくつかの独立した改良を加えてきた．しかし、これらの拡張機能のうち、どの機能が補完的であり、実りある組み合わせが可能であるかは不明である。本論文では、DQNアルゴリズムに対する6つの拡張機能を検討し、それらの組み合わせを実証的に研究する。実験の結果、この組み合わせにより、Atari 2600ベンチマークにおいて、データ効率と最終性能の両面で最先端の性能が得られることがわかりました。また、各コンポーネントの全体的な性能への貢献度を示す詳細なアブレーション研究の結果も提供します。
ジェネレーティブ・エンコーダー・デコーダー・モデルは、ドメイン・ジェネラルな対話システムの開発に大きな期待が寄せられています。しかし、それらは主にオープンドメインの会話に適用されてきた。本論文では、エンコーダ・デコーダモデルに基づいてタスク指向の対話システムを構築するための実用的で斬新なフレームワークを紹介する。このフレームワークにより、エンコーダ-デコーダモデルは、スロット値に依存しない意思決定や、外部データベースとの対話が可能となる。さらに、本論文では、チャット機能とスロット充填システムを組み合わせることで、より良いアウトオブドメインリカバリーを実現し、提案手法の柔軟性を示している。提案モデルは、バス情報システムからの実ユーザーデータと、人間と人間のチャットデータの両方で学習された。その結果、提案したフレームワークは、オフラインでの評価指標と、人間のユーザーとのタスク成功率の両方において、良好な性能を達成することができた。
オブジェクト検出、シーングラフ生成、リージョンキャプションという、意味的に異なるレベルの3つのシーン理解タスクが結びついています。シーングラフは、画像内で検出されたオブジェクトの上に、それらのペア関係を予測して生成され、リージョンキャプションは、オブジェクト、その属性、関係、その他のコンテキスト情報を言語で説明します。本研究では、意味レベル間の相互関係を活用するために、Multi-level Scene Description Network (MSDN)と呼ばれる新しいニューラルネットワークモデルを提案し、3つのビジョンタスクをエンド・ツー・エンドで共同で解決しています。まず、オブジェクト、フレーズ、キャプション領域は、それらの空間的および意味的なつながりに基づいて、ダイナミックグラフで整列されます。次に、特徴を絞り込む構造を用いて、グラフを介して3つのレベルの意味的タスクにメッセージを渡します。学習したモデルを3つのタスクでベンチマークした結果、提案手法による3つのタスクの共同学習は、従来のモデルよりも相互に改善できることがわかった。特に、シーングラフ生成タスクでは、提案手法は従来手法を3%以上のマージンで上回ることができた。
データの集合体の中で注目すべき主な変化を捉える低次元の埋め込みは、多くのアプリケーションにとって重要である。このようなエンベッディングを構築する一つの方法は、群衆から類似性の推定値を取得することである。しかし、類似性は個人ごとに異なる多次元の概念である。群集から埋め込みを学習する既存のモデルは、すべての個人が同じ基準で類似性を推定する、基準のリストは事前に知られている、群集作業者は自分が見たデータに影響されない、などの単純化された仮定をしているのが一般的である。これらの限界を克服するために、我々はContext Embedding Networks (CEN)を導入した。CENは、画像から解釈可能な埋め込みを学習することに加えて、作業者の異なる属性に対するバイアスを、一連の画像によって強調された視覚的属性であるビジュアルコンテキストとともにモデル化する。ノイズの多い群集注釈付きデータセット2つを用いた実験では、作業者の偏りと視覚的コンテキストの両方をモデル化することで、既存のアプローチと比較してより解釈しやすい埋め込みが得られることが示された。
1995年に発表されたLSTM（Long Short-Term Memory）アーキテクチャの再帰型ニューラルネットワークには、いくつかのバリエーションがあります。近年、これらのネットワークは、様々な機械学習問題に対する最先端のモデルとなっています。これに伴い、LSTMの典型的なバリエーションの様々な計算コンポーネントの役割と有用性を理解することに新たな関心が寄せられている。本論文では，音声認識，手書き認識，ポリフォニック・ミュージック・モデリングという3つの代表的なタスクにおいて，8つのLSTMバリアントを初めて大規模に分析した．各タスクに対するすべてのLSTMバリアントのハイパーパラメータは、ランダム検索を用いて個別に最適化され、その重要性は強力なfANOVAフレームワークを用いて評価されました。合計で5400回の実験（約15年分のCPU時間）の結果をまとめており、この種のLSTMネットワークの研究としては最大規模となっています。その結果、どのバリエーションも標準的なLSTMアーキテクチャを大きく改善することはできず、忘却ゲートと出力活性化関数が最も重要な構成要素であることがわかりました。さらに、研究されたハイパーパラメータが実質的に独立であることを確認し、その効率的な調整のためのガイドラインを導き出した。
本論文では、Generative Adversarial Networks (GAN)を学習するための一般的なアルゴリズムの数値解析を行っています。滑らかな2プレイヤーゲームの形式を用いて、GANの学習目標に関連する勾配ベクトルフィールドを分析する。その結果、現在のアルゴリズムの収束性には、次の2つの要因があることが示唆された。i) 勾配ベクトル場のヤコビアンのうち、実数部がゼロの固有値が存在すること、ii) 虚数部が大きい固有値が存在すること。これらの知見をもとに、これらの限界を克服し、より良い収束特性を持つ新しいアルゴリズムを設計した。実験的には、一般的なGANアーキテクチャの学習においてこのアルゴリズムが優れていることを実証し、学習が困難であることが知られているGANアーキテクチャにおいても収束することを示した。
本論文では、初めての高フレームレートのビデオデータセット（Need for Speed - NfSと呼ばれる）と視覚的物体追跡のベンチマークを提案します。このデータセットは、現在一般的に使用されている高フレームレート（240 FPS）のカメラで撮影された100本のビデオ（380Kフレーム）で構成されています。すべてのフレームには、軸合わせされたバウンディングボックスが付けられ、すべてのシーケンスには、オクルージョン、速い動き、背景の乱雑さなど、9つの視覚的属性が手動で付けられています。このベンチマークでは，高フレームレートのシーケンスを対象に，最近の最先端のトラッカーを幅広く評価しました．これらのトラッカーを、トラッキング精度とリアルタイム性能に基づいてランク付けしました。驚くべき結論の一つは、高フレームレートでは、相関フィルタのような単純なトラッカーが、ディープネットワークに基づく複雑な手法よりも優れているということです。これは、ロボット工学やエンベデッド・ビジョンなどの実用的なアプリケーションでは、より高いフレームレートの取得に伴う帯域幅の制約、リアルタイム解析の計算コスト、および必要なアプリケーションの精度を慎重にトレードオフする必要があることを示唆しています。我々のデータセットとベンチマークは、（我々の知る限り）初めてこのような問題を体系的に調査することを可能にし、この分野でのさらなる研究を可能にするために公開される予定です。
GANは、データ分布を模倣した生成モデルを学習するためのフレームワークを提供します。しかし、多くの場合、我々はこれらの生成モデルを、生成されたデータの中で何らかの補助的な目的関数を最適化するように訓練したいと考えています（例えば、より美しい画像を作るなど）。しかし、これらの目的関数を評価するには、人間の操作が必要な場合もあります。ここでは、GANを効率的に改良して、人とのインタラクションを伴う目的、具体的にはユーザーのポジティブなインタラクションの割合を増やす画像を生成するシステムを開発しました。生成モデルを改良するために、比較的小さなインタラクションのセットから、対象となるドメインにおける人間の行動のモデルを構築し、この行動モデルを生成モデルを改良するための補助的な損失関数として使用する。このシステムが、少なくともシミュレーションデータ上では、肯定的なインタラクション率を向上させることに成功したことを示し、その性能に影響を与えるいくつかの要因を特徴づける。
文章の新しい生成モデルを提案する。このモデルは、まず学習コーパスからプロトタイプの文章をサンプリングし、それを編集して新しい文章を作る。左から右へ、あるいは潜在的な文ベクトルを最初にサンプリングしてゼロから生成する従来のモデルと比較して、我々のprototype-then-editモデルは、言語モデリングのパープレキシティを改善し、人間の評価によれば、より高品質の出力を生成する。さらに、このモデルは、文の類似性や文レベルの類似性などの解釈可能なセマンティクスを捉える潜在的な編集ベクトルを生成します。
抽象的な要約は、コンパクトで一貫性のある方法で、すべての重要なポイントをカバーする文書の短いバージョンを生成することを目的としています。一方、クエリベースの要約では、与えられたクエリのコンテキストに関連するポイントをハイライトします。encod-attend-decodeのパラダイムは、機械翻訳、抽出型要約、対話システムなどで大きな成功を収めている。しかし、これには繰り返されるフレーズの生成という難点がある。本研究では、encode-attend-decodeパラダイムに基づいて、クエリベースの要約タスクのためのモデルを提案する。(i) (文書注目モデルに加えて)クエリ注目モデルは、(クエリのための静的な表現を使用する代わりに)異なる時間ステップでクエリの異なる部分に焦点を当てることを学習する。また、(ii) 新しい多様性ベースの注目モデルは、要約中の繰り返しフレーズの問題を軽減することを目的とする。このモデルをテストするために、debatepediaをベースにした新しいクエリベースの要約データセットを導入した。実験の結果，この2つの追加要素により，提案モデルはROUGE-Lスコアで28%（絶対値）の向上を示し，従来のencode-attend-decodeモデルを明らかに凌駕した．
長い文書を理解するためには、エンティティがどのように導入され、時間とともに進化していくかを追跡する必要があります。我々は、エンティティを明示的にモデル化し、その表現を動的に更新し、その言及を文脈に応じて生成することができる新しいタイプの言語モデル、EntityNLMを発表する。このモデルは生成的で柔軟性があり、任意の数のエンティティを文脈に沿ってモデル化し、各エンティティの言及を任意の長さで生成することができます。さらに、このモデルは、言語モデリング、共参照の解決、エンティティの予測など、さまざまなタスクに使用することができます。これらのタスクの実験結果は、我々のモデルが強力なベースラインや先行研究よりも一貫して優れていることを示している。
文の新しい生成モデルを提案します。このモデルは、まず学習コーパスからプロトタイプの文をサンプリングし、それを編集して新しい文を作ります。左から右へ、あるいは潜在的な文のベクトルを最初にサンプリングしてゼロから生成する従来のモデルと比較して、我々のプロトタイプ-編集モデルは、言語モデリングのパープレキシティを改善し、人間の評価によればより高品質の出力を生成する。さらに、このモデルは、文の類似性や文レベルの類似性などの解釈可能なセマンティクスをキャプチャする潜在的な編集ベクトルを生成します。
最新の機械学習アルゴリズムを学習するために、アノテーション付きの視覚的把握データを収集することは、非常に時間とコストがかかります。そこで、市販のシミュレータを使って合成データを作成し、そこに基づいてアノテーションを自動生成するという方法が考えられます。しかし、シミュレートされたデータのみを用いて学習したモデルは、残念ながら現実世界への一般化に失敗することが多い。本研究では，ランダム化されたシミュレーション環境と領域適応法を拡張して，単眼RGB画像から新奇な物体を把持する把持システムを学習する方法を検討する．我々は、25,000以上の物理的なテスト把持を用いて、我々のアプローチを広範囲に評価し、様々なシミュレーション条件と領域適応法（我々がGraspGANと呼ぶピクセルレベルの領域適応の新しい拡張を含む）を研究した。その結果、合成データと領域適応を用いることで、ランダムに生成された模擬物体のみを用いた場合と比較して、所定の性能を達成するために必要な実世界のサンプル数を最大で50分の1に減らすことができることを示した。また、ラベルのない実世界データと我々のGraspGAN手法を用いることで、939,777個のラベル付き実世界サンプルを用いた場合と同等の実世界での把持性能を得ることができることを示した。
GAN（Generative Adversarial Networks）は、クラスラベル情報が提供されている場合、つまり条件付きGANの設定では、系統的に優れた品質のサンプルを生成します。これは、最近提案されたWasserstein GAN方式でも同じことが言えます。Wasserstein GAN方式は、敵対的学習を安定化させ、ResNetのような大容量ネットワークアーキテクチャを考慮することができます。本研究では、利用可能なクラスラベルを増強することで、条件付きGANを向上させる方法を示します。この新しいクラスは、同じGANモデルによって学習された表現空間内のクラスタリングから得られる。提案された戦略は、クラス情報が得られない場合、つまり教師なしの設定でも実行可能である。我々が生成したサンプルは，CIFAR-10およびSTL-10データセットにおいて，教師ありおよび教師なしの両方で最先端のInceptionスコアを達成した．
ディープニューラルネットワークの背後にある最適化問題は非常に非凸であるにもかかわらず、実際には、サブオプティマルポイントで立ち往生することなく、ディープネットワークのトレーニングが可能であるように見えることがよく観察されます。これは、すべてのローカルミニマムが大域的に最適な状態に近いためであると主張されてきました。我々は、ネットワークの1つの層の隠れユニットの数がトレーニングポイントの数よりも大きく、この層以降のネットワーク構造がピラミッド型である場合、二乗損失と解析的活性化関数を持つ完全連結ネットワークに対して、これは（ほぼ）真実であり、実際にほとんどすべてのローカルミニマムが大域的に最適であることを示す。
デザイナーが作成したグラフィカル・ユーザー・インターフェースのスクリーンショットをコンピュータ・コードに変換することは、カスタマイズされたソフトウェア、ウェブサイト、モバイル・アプリケーションを構築するために開発者が行う典型的な作業である。本論文では、ディープラーニングの手法を活用して、3つの異なるプラットフォーム（iOS、Android、Webベースの技術など）において、1つの入力画像から77%以上の精度でコードを自動生成するモデルをエンドツーエンドで学習できることを示します。
深層学習アーキテクチャに焦点を当てた、最適化手法を発見するプロセスを自動化するアプローチを紹介します。リカレント・ニューラル・ネットワークのコントローラを訓練し、勾配や勾配の実行平均などのプリミティブな関数のリストに基づいて数学的な更新方程式を記述するドメイン固有の言語の文字列を生成します。このコントローラは、数回のエポックの後、モデルの性能を最大化するために強化学習で学習されます。CIFAR-10において、我々の手法は、Adam、RMSProp、ConvNetモデルにおけるSGD with and without Momentumなど、一般的に使用されている多くのオプティマイザよりも優れた更新規則を発見した。PowerSignとAddSignと名付けられた2つの新しいオプティマイザを紹介し、ImageNet分類やGoogleのニューラル機械翻訳システムなど、様々な異なるタスクやアーキテクチャにおいて、うまく転送し、学習を改善することを示した。
このベンチマークは、712.5km^2の土地、8439kmの道路、約40万の建物からなる大トロント地域（GTA）をカバーしています。このベンチマークでは、飛行機やドローン、街中を走る車から撮影された世界のさまざまな視点を提供しています。このような大規模なデータセットを手動でラベリングすることは不可能です。その代わりに、高精度な地図のさまざまなソースを利用して、グランドトゥルースを作成することを提案しています。この目的のために、人間の監督を最小限に抑えながら、すべてのデータソースを地図に合わせることができるアルゴリズムを開発しました。我々は、建物の高さの推定（再構築）、道路の中心線と縁石の抽出、建物のインスタンスのセグメンテーション、建物の輪郭の抽出（再編成）、セマンティックラベリング、シーンタイプの分類（認識）など、さまざまなタスクを設計しました。我々のパイロット研究では、これらのタスクのほとんどが、現代の畳み込みニューラルネットワークにとってはまだ難しいことがわかっています。
私たちは、視覚認識のためのベンチマーク・スイートを発表します。このベンチマークは、25万枚以上の高解像度ビデオフレームに基づいており、オプティカルフロー、セマンティックインスタンスセグメンテーション、オブジェクトの検出と追跡、オブジェクトレベルの3Dシーンレイアウト、ビジュアルオドメトリなど、低レベルおよび高レベルの視覚タスクのグランドトゥルースデータがアノテーションされています。すべてのタスクのグランドトゥルースデータは、すべてのフレームで利用可能です。このデータは、現実的な仮想世界において、多様な環境条件の中で、運転、乗車、歩行を繰り返しながら、合計184kmを収集したものです。ベンチマークを作成するために、ソースコードやコンテンツにアクセスすることなくシミュレートされた世界からグランドトゥルースデータを収集する新しいアプローチを開発しました。統計的な分析を行った結果、ベンチマークのシーンの構成は、対応する物理的な環境の構成と密接に一致していることが分かりました。さらに，収集したデータの現実性を知覚実験によって検証した．また，複数のタスクに対する最先端の手法の性能を分析し，基準となるベースラインを示すとともに，今後の研究課題を明らかにしました．補足ビデオはこちらのhttps URLでご覧いただけます。
StarSpaceは、テキスト分類などのラベリングタスク、情報検索/ウェブ検索などのランキングタスク、協調フィルタリングベースまたはコンテンツベースの推薦、多関係グラフの埋め込み、単語・文・文書レベルの埋め込みの学習など、さまざまな問題を解決できる汎用のニューラル埋め込みモデルです。いずれの場合も、個別の特徴で構成されたエンティティを埋め込み、それらを互いに比較することで、タスクに応じた類似性を学習するモデルです。数多くのタスクでの実証実験の結果、StarSpaceは既存の手法に対して高い競争力を持つ一方で、既存の手法では対応できない新しいケースにも一般的に適用可能であることがわかりました。
埋め込み型2値化ニューラルネットワーク（eBNN）は、現在の2値化ニューラルネットワーク（BNN）が小型の埋め込みデバイスでフィードフォワード推論を効率的に実行できるようにすることを目的としています。その目的は、現在の2値化ニューラルネットワーク（BNN）を小型の組み込み機器で効率的にフィードフォワード推論できるようにすることです。BNNのように重みを保存するために必要なメモリを最小化するだけでなく、フィードフォワード推論において層間の中間結果を保持するテンポラリーに使用するメモリを最小化することが不可欠であることを示しています。これを実現するために、eBNNは、元のBNN構造を維持したまま、推論の計算を再編成し、ニューラルネットワーク全体で単一の浮動小数点テンポラリーを使用しています。各層の中間結果は，現在のBNN実装で使用されている浮動小数点ではなく，すべて2進数で格納されており，必要なテンポラリスペースを32倍に削減しています。今回提案したeBNNアプローチは、メモリが数十KBと非常に限られたデバイス上で、効率的な推論（数十ms）を可能にすることを実証しています。例えば，使用可能なメモリが15KBしかないIntel Curie上で動作するMNISTデータセットにおいて，eBNNは95%の精度を達成し，1サンプルあたりの推論実行時間は50ms以下であった．組込みアプリケーションの開発を容易にするために、我々はソースコードを公開しています。これにより、ユーザーは、ターゲットデバイスのメモリ制約内に収まるような学習タスクのためにeBNNモデルを学習・発見することができます。

