L'addestramento a precisione mista (MPT) sta diventando una tecnica pratica per migliorare la velocità e l'efficienza energetica dell'addestramento delle reti neurali profonde, sfruttando il supporto hardware veloce per la semiprecisione IEEE in virgola mobile che è disponibile nelle GPU esistenti. MPT è tipicamente usato in combinazione con una tecnica chiamata loss scaling, che funziona scalando il valore di perdita prima dell'inizio della backpropagation al fine di minimizzare l'impatto dell'underflow numerico sull'addestramento. Sfortunatamente, i metodi esistenti rendono questo valore di scala di perdita un iperparametro che deve essere sintonizzato per modello, e una singola scala non può essere adattata a diversi livelli in diverse fasi di addestramento. Introduciamo un metodo di formazione basato sul loss scaling chiamato adaptive loss scaling che rende MPT più facile e pratico da usare, rimuovendo la necessità di sintonizzare un iperparametro specifico per modello, introducendo valori di loss scale a livello che vengono calcolati automaticamente durante la formazione per gestire l'underflow in modo più efficace rispetto ai metodi esistenti. Presentiamo risultati sperimentali su una varietà di reti e compiti che mostrano che il nostro approccio può ridurre il tempo di convergenza e migliorare la precisione, rispetto all'utilizzo dell'attuale stato dell'arte di MPT e della virgola mobile a singola precisione.
Molti problemi del mondo reale, ad esempio il rilevamento di oggetti, hanno output che sono naturalmente espressi come insiemi di entità, il che crea una sfida per le reti neurali profonde tradizionali che si occupano naturalmente di output strutturati come vettori, matrici o tensori. In particolare, nella nostra formulazione incorporiamo la permutazione come variabile non osservabile e stimiamo la sua distribuzione durante il processo di apprendimento utilizzando l'ottimizzazione alternata.Dimostriamo la validità di questa nuova formulazione su due problemi di visione rilevanti: il rilevamento di oggetti, per il quale la nostra formulazione supera i rilevatori allo stato dell'arte come Faster R-CNN e YOLO, e un complesso test CAPTCHA, dove osserviamo che, sorprendentemente, la nostra rete basata su set ha acquisito la capacità di imitare l'aritmetica senza alcuna regola codificata.
La foveazione è una parte importante della visione umana, e anche un certo numero di reti profonde ha utilizzato la foveazione.Tuttavia, ci sono stati pochi confronti sistematici tra reti profonde foveanti e non foveanti, e tra diversi metodi di downsampling a risoluzione variabile.Qui definiamo diversi metodi, e confrontiamo le loro prestazioni sul riconoscimento di ImageNet con una rete Densenet-121.Il miglior metodo a risoluzione variabile supera leggermente il downsampling uniforme.Quindi nei nostri esperimenti, la foveazione non aiuta o ostacola sostanzialmente il riconoscimento degli oggetti nelle reti profonde.
Esploriamo il concetto di co-design nel contesto della verifica delle reti neurali.In particolare, miriamo ad addestrare reti neurali profonde che non solo siano robuste alle perturbazioni avversarie, ma anche la cui robustezza possa essere verificata più facilmente.A tal fine, identifichiamo due proprietà dei modelli di rete - sparsità dei pesi e la cosiddetta stabilità ReLU - che risultano avere un impatto significativo sulla complessità del compito di verifica corrispondente. Dimostriamo che il solo miglioramento della sparsità dei pesi ci permette già di trasformare problemi di verifica computazionalmente intrattabili in problemi trattabili, mentre il miglioramento della stabilità di ReLU porta a un'ulteriore accelerazione di 4-13 volte nei tempi di verifica. Una caratteristica importante della nostra metodologia è la sua "universalità", nel senso che può essere usata con una vasta gamma di procedure di addestramento e approcci di verifica.
La normalizzazione dei lotti (BatchNorm) ha dimostrato di essere efficace per migliorare e accelerare l'addestramento delle reti neurali profonde, tuttavia, recentemente è stato dimostrato che è anche vulnerabile alle perturbazioni avversarie.In questo lavoro, ci proponiamo di indagare la causa della vulnerabilità avversaria della BatchNorm. Ipotizziamo che l'uso di diverse statistiche di normalizzazione durante l'addestramento e l'inferenza (statistiche mini-batch per l'addestramento e media mobile di questi valori all'inferenza) sia la causa principale di questa vulnerabilità avversaria nel livello BatchNorm. Abbiamo dimostrato empiricamente questo attraverso esperimenti su varie architetture di reti neurali e dataset.
Le cartelle cliniche elettroniche (EHR) comprendono osservazioni cliniche longitudinali ritratte con sparsità, irregolarità e alta dimensionalità che diventano i maggiori ostacoli nel trarre risultati affidabili a valle. Nonostante un gran numero di metodi di imputazione siano stati proposti per affrontare questi problemi, la maggior parte dei metodi esistenti ignorano le caratteristiche correlate o le dinamiche temporali e mettono completamente da parte l'incertezza. In questo lavoro, proponiamo una nuova rete di imputazione variazionale-recorrente (V-RIN), che ha unificato l'imputazione e la rete di previsione, prendendo in considerazione le caratteristiche correlate, le dinamiche temporali, e utilizzando ulteriormente l'incertezza per alleviare il rischio di stime distorte dei valori mancanti. In particolare, sfruttiamo il modello generativo profondo per stimare i valori mancanti in base alla distribuzione tra le variabili e una rete di imputazione ricorrente per sfruttare le relazioni temporali insieme all'utilizzo dell'incertezza. Abbiamo convalidato l'efficacia del nostro modello proposto con il dataset EHR del mondo reale pubblicamente disponibile, PhysioNet Challenge 2012, e confrontato i risultati con altri metodi concorrenti all'avanguardia presenti in letteratura.
Nonostante l'accuratezza allo stato dell'arte delle reti neurali profonde (DNN) in vari problemi di classificazione, la loro distribuzione su dispositivi di edge computing con risorse limitate rimane impegnativa a causa delle loro grandi dimensioni e complessità.Diversi studi recenti hanno riportato risultati notevoli nel ridurre questa complessità attraverso la quantizzazione dei modelli DNN. Tuttavia, questi studi di solito non considerano i cambiamenti nella funzione di perdita quando si esegue la quantizzazione, né prendono in considerazione la diversa importanza dei parametri del modello DNN per l'accuratezza. Noi affrontiamo questi problemi in questo articolo proponendo un nuovo metodo, chiamato quantizzazione adattiva, che semplifica un modello DNN addestrato trovando un'unica precisione ottimale per ogni parametro di rete in modo che l'aumento della perdita sia minimizzato. Il problema di ottimizzazione al centro di questo metodo utilizza iterativamente il gradiente della funzione di perdita per determinare un margine di errore per ogni parametro e gli assegna una precisione di conseguenza. Poiché questo problema utilizza funzioni lineari, è computazionalmente economico e, come mostreremo, ha una soluzione approssimata in forma chiusa. Gli esperimenti su MNIST, CIFAR e SVHN hanno mostrato che il metodo proposto può raggiungere una riduzione vicina o migliore dello stato dell'arte nella dimensione del modello con tassi di errore simili.
Studiamo il problema dell'apprendimento delle rappresentazioni invarianti di permutazione che possono catturare le relazioni di contenimento.Proponiamo l'addestramento di un modello su un compito nuovo: predire la dimensione della differenza simmetrica tra coppie di multiset, insiemi che possono contenere più copie dello stesso oggetto.Con la motivazione dalla teoria degli insiemi fuzzy, formuliamo sia le rappresentazioni di multiset sia come predire le dimensioni della differenza simmetrica date queste rappresentazioni. Dimostriamo che le nostre rappresentazioni predicono più efficacemente le dimensioni delle differenze simmetriche rispetto agli approcci basati su DeepSets con rappresentazioni di oggetti non vincolate.Inoltre, dimostriamo che il modello impara rappresentazioni significative, mappando oggetti di classi diverse a diversi vettori di base standard.
È importante raccogliere campioni di allenamento credibili $(x,y)$ per la costruzione di sistemi di apprendimento ad alta intensità di dati (ad esempio, un sistema di apprendimento profondo).Nella letteratura, c'è una linea di studi su come ottenere informazioni distributive da agenti auto-interessati che detengono un'informazione rilevante.  Chiedere alle persone di riportare una distribuzione complessa $p(x)$, anche se teoricamente fattibile, è impegnativo nella pratica, principalmente a causa dei pesanti carichi cognitivi richiesti agli agenti umani per ragionare e riportare queste informazioni ad alta dimensione. Consideriamo l'esempio in cui siamo interessati a costruire un classificatore di immagini raccogliendo prima una certa categoria di dati di immagini ad alta dimensione. Mentre i risultati classici di elicitazione si applicano per elicitare una distribuzione complessa e generativa (e continua) $p(x)$ per questi dati di immagini, noi siamo interessati a elicitare campioni $x_i \sim p(x)$ dagli agenti. Questo articolo introduce un metodo di deep learning per incentivare i contributi di campioni credibili da parte di agenti egoisti e razionali. La sfida è quella di progettare una funzione di punteggio compatibile con gli incentivi per assegnare un punteggio a ciascun campione riportato per indurre rapporti veritieri, invece di una funzione arbitraria o addirittura avversaria. Mostriamo che con una stima accurata di una certa funzione $f$-divergenza siamo in grado di raggiungere una compatibilità approssimativa degli incentivi nell'elicitazione di campioni veritieri.Presentiamo poi uno stimatore efficiente con garanzia teorica attraverso lo studio delle forme variazionali della funzione $f$-divergenza.Il nostro lavoro completa la letteratura sull'elicitazione delle informazioni introducendo il problema dell'elicitazione dei campioni.  Mostriamo anche una connessione tra questo problema di elicitazione del campione e $f$-GAN, e come questa connessione può aiutare a ricostruire uno stimatore della distribuzione basato sui campioni raccolti.
La celebre tecnica di apprendimento da sequenza a sequenza (Seq2Seq) e le sue numerose varianti raggiungono prestazioni eccellenti su molti compiti. Tuttavia, molti compiti di apprendimento automatico hanno input rappresentati naturalmente come grafici; i modelli esistenti di Seq2Seq affrontano una sfida significativa nel realizzare una conversione accurata dalla forma del grafico alla sequenza appropriata. Per affrontare questa sfida, introduciamo un'architettura neurale end-to-end di codifica-decodifica da grafico a sequenza che mappa un grafico di input in una sequenza di vettori e utilizza un metodo LSTM basato sull'attenzione per decodificare la sequenza di destinazione da questi vettori. Il nostro metodo genera prima le embeddings del nodo e del grafico usando una rete neurale basata sul grafico migliorata con una nuova strategia di aggregazione per incorporare le informazioni sulla direzione del bordo nelle embeddings del nodo. Introduciamo inoltre un meccanismo di attenzione che allinea le embeddings del nodo e la sequenza di decodifica per affrontare meglio i grandi grafici. I risultati sperimentali sui compiti di bAbI, Shortest Path e Natural Language Generation dimostrano che il nostro modello raggiunge prestazioni all'avanguardia e supera significativamente i modelli esistenti di reti neurali a grafo, Seq2Seq e Tree2Seq; utilizzando la strategia di aggregazione proposta di embedding bidirezionale dei nodi, il modello può convergere rapidamente verso le prestazioni ottimali.
Essere in grado di imparare la geometria precedente delle parti e trasferire questa precedenza alle categorie non viste pone sfide fondamentali per gli approcci di segmentazione della forma guidati dai dati. Formulato come un problema di bandito contestuale, proponiamo un quadro di raggruppamento iterativo basato sull'apprendimento che impara una politica di raggruppamento per unire progressivamente le piccole proposte di parti in quelle più grandi in un modo bottom-up. Su un dataset di parti 3D a grana fine su larga scala proposto di recente, PartNet, dimostriamo che il nostro metodo può trasferire la conoscenza delle parti appresa da 3 categorie di allenamento a 21 categorie di test non viste, senza vedere alcun campione annotato.i confronti quantitativi contro quattro forti baseline di segmentazione della forma mostrano che raggiungiamo le prestazioni più avanzate.
La rete neurale a grafo balistico affronta la distribuzione dei pesi da una prospettiva di trasporto e ha molte proprietà diverse rispetto alla rete neurale a grafo tradizionale. La rete neurale a grafo balistico non richiede di calcolare alcun autovalore, i filtri si propagano esponenzialmente più velocemente ($sigma^2 \sim T^2$) rispetto alla rete neurale a grafo tradizionale ($sigma^2 \sim T$). I nostri risultati mostrano che selezionando la velocità di diffusione, la rete può raggiungere una precisione simile con meno parametri e che i filtri perturbati agiscono come migliori rappresentazioni rispetto a quelli balistici puri. Forniamo una nuova prospettiva di formazione delle reti neurali a grafo, regolando la velocità di diffusione, le prestazioni della rete neurale possono essere migliorate.
In questo articolo, proponiamo una struttura di supervisione debole per compiti di classificazione neurale basata sul paradigma di programmazione dei dati Ratner2016, che ci permette di sfruttare più segnali di supervisione deboli provenienti da fonti diverse.Empiricamente, consideriamo due fonti di segnali di supervisione deboli, funzioni di classificazione non supervisionate e somiglianze di caratteristiche semantiche. Addestriamo un modello di classificazione dei passaggi basato su BERT (che raggiunge nuove prestazioni allo stato dell'arte su due set di dati di riferimento con supervisione completa) nel nostro quadro di supervisione debole.Senza utilizzare etichette di formazione ground-truth, i modelli BERT-PR superano la baseline BM25 con un ampio margine su tutti e tre i set di dati e addirittura battono i precedenti risultati allo stato dell'arte con supervisione completa su due dei set di dati.
Studiamo il processo di formazione delle Reti Neurali Profonde (DNN) dal punto di vista dell'analisi di Fourier.dimostriamo un principio di frequenza molto universale (F-Principio) --- le DNN spesso si adattano alle funzioni target dalle basse alle alte frequenze --- su set di dati di riferimento ad alta dimensione, come MNIST/CIFAR10, e reti profonde, come VGG16.Questo F-Principio delle DNN è opposto al comportamento di apprendimento della maggior parte degli schemi numerici iterativi convenzionali (ad esempio, Con una teoria ingenua, illustriamo che questo principio F deriva dalla regolarità delle funzioni di attivazione comunemente utilizzate. Il principio F implica un pregiudizio implicito che le DNN tendono ad adattarsi ai dati di formazione con una funzione a bassa frequenza. Questa comprensione fornisce una spiegazione della buona generalizzazione delle DNN sulla maggior parte dei set di dati reali e della cattiva generalizzazione delle DNN sulla funzione di parità o su set di dati randomizzati.
Il problema di accelerare la scoperta della droga si basa pesantemente su strumenti automatici per ottimizzare le molecole precursori per permettersi con migliori proprietà biochimiche.Il nostro lavoro in questo documento estende sostanzialmente precedente state-of-the-art sui metodi di traduzione grafo-grafico per l'ottimizzazione molecolare.In particolare, realizziamo rappresentazioni coerenti multirisoluzione intrecciando la codifica dei componenti di sottostruttura con la codifica a livello di atomo del grafico molecolare originale. Inoltre, il nostro decodificatore del grafico è completamente autoregressivo, e intreccia ogni passo dell'aggiunta di una nuova sottostruttura con il processo di risoluzione del suo attaccamento alla molecola emergente.Valutiamo il nostro modello su più compiti di ottimizzazione molecolare e mostriamo che il nostro modello supera significativamente le precedenti baseline dello stato dell'arte.
Anche se alcune combinazioni di trasformazioni potrebbero non apparire mai (ad esempio un volto eretto con un naso orizzontale), le attuali architetture equivarianti considerano l'insieme di tutte le possibili trasformazioni in un gruppo di trasformazioni quando imparano le rappresentazioni delle caratteristiche.Al contrario, il sistema visivo umano è in grado di partecipare all'insieme delle trasformazioni rilevanti che si verificano nell'ambiente e utilizza queste informazioni per assistere e migliorare il riconoscimento degli oggetti. Sulla base di questa osservazione, modifichiamo le mappature convenzionali delle caratteristiche equivarianti in modo che siano in grado di partecipare all'insieme delle trasformazioni co-occorrenti nei dati e generalizziamo questa nozione per agire su gruppi costituiti da simmetrie multiple. Mostriamo che le nostre reti neurali equivarianti co-attentive proposte superano costantemente le reti neurali equivarianti di rotazione convenzionali e di rotazione e riflessione equivarianti su MNIST ruotato e CIFAR-10.
La generazione rapida e il raffinamento delle ossa della proteina costituirebbero un importante progresso alla metodologia attuale per la progettazione e lo sviluppo di proteine de novo.In questo studio, addestriamo le reti adversariali generative (GAN) per generare ossa proteiche full-atom di lunghezza fissa, con l'obiettivo di campionare dalla distribuzione di frammenti realistici di ossa 3-D. Rappresentiamo strutture proteiche da distanze a coppie tra tutti gli atomi delle ossa, e presentiamo un metodo per recuperare e raffinare direttamente le coordinate delle ossa corrispondenti in modo differenziabile. Mostriamo che le interpolazioni nello spazio latente del generatore corrispondono a deformazioni lisce delle ossa dorsali in uscita, e che le strutture del set di prova non viste dal generatore durante l'addestramento esistono nella sua immagine. Infine, eseguiamo la progettazione della sequenza, il rilassamento e il ripiegamento ab initio di un sottoinsieme di strutture generate, e mostriamo che in alcuni casi possiamo recuperare le pieghe generate dopo il forward-folding.insieme, questi risultati suggeriscono un meccanismo per il raffinamento e il ripiegamento veloce della struttura proteica usando funzioni energetiche esterne.
Few-Shot Learning (apprendimento con dati etichettati limitati) mira a superare le limitazioni dei tradizionali approcci di apprendimento automatico che richiedono migliaia di esempi etichettati per addestrare un modello efficace.Considerato come un segno distintivo dell'intelligenza umana, la comunità ha recentemente assistito a diversi contributi su questo argomento, in particolare attraverso il meta-apprendimento, dove un modello impara come imparare un modello efficace per l'apprendimento few-shot.L'idea principale è quella di acquisire conoscenze precedenti da un insieme di compiti di formazione, che viene poi utilizzato per eseguire (few-shot) compiti di test. La maggior parte dei lavori esistenti presuppone che sia i compiti di formazione che quelli di test siano tratti dalla stessa distribuzione, e che sia disponibile una grande quantità di dati etichettati nei compiti di formazione. Questo è un presupposto molto forte che limita l'uso di strategie di meta-apprendimento nel mondo reale, dove potrebbero non essere disponibili ampi compiti di formazione che seguono la stessa distribuzione dei compiti di test. In questo articolo, proponiamo un nuovo paradigma di meta-apprendimento in cui viene appreso un modello di apprendimento a pochi scatti, che simultaneamente supera lo spostamento del dominio tra i compiti di addestramento e quelli di test attraverso l'adattamento del dominio avversario, dimostrando l'efficacia del metodo proposto attraverso ampi esperimenti.
I sistemi di programmazione probabilistici universali (PPSs) forniscono una struttura potente per specificare modelli probabilistici ricchi e complessi. Tuttavia, questa espressività viene al costo di complicare sostanzialmente il processo di trarre inferenze dal modello. In particolare, l'inferenza può diventare difficile quando il supporto del modello varia tra le esecuzioni: Divide, Conquer, and Combine (DCC).DCC divide il programma in sottoprogrammi separati in linea retta, ognuno dei quali ha un supporto fisso che permette agli algoritmi di inferenza più potenti di essere eseguiti localmente, prima di ricombinare i loro output in un modo di principio.Mostriamo come DCC può essere implementato come un motore di inferenza PPS automatico e general-purpose, e confermiamo empiricamente che può fornire miglioramenti sostanziali delle prestazioni rispetto agli approcci precedenti.
Rilevare le comunità o la struttura modulare delle reti della vita reale (ad esempio, un socialnetwork o una rete di acquisto di prodotti) è un compito importante perché il modo in cui una rete funziona è spesso determinato dalle sue comunità.Gli approcci tradizionali al rilevamento delle comunità coinvolgono approcci basati sulla modularità, che in generale, costruiscono partizioni basate su euristiche che cercano di massimizzare il rapporto tra i bordi all'interno delle partizioni e quelli tra di esse. Gli approcci di embedding dei nodi, che rappresentano ogni nodo in un grafo come un vettore con valore nominale, trasformano il problema del rilevamento delle comunità in un grafo in quello del raggruppamento di un insieme di vettori. Gli approcci di embedding dei nodi esistenti si basano principalmente sull'avvio di passeggiate casuali uniformi da ogni nodo per costruire il contesto di un nodo e poi cercano di rendere la rappresentazione vettoriale del nodo vicina al suo contesto. Tuttavia, gli approcci standard di incorporazione dei nodi non prendono direttamente in considerazione la struttura della comunità di una rete mentre costruiscono il contesto intorno ad ogni nodo. Per alleviare questo, esploriamo due diversi filoni di lavoro. In primo luogo, studiamo l'uso di passeggiate casuali distorte (in particolare, passeggiate basate sulla massima entropia) per ottenere un'incorporazione dei nodi che preservi la centralità, che ipotizziamo possa portare a cluster più efficaci nello spazio incorporato. In secondo luogo, proponiamo un approccio di embedding del nodo consapevole della struttura della comunità in cui incorporiamo l'euristica di partizionamento basata sulla modularità nella funzione obiettivo dell'embedding del nodo. Dimostriamo che il nostro approccio proposto per il rilevamento della comunità supera un certo numero di basi basate sulla modularità così come K-means su uno spazio vettoriale standard embedded (in particolare, node2vec) su una vasta gamma di reti della vita reale di diverse dimensioni e densità.
Questo lavoro presenta un nuovo modello autoregressivo, PointGrow, che genera campioni di nuvole di punti realistici da zero o condizionati da contesti semantici dati. Il nostro modello opera in modo ricorrente, con ogni punto campionato secondo una distribuzione condizionata data dai suoi punti precedentemente generati. Poiché le forme degli oggetti delle nuvole di punti sono tipicamente codificate da dipendenze interpunto a lungo raggio, aumentiamo il nostro modello con moduli di auto-attenzione dedicati per catturare queste relazioni. Un'ampia valutazione dimostra che PointGrow raggiunge prestazioni soddisfacenti sia su compiti di generazione di nuvole di punti incondizionati che condizionati, per quanto riguarda la fedeltà, la diversità e la conservazione semantica.Inoltre, PointGrow condizionato impara un manifold liscio di immagini date dove l'interpolazione della forma 3D e il calcolo aritmetico possono essere eseguiti all'interno.
L'apprendimento per rinforzo e gli algoritmi evolutivi possono essere usati per creare soluzioni di controllo sofisticate.Sfortunatamente spiegare come funzionano queste soluzioni può essere difficile a causa della loro natura di "scatola nera".Inoltre, la natura estesa nel tempo degli algoritmi di controllo spesso impedisce applicazioni dirette di tecniche di spiegabilità usate per algoritmi standard di apprendimento supervisionato.Questo articolo cerca di affrontare la spiegabilità degli algoritmi di controllo blackbox attraverso sei diverse tecniche:1) liste di regole bayesiane,2) Analisi delle funzioni,3) Gradienti integrati in un singolo passo temporale,4) Queste tecniche sono testate su un semplice dominio 2d, dove un rover simulato tenta di navigare attraverso gli ostacoli per raggiungere un obiettivo. Per il controllo, questo rover utilizza una percezione multistrato evoluta che mappa un campo 8d di sensori di ostacoli e obiettivi in un'azione che determina dove dovrebbe andare nel prossimo passo temporale.
Il compito Vision-and-Language Navigation (VLN) comporta che un agente segua istruzioni di navigazione in ambienti sconosciuti fotorealistici. Questo compito impegnativo richiede che l'agente sia consapevole di quale istruzione è stata completata, quale istruzione è necessaria dopo, quale strada percorrere e il suo progresso di navigazione verso l'obiettivo: (1) modulo di co-grounding visivo-testuale per individuare l'istruzione completata in passato, l'istruzione necessaria per l'azione successiva e la prossima direzione di movimento dalle immagini circostanti e (2) monitor di progresso per garantire che l'istruzione a terra rifletta correttamente il progresso della navigazione. Testiamo il nostro agente di auto-monitoraggio su un benchmark standard e analizziamo il nostro approccio proposto attraverso una serie di studi di ablazione che delucidano i contributi dei componenti primari.Utilizzando il nostro metodo proposto, abbiamo fissato il nuovo stato dell'arte con un margine significativo (8% di aumento assoluto del tasso di successo sul set di test non visto).Il codice è disponibile su https://github.com/chihyaoma/selfmonitoring-agent.
Gli ambienti nel Reinforcement Learning (RL) sono di solito solo parzialmente osservabili.Per affrontare questo problema, una possibile soluzione è quella di fornire all'agente informazioni sulle osservazioni passate.Mentre i metodi comuni rappresentano questa storia utilizzando una Rete Neurale Ricorrente (RNN), in questo articolo proponiamo una rappresentazione alternativa che si basa sulla registrazione degli eventi passati osservati in un dato episodio.Ispirati dalla memoria umana, questi eventi descrivono solo importanti cambiamenti nell'ambiente e, nel nostro approccio, sono scoperti automaticamente utilizzando l'auto-supervisione. Valutiamo il nostro metodo di rappresentazione della storia utilizzando due benchmark RL impegnativi: alcuni giochi della suite Atari-57 e l'ambiente 3D Obstacle Tower. Utilizzando questi benchmark mostriamo il vantaggio della nostra soluzione rispetto ai comuni approcci basati su RNN.
La generazione incondizionata di immagini ad alta fedeltà è un benchmark di lunga data per testare le prestazioni dei decodificatori di immagini. I modelli di immagini autoregressivi sono stati in grado di generare incondizionatamente immagini di piccole dimensioni, ma l'estensione di questi metodi a immagini di grandi dimensioni, dove la fedeltà può essere valutata più facilmente, è rimasta un problema aperto. Tra le maggiori sfide ci sono la capacità di codificare il vasto contesto precedente e la difficoltà di imparare una distribuzione che conservi sia la coerenza semantica globale che l'esattezza dei dettagli. Per affrontare la sfida precedente, proponiamo la Subscale Pixel Network (SPN), un'architettura di decodificatore condizionato che genera un'immagine come una sequenza di fette di immagine di uguale dimensione. La SPN cattura in modo compatto le dipendenze spaziali a livello di immagine e richiede una frazione della memoria e del calcolo. Per affrontare la seconda sfida, proponiamo di utilizzare l'upscaling multidimensionale per far crescere un'immagine sia in dimensione che in profondità attraverso fasi intermedie corrispondenti a SPN distinte. Valutiamo gli SPN sulla generazione condizionale di CelebAHQ di dimensioni 256 e di ImageNet da 32 a 128. Raggiungiamo risultati di verosimiglianza allo stato dell'arte in più impostazioni, impostiamo nuovi risultati di benchmark in impostazioni precedentemente inesplorate e siamo in grado di generare ogni campione su larga scala ad alta fedeltà sulla base di entrambi i dataset.
I sistemi dinamici del mondo reale sono spesso costituiti da più sottosistemi stocastici che interagiscono tra di loro. La modellazione e la previsione del comportamento di tali dinamiche non sono generalmente facili, a causa della difficoltà intrinseca nella comprensione delle complicate interazioni ed evoluzioni dei loro costituenti. Questo articolo introduce il modello relazionale dello spazio di stato (R-SSM), un modello gerarchico sequenziale di variabile latente che fa uso di reti neurali a grafo (GNN) per simulare le transizioni di stato congiunte di più oggetti correlati. Permettendo alle GNN di cooperare con SSM, R-SSM fornisce un modo flessibile per incorporare le informazioni relazionali nella modellazione delle dinamiche di multi-oggetto. Suggeriamo inoltre di aumentare il modello con flussi normalizzanti istanziati per variabili casuali indicizzate ai vertici e proponiamo due obiettivi ausiliari contrastivi per facilitare l'apprendimento.L'utilità di R-SSM è valutata empiricamente su serie di dati sintetici e reali.
Il linguaggio naturale è strutturato gerarchicamente: le unità più piccole (ad esempio, le frasi) sono annidate all'interno di unità più grandi (ad esempio, le clausole), Mentre l'architettura LSTM standard permette a diversi neuroni di tracciare informazioni su diverse scale temporali, non ha un bias esplicito verso la modellazione di una gerarchia di costituenti. La nostra nuova architettura ricorrente, ordinata ai neuroni LSTM (ON-LSTM), raggiunge buone prestazioni in quattro diversi compiti: modellazione del linguaggio, parsing non supervisionato, valutazione sintattica mirata e inferenza logica.
Le connessioni di salto hanno reso possibile l'addestramento di reti molto profonde e sono diventate un componente indispensabile in una varietà di architetture neurali. Una spiegazione completamente soddisfacente per il loro successo rimane elusiva. La difficoltà dell'addestramento delle reti profonde è in parte dovuta alle singolarità causate dalla non identificabilità del modello.Diverse singolarità di questo tipo sono state identificate in lavori precedenti:(i) singolarità di sovrapposizione causate dalla simmetria di permutazione dei nodi in un dato strato,(ii) singolarità di eliminazione corrispondenti all'eliminazione, cioè alla (iii) singolarità generate dalla dipendenza lineare dei nodi. Queste singolarità causano collettori degenerati nel paesaggio di perdita che rallentano l'apprendimento. Noi sosteniamo che le connessioni di salto eliminano queste singolarità rompendo la simmetria di permutazione dei nodi, riducendo la possibilità di eliminazione dei nodi e rendendo i nodi meno linearmente dipendenti. Inoltre, per inizializzazioni tipiche, le connessioni saltate allontanano la rete dai "fantasmi" di queste singolarità e scolpiscono il paesaggio intorno ad esse per alleviare il rallentamento dell'apprendimento. Queste ipotesi sono supportate da prove da modelli semplificati, così come da esperimenti con reti profonde allenate su set di dati del mondo reale.
Nell'apprendimento per rinforzo, rappresentazioni efficaci e funzionali hanno il potenziale per accelerare enormemente il progresso dell'apprendimento e risolvere problemi più impegnativi. La maggior parte dei lavori precedenti sull'apprendimento delle rappresentazioni si è concentrata su approcci generativi, imparando rappresentazioni che catturano tutti i fattori sottostanti di variazione nello spazio di osservazione in un modo più distinto o ben ordinato. In questo lavoro, invece, puntiamo ad apprendere rappresentazioni funzionalmente salienti: rappresentazioni che non sono necessariamente complete in termini di cattura di tutti i fattori di variazione nello spazio di osservazione, ma piuttosto mirano a catturare quei fattori di variazione che sono importanti per il processo decisionale - che sono "actionable". Queste rappresentazioni sono consapevoli delle dinamiche dell'ambiente, e catturano solo gli elementi dell'osservazione che sono necessari per il processo decisionale piuttosto che tutti i fattori di variazione, eliminando la necessità di una ricostruzione esplicita. Mostriamo come queste rappresentazioni apprese possano essere utili per migliorare l'esplorazione per problemi di ricompensa sparsi, per permettere l'apprendimento gerarchico di rinforzo a lungo orizzonte, e come rappresentazione di stato per l'apprendimento delle politiche per i compiti a valle.Valutiamo il nostro metodo su una serie di ambienti simulati, e lo confrontiamo con i metodi precedenti per l'apprendimento di rappresentazione, esplorazione e apprendimento gerarchico di rinforzo.
Esploriamo il comportamento di una rete neurale convoluzionale standard in un ambiente che introduce compiti di classificazione in modo sequenziale e richiede alla rete di padroneggiare i nuovi compiti preservando la padronanza dei compiti precedentemente appresi.  Questa impostazione corrisponde a quella che gli studenti umani affrontano quando acquisiscono competenze di dominio, per esempio, quando un individuo legge un libro di testo capitolo per capitolo. Attraverso simulazioni che coinvolgono sequenze di 10 compiti correlati, troviamo motivo di ottimismo sul fatto che le reti scaleranno bene mentre avanzano dall'avere una singola abilità a diventare esperti di dominio. In primo luogo, la facilitazione in avanti - l'apprendimento accelerato del compito n+1 dopo aver appreso n compiti precedenti - cresce con n. In secondo luogo, l'interferenza all'indietro - la dimenticanza dei n compiti precedenti quando si apprende il compito n+1 - diminuisce con n. La facilitazione in avanti è l'obiettivo della ricerca sul metalearning, e la ridotta interferenza all'indietro è l'obiettivo della ricerca sul miglioramento dell'oblio catastrofico.
Dimostriamo un metodo a basso sforzo che costruisce in modo non supervisionato embeddings ottimizzati per il compito a partire da embeddings di parole esistenti per ottenere prestazioni su un compito finale supervisionato, evitando così l'etichettatura aggiuntiva o la costruzione di architetture di modelli più complessi, fornendo invece embeddings specializzate più adatte al compito finale. Inoltre, il metodo può essere utilizzato per stimare approssimativamente se uno specifico tipo di compito finale può essere appreso da, o è rappresentato in, un dato set di dati non etichettati, ad esempio utilizzando compiti di sondaggio pubblicamente disponibili. Valutiamo il nostro metodo per diversi compiti di sondaggio di incorporazione di parole e per dimensione del corpus di formazione di incorporazione - cioè per esplorare il suo uso in impostazioni ridotte (preformazione-risorse).
L'aumento dei dati è comunemente usato per codificare le invarianze nei metodi di apprendimento. Tuttavia, questo processo è spesso eseguito in modo inefficiente, poiché gli esempi artificiali sono creati applicando una serie di trasformazioni a tutti i punti del set di formazione. L'esplosione risultante della dimensione del set di dati può essere un problema in termini di costi di archiviazione e formazione, così come nella selezione e messa a punto del set ottimale di trasformazioni da applicare. In questo lavoro, dimostriamo che è possibile ridurre significativamente il numero di punti di dati inclusi nell'aumento dei dati, pur realizzando la stessa accuratezza e i benefici di invarianza dell'aumento dell'intero set di dati. Proponiamo una nuova serie di politiche di sottocampionamento, basate sull'influenza e la perdita del modello, che possono raggiungere una riduzione del 90% delle dimensioni del set di aumento, mantenendo i guadagni di accuratezza dell'aumento dei dati standard.
Negli ultimi anni un lavoro entusiasmante nei modelli generativi profondi ha prodotto modelli in grado di suggerire nuove molecole organiche generando stringhe, alberi e grafici che rappresentano la loro struttura.Mentre tali modelli sono in grado di generare molecole con proprietà desiderabili, la loro utilità nella pratica è limitata a causa della difficoltà di sapere come sintetizzare queste molecole. Più specificamente, il nostro modello generativo propone un sacchetto di reagenti iniziali (selezionati da un pool di molecole disponibili in commercio) e utilizza un modello di reazione per prevedere come reagiscono insieme per generare nuove molecole. Modellare l'intero processo di costruzione di una molecola durante la generazione offre una serie di vantaggi.In primo luogo, dimostriamo che un tale modello ha la capacità di generare un ampio e diversificato insieme di molecole valide e uniche grazie alle utili distorsioni induttive della modellazione delle reazioni.In secondo luogo, modellare percorsi di sintesi piuttosto che molecole finali offre vantaggi pratici ai chimici che non sono solo interessati a nuove molecole ma anche suggerimenti su percorsi sintetici stabili e sicuri.In terzo luogo, dimostriamo le capacità del nostro modello di risolvere anche problemi di retrosintesi one-step, predicendo un insieme di reagenti che possono produrre un prodotto target.
Le reti neurali profonde sono modelli complessi non lineari utilizzati come strumento di analisi predittiva e hanno dimostrato prestazioni all'avanguardia su molti compiti di classificazione.  Tuttavia, non hanno alcuna capacità intrinseca di riconoscere quando le loro previsioni potrebbero andare male. Ci sono stati diversi sforzi nel recente passato per rilevare gli errori naturali, vale a dire gli input classificati male, ma questi meccanismi pongono ulteriori requisiti energetici.  Per affrontare questo problema, presentiamo una nuova struttura post-hoc per rilevare gli errori naturali in modo efficiente dal punto di vista energetico.  Raggiungiamo questo obiettivo aggiungendo classificatori lineari basati su caratteristiche rilevanti per classe, denominati Relevant features based Auxiliary Cells (RACs).   La tecnica proposta si avvale del consenso tra i RAC aggiunti a pochi strati nascosti selezionati per distinguere gli input classificati correttamente da quelli classificati in modo errato. La fiducia combinata dei RAC viene utilizzata per determinare se la classificazione deve terminare in una fase iniziale. Dimostriamo l'efficacia della nostra tecnica su vari set di dati di classificazione delle immagini come CIFAR10, CIFAR100 e Tiny-ImageNet.I nostri risultati mostrano che per il set di dati CIFAR100 addestrato sulla rete VGG16, i RAC possono rilevare il 46% degli esempi mal classificati insieme al 12% di riduzione di energia rispetto alla rete di base, mentre il 69% degli esempi sono classificati correttamente.
Sono stati sviluppati molti metodi per rappresentare i dati dei grafi di conoscenza, che sfruttano implicitamente la struttura latente a basso rango nei dati per codificare le informazioni note e consentire l'inferenza di fatti sconosciuti.Per prevedere se una relazione esiste tra entità, le loro embeddings sono tipicamente confrontate nello spazio latente seguendo una mappatura specifica per la relazione.Mentre la previsione dei collegamenti è costantemente migliorata, la struttura latente, e quindi perché tali modelli catturano informazioni semantiche, rimane inspiegabile. Per i tipi di relazione identificabili, siamo in grado di prevedere le proprietà e giustificare le prestazioni relative dei principali metodi di rappresentazione dei grafi di conoscenza, compresa la loro capacità, spesso trascurata, di fare previsioni indipendenti.
Molte applicazioni del mondo reale coinvolgono dati di serie temporali multivariati e geo-taggati: in ogni luogo, più sensori registrano le misurazioni corrispondenti, per esempio, il sistema di monitoraggio della qualità dell'aria registra PM2.5, CO, etc. I dati di serie temporali risultanti hanno spesso valori mancanti a causa di interruzioni del dispositivo o errori di comunicazione. Al fine di imputare i valori mancanti, i metodi all'avanguardia sono costruiti su Reti Neurali Ricorrenti (RNN), che elaborano ogni timbro temporale in modo sequenziale, vietando la modellazione diretta della relazione tra timbri temporali distanti.Recentemente, il meccanismo di auto-attenzione è stato proposto per compiti di modellazione di sequenza come la traduzione automatica, superando significativamente RNN perché la relazione tra ogni due timbri temporali può essere modellata esplicitamente. Al fine di catturare congiuntamente l'auto-attenzione attraverso diverse dimensioni (cioè tempo, posizione e misurazioni del sensore) mantenendo la dimensione delle mappe di attenzione ragionevole, proponiamo un nuovo approccio chiamato Cross-Dimensional Self-Attention (CDSA) per elaborare ogni dimensione in modo sequenziale, ma in un modo indipendente dall'ordine. Su tre insiemi di dati del mondo reale, compreso un nostro nuovo set di dati sul traffico di NYC, esperimenti estesi dimostrano la superiorità del nostro approccio rispetto ai metodi allo stato dell'arte sia per l'imputazione che per i compiti di previsione. 
Questo lavoro si concentra sul miglioramento della qualità dei documenti scansionati per migliorare l'output OCR.Creiamo una pipeline di miglioramento dei documenti end-to-end che prende un set di documenti rumorosi e produce quelli puliti.I denoising auto-encoders basati su reti neurali profonde sono addestrati per migliorare la qualità OCR.Addestriamo un modello cieco che funziona su diversi livelli di rumore dei documenti di testo scansionati.I risultati sono mostrati per la rimozione del rumore di sfocatura e filigrana dai documenti scansionati rumorosi.
L'esistenza di esempi avversari, o previsioni errate intenzionali costruite da piccole modifiche agli esempi correttamente previsti, è una delle sfide più significative nella ricerca sulle reti neurali di oggi.Ironicamente, molte nuove difese sono basate su una semplice osservazione - gli stessi input avversari non sono robusti e piccole perturbazioni all'input attaccante spesso recuperano la previsione desiderata. Mentre l'intuizione è piuttosto chiara, una comprensione dettagliata di questo fenomeno manca nella letteratura di ricerca. Questo articolo presenta un'analisi sperimentale completa di quando e perché le difese a perturbazione funzionano e i potenziali meccanismi che potrebbero spiegare la loro efficacia (o inefficacia) in diverse impostazioni.
Non c'è ancora un consenso sulla questione se i metodi di gradiente adattivi come Adam siano più facili da usare rispetto ai metodi di ottimizzazione non adattivi come SGD. In questo lavoro, riempiamo l'importante, ma ambiguo concetto di "facilità d'uso" definendo la sintonizzabilità di un ottimizzatore: quanto è facile trovare buone configurazioni di iperparametri usando la ricerca casuale automatica di iperparametri?  Valutando una varietà di ottimizzatori su un ampio set di set di dati e architetture standard, troviamo che Adam è il più sintonizzabile per la maggior parte dei problemi, specialmente con un basso budget per la sintonizzazione degli iperparametri.
Il problema della fase nella fisica della diffrazione è uno dei più vecchi problemi inversi in tutta la scienza.La difficoltà centrale che qualsiasi approccio per risolvere questo problema inverso deve superare è che metà delle informazioni, cioè la fase del fascio diffratto, è sempre mancante.Nel contesto della microscopia elettronica, il problema della fase è generalmente non lineare e le soluzioni fornite dalle tecniche di recupero della fase sono note per essere approssimazioni povere alla fisica degli elettroni che interagiscono con la materia.Qui, mostriamo che un approccio di apprendimento semi-supervisionato può risolvere efficacemente il problema della fase nella microscopia elettronica/scattering. In particolare, introduciamo una nuova rete neurale profonda (DNN), Y-net, che impara simultaneamente un algoritmo di ricostruzione tramite l'addestramento supervisionato, oltre ad apprendere una regolarizzazione basata sulla fisica tramite l'addestramento non supervisionato. dimostriamo che questo approccio vincolato e semi-supervisionato è un ordine di grandezza più efficiente e accurato rispetto allo stesso modello addestrato in modo puramente supervisionato. inoltre, l'architettura del modello Y-net fornisce una valutazione diretta della coerenza della previsione del modello durante l'inferenza ed è generalmente applicabile al problema della fase in altre impostazioni.
La maggior parte dei metodi di embedding si basano su un modello log-bilineare per prevedere l'occorrenza di una parola in un contesto di altre parole. Qui proponiamo word2net, un metodo che sostituisce la loro parametrizzazione lineare con reti neurali. Per ogni termine nel vocabolario, word2net pone una rete neurale che prende il contesto come input e produce una probabilità di occorrenza.Inoltre, word2net può utilizzare l'organizzazione gerarchica delle sue reti di parole per incorporare ulteriori meta-dati, come le caratteristiche sintattiche, nel modello di incorporazione. Abbiamo studiato word2net con due dataset, una collezione di articoli di Wikipedia e un corpus di discorsi del Senato degli Stati Uniti. Quantitativamente, abbiamo trovato che word2net supera i metodi di embedding popolari nel prevedere le parole tenute fuori e che la condivisione di parametri basati sulla parte del discorso aumenta ulteriormente le prestazioni.
Un approccio emergente è quello di studiare la dinamica degli "stati cerebrali" utilizzando la risonanza magnetica funzionale (fMRI). Finora in letteratura, gli stati cerebrali sono stati tipicamente studiati utilizzando 30 secondi di dati fMRI o più, e non è chiaro fino a che punto gli stati cerebrali possano essere identificati in modo affidabile da serie temporali molto brevi. In questo progetto, abbiamo applicato le reti convoluzionali a grafo (GCN) per decodificare l'attività cerebrale su brevi finestre temporali in un set di dati fMRI di compito, cioè associare una data finestra di serie temporali fMRI con il compito utilizzato. partendo da un grafo cerebrale popolazionale con nodi definiti da una parcellizzazione della corteccia cerebrale e la matrice adiacente estratta dal connectome funzionale, GCN prende una breve serie di volumi fMRI come input, genera rappresentazioni grafiche di alto livello specifiche del dominio, e quindi predice lo stato cognitivo corrispondente. Abbiamo studiato le prestazioni di questa "annotazione di stato cognitivo" GCN nel database Human Connectome Project (HCP), che presenta 21 diverse condizioni sperimentali che abbracciano sette domini cognitivi principali, e dati fMRI ad alta risoluzione temporale. Poiché la batteria di compiti HCP è stata progettata per attivare selettivamente una vasta gamma di reti funzionali specializzate, prevediamo che l'annotazione GCN sia applicabile come modello di base per altre applicazioni di apprendimento di trasferimento, per esempio, adattandosi a nuovi domini di compiti.
Le moderne reti neurali profonde (DNN) richiedono un alto consumo di memoria e grandi carichi computazionali.  Al fine di distribuire gli algoritmi DNN in modo efficiente su dispositivi edge o mobili, sono stati esplorati una serie di algoritmi di compressione DNN, compresa la linea di lavori sui metodi di fattorizzazione.I metodi di fattorizzazione approssimano la matrice di peso di uno strato DNN con la moltiplicazione di due o più matrici a basso rango. Tuttavia, è difficile misurare i ranghi degli strati DNN durante il processo di formazione.I lavori precedenti inducono principalmente il basso rango attraverso approssimazioni implicite o attraverso il costoso processo di decomposizione dei valori singolari (SVD) su ogni passo di formazione.Il primo approccio di solito induce una perdita di precisione elevata mentre il secondo impedisce la fattorizzazione DNN di raggiungere in modo efficiente un alto tasso di compressione. In questo lavoro, proponiamo l'addestramento SVD, che prima applica SVD per decomporre gli strati della DNN e poi esegue l'addestramento sui pesi decomposti full-rank.Per migliorare la qualità dell'addestramento e la convergenza, aggiungiamo la regolarizzazione dell'ortogonalità ai vettori singolari, che assicurano la forma valida di SVD ed evitano che il gradiente svanisca/sploda. Il low-rank è incoraggiato dall'applicazione di regolatori che inducono la sparsità sui valori singolari di ogni strato, mentre la potatura dei valori singolari è applicata alla fine per raggiungere un modello a basso rank. Mostriamo empiricamente che l'addestramento SVD può ridurre significativamente il rank degli strati DNN e raggiungere una maggiore riduzione del carico di calcolo con la stessa precisione, confrontando non solo i precedenti metodi di fattorizzazione ma anche i metodi di potatura dei filtri allo stato dell'arte.
Il recente aumento di popolarità degli algoritmi di apprendimento few-shot ha permesso ai modelli di adattarsi rapidamente a nuovi compiti basati solo su pochi campioni di formazione.I precedenti lavori di apprendimento few-shot si sono concentrati principalmente sulla classificazione e sull'apprendimento di rinforzo. Il nostro modello si basa sull'idea che il grado di libertà della funzione sconosciuta può essere significativamente ridotto se essa viene rappresentata come una combinazione lineare di un insieme di funzioni base appropriate. Progettiamo una rete Feature Extractor per codificare le funzioni di base per una distribuzione di compiti, e un Weights Generator per generare il vettore di pesi per un nuovo compito. Mostriamo che il nostro modello supera lo stato attuale dei metodi di meta-apprendimento in vari compiti di regressione.
La maggior parte dei dataset di classificazione e segmentazione presuppone uno scenario a mondo chiuso in cui le previsioni sono espresse come distribuzione su un set predeterminato di classi visive, ma tale presupposto implica inevitabili e spesso impercettibili fallimenti in presenza di input fuori distribuzione (OOD). Questi fallimenti sono destinati ad accadere nella maggior parte delle applicazioni della vita reale poiché le ontologie visive attuali sono lontane dall'essere complete.Proponiamo di affrontare questo problema attraverso il rilevamento discriminatorio dei pixel OOD nei dati di input.Diverso dai recenti approcci, evitiamo di portare qualsiasi decisione osservando solo il dataset di allenamento del modello primario addestrato per risolvere il compito di visione artificiale desiderato. Invece, addestriamo un modello OOD dedicato che discrimina il set di allenamento primario da un set di dati di "sfondo" molto più grande che approssima la varietà del mondo visivo.Eseguiamo i nostri esperimenti su immagini naturali ad alta risoluzione in una configurazione di predizione densa.Usiamo diversi set di dati di guida stradale come nostra distribuzione di formazione, mentre approssimiamo la distribuzione di sfondo con il set di dati ILSVRC. Valutiamo il nostro approccio sul test WildDash, che è attualmente l'unico dataset di test pubblico con immagini fuori distribuzione.I risultati ottenuti mostrano che l'approccio proposto riesce a identificare i pixel fuori distribuzione mentre supera i lavori precedenti con un ampio margine.
Le recenti tecniche di quantizzazione della rete quantizzano ogni kernel di peso in uno strato convoluzionale in modo indipendente per una maggiore precisione di inferenza, dal momento che i kernel di peso in uno strato presentano diverse varianti e quindi hanno diverse quantità di ridondanza. La larghezza di bit di quantizzazione o il numero di bit (QBN) decide direttamente l'accuratezza dell'inferenza, la latenza, l'energia e l'overhead dell'hardware.Per ridurre efficacemente la ridondanza e accelerare le inferenze CNN, i vari kernel di peso dovrebbero essere quantizzati con QBNs diversi.Tuttavia, gli impianti precedenti usano solo un QBN per quantizzare ogni strato convoluzionale o l'intera CNN, perché lo spazio di progettazione della ricerca di un QBN per ogni kernel di peso è troppo grande. L'euristica artigianale della ricerca QBN kernel-wise è così sofisticata che gli esperti di dominio possono ottenere solo risultati sub-ottimali. è difficile anche per gli agenti basati sull'apprendimento di rinforzo profondo (DRL) DDPG trovare una configurazione QBN kernel-wise che possa raggiungere una ragionevole precisione di inferenza. In questo documento, proponiamo una tecnica di quantizzazione della rete basata su kernel gerarchico-DRL, AutoQ, per cercare automaticamente un QBN per ogni kernel di peso e scegliere un altro QBN per ogni strato di attivazione.Rispetto ai modelli quantizzati dagli schemi basati su DRL allo stato dell'arte, in media, gli stessi modelli quantizzati da AutoQ riducono la latenza di inferenza del 54,06% e diminuiscono il consumo di energia di inferenza del 50,69%, pur ottenendo la stessa precisione di inferenza.
I recenti sistemi di visual analytics fanno uso di più modelli di machine learning per adattarsi meglio ai dati rispetto ai tradizionali sistemi a modello singolo e predefinito.Tuttavia, mentre i sistemi di visual analytics multi-modello possono essere efficaci, la loro complessità aggiunta pone problemi di usabilità, poiché gli utenti devono interagire con i parametri di più modelli.Inoltre, l'avvento di vari algoritmi di modelli e iperparametri associati crea uno spazio esaustivo di modelli da cui campionare i modelli.Questo pone la complessità di navigare questo spazio di modelli per trovare il modello giusto per i dati e l'attività. In questo documento, presentiamo Gaggle, un sistema analitico visivo multi-modello che consente agli utenti di navigare in modo interattivo nello spazio del modello. Traducendo ulteriormente le interazioni dell'utente in inferenze, Gaggle semplifica il lavoro con più modelli trovando automaticamente il modello migliore dallo spazio del modello ad alta densità per supportare vari compiti dell'utente.Attraverso uno studio qualitativo dell'utente, mostriamo come il nostro approccio aiuta gli utenti a trovare un modello migliore per un compito di classificazione e classificazione.I risultati dello studio confermano che Gaggle è intuitivo e facile da usare, supportando la navigazione interattiva dello spazio del modello e la selezione automatica del modello senza richiedere alcuna competenza tecnica da parte degli utenti.
Tuttavia, il problema della rappresentazione del testo cinese ostacola ancora il miglioramento della classificazione del testo cinese, in particolare la polifonia e l'omofonia nei social media. Per farvi fronte efficacemente, proponiamo una nuova struttura, l'estrattore, basata sui meccanismi di attenzione e progettiamo nuove reti di attenzione chiamate Extractor-attention network (EAN).A differenza della maggior parte dei lavori precedenti, EAN usa una combinazione di un codificatore di parole e un codificatore di caratteri Pinyin invece di un singolo codificatore. Inoltre, rispetto ai metodi di codificatore ibrido, EAN ha un'architettura di combinazione più complessa e più strutture di parametri di riduzione.Quindi, EAN può sfruttare una grande quantità di informazioni che provengono da multi-input e allevia i problemi di efficienza.Il modello proposto raggiunge lo stato dell'arte dei risultati su 5 grandi set di dati per la classificazione del testo cinese.
I recenti progressi nell'apprendimento dalle dimostrazioni (LfD) con reti neurali profonde hanno permesso l'apprendimento di complesse abilità robotiche che coinvolgono la percezione ad alta dimensione come gli input di immagini grezze. In pratica, tuttavia, è più efficiente per un insegnante dimostrare una moltitudine di compiti senza un'attenta impostazione dei compiti, l'etichettatura e l'ingegneria. Purtroppo in questi casi, le tecniche tradizionali di apprendimento per imitazione non riescono a rappresentare la natura multi-modale dei dati e spesso risultano in un comportamento sub-ottimale. Il nostro approccio si basa su una rete neurale profonda stocastica (SNN), che rappresenta l'intenzione sottostante alla dimostrazione come un'attivazione stocastica nella rete. Presentiamo un algoritmo efficiente per addestrare le SNN, e per l'apprendimento con input di visione, proponiamo anche un'architettura che associa l'intenzione a un modulo di attenzione stocastica.
L'interpretabilità delle reti neurali è diventata cruciale per le loro applicazioni nel mondo reale per quanto riguarda l'affidabilità e l'attendibilità.I metodi di generazione di spiegazioni esistenti di solito forniscono caratteristiche importanti segnando i loro contributi individuali alla previsione del modello e ignorano le interazioni tra le caratteristiche, che alla fine forniscono una rappresentazione di un sacco di parole come spiegazione.Nell'elaborazione del linguaggio naturale, questo tipo di spiegazioni è impegnativo per l'utente umano per capire il significato di una spiegazione e tracciare la connessione tra spiegazione e previsione del modello, soprattutto per testi lunghi. Il metodo proposto è valutato con tre classificatori neurali, LSTM, CNN e BERT, su due serie di dati di classificazione del testo di riferimento. Le spiegazioni generate sono valutate sia da misure di valutazione automatica che da valutatori umani. Gli esperimenti mostrano l'efficacia del metodo proposto nel fornire spiegazioni che sono sia fedeli ai modelli che comprensibili per gli esseri umani.
In questo articolo, riduciamo questo costo sfruttando il fatto che l'importanza delle caratteristiche calcolate dagli strati convoluzionali è altamente dipendente dall'input, e proponiamo il feature boosting e la soppressione (FBS), un nuovo metodo per amplificare in modo predittivo i canali convoluzionali salienti e saltare quelli non importanti a tempo di esecuzione.FBS introduce piccole connessioni ausiliarie agli strati convoluzionali esistenti. In contrasto con i metodi di potatura dei canali che rimuovono permanentemente i canali, conserva le strutture di rete complete e accelera la convoluzione saltando dinamicamente i canali di input e di output non importanti. Le reti amplificate con FBS sono addestrate con la convenzionale discesa del gradiente stocastico, rendendola facilmente disponibile per molte CNN all'avanguardia. Confrontiamo FBS ad una gamma di schemi esistenti di potatura della scanalatura e di esecuzione dinamica e dimostriamo i grandi miglioramenti sulla classificazione di ImageNet. Gli esperimenti mostrano che FBS puÃ² fornire rispettivamente 5Ã- e 2Ã- risparmi nel calcolo su VGG-16 e ResNet-18, entrambi con meno di 0.6% perdita di esattezza top-5.
I nostri risultati indicano che le reti neurali convoluzionali possono funzionare senza alcuna perdita di precisione a meno dello 0,5% di densità di connessione dello strato di classificazione, o meno del 5% di densità di connessione complessiva della rete. Inoltre indaghiamo gli effetti della predefinizione della sparsità delle reti con solo strati completamente connessi.Sulla base della nostra tecnica di sparsificazione, introduciamo la metrica `scatter' per caratterizzare la qualità di un particolare modello di connessione.Come prova del concetto, mostriamo risultati su CIFAR, MNIST e un nuovo dataset sulla classificazione dei simboli del codice Morse, che evidenzia alcune tendenze interessanti e i limiti dei modelli di connessione sparsi.
Le reti neurali profonde sono vulnerabili agli esempi avversari, che diventa uno dei problemi più importanti nello sviluppo dell'apprendimento profondo.Mentre molti sforzi sono stati fatti negli ultimi anni, è di grande importanza eseguire valutazioni corrette e complete dell'attacco avversario e degli algoritmi di difesa.In questo documento, stabiliamo un benchmark completo, rigoroso e coerente per valutare la robustezza avversaria sui compiti di classificazione delle immagini. Dopo aver esaminato brevemente molti metodi di attacco e di difesa rappresentativi, eseguiamo esperimenti su larga scala con due curve di robustezza come criteri di valutazione equa per comprendere appieno le prestazioni di questi metodi.Sulla base dei risultati della valutazione, traiamo diversi risultati importanti e forniamo spunti per la ricerca futura.
Proponiamo una modifica alle Reti Neurali Artificiali (RNA) tradizionali, che fornisce alle RNA nuove attitudini motivate dai neuroni biologici.  I neuroni biologici lavorano molto più che sommare linearmente gli ingressi sinaptici e poi trasformare l'informazione integrata.  Un neurone biologico cambia le modalità di fuoco in base a fattori periferici (ad esempio, i neuromodulatori) e intrinseci.  La nostra modifica collega un nuovo tipo di nodi ANN, che imitano la funzione dei neuromodulatori biologici e sono chiamati modulatori, per consentire ad altri nodi ANN tradizionali di regolare le loro sensibilità di attivazione in run-time sulla base dei loro modelli di input.  In questo modo, permettiamo alla pendenza della funzione di attivazione di essere dipendente dal contesto.  Questa modifica produce miglioramenti statisticamente significativi rispetto ai nodi ANN tradizionali nel contesto delle Reti Neurali Convoluzionali e delle reti a memoria lunga a breve termine.
In questo lavoro, studiamo come il quadro di pretrain-finetune su larga scala cambi il comportamento di un generatore di linguaggio neurale. Ci concentriamo sul modello di trasformatore encoder-decoder per il compito di generazione di risposte di dialogo a dominio aperto. Troviamo che dopo il fine-tuning standard, il modello dimentica importanti abilità di generazione del linguaggio acquisite durante il pretraining su larga scala. Adottando il concetto di miscelazione dei dati, proponiamo una strategia intuitiva di messa a punto denominata "mix-review". Troviamo che il mix-review regolarizza efficacemente il processo di messa a punto, e il problema della dimenticanza è ampiamente alleviato.
La combinazione di modelli di conoscenza del dominio con modelli neurali è stata una sfida.  I modelli neurali addestrati end-to-end spesso danno risultati migliori (errore quadratico medio più basso) rispetto ai modelli di conoscenza del dominio o alle combinazioni dominio/neurale, e la combinazione è inefficiente da addestrare.  In questo articolo, dimostriamo che componendo modelli di dominio con modelli di apprendimento automatico, utilizzando set di test estrapolativi e invocando funzioni obiettivo di decorrelazione, creiamo modelli che possono prevedere sistemi più complessi. I modelli sono interpretabili, estrapolativi, efficienti dal punto di vista dei dati e catturano un comportamento prevedibile ma complesso non stocastico, come i gradi di libertà non modellati e il rumore sistemico della misurazione.  Applichiamo questo paradigma di modellazione migliorato a diversi sistemi simulati e a un sistema fisico reale nel contesto dell'identificazione del sistema.   Diversi modi di comporre modelli di dominio con modelli neurali sono esaminati per serie temporali, boosting, bagging e autocodifica su vari sistemi di varia complessità e non linearità.  Anche se questo lavoro è preliminare, mostriamo che la capacità di combinare i modelli è una direzione molto promettente per la modellazione neurale.
In questo lavoro, proponiamo Scoring-Aggregating-Planning (SAP), una struttura che può apprendere priori semantici e dinamici indipendenti dal compito da interazioni di qualità arbitraria così come le corrispondenti ricompense sparse e poi pianificare su compiti non visti in condizioni di zero-shot. La struttura trova una funzione di punteggio neurale per lo stato regionale locale e le coppie di azioni che possono essere aggregate per approssimare la qualità di una traiettoria completa; inoltre, un modello dinamico che viene appreso con auto-supervisione può essere incorporato per la pianificazione. Molti dei lavori precedenti che sfruttano i dati interattivi per l'apprendimento delle politiche hanno bisogno di massicce interazioni ambientali on-policy o presuppongono l'accesso a dati esperti, mentre noi possiamo raggiungere un obiettivo simile con puri dati imperfetti off-policy.
L'algoritmo di inferenza basato su particelle è un metodo promettente per generare in modo efficiente campioni per una distribuzione di destinazione intrattabile aggiornando iterativamente un insieme di particelle.Come esempio evidente, Stein variational gradient descent (SVGD) fornisce un aggiornamento deterministico e computazionalmente efficiente, ma è noto per sottostimare la varianza in alte dimensioni, il cui meccanismo è poco compreso.In questo lavoro esploriamo una connessione tra SVGD e algoritmo di inferenza basato su MMD attraverso il lemma di Stein. Confrontando le due regole di aggiornamento, identifichiamo la fonte di bias in SVGD come una combinazione di alta varianza e bias deterministico, e dimostriamo empiricamente che la rimozione di entrambi i fattori porta a una stima accurata della varianza.Inoltre, per l'apprendimento di target gaussiani ad alta dimensione, deriviamo analiticamente la varianza convergente per entrambi gli algoritmi, e confermiamo che solo SVGD soffre della "maledizione della dimensionalità".
Descriviamo un approccio per comprendere le proprietà di generalizzazione peculiari e controintuitive delle reti neurali profonde.  L'approccio implica andare oltre i quadri teorici di controllo della capacità nel caso peggiore che sono stati popolari nell'apprendimento automatico negli ultimi anni per rivisitare vecchie idee nella meccanica statistica delle reti neurali.  All'interno di questo approccio, presentiamo un modello prototipico Very Simple Deep Learning (VSDL), il cui comportamento è controllato da due parametri di controllo, uno che descrive una quantità effettiva di dati, o carico, sulla rete (che diminuisce quando il rumore viene aggiunto all'input), e uno con un'interpretazione della temperatura effettiva (che aumenta quando gli algoritmi vengono fermati in anticipo).  Usando questo modello, descriviamo come un'applicazione molto semplice delle idee della teoria della meccanica statistica della generalizzazione fornisca una forte descrizione qualitativa dei risultati empirici recentemente osservati riguardo all'incapacità delle reti neurali profonde di non sovradimensionare i dati di allenamento, l'apprendimento discontinuo e le transizioni nette nelle proprietà di generalizzazione degli algoritmi di apprendimento, ecc.
I calcoli per la funzione softmax nei modelli di rete neurale sono costosi quando il numero di classi di output è grande, il che può diventare un problema significativo sia nella formazione che nell'inferenza per tali modelli. In questo articolo, presentiamo Doubly Sparse Softmax (DS-Softmax), Sparse Mixture of Sparse of Sparse Experts, per migliorare l'efficienza dell'inferenza softmax. Ogni esperto è responsabile di un sottoinsieme appreso dello spazio delle classi di uscita e ogni classe di uscita appartiene solo a un piccolo numero di questi esperti.Durante l'inferenza, il nostro metodo individua rapidamente l'esperto più probabile per calcolare softmax su piccola scala.Il nostro metodo è basato sull'apprendimento e non richiede alcuna conoscenza dello spazio di partizione delle classi di uscita a priori.Valutiamo empiricamente il nostro metodo su diversi compiti del mondo reale e dimostriamo che possiamo ottenere significative riduzioni di calcolo senza perdita di prestazioni.
I modelli di apprendimento automatico supervisionati per applicazioni di computer vision di alto valore come la classificazione delle immagini mediche spesso richiedono grandi set di dati etichettati da esperti di dominio, che sono lenti da raccogliere, costosi da mantenere e statici rispetto ai cambiamenti nella distribuzione dei dati. In questo contesto, valutiamo l'utilità della supervisione osservazionale, dove sfruttiamo i segnali raccolti passivamente come il tracciamento degli occhi o i dati di "sguardo", per ridurre la quantità di dati etichettati a mano necessari per la formazione del modello. In particolare, sfruttiamo le informazioni di sguardo per supervisionare direttamente un livello di attenzione visiva, penalizzando il disaccordo tra le regioni spaziali che l'etichettatore umano ha guardato piÃ¹ a lungo e quelle che influenzano piÃ¹ pesantemente l'output del modello. Presentiamo la prova che vincolare il modello in questo modo puÃ² ridurre il numero di esempi etichettati necessari per raggiungere un determinato livello di prestazioni fino al 50%, e che le informazioni di sguardo sono piÃ¹ utili nei compiti piÃ¹ difficili.
Combinando i modelli neurali non lineari di message-passing (ad esempio Graph Isomorphism Networks, GraphSAGE, ecc.) con metodi di correzione delle perdite, presentiamo un approccio tollerante al rumore per il compito di classificazione dei grafi e i nostri esperimenti dimostrano che l'accuratezza del test può essere migliorata sotto l'impostazione artificiale simmetrica rumorosa.
Attraverso molti progressi recenti nell'apprendimento della rappresentazione del grafico, le prestazioni ottenute sui compiti che coinvolgono dati strutturati a grafo sono aumentate sostanzialmente negli ultimi anni---principalmente sui compiti che coinvolgono le previsioni a livello di nodo. L'impostazione dei compiti di predizione su interi grafi (come la predizione delle proprietà per una molecola o la predizione degli effetti collaterali per un farmaco), tuttavia, si rivela più impegnativa, poiché l'algoritmo deve combinare le prove su diverse patch strutturalmente rilevanti del grafico in una singola predizione. La maggior parte dei lavori precedenti tenta di predire queste proprietà a livello di grafico considerando solo un grafico alla volta - non permettendo al discente di sfruttare direttamente le somiglianze strutturali e i motivi tra i grafi. Qui proponiamo una configurazione in cui una rete neurale a grafo riceve coppie di grafi in una volta sola, e la estendiamo con uno strato co-attenzionale che permette alle rappresentazioni dei nodi di scambiare facilmente informazioni strutturali tra di loro.Mostriamo prima che tale configurazione fornisce benefici naturali su un compito di classificazione a coppie di grafi (previsione di interazione farmaco-farmaco), e poi ci espandiamo a una configurazione di regressione a grafo più generica: migliorando le previsioni su QM9, un benchmark standard di previsione molecolare.La nostra configurazione è flessibile, potente e non fa assunzioni sulle proprietà del dataset sottostante, oltre a prevedere l'esistenza di più grafi di allenamento.
In questo articolo studiamo la didascalia delle immagini come un addestramento GAN condizionale, proponendo sia un didascalizzatore LSTM consapevole del contesto che un discriminatore co-attentivo, che impone l'allineamento semantico tra immagini e didascalie: Self-critical Sequence Training (SCST) e Gumbel Straight-Through (ST) e dimostriamo che SCST mostra un comportamento del gradiente più stabile e risultati migliori rispetto a Gumbel ST.
Presentiamo Newtonian Monte Carlo (NMC), un metodo per migliorare la convergenza Markov Chain Monte Carlo (MCMC) analizzando i gradienti di primo e secondo ordine della densità di destinazione per determinare una densità di proposta adatta in ogni punto. Un passo troppo piccolo richiederà un gran numero di passi per convergere, mentre un passo molto grande causerà il superamento della regione ad alta densità.NMC è simile all'aggiornamento Newton-Raphson nell'ottimizzazione dove il gradiente del secondo ordine è usato per scalare automaticamente la dimensione del passo in ogni dimensione.Tuttavia, il nostro obiettivo non è quello di trovare un massimo ma invece di trovare una densità parametrizzata che può corrispondere meglio alla curvatura locale della densità di destinazione.  Come ulteriore miglioramento dei metodi del primo ordine, mostriamo che le variabili casuali con supporti vincolati non hanno bisogno di essere trasformate prima di fare un passo di gradiente. NMC abbina direttamente le variabili casuali vincolate a una densità proposta con lo stesso supporto, mantenendo così intatta la curvatura della densità di destinazione. Dimostriamo l'efficienza di NMC su una serie di domini diversi: per modelli statistici in cui il priore è coniugato alla probabilità, il nostro metodo recupera il posteriore in modo abbastanza banale in un solo passo; tuttavia, mostriamo anche risultati su modelli non coniugati abbastanza grandi, dove NMC si comporta meglio dei metodi adattivi del primo ordine come NUTS o altri metodi di inferenza scalabili inesatti come Stochastic Variational Inference o bootstrapping.
Neural Tangents è una libreria progettata per consentire la ricerca sulle reti neurali a larghezza infinita e fornisce un'API di alto livello per specificare architetture di reti neurali complesse e gerarchiche. Queste reti possono essere addestrate e valutate sia a larghezza finita, come al solito, sia nel loro limite di larghezza infinita. Le reti a larghezza infinita possono essere addestrate analiticamente usando l'inferenza bayesiana esatta o usando la discesa a gradiente tramite il kernel Neural Tangent; inoltre, Neural Tangents fornisce strumenti per studiare le dinamiche di addestramento a discesa a gradiente di reti ampie ma finite sia nello spazio delle funzioni sia nello spazio dei pesi. L'intera libreria funziona out-of-the-box su CPU, GPU, o TPU.Tutti i calcoli possono essere automaticamente distribuiti su più acceleratori con una scalabilità quasi lineare nel numero di dispositivi. Neural Tangents è disponibile all'indirizzo https://www.github.com/google/neural-tangentsWe e fornisce anche un notebook Colab interattivo all'indirizzo https://colab.sandbox.google.com/github/google/neural-tangents/blob/master/notebooks/neural_tangents_cookbook.ipynb
Le reti neurali profonde hanno ottenuto un grande successo nei compiti di classificazione durante gli ultimi anni. Tuttavia, uno dei problemi principali per il percorso verso l'intelligenza artificiale è l'incapacità delle reti neurali di rilevare accuratamente i campioni da distribuzioni di classi nuove e quindi, la maggior parte degli algoritmi di classificazione esistenti presuppongono che tutte le classi siano note prima della fase di formazione. In questo lavoro, proponiamo una metodologia per l'addestramento di una rete neurale che le permette di rilevare in modo efficiente gli esempi fuori distribuzione (OOD) senza compromettere gran parte della sua accuratezza di classificazione sugli esempi di test da classi note. Sulla base della tecnica Outlier Exposure (OE), proponiamo una nuova funzione di perdita che raggiunge risultati allo stato dell'arte nella rilevazione di out-of-distribution con OE sia su immagini che su compiti di classificazione del testo; inoltre, il modo in cui questo metodo è stato costruito lo rende adatto all'addestramento di qualsiasi algoritmo di classificazione che si basa su metodi di Maximum Likelihood.
La navigazione è cruciale per il comportamento animale e si presume che richieda una rappresentazione interna dell'ambiente esterno, denominata mappa cognitiva. La forma precisa di questa rappresentazione è spesso considerata come una rappresentazione metrica dello spazio. Una rappresentazione interna, tuttavia, è giudicata in base al suo contributo alle prestazioni su un dato compito, e può quindi variare tra diversi tipi di compiti di navigazione. Qui addestriamo una rete neurale ricorrente che controlla un agente che esegue diversi compiti di navigazione in un ambiente semplice. Per concentrarci sulle rappresentazioni interne, abbiamo diviso l'apprendimento in una fase di pre-addestramento indipendente dal compito che modifica la connettività interna e una fase di apprendimento Q specifica del compito che controlla l'uscita della rete. Mostriamo che il pre-addestramento modella il paesaggio di attrazione delle reti, portando a un attrattore continuo, ad attrattori discreti o a uno stato disordinato. Queste strutture inducono una distorsione nella fase di Q-Learning, portando a un modello di prestazioni attraverso i compiti corrispondenti a regolarità metriche e topologiche. I nostri risultati mostrano che, nelle reti ricorrenti, la distorsione induttiva prende la forma di paesaggi di attrazione - che possono essere modellati dal pre-addestramento e analizzati con metodi di sistemi dinamici.  
La verifica formale dei modelli di apprendimento automatico ha attirato l'attenzione di recente, e sono stati fatti progressi significativi sulla dimostrazione di proprietà semplici come la robustezza a piccole perturbazioni delle caratteristiche di input.In questo contesto, è stato anche osservato che piegare la procedura di verifica nella formazione rende più facile addestrare modelli verificabilmente robusti. In questo articolo, estendiamo l'applicabilità dell'addestramento verificato estendendolo a (1) architetture di reti neurali ricorrenti e (2) specifiche complesse che vanno oltre la semplice robustezza avversaria, in particolare specifiche che catturano proprietà temporali come richiedere che un robot visiti periodicamente una stazione di ricarica o che un modello linguistico produca sempre frasi di lunghezza limitata.Gli esperimenti mostrano che mentre i modelli addestrati usando l'addestramento standard spesso violano le specifiche desiderate, il nostro metodo di addestramento verificato produce modelli che sia eseguono bene (in termini di errore di prova o ricompensa) e possono essere dimostrati di essere provabilmente coerenti con le specifiche.
Le reti neurali (NN) hanno raggiunto prestazioni allo stato dell'arte in molti compiti nei domini delle immagini, del parlato e del testo. Tale grande successo è dovuto principalmente alla progettazione di strutture speciali per adattarsi a particolari modelli di dati, come CNN che cattura la località spaziale e RNN che modella la dipendenza sequenziale.Essenzialmente, queste specifiche NN ottengono buone prestazioni sfruttando la conoscenza precedente sui dati del dominio corrispondente. Poiché non ci sono modelli condivisi tra questi diversi dati tabulari, è difficile progettare strutture specifiche per adattarle tutte.Senza un'attenta progettazione dell'architettura basata sulla conoscenza del dominio, è piuttosto impegnativo per NN raggiungere prestazioni soddisfacenti in questi domini di dati tabulari.Per colmare la lacuna di NN nell'apprendimento dei dati tabulari, proponiamo una soluzione di rete neurale universale, chiamata TabNN, per derivare architetture NN efficaci per i dati tabulari in tutti i tipi di compiti automaticamente.In particolare, il design di TabNN segue due principi: \Poiché GBDT ha empiricamente dimostrato la sua forza nella modellazione dei dati tabulari, usiamo GBDT per alimentare l'implementazione di TabNN. Analisi sperimentali complete su una varietà di set di dati tabulari dimostrano che TabNN può raggiungere prestazioni molto migliori di molte soluzioni di base.
Le basi di conoscenza (KBs) stanno diventando sempre più grandi, rade e probabilistiche.Queste KBs sono usate tipicamente per eseguire le inferenze di query e l'estrazione di regole.Ma la loro efficacia è solo alta quanto la loro completezza.Efficientemente utilizzando KBs incompleti rimane una sfida importante come le tecniche correnti di completamento di KB o non prendono in considerazione l'incertezza inerente associata con ogni tupla di KB o non scala a grande KBs.Probabilistic che impara la regola non solo considera la probabilità di ogni tupla di KB ma inoltre affronta il problema di completamento di KB in un modo spiegabile. Per qualsiasi KB probabilistica data, impara le regole probabilistiche di primo ordine dalle sue relazioni per identificare i modelli interessanti.Ma, le tecniche probabilistiche correnti che imparano la regola effettuano il grounding per fare l'inferenza probabilistica per la valutazione delle regole del candidato.Non scala bene a grande KBs come la complessità di tempo di inferenza usando il grounding è esponenziale sopra la dimensione del KB.In questa carta, presentiamo SafeLearner -- una soluzione scalabile al completamento probabilistico di KB che effettua l'apprendimento probabilistico della regola usando l'inferenza probabilistica sollevata -- come metodo più veloce invece di grounding. Abbiamo confrontato SafeLearner con lo stato dell'arte dell'apprendimento probabilistico ProbFOIL+ e con il suo contemporaneo deterministico AMIE+ su KB probabilistiche standard di NELL (Never-Ending Language Learner) e Yago. I nostri risultati dimostrano che SafeLearner è scalabile quanto AMIE+ quando apprende regole semplici ed è anche significativamente più veloce di ProbFOIL+.
Gli sforzi recenti nel Dialogue State Tracking (DST) per i dialoghi orientati ai compiti sono progrediti verso approcci basati sul vocabolario aperto o sulla generazione, in cui i modelli possono generare candidati al valore degli slot dalla storia del dialogo stesso.Questi approcci hanno mostrato un buon guadagno in termini di prestazioni, specialmente in domini di dialogo complicati con valori dinamici degli slot: (1) non permettono ai modelli di imparare esplicitamente i segnali attraverso i domini e gli slot per rilevare potenziali dipendenze tra le coppie \testo{(dominio, slot)}; e (2) i modelli esistenti seguono approcci auto-regressivi che incorrono in un alto costo temporale quando il dialogo si evolve su più domini e più turni. In questo articolo, proponiamo una nuova struttura di Non-Autoregressive Dialog State Tracking (NADST) che può tenere conto delle potenziali dipendenze tra i domini e gli slot per ottimizzare i modelli verso una migliore previsione degli stati di dialogo come un insieme completo piuttosto che slot separati. In particolare, la natura non autoregressiva del nostro metodo non solo permette la decodifica in parallelo per ridurre significativamente la latenza del DST per la generazione di risposte di dialogo in tempo reale, ma anche di rilevare le dipendenze tra gli slot a livello di token oltre allo slot e al livello di dominio. I nostri risultati empirici mostrano che il nostro modello raggiunge l'accuratezza congiunta allo stato dell'arte in tutti i domini sul corpus MultiWOZ 2.1, e la latenza del nostro modello è un ordine di grandezza inferiore al precedente stato dell'arte man mano che la storia del dialogo si estende nel tempo.
L'operazione di zoom 3D è la traslazione positiva della telecamera sull'asse Z, perpendicolare al piano dell'immagine; al contrario, lo zoom ottico cambia la lunghezza focale e lo zoom digitale è usato per ingrandire una certa regione di un'immagine alle dimensioni dell'immagine originale. Un quadro non supervisionato è conveniente, poiché è un compito impegnativo ottenere un set di dati 3D-zoom di scene naturali a causa della necessità di attrezzature speciali per garantire che il movimento della telecamera sia limitato all'asse Z. Inoltre, gli oggetti nelle scene non dovrebbero muoversi quando vengono catturati, il che ostacola la costruzione di un grande set di dati di scene all'aperto. Presentiamo un nuovo quadro non supervisionato per imparare a generare versioni arbitrariamente 3D-zoom di una singola immagine, senza richiedere una verità di base 3D-zoom, chiamato Deep 3D-Zoom Net. La Deep 3D-Zoom Net incorpora le seguenti caratteristiche:(i) apprendimento di trasferimento da una rete di stima della disparità pre-addestrata tramite una perdita di ricostruzione della retroproiezione;(ii) un'architettura di rete completamente convoluzionale che modella il rendering basato sulla profondità dell'immagine (DIBR), tenendo conto dei dettagli ad alta frequenza senza la necessità di stimare la disparità intermedia; e(iii) incorporando una rete discriminatrice che agisce come una penalità senza riferimento per le aree rese innaturalmente. Anche se non c'è una linea di base per confrontare equamente i nostri risultati, il nostro metodo supera le precedenti ricerche di sintesi della vista in termini di aspetto realistico su grandi baseline di telecamere. Abbiamo eseguito esperimenti approfonditi per verificare l'efficacia del nostro metodo sui dataset KITTI e Cityscapes.
Il teorema di approssimazione universale, in una delle sue versioni più generali, dice che se consideriamo solo funzioni di attivazione continue Ïƒ, allora una rete neurale feedforward standard con uno strato nascosto è in grado di approssimare qualsiasi funzione continua multivariata f a qualsiasi soglia di approssimazione data Îµ, se e solo se Ïƒ non è polinomiale.In questo articolo, diamo una prova algebrica diretta del teorema. In particolare, se X in R^n è compatto, allora una rete neurale con n unità di input, m unità di output e un singolo strato nascosto con {n+d scelgono d} unità nascoste (indipendenti da m e Îµ), può approssimare uniformemente qualsiasi funzione polinomiale f:X -> R^m il cui grado totale è al massimo d per ciascuna delle sue m funzioni coordinate. Nel caso generale in cui f sia una qualsiasi funzione continua, dimostriamo che esiste un certo N in O(Îµ^{-n}) (indipendente da m), tale che N unità nascoste sarebbero sufficienti per approssimare f. Mostriamo inoltre che questa proprietà di approssimazione uniforme (UAP) è ancora valida anche sotto condizioni apparentemente forti imposte sui pesi, evidenziando diverse conseguenze: (i) Per qualsiasi Î´ > 0, la UAP è ancora valida se limitiamo tutti i pesi non bias w nell'ultimo strato a soddisfare |w| < Î´. (ii) Esiste qualche Î">0 (che dipende solo da f e Ïƒ), tale che l'UAP vale ancora se limitiamo tutti i pesi non-bias w nel primo strato a soddisfare |w|>Î".(iii) Se i pesi non-bias nel primo strato sono *fissi* e scelti a caso da un intervallo adatto, allora l'UAP vale con probabilità 1.
In questo articolo, progettiamo una struttura generica per l'apprendimento di un modello di classificazione del testo robusto che raggiunga un'accuratezza paragonabile ai modelli standard completi sotto vincoli di budget per i test, adottando un approccio diverso dai metodi esistenti e imparando ad eliminare dinamicamente una grande frazione di parole non importanti tramite un selettore a bassa complessità in modo che il classificatore ad alta complessità debba elaborare solo una piccola frazione di parole importanti. Inoltre, proponiamo un nuovo metodo di aggregazione dei dati per addestrare il classificatore, permettendogli di fare previsioni accurate anche su sequenze frammentate di parole. Il nostro metodo end-to-end raggiunge prestazioni all'avanguardia mentre la sua complessità computazionale scala linearmente con la piccola frazione di parole importanti nell'intero corpus. Inoltre, un singolo classificatore di rete neurale profonda addestrato dalla nostra struttura può essere sintonizzato dinamicamente su diversi livelli di budget al momento dell'inferenza.
La ricerca dell'architettura differenziabile (DARTS) ha fornito una soluzione veloce nel trovare architetture di rete efficaci, ma ha sofferto di grandi spese generali di memoria e di calcolo nell'addestramento congiunto di una super-rete e nella ricerca di un'architettura ottimale.In questo documento, presentiamo un nuovo approccio, cioè DARTS parzialmente connesso, campionando una piccola parte della super-rete per ridurre la ridondanza nell'esplorare lo spazio della rete, eseguendo così una ricerca più efficiente senza comprendere le prestazioni. In particolare, eseguiamo la ricerca dell'operazione in un sottoinsieme di canali mentre bypassiamo la parte tenuta fuori in una scorciatoia.Questa strategia può soffrire di un'incoerenza indesiderata sulla selezione dei bordi della super-rete causata dal campionamento di canali diversi. Risolviamo introducendo la normalizzazione del bordo, che aggiunge un nuovo set di iper-parametri a livello di bordo per ridurre l'incertezza nella ricerca.Grazie al costo ridotto della memoria, PC-DARTS può essere addestrato con una dimensione del batch più grande e, di conseguenza, godere sia di una maggiore velocità e stabilità di formazione.I risultati degli esperimenti dimostrano l'efficacia del metodo proposto. In particolare, raggiungiamo un tasso di errore del 2,57% su CIFAR10 in soli 0,1 giorni GPU per la ricerca dell'architettura, e un tasso di errore top-1 allo stato dell'arte del 24,2% su ImageNet (con impostazione mobile) in 3,8 giorni GPU per la ricerca.Il nostro codice è stato reso disponibile su https://www.dropbox.com/sh/on9lg3rpx1r6dkf/AABG5mt0sMHjnEJyoRnLEYW4a?dl=0.
La ricerca sul dialogo tende a distinguere tra le attività di chit-chat e quelle orientate all'obiettivo.Mentre la prima è probabilmente più naturalistica e ha un uso più ampio del linguaggio, la seconda ha metriche più chiare e un segnale di apprendimento più diretto.Gli esseri umani combinano senza sforzo le due cose, e si impegnano in chit-chat per esempio con l'obiettivo di scambiare informazioni o suscitare una risposta specifica.Qui, noi colmiamo il divario tra questi due domini nell'impostazione di un ricco ambiente fantasy multi-player basato sul testo dove agenti e umani si impegnano sia in azioni che in dialogo. In particolare, addestriamo un modello orientato all'obiettivo con l'apprendimento di rinforzo attraverso il gioco autonomo contro un modello di chit-chat appreso per imitazione con due nuovi approcci: la politica impara a scegliere un argomento o impara a scegliere un enunciato dato gli enunciati top-k. Mostriamo che entrambi i modelli superano un modello di base inverso forte e possono conversare naturalmente con il loro partner di dialogo per raggiungere gli obiettivi.
Consideriamo la valutazione della politica off-policy quando i dati della traiettoria sono generati da più politiche di comportamento.Il lavoro recente ha mostrato il ruolo chiave giocato dalle correzioni della distribuzione stazionaria di stato o stato-azione nel contesto dell'orizzonte infinito per la valutazione della politica off-policy.Proponiamo la politica stimata della miscela (EMP), una nuova classe di metodi parzialmente politica-agnostici per stimare accuratamente quelle quantità. Con un'attenta analisi, dimostriamo che l'EMP dà luogo a stime con una varianza ridotta per la stima della correzione della distribuzione stazionaria dello stato, mentre offre anche un utile bias di induzione per la stima della correzione della distribuzione stazionaria dello stato-azione.in ampi esperimenti con ambienti continui e discreti, dimostriamo che il nostro algoritmo offre una precisione significativamente migliorata rispetto ai metodi all'avanguardia.
Introduciamo un'architettura neurale più efficiente per l'inferenza ammortizzata, che combina flussi di normalizzazione continui e condizionali utilizzando una scelta di principio della struttura.Il nostro flusso gradiente deriva il suo modello di sparsità dall'inverso minimamente fedele del suo modello grafico sottostante.Troviamo che questa fattorizzazione riduce il numero necessario sia di parametri nella rete neurale che di passi di integrazione adattivi nel solutore ODE. Esprimendo l'inversione strutturale e la costruzione del flusso come passaggi di compilazione di un linguaggio di programmazione probabilistico, dimostriamo la loro applicabilità all'inversione stocastica di modelli realistici come le reti neurali convoluzionali (CNN).
Presentiamo un algoritmo di ricerca di architetture neurali per costruire politiche compatte di apprendimento per rinforzo (RL), combinando ENAS e ES in un modo altamente scalabile e intuitivo. Definendo lo spazio di ricerca combinatorio di NAS come l'insieme di diverse partizioni dei bordi (colorazioni) in classi dello stesso peso, rappresentiamo architetture compatte attraverso efficienti partizioni dei bordi apprese. Per diversi compiti RL, riusciamo a imparare colorazioni che si traducono in politiche efficaci parametrizzate da soli 17 parametri di peso, fornendo una compressione >90% rispetto alle politiche vanilla e una compressione 6x rispetto alle politiche compatte allo stato dell'arte basate su matrici Toeplitz, pur mantenendo una buona ricompensa. Crediamo che il nostro lavoro sia uno dei primi tentativi di proporre un approccio rigoroso per addestrare architetture di reti neurali strutturate per problemi RL che sono di interesse soprattutto nella robotica mobile con risorse di memoria e computazionali limitate.
Gli approcci profondi al rilevamento delle anomalie hanno recentemente mostrato risultati promettenti rispetto ai metodi superficiali su set di dati grandi e complessi.tipicamente il rilevamento delle anomalie è trattato come un problema di apprendimento non supervisionato.in pratica però, si può avere---in aggiunta a un grande insieme di campioni non etichettati---accesso a un piccolo pool di campioni etichettati, per esempio Gli approcci semi-supervisionati al rilevamento delle anomalie mirano a utilizzare tali campioni etichettati, ma la maggior parte dei metodi proposti si limitano a includere semplicemente campioni normali etichettati; solo pochi metodi sfruttano le anomalie etichettate, mentre gli approcci profondi esistenti sono specifici del dominio. In questo lavoro presentiamo Deep SAD, una metodologia profonda end-to-end per il rilevamento semi-supervisionato delle anomalie, utilizzando una prospettiva teorica dell'informazione sul rilevamento delle anomalie, deriviamo una perdita motivata dall'idea che l'entropia della distribuzione latente per i dati normali dovrebbe essere inferiore all'entropia della distribuzione anomala. Dimostriamo in ampi esperimenti su MNIST, Fashion-MNIST, e CIFAR-10, insieme ad altri set di dati di riferimento per il rilevamento delle anomalie, che il nostro metodo è alla pari o supera i concorrenti superficiali, ibridi e profondi, producendo miglioramenti apprezzabili delle prestazioni anche quando vengono forniti solo pochi dati etichettati.
Per analizzare la rete profonda ReLU, adottiamo un'impostazione studente-insegnante in cui una rete studente iper-parametrizzata impara dall'output di una rete insegnante fissa della stessa profondità, con Stochastic Gradient Descent (SGD). i nostri contributi sono duplici. in primo luogo, dimostriamo che quando il gradiente è zero (o delimitato sopra da una piccola costante) in ogni punto dei dati in formazione, una situazione chiamata \emph{ impostazione di interpolazione}, esiste un \emph{allineamento} molti a uno tra i nodi studente e insegnante nello strato più basso in condizioni blande. Questo suggerisce che la generalizzazione in set di dati non visti è realizzabile, anche la stessa condizione spesso porta a zero l'errore di formazione.In secondo luogo, l'analisi del recupero rumoroso e le dinamiche di formazione nella rete a 2 strati mostrano che i nodi insegnanti forti (con grandi pesi a ventaglio) sono appresi per primi e i nodi insegnanti sottili sono lasciati non appresi fino alla fase finale della formazione.Come risultato, potrebbe essere necessario molto tempo per convergere in questi punti critici a piccolo gradiente.La nostra analisi mostra che la sovra-parametrizzazione gioca due ruoli: (1) è una condizione necessaria perché l'allineamento avvenga nei punti critici, e (2) nella dinamica dell'addestramento, aiuta i nodi studente a coprire più nodi insegnante con meno iterazioni.Entrambi migliorano la generalizzazione.Gli esperimenti giustificano la nostra scoperta.
Studiamo la convergenza della discesa del gradiente (GD) e della discesa stocastica del gradiente (SGD) per l'addestramento di reti lineari residue (ResNets) a strati nascosti $L$.Proviamo che per l'addestramento di reti residue profonde con certe trasformazioni lineari agli strati di input e output, che sono fisse durante l'addestramento, sia GD che SGD con inizializzazione zero su tutti i pesi nascosti possono convergere al minimo globale della perdita di addestramento.Inoltre, quando si specializzano in appropriate trasformazioni lineari casuali gaussiane, GD e SGD ottimizzano in modo dimostrabile reti ResNets lineari abbastanza ampie. Rispetto al risultato di convergenza globale di GD per l'addestramento di reti lineari profonde standard \citep{du2019width}, la nostra condizione sulla larghezza della rete neurale è più nitida di un fattore di $O(\kappa L)$, dove $kappa$ denota il numero di condizione della matrice di covarianza dei dati di addestramento.Inoltre, per la prima volta stabiliamo la convergenza globale di SGD per l'addestramento di ResNets lineari profonde e dimostriamo un tasso di convergenza lineare quando il minimo globale è $0$.
In questo articolo, indaghiamo empiricamente il percorso di formazione delle reti neurali profonde rispetto ai modelli di apprendimento automatico poco profondi completamente addestrati.Osserviamo che le reti neurali profonde (DNN) si addestrano imparando a classificare correttamente gli esempi imparabili poco profondi nelle prime epoche prima di imparare gli esempi più difficili. Ci basiamo su questa osservazione per suggerire un modo per suddividere il set di dati in sottoinsiemi difficili e facili che possono essere utilizzati per migliorare il processo generale di formazione. Per inciso, abbiamo anche trovato prove di un sottoinsieme di esempi intriganti in tutti i set di dati che abbiamo considerato, che erano apprendibili in modo superficiale ma non in modo profondo.Per aiutare la riproducibilità, abbiamo anche debitamente rilasciato il nostro codice per questo lavoro a https://github.com/karttikeya/Shallow_to_Deep/
Mentre molti lavori recenti si sono rivolti all'apprendimento di modelli profondi di variabili latenti discrete con inferenza variazionale, questa impostazione rimane impegnativa, ed è spesso necessario fare uso di stimatori di gradiente potenzialmente ad alta varianza nell'ottimizzazione dell'ELBO.Come alternativa, proponiamo di ottimizzare un obiettivo non-ELBO derivato dall'approssimazione di energia libera di Bethe alla funzione di partizione di una MRF. L'obiettivo derivato non richiede alcun campionamento e può essere calcolato in modo efficiente per molte MRF di interesse. Valutiamo l'approccio proposto nell'apprendimento di HMM neurali di alto ordine su testo, e troviamo che spesso supera altri schemi di inferenza approssimativa in termini di verosimiglianza logica tenuta fuori.Allo stesso tempo, troviamo che tutti gli approcci basati sull'inferenza approssimativa per imparare HMM neurali di alto ordine che consideriamo sottoperformano l'apprendimento con inferenza esatta con un margine significativo.
In un problema di generazione di spiegazioni, un agente ha bisogno di identificare e spiegare le ragioni delle sue decisioni ad un altro agente.Il lavoro esistente in questo settore è per lo più confinato a sistemi basati sulla pianificazione che utilizzano approcci di pianificazione automatica per risolvere il problema.In questo articolo, ci avviciniamo a questo problema da una nuova prospettiva, dove proponiamo un quadro generale basato sulla logica per la generazione di spiegazioni. In particolare, data una base di conoscenza $KB_1$ che implica una formula $\phi$ e una seconda base di conoscenza $KB_2$ che non implica $\phi$, cerchiamo di identificare una spiegazione $\epsilon$ che sia un sottoinsieme di $KB_1$ tale che l'unione di $KB_2$ e $\epsilon$ comporti $\phi$. Definiamo due tipi di spiegazioni, spiegazioni teoriche del modello e spiegazioni teoriche della prova, e usiamo funzioni di costo per riflettere le preferenze tra le spiegazioni. Inoltre, presentiamo il nostro algoritmo implementato per la logica proposizionale che calcola tali spiegazioni e lo valutiamo empiricamente in basi di conoscenza casuale e un dominio di pianificazione.
Un recente lavoro teorico ha dimostrato che le reti neurali profonde hanno prestazioni superiori alle reti superficiali, ma il loro addestramento è più difficile, ad es, Questo problema può essere tipicamente risolto con l'attivazione dell'unità lineare rettificata (ReLU), ma qui mostriamo che anche per tale attivazione, le reti neurali profonde e strette (NN) convergeranno a stati medi o mediani errati della funzione obiettivo a seconda della perdita con alta probabilità.Le NN profonde e strette si incontrano nella risoluzione di equazioni differenziali parziali con derivate di alto ordine. Dimostriamo questo collasso di tali NN sia numericamente che teoricamente, e forniamo stime della probabilità di collasso.Costruiamo anche un diagramma di una regione sicura per progettare NN che evitino il collasso a stati errati.Infine, esaminiamo diversi modi di inizializzazione e normalizzazione che possono evitare il problema del collasso.Inizializzazioni asimmetriche possono ridurre la probabilità di collasso ma non eliminarla totalmente.
Studiamo la robustezza avversaria delle reti neurali da una prospettiva di massimizzazione dei margini, dove i margini sono definiti come le distanze dagli ingressi al confine decisionale di un classificatore. Il nostro studio mostra che la massimizzazione dei margini può essere raggiunta minimizzando la perdita avversaria sul confine decisionale alla "perturbazione di successo più breve", dimostrando una stretta connessione tra le perdite avversarie e i margini. Invece dell'addestramento avversario con un fisso $epsilon$, MMA offre un miglioramento consentendo la selezione adattiva del "corretto" $epsilon$ come margine individualmente per ogni datapoint. I nostri esperimenti confermano empiricamente la nostra teoria e dimostrano l'efficacia dell'addestramento MMA sui dataset MNIST e CIFAR10 per quanto riguarda la robustezza di $ell_\infty$ e $ell_2$.
Esistono molti metodi di rilevamento delle anomalie che si comportano bene su problemi di bassa dimensione, tuttavia c'è una notevole mancanza di metodi efficaci per spazi ad alta dimensione, come le immagini. Ispirati dai recenti successi nel deep learning, proponiamo un nuovo approccio al rilevamento delle anomalie utilizzando reti generative avversarie. Dato un campione in esame, il nostro metodo si basa sulla ricerca di una buona rappresentazione di quel campione nello spazio latente del generatore; se tale rappresentazione non viene trovata, il campione viene considerato anomalo.  Raggiungiamo prestazioni allo stato dell'arte su set di dati standard di riferimento delle immagini e l'ispezione visiva dei campioni più anomali rivela che il nostro metodo restituisce effettivamente delle anomalie.
L'inferenza variazionale (VI) e Markov chain Monte Carlo (MCMC) sono algoritmi di inferenza a posteriori approssimati che spesso si dice abbiano punti di forza complementari, con VI che è veloce ma distorto e MCMC che è più lento ma asintoticamente imparziale.In questo articolo, analizziamo le procedure MCMC basate sul gradiente e VI e troviamo prove teoriche ed empiriche che queste procedure non sono così diverse come si potrebbe pensare. In particolare, un attento esame dell'equazione di Fokker-Planck che governa la procedura Langevin dynamics (LD) MCMC rivela che LD segue implicitamente un flusso di gradiente che corrisponde a una procedura di inferenza variazionale basata sull'ottimizzazione di un flusso normalizzante non parametrico. Questo risultato suggerisce che il bias transitorio di LD (dovuto a troppo pochi passi di riscaldamento) può seguire quello di VI (dovuto a troppo pochi passi di ottimizzazione), fino alle differenze dovute alla parametrizzazione e al bias asintotico di VI. Empiricamente, troviamo che i bias transitori di questi algoritmi (e le versioni accelerate dal momento) si evolvono in modo simile. Questo suggerisce che i professionisti con un budget di tempo limitato possono ottenere risultati più accurati eseguendo una procedura MCMC (anche se è lontana dall'essere bruciata) piuttosto che una procedura VI, a condizione che la varianza dello stimatore MCMC possa essere gestita (ad es, eseguendo molte catene parallele).
I Graph Convolutional Networks (GCNs) hanno recentemente dimostrato di avere un discreto successo nella modellazione di dati strutturati a grafo. Tuttavia, l'attenzione principale si è concentrata sulla gestione di semplici grafi indiretti. I grafi multirelazionali sono una forma più generale e prevalente di grafi in cui ogni bordo ha un'etichetta e una direzione associata ad esso.La maggior parte degli approcci esistenti per gestire tali grafi soffrono di un eccesso di parametrizzazione e sono limitati all'apprendimento delle rappresentazioni dei soli nodi. CompGCN sfrutta una varietà di operazioni di composizione entità-relazione da tecniche di Knowledge Graph Embedding e scala con il numero di relazioni; inoltre generalizza molti dei metodi GCN multi-relazionali esistenti. Valutiamo il nostro metodo proposto su compiti multipli come la classificazione dei nodi, la previsione dei collegamenti e la classificazione dei grafi, e otteniamo risultati dimostrabilmente superiori.
Lo stato dell'arte dei metodi di traduzione automatica neurale impiega enormi quantità di parametri, riducendo drasticamente i costi computazionali di tali metodi senza influenzare le prestazioni, fino a questo punto è stato irrisolto. Valutiamo il nostro metodo sui compiti di traduzione WMT14 EN-FR e WMT14 EN-DE e raggiungiamo risultati di quantizzazione allo stato dell'arte per il Transformer, ottenendo nessuna perdita nei punteggi BLEU rispetto alla baseline non quantizzata.
Le tecniche di meta-apprendimento basate sul gradiente sono sia ampiamente applicabili che abili nel risolvere problemi impegnativi di apprendimento a pochi colpi e di adattamento veloce. Tuttavia, hanno difficoltà pratiche quando operano su spazi di parametri ad alta densità in regimi estremi di dati bassi. Mostriamo che è possibile aggirare queste limitazioni imparando una rappresentazione generativa latente dipendente dai dati dei parametri del modello, ed eseguendo il meta-apprendimento basato sul gradiente in questo spazio latente a bassa densità. L'approccio risultante, latent embedding optimization (LEO), disaccoppia la procedura di adattamento basata sul gradiente dal sottostante spazio ad alta densità dei parametri del modello. La nostra valutazione mostra che LEO può raggiungere lo stato dell'arte delle prestazioni sui compiti di classificazione competitivi miniImageNet e tieredImageNet few-shot. ulteriori analisi indicano che LEO è in grado di catturare l'incertezza nei dati, e può eseguire l'adattamento in modo più efficace ottimizzando nello spazio latente.
La nostra architettura codifica un'immagine come un insieme di vettori e applica una procedura iterativa di message-passing per scoprire e ragionare su entità e relazioni rilevanti in una scena. In sei dei sette mini-giochi di StarCraft II Learning Environment, il nostro agente ha raggiunto prestazioni allo stato dell'arte e ha superato il livello grandmaster umano su quattro. In un nuovo compito di navigazione e pianificazione, le prestazioni del nostro agente e l'efficienza di apprendimento hanno superato di gran lunga le basi non relazionali, ed è stato in grado di generalizzare a scene più complesse di quelle che aveva sperimentato durante l'addestramento. Il contributo principale di questo lavoro è l'introduzione di tecniche per rappresentare e ragionare sugli stati in agenti di apprendimento di rinforzo profondo senza modello tramite pregiudizi induttivi relazionali. I nostri esperimenti dimostrano che questo approccio può offrire vantaggi in termini di efficienza, generalizzazione e interpretabilità, e può scalare fino a soddisfare alcuni degli ambienti di test più impegnativi nella moderna intelligenza artificiale.
La traduzione di immagini tra due domini è una classe di problemi che mira a imparare la mappatura da un'immagine di input nel dominio di origine a un'immagine di output nel dominio di destinazione, ed è stata applicata a numerose applicazioni, come l'aumento dei dati, l'adattamento del dominio e l'addestramento non supervisionato. Vincoliamo il problema con il presupposto che l'immagine tradotta deve essere percettivamente simile all'immagine originale e sembra anche essere tratta dal nuovo dominio, e proponiamo un modello di traduzione di immagini semplice ma efficace che consiste in un singolo generatore addestrato con un termine di autoregolarizzazione e un termine avversario. Notiamo inoltre che le tecniche esistenti di traduzione di immagini sono agnostiche rispetto ai soggetti di interesse e spesso introducono modifiche indesiderate o artefatti all'input. Quindi proponiamo di aggiungere un modulo di attenzione per prevedere una mappa di attenzione per guidare il processo di traduzione di immagini. La mappa di attenzione prevista apre anche le porte ad applicazioni come la segmentazione non supervisionata e il rilevamento della salienza. esperimenti e valutazioni estese mostrano che il nostro modello, pur essendo più semplice, raggiunge prestazioni significativamente migliori rispetto ai metodi esistenti di traduzione delle immagini.
Costruire reti neurali profonde per controllare agenti autonomi che devono interagire in tempo reale con il mondo fisico, come i robot o i veicoli automobilistici, richiede una perfetta integrazione del tempo nell'architettura di una rete. La questione centrale di questo lavoro è come la natura temporale della realtà dovrebbe essere riflessa nell'esecuzione di una rete neurale profonda e dei suoi componenti. La maggior parte delle reti neurali profonde artificiali sono partizionate in un grafo diretto di moduli collegati o strati e gli strati stessi consistono di blocchi elementari, come le singole unità.Per la maggior parte delle reti neurali profonde, tutte le unità di uno strato sono elaborate sincronicamente e in parallelo, ma gli strati stessi sono elaborati in modo sequenziale.Al contrario, tutti gli elementi di una rete neurale biologica sono elaborati in parallelo.In questo lavoro, definiamo una classe di reti tra questi due casi estremi. Queste reti sono eseguite in un flusso o in un modo sincrono layerwise-parallel, sbloccando gli strati di tali reti per l'elaborazione parallela.Rispetto alle reti profonde standard layerwise-sequential, queste nuove reti layerwise-parallel mostrano un comportamento temporale e un flusso di informazioni fondamentalmente diversi, specialmente per le reti con connessioni saltanti o ricorrenti. Sosteniamo che le reti profonde layerwise-parallel sono più adatte per le sfide future della progettazione di reti neurali profonde, come le grandi architetture funzionali modularizzate e/o ricorrenti, così come le reti che allocano diverse capacità di rete a seconda dello stimolo corrente e/o della complessità del compito.Impostiamo le proprietà di base e discutiamo le principali sfide per le reti layerwise-parallel.Inoltre, forniamo un toolbox per progettare, formare, valutare e interagire online con le reti layerwise-parallel.
Le reti neurali profonde sono note per essere vulnerabili alle perturbazioni avversarie. In questo articolo, colleghiamo la robustezza avversaria delle reti neurali con la stabilità di Lyapunov dei sistemi dinamici. Da questo punto di vista, addestrare le reti neurali è equivalente a trovare un controllo ottimale del sistema dinamico discreto, il che permette di utilizzare i metodi di approssimazioni successive, un algoritmo di controllo ottimale basato sul principio di massimo di Pontryagin, per addestrare le reti neurali. Questo metodo di addestramento disaccoppiato ci permette di aggiungere vincoli all'ottimizzazione, il che rende il modello profondo più robusto. Il problema di ottimizzazione vincolato può essere formulato come un problema di programmazione semi-definita e quindi può essere risolto in modo efficiente.
In questo articolo, proponiamo un metodo chiamato Dimensional reweighting Graph Convolutional Networks (DrGCNs), per affrontare il problema della varianza tra le informazioni dimensionali nelle rappresentazioni dei nodi di GCNs.We dimostrare che DrGCNs può ridurre la varianza delle rappresentazioni dei nodi collegando il nostro problema alla teoria del campo medio. Tuttavia, in pratica, troviamo che i gradi di aiuto delle DrGCN variano fortemente su diversi set di dati, rivisitiamo il problema e sviluppiamo una nuova misura K per quantificare l'effetto, che guida quando dovremmo usare la riponderazione dimensionale nelle GCN e quanto può aiutare. Il blocco di riponderazione dimensionale è leggero e altamente flessibile per essere costruito sulla maggior parte delle varianti di GCN. Esperimenti accuratamente progettati, comprese diverse correzioni su duplicati, perdite di informazioni ed etichette sbagliate dei ben noti set di dati di classificazione dei nodi, dimostrano le prestazioni superiori di DrGCNs rispetto agli approcci esistenti allo stato dell'arte.
Il dialogo basato sulla conoscenza è un compito che consiste nel generare una risposta informativa basata sia sul contesto del discorso che sulla conoscenza esterna. Poiché ci concentriamo su una migliore modellazione della selezione della conoscenza nel dialogo multiturno basato sulla conoscenza, proponiamo un modello di variabile latente sequenziale come primo approccio a questo problema. Il modello chiamato trasformatore di conoscenza sequenziale (SKT) può tenere traccia della distribuzione anteriore e posteriore sulla conoscenza; di conseguenza, può non solo ridurre l'ambiguità causata dalla diversità nella selezione della conoscenza della conversazione, ma anche sfruttare meglio le informazioni di risposta per la scelta corretta della conoscenza.I nostri risultati sperimentali mostrano che il modello proposto migliora l'accuratezza della selezione della conoscenza e successivamente le prestazioni della generazione di enunciati.Raggiungiamo il nuovo stato dell'arte delle prestazioni su Wizard of Wikipedia (Dinan et al, 2019) come uno dei benchmark più grandi e impegnativi.Convalidiamo ulteriormente l'efficacia del nostro modello rispetto ai metodi di conversazione esistenti in un altro dataset di dialogo basato sulla conoscenza Holl-E (Moghe et al., 2018).
Meta-learning, o learning-to-learn, ha dimostrato di essere una strategia di successo nell'attaccare i problemi nell'apprendimento supervisionato e nell'apprendimento di rinforzo che coinvolgono piccole quantità di dati.Le soluzioni allo stato dell'arte comportano l'apprendimento di un algoritmo di inizializzazione e/o apprendimento utilizzando un set di episodi di formazione in modo che il meta-learner possa generalizzare a un episodio di valutazione rapidamente.Questi metodi funzionano bene ma spesso mancano di una buona quantificazione dell'incertezza, che può essere vitale per le applicazioni del mondo reale quando mancano i dati. Proponiamo un metodo di meta-apprendimento che ammortizza in modo efficiente l'inferenza variazionale gerarchica tra le attività, imparando una distribuzione a priori sui pesi delle reti neurali in modo che alcuni passi di Bayes con Backprop producano un buon posteriore approssimato specifico dell'attività.
  Spesso desideriamo trasferire la conoscenza rappresentazionale da una rete neurale a un'altra, ad esempio distillando una grande rete in una più piccola, trasferendo la conoscenza da una modalità sensoriale a una seconda, o riunendo una collezione di modelli in un unico stimatore. La distillazione della conoscenza, l'approccio standard a questi problemi, minimizza la divergenza KL tra gli output probabilistici di una rete insegnante e una rete studente. Questo motiva un obiettivo alternativo con il quale addestriamo uno studente a catturare significativamente più informazioni nella rappresentazione dei dati da parte dell'insegnante.formuliamo questo obiettivo come apprendimento contrastivo.gli esperimenti dimostrano che il nostro nuovo obiettivo risultante supera la distillazione della conoscenza su una varietà di compiti di trasferimento della conoscenza, compresa la compressione del modello singolo, la distillazione dell'ensemble e il trasferimento cross-modale.quando combinato con la distillazione della conoscenza, il nostro metodo stabilisce uno stato dell'arte in molti compiti di trasferimento, a volte anche superando la rete dell'insegnante.
Lo sviluppo di efficaci regole di apprendimento biologicamente plausibili per le reti neurali profonde è importante per far progredire le connessioni tra l'apprendimento profondo e le neuroscienze. Fino ad oggi, le regole di apprendimento sinaptiche locali come quelle impiegate dal cervello non sono riuscite a eguagliare le prestazioni della backpropagation nelle reti profonde. Si può dimostrare matematicamente che questo approccio ha un'espressività sufficiente per approssimare qualsiasi algoritmo di apprendimento online. I nostri esperimenti dimostrano che le reti meta-allenate utilizzano efficacemente le connessioni di feedback per eseguire l'assegnazione dei crediti online in architetture multistrato. Inoltre, dimostriamo empiricamente che questo modello supera un algoritmo di meta-apprendimento basato sul gradiente allo stato dell'arte per l'apprendimento continuo sui benchmark di regressione e classificazione.
Nel sistema visivo, i neuroni rispondono a una zona dell'input conosciuta come il loro campo recettivo classico (RF), e possono essere modulati da stimoli nel circondario.Queste interazioni sono spesso mediate da connessioni laterali, dando origine a RF extra-classici. Usiamo l'apprendimento supervisionato tramite backpropagation per imparare le connessioni feedforward, combinato con una regola di apprendimento non supervisionato per imparare le connessioni laterali tra le unità all'interno di una rete neurale convoluzionale.Queste connessioni permettono ad ogni unità di integrare le informazioni dal suo intorno, generando campi recettivi extra-classici per le unità nel nostro nuovo modello proposto (CNNEx). Dimostriamo che queste connessioni rendono la rete più robusta e raggiungono prestazioni migliori sulle versioni rumorose dei dataset MNIST e CIFAR-10. Sebbene le statistiche delle immagini MNIST e CIFAR-10 differiscano notevolmente, la stessa regola di apprendimento non supervisionato è generalizzata a entrambi i dataset. Il nostro quadro può essere potenzialmente applicato a reti addestrate su altri compiti, con le connessioni laterali apprese che aiutano i calcoli implementati dalle connessioni feedforward quando l'input non è affidabile.
Tuttavia, mentre le lingue naturali sono ricche di strutture grammaticali, la DL non è stata in grado di rappresentare esplicitamente e applicare tali strutture. Questo articolo propone una nuova architettura per colmare questa lacuna sfruttando le rappresentazioni del prodotto tensore (TPR), un quadro neurale-simbolico strutturato sviluppato nelle scienze cognitive negli ultimi 20 anni, con lo scopo di integrare la DL con strutture e regole linguistiche esplicite. La chiamiamo Tensor Product Generation Network (TPGN), e la applichiamo alla didascalia delle immagini. Le idee chiave della TPGN sono: 1) apprendimento non supervisionato di vettori di parole non vincolanti tramite una rete neurale profonda basata sulla TPR, e 2) integrazione della TPR con le tipiche architetture DL, compresi i modelli LSTM (Long Short-Term Memory). La novità del nostro approccio risiede nella sua capacità di generare una frase ed estrarre la struttura grammaticale parziale della frase utilizzando i vettori di disaggregazione dei ruoli, che sono ottenuti in modo non supervisionato.I risultati sperimentali dimostrano l'efficacia dell'approccio proposto.
Tuttavia, le robustezze certificate esistenti sono limitate alle previsioni top-1. In molte applicazioni del mondo reale, le previsioni top-$k$ sono più rilevanti. In questo lavoro, miriamo a derivare la robustezza certificata per le previsioni top-$k$. In particolare, la nostra robustezza certificata si basa sullo smoothing randomizzato, che trasforma qualsiasi classificatore in un nuovo classificatore aggiungendo rumore a un esempio di input. Adottiamo lo smussamento randomizzato perché è scalabile alle reti neurali su larga scala e applicabile a qualsiasi classificatore.Diamo una robustezza stretta nella norma $\ell_2$ per le previsioni top-$k$ quando usiamo lo smussamento randomizzato con rumore gaussiano.Troviamo che generalizzare la robustezza certificata dalle previsioni top-1 a quelle top-$k$ affronta sfide tecniche significative. Abbiamo anche valutato empiricamente il nostro metodo su CIFAR10 e ImageNet.Per esempio, il nostro metodo può ottenere un classificatore ImageNet con un'accuratezza certificata top-5 del 62.8\% quando le $\ell_2$-norme delle perturbazioni avversarie sono inferiori a 0.5 (=127/255).Il nostro codice è pubblicamente disponibile a: \https://github.com/jjy1994/Certify_Topk.
Il lavoro recente ha mostrato un crescente interesse nell'uso del Variational Autoencoder (VAE) per scoprire rappresentazioni interpretabili dei dati in modo non supervisionato.Questi metodi si sono concentrati in gran parte sulla modifica della funzione di costo variazionale per raggiungere questo obiettivo.Tuttavia, dimostriamo che metodi come il beta-VAE semplificano la tendenza dell'inferenza variazionale a sottofittare causando un patologico over-pruning e una sovra-ortogonalizzazione delle componenti apprese.In questo articolo adottiamo un approccio complementare: modificare il modello probabilistico per favorire la scoperta di rappresentazioni strutturate di variabili latenti. In particolare, il modello probabilistico VAE standard non è identificabile: la verosimiglianza dei parametri è invariante sotto le rotazioni dello spazio latente, il che significa che non c'è pressione per identificare ogni vero fattore di variazione con una variabile latente, quindi impieghiamo una distribuzione prioritaria ricca, simile al modello ICA, che rompe la simmetria rotazionale. Esperimenti quantitativi e qualitativi estesi dimostrano che il priore proposto mitiga il trade-off introdotto dalle funzioni di costo modificate come beta-VAE e TCVAE tra la perdita di ricostruzione e il disinserimento, permettendo di migliorare questi approcci sia rispetto al disinserimento che alla qualità della ricostruzione in modo significativo rispetto allo stato dell'arte.
A causa del successo delle reti residuali (resnet) e delle architetture correlate, le connessioni di scorciatoia sono diventate rapidamente strumenti standard per la costruzione di reti neurali convoluzionali.Le spiegazioni in letteratura per l'apparente efficacia delle scorciatoie sono varie e spesso contraddittorie.Noi ipotizziamo che le scorciatoie funzionino principalmente perché agiscono come controparti lineari a strati non lineari. I nostri esperimenti mostrano che altri tipi di connessioni lineari possono essere ancora più efficaci delle scorciatoie identiche. I nostri risultati suggeriscono anche che il miglior tipo di connessione lineare per una data applicazione può dipendere sia dalla larghezza che dalla profondità della rete.
Gli ottimizzatori Adam-typed, come una classe di metodi adattativi di stima del momento con lo schema della media mobile esponenziale, sono stati utilizzati con successo in molte applicazioni di deep learning.Tali metodi sono attraenti per la capacità su grandi insiemi di dati sparsi.In cima a quello, sono computazionalmente efficienti e insensibili alle impostazioni iper-parametro.In questo articolo, presentiamo un nuovo quadro per adattare i metodi Adam-typed, cioè AdamT. Invece di applicare una semplice media pesata esponenziale, AdamT include anche le informazioni di tendenza quando aggiorna i parametri con la dimensione del passo e i gradienti adattivi. Il nuovo termine aggiunto dovrebbe catturare in modo efficiente i modelli mobili non orizzontali sulla superficie dei costi, e quindi convergere più rapidamente. Mostriamo empiricamente l'importanza della componente di tendenza, dove AdamT supera costantemente il metodo Adam convenzionale in entrambe le impostazioni convesse e non convesse.
Poiché i metodi di apprendimento automatico vedono una maggiore adozione e implementazione in applicazioni ad alta posta in gioco come la diagnosi delle immagini mediche, la necessità di interpretabilità e spiegazione del modello è diventata più critica. Gli approcci classici che valutano l'importanza delle caratteristiche (ad esempio le mappe di salienza) non spiegano come e perché una particolare regione di un'immagine è rilevante per la previsione. Dato un input di query a un classificatore, il nostro metodo produce un insieme progressivo di variazioni plausibili di quella query, che cambiano gradualmente la probabilità posteriore dalla sua classe originale alla sua negazione.Questi campioni generati controfattualmente conservano caratteristiche non correlate alla decisione di classificazione, in modo tale che un utente può impiegare il nostro metodo come una ``manopola di regolazione'' per attraversare un collettore di dati mentre attraversa il confine della decisione.  Il nostro metodo è agnostico e richiede solo il valore di uscita e il gradiente del predittore rispetto al suo input.
Studiamo il problema di spiegare una ricca classe di proprietà comportamentali delle reti neurali profonde; le nostre spiegazioni dirette all'influenza affrontano questo problema sbirciando all'interno della rete per identificare i neuroni con un'alta influenza sulla proprietà di interesse usando una misura di influenza assiomaticamente giustificata, e poi fornendo un'interpretazione per i concetti che questi neuroni rappresentano; valutiamo il nostro approccio addestrando reti neurali convoluzionali su Pubfig, ImageNet e dataset di retinopatia diabetica.  La nostra valutazione dimostra che le spiegazioni dirette dall'influenza (1) localizzano le caratteristiche utilizzate dalla rete, (2) isolano le caratteristiche che distinguono le istanze correlate, (3) aiutano ad estrarre l'essenza di ciò che la rete ha imparato sulla classe e (4) aiutano a risolvere gli errori di classificazione.
I sistemi standard di deep learning richiedono migliaia o milioni di esempi per imparare un concetto, e non possono integrare facilmente nuovi concetti. Al contrario, gli esseri umani hanno un'incredibile capacità di fare apprendimento one-shot o few-shot. Per esempio, dal solo sentire una parola usata in una frase, gli esseri umani possono dedurre molto su di essa, sfruttando ciò che la sintassi e la semantica delle parole circostanti ci dicono. Qui, ci ispiriamo a questo per evidenziare una semplice tecnica con cui le reti ricorrenti profonde possono similmente sfruttare la loro conoscenza precedente per imparare una rappresentazione utile per una nuova parola da pochi dati, il che potrebbe rendere i sistemi di elaborazione del linguaggio naturale molto più flessibili, permettendo loro di imparare continuamente dalle nuove parole che incontrano.
Le ricerche recenti che sviluppano architetture di reti neurali con memoria esterna hanno spesso utilizzato il set di dati di benchmark bAbI, che fornisce un numero impegnativo di compiti che richiedono il ragionamento. Qui abbiamo impiegato un classico compito di inferenza associativa dalla letteratura di neuroscienze umane, al fine di sondare più attentamente la capacità di ragionamento delle architetture con memoria aumentata esistenti. Risultati simili sono stati ottenuti su un compito più complesso che coinvolge la ricerca del percorso più breve tra i nodi di un percorso.Abbiamo quindi sviluppato una nuova architettura, MEMO, dotata della capacità di ragionare su distanze più lunghe.Questo è stato realizzato con l'aggiunta di due nuovi componenti. In primo luogo, introduce una separazione tra le memorie/fatti immagazzinati nella memoria esterna e gli elementi che comprendono questi fatti nella memoria esterna; in secondo luogo, fa uso di un meccanismo di recupero adattivo, consentendo un numero variabile di "salti di memoria" prima che la risposta sia prodotta.MEMO è in grado di risolvere i nostri nuovi compiti di ragionamento, così come tutti i 20 compiti di bAbI.
Le convoluzioni separabili in senso profondo riducono il numero di parametri e di calcoli utilizzati nelle operazioni convoluzionali, mentre aumentano l'efficienza rappresentazionale.Hanno dimostrato di avere successo nei modelli di classificazione delle immagini, sia nell'ottenere modelli migliori di quelli precedentemente possibili per un dato numero di parametri (l'architettura Xception) sia nel ridurre considerevolmente il numero di parametri richiesti per eseguire un dato livello (la famiglia di architetture MobileNets).Recentemente, le reti convoluzionali sequence-to-sequence sono state applicate a compiti di traduzione automatica con buoni risultati.In questo lavoro, studiamo come le convoluzioni separabili in senso profondo possano essere applicate alla traduzione automatica neurale. Introduciamo una nuova architettura ispirata a Xception e ByteNet, chiamata SliceNet, che permette una riduzione significativa del numero di parametri e della quantità di calcoli necessari per ottenere risultati come ByteNet e, con un numero di parametri simile, raggiunge risultati migliori. Oltre a dimostrare che le convoluzioni separabili in senso profondo funzionano bene per la traduzione automatica, indaghiamo i cambiamenti architetturali che esse consentono: osserviamo che grazie alla separabilità in senso profondo, possiamo aumentare la lunghezza delle finestre di convoluzione, eliminando la necessità della dilatazione dei filtri, e introduciamo una nuova operazione di convoluzione super-separabile che riduce ulteriormente il numero di parametri e il costo computazionale dei modelli.
Interpretare l'addestramento delle reti generative avversarie (GAN) come minimizzazione approssimativa della divergenza è stato teoricamente interessante, ha stimolato la discussione e ha portato a estensioni teoricamente e praticamente interessanti come le f-GAN e le Wasserstein GAN. Sia per le GAN classiche che per le f-GAN, c'è una variante originale di addestramento e una variante "non saturante" che usa una forma alternativa di gradiente del generatore. Lo schema non saturante è spesso considerato come una semplice modifica per affrontare i problemi di ottimizzazione, ma noi dimostriamo che in realtà lo schema non saturante per i GAN sta effettivamente ottimizzando una f-divergenza inversa simile a KL.Sviluppiamo anche una serie di strumenti teorici per aiutare a confrontare e classificare le f-divergenze.Speriamo che questi risultati possano aiutare a chiarire alcune delle discussioni teoriche che circondano la visione della minimizzazione della divergenza nella formazione dei GAN.
Introduciamo un nuovo metodo per convertire i dati di testo in rappresentazioni astratte dell'immagine, che permette alle tecniche di elaborazione basate sulle immagini (ad esempio le reti di classificazione delle immagini) di essere applicate a problemi di confronto basati sul testo. Applichiamo la tecnica alla disambiguazione delle entità dei nomi degli inventori nei brevetti USA. Abbiamo quindi addestrato una rete neurale di classificazione delle immagini per discriminare tra tali immagini di confronto a coppie, e usiamo la rete addestrata per etichettare ogni coppia di record come abbinata (stesso inventore) o non abbinata (inventori diversi), ottenendo risultati molto accurati (F1: 99,09%, precisione: 99,41%, richiamo: 98,76%). Il nostro nuovo metodo di rappresentazione testo-immagine potrebbe essere usato più ampiamente per altri problemi di confronto NLP, come la disambiguazione di pubblicazioni accademiche, o per problemi che richiedono la classificazione simultanea di testo e immagini.
Proponiamo un nuovo algoritmo, Difference-Seeking Generative Adversarial Network (DSGAN), sviluppato dalla tradizionale GAN.DSGAN considera lo scenario in cui i campioni di formazione della distribuzione target, $p_{t}$, sono difficili da raccogliere.Supponiamo che ci siano due distribuzioni $p_{bar{d}}$ e $p_{d}$ tali che la densità della distribuzione target può essere la differenza tra le densità di $p_{bar{d}$ e $p_{d}$. Mostriamo come apprendere la distribuzione target $p_{t}$ solo attraverso i campioni di $p_{d}$ e $p_{\bar{d}}$ (relativamente facile da ottenere).DSGAN ha la flessibilità di produrre campioni da varie distribuzioni target (per esempio la distribuzione fuori-distribuzione).Due applicazioni chiave, l'apprendimento semi-supervisionato e l'addestramento avversario, sono presi come esempi per convalidare l'efficacia di DSGAN.Forniamo anche analisi teoriche sulla convergenza di DSGAN.
Recentemente, Generative Adversarial Network (GAN) e molte delle sue varianti sono state ampiamente utilizzate per risolvere il problema della traduzione immagine-immagine e hanno raggiunto risultati straordinari sia in modo supervisionato che non supervisionato.Tuttavia, la maggior parte dei metodi basati su GAN soffrono del problema dello squilibrio tra il generatore e il discriminatore in pratica.Vale a dire, le capacità relative del modello del generatore e del discriminatore non corrispondono, portando al collasso della modalità e/o alla diminuzione dei gradienti.Per affrontare questo problema, proponiamo un GuideGAN basato sul meccanismo di attenzione. Più specificamente, armiamo il discriminatore con un meccanismo di attenzione così non solo stima la probabilità che il suo input sia reale, ma crea anche una mappa di attenzione che evidenzia le caratteristiche critiche per tale previsione.Questa mappa di attenzione assiste poi il generatore a produrre immagini più plausibili e realistiche.Valutiamo estensivamente la struttura GuideGAN proposta su una serie di compiti di trasferimento di immagini.Sia i risultati qualitativi che il confronto quantitativo dimostrano la superiorità del nostro approccio proposto.
Il problema di verificare se un'ipotesi testuale è valida sulla base delle prove fornite, noto anche come verifica dei fatti, gioca un ruolo importante nello studio della comprensione del linguaggio naturale e della rappresentazione semantica, Tuttavia, gli studi esistenti si limitano principalmente a trattare con prove non strutturate (ad esempio, frasi e documenti in linguaggio naturale, notizie, ecc.), mentre la verifica con prove strutturate, come tabelle, grafici e database, rimane inesplorata.Questo articolo mira specificamente a studiare la verifica dei fatti con dati semi-strutturati come prova. A questo scopo, costruiamo un set di dati su larga scala chiamato TabFact con 16k tabelle di Wikipedia come prova per 118k affermazioni in linguaggio naturale annotate dall'uomo, che sono etichettate come ENTAILED o REFUTED.TabFact è impegnativo poiché coinvolge sia il ragionamento linguistico morbido che il ragionamento simbolico duro.Per affrontare queste sfide di ragionamento, progettiamo due diversi modelli: Table-BERT e Latent Program Algorithm (LPA).Table-BERT sfrutta il modello linguistico pre-addestrato allo stato dell'arte per codificare le tabelle linearizzate e le dichiarazioni in vettori continui per la verifica.LPA analizza le dichiarazioni in programmi simili a LISP e li esegue contro le tabelle per ottenere il valore binario restituito per la verifica.Entrambi i metodi raggiungono una precisione simile ma sono ancora molto indietro rispetto alle prestazioni umane.Eseguiamo anche un'analisi completa per dimostrare grandi opportunità future.
Questo lavoro presenta un'architettura neurale a due stadi per l'apprendimento e la raffinazione delle corrispondenze strutturali tra i grafi. in primo luogo, usiamo le embeddings localizzate dei nodi calcolate da una rete neurale a grafo per ottenere una classifica iniziale delle corrispondenze soft tra i nodi. in secondo luogo, impieghiamo reti sincrone di passaggio di messaggi per riorganizzare iterativamente le corrispondenze soft per raggiungere un consenso corrispondente nelle vicinanze locali tra i grafi. Dimostriamo, teoricamente ed empiricamente, che il nostro schema di passaggio di messaggi calcola una misura ben fondata di consenso per i quartieri corrispondenti, che è poi usata per guidare il processo iterativo di ri-ranking.La nostra architettura puramente locale e sparsity-aware scala bene a grandi input del mondo reale, pur essendo in grado di recuperare corrispondenze globali in modo coerente.Dimostriamo l'efficacia pratica del nostro metodo su compiti del mondo reale dai campi della visione artificiale e dell'allineamento di entità tra grafi di conoscenza, su cui miglioriamo rispetto all'attuale stato dell'arte.
Questo articolo estende la prova di densità delle reti neurali nello spazio di funzioni continue (o anche misurabili) su spazi euclidei a funzioni su insiemi compatti di misure di probabilità. Facendo così il lavoro va in parallelo a risultati più vecchi di un decennio sull'incorporazione di mean-map di misure di probabilità in spazi di Hilbert a kernel riproducenti.  Il risultato viene poi esteso ai prodotti cartesiani, ottenendo un teorema di approssimazione universale per domini strutturati ad albero, che si verificano naturalmente nei formati di scambio dati come JSON, XML, YAML, AVRO e ProtoBuffer. Ciò ha importanti implicazioni pratiche, poiché consente di creare automaticamente un'architettura di reti neurali per l'elaborazione di dati strutturati (paradigmi AutoML), come dimostrato da una libreria accompagnata per il formato JSON.
Interazioni come la doppia negazione nelle frasi e le interazioni di scena nelle immagini sono forme comuni di dipendenze complesse catturate da modelli di apprendimento automatico all'avanguardia.Proponiamo Mahé, un nuovo approccio per fornire spiegazioni gerarchiche modello-agnostiche di come potenti modelli di apprendimento automatico, come le reti neurali profonde, catturano queste interazioni come dipendenti o libere dal contesto delle istanze di dati. In particolare, Mahé fornisce spiegazioni dipendenti dal contesto attraverso un nuovo algoritmo di interpretazione locale che cattura efficacemente le interazioni di qualsiasi ordine, e ottiene spiegazioni senza contesto attraverso la generalizzazione delle interazioni dipendenti dal contesto per spiegare i comportamenti globali. I risultati sperimentali mostrano che Mahé ottiene migliori interpretazioni di interazioni locali rispetto ai metodi all'avanguardia e fornisce con successo spiegazioni di interazioni che sono senza contesto.
Per realizzare la promessa di inferenza di rete profonda incorporata ubiquitaria, Ã¨ essenziale cercare i limiti di efficienza energetica e di area.  A tal fine, le reti a bassa precisione offrono un'enorme promessa perché sia l'energia che l'area diminuiscono in modo quadratico con la riduzione della precisione.  Qui, per la prima volta, dimostriamo ResNet-18, ResNet-34, ResNet-50, ResNet-152, Inception-v3, densenet-161, e reti VGG-16bn sul benchmark di classificazione ImageNet che, a 8-bit di precisione superano l'accuratezza delle reti di base a piena precisione dopo un'epoca di finetuning, sfruttando così la disponibilità di modelli preaddestrati. Sorprendentemente, i pesi delle reti a bassa precisione sono molto vicini (nella somiglianza del coseno) ai pesi delle reti di base corrispondenti, rendendo la formazione da zero inutile.Troviamo che il rumore del gradiente dovuto alla quantizzazione durante la formazione aumenta con precisione ridotta, e cerchiamo modi per superare questo rumore.Il numero di iterazioni richiesto dalla discesa del gradiente stocastico per raggiungere un dato errore di formazione è legato al quadrato di (a) la distanza della soluzione iniziale dalla finale più (b) la varianza massima delle stime del gradiente.  Traendo ispirazione da questa osservazione, noi (a) riduciamo la distanza della soluzione iniziando con reti di base di precisione fp32 preaddestrate e con un fine-tuning, e (b) combattiamo il rumore introdotto dalla quantizzazione dei pesi e delle attivazioni durante l'addestramento, usando lotti più grandi insieme ad un ricottura di tasso di apprendimento abbinato.  L'analisi della sensibilità indica che queste tecniche, accoppiate con una corretta calibrazione dell'intervallo delle funzioni di attivazione, offrono un'euristica promettente per scoprire reti a bassa precisione, se esistono, vicine alle reti di base di precisione fp32.
  I metodi di analisi che ci permettono di capire meglio le rappresentazioni e il funzionamento dei modelli neurali del linguaggio sono sempre più necessari man mano che l'apprendimento profondo diventa l'approccio dominante in NLP. Qui presentiamo due metodi basati su Representational Similarity Analysis (RSA) e Tree Kernels (TK) che ci permettono di quantificare direttamente quanto fortemente l'informazione codificata nei modelli di attivazione neurale corrisponde all'informazione rappresentata da strutture simboliche come gli alberi della sintassi. Per prima cosa validiamo i nostri metodi sul caso di un semplice linguaggio sintetico per espressioni aritmetiche con una sintassi e una semantica ben definite, e mostriamo che essi esibiscono il modello di risultati previsto, quindi applichiamo i nostri metodi per correlare le rappresentazioni neurali delle frasi inglesi con i loro alberi di parsing della costituzione.
L'apprendimento profondo supervisionato richiede una grande quantità di campioni di allenamento con annotazioni (ad esempio, classe di etichette per compiti di classificazione, mappa di etichette pixel- o voxel-wise per compiti di segmentazione), che sono costosi e richiedono tempo per essere ottenuti.Durante la formazione di una rete neurale profonda, i campioni annotati sono alimentati nella rete in un modo mini-batch, dove sono spesso considerati di uguale importanza. Tuttavia, alcuni dei campioni possono diventare meno informativi durante l'addestramento, poiché la grandezza del gradiente inizia a svanire per questi campioni. Nel frattempo, altri campioni di maggiore utilità o durezza possono essere più richiesti per il processo di addestramento per procedere e richiedere più sfruttamento. Per affrontare le sfide delle annotazioni costose e della perdita di informazioni del campione, proponiamo un nuovo quadro di formazione che seleziona in modo adattivo i campioni informativi che vengono alimentati al processo di formazione. La selezione o il campionamento adattivo viene eseguito sulla base di una strategia consapevole della durezza nello spazio latente costruito da un modello generativo. Per valutare il quadro di formazione proposto, eseguiamo esperimenti su tre diversi set di dati, tra cui MNIST e CIFAR-10 per il compito di classificazione delle immagini e un set di dati di immagini mediche IVUS per il compito di simulazione biofisica.Su tutti e tre i set di dati, il quadro proposto supera un metodo di campionamento casuale, che dimostra l'efficacia del nostro quadro.
I metodi esistenti per le opere d'arte generate dall'intelligenza artificiale lottano ancora con la generazione di contenuti stilizzati di alta qualità, dove la semantica di alto livello è preservata, o separando gli stili a grana fine da vari artisti.Proponiamo un nuovo Generative Adversarial Disentanglement Network che può distinguere due fattori complementari di variazioni quando solo uno di essi è etichettato in generale, e decomporre completamente le complesse illustrazioni di anime in stile e contenuto in particolare.L'addestramento di tale modello è impegnativo, poiché dato uno stile, possono esistere vari dati di contenuto ma non il contrario. Il nostro approccio è diviso in due fasi, una che codifica un'immagine di input in un contenuto indipendente dallo stile, e una basata su un generatore a doppia condizione.Dimostriamo la capacità di generare ritratti di anime ad alta fedeltà con un contenuto fisso e una grande varietà di stili da oltre mille artisti, e viceversa, utilizzando una singola rete end-to-end e con applicazioni nel trasferimento di stile.Mostriamo questa capacità unica così come un output superiore allo stato attuale dell'arte.
Una recente ricerca ha dimostrato che le CNN sono spesso eccessivamente sensibili ai modelli testuali ad alta frequenza; ispirandoci all'intuizione che gli esseri umani sono più sensibili ai modelli a bassa frequenza (su larga scala), progettiamo uno schema di regolarizzazione che penalizza le grandi differenze tra componenti adiacenti all'interno di ciascun kernel convoluzionale. Applichiamo la nostra regolarizzazione a diversi metodi di formazione popolari, dimostrando che i modelli con i kernel lisci proposti godono di una migliore robustezza avversaria. Inoltre, basandoci sul recente lavoro che stabilisce connessioni tra robustezza avversaria e interpretabilità, mostriamo che il nostro metodo sembra dare gradienti più allineati a livello percettivo.
Nonostante una letteratura sempre crescente sugli algoritmi di apprendimento di rinforzo e sulle applicazioni, molto meno si sa sulla loro inferenza statistica. In questo documento, studiamo i comportamenti a grande campione delle stime del valore Q con caratterizzazioni in forma chiusa delle varianze asintotiche. Questo ci permette di costruire in modo efficiente le regioni di fiducia per le funzioni di valore Q e di valore ottimale, e di sviluppare politiche per minimizzare i loro errori di stima.
I vettori di codifica sono un modo di principio per codificare in un vettore quali informazioni sono note e quali sono sconosciute.  Sono progettati per modellare relazioni in cui un vettore dovrebbe includere tutte le informazioni in un altro vettore, chiamato entailment.  Questo articolo studia l'apprendimento non supervisionato di vettori di implicazione per la semantica delle parole.  Usando semplici modelli basati sull'entailment della semantica delle parole nel testo (semantica distributiva), induciamo embeddings di parole con vettore di entailment che superano i migliori risultati precedenti per predire l'entailment tra parole, in esperimenti non supervisionati e semi-supervisionati sull'iponimia.
Descriviamo un semplice schema che permette a un agente di conoscere il suo ambiente in modo non supervisionato. Il nostro schema mette due versioni dello stesso agente, Alice e Bob, l'una contro l'altra: Alice propone a Bob un compito da completare, e Bob tenta di completare il compito.  In questo lavoro ci concentreremo su due tipi di ambienti: (Alice "propone" il compito facendo una sequenza di azioni e poi Bob deve annullarle o ripeterle, rispettivamente.  Tramite una struttura di ricompensa appropriata, Alice e Bob generano automaticamente un curriculum di esplorazione, consentendo un addestramento non supervisionato dell'agente.Quando Bob viene schierato su un compito RL all'interno dell'ambiente, questo addestramento non supervisionato riduce il numero di episodi supervisionati necessari per imparare, e in alcuni casi converge verso una ricompensa più alta.
Molti insiemi di dati del mondo reale sono rappresentati come grafi, come i collegamenti citazionali, i social media e le interazioni biologiche. La struttura volatile dei grafi rende non banale l'impiego di reti neurali convoluzionali (CNN) per l'elaborazione dei dati dei grafi. Recentemente, la rete di attenzione del grafico (GAT) ha dimostrato un tentativo promettente combinando le reti neurali del grafico con il meccanismo di attenzione, in modo da realizzare il passaggio del massaggio nei grafici con le strutture arbitrarie.Tuttavia, l'attenzione in GAT è calcolata pricipalmente basata sulla somiglianza fra il contenuto del nodo, mentre le strutture del grafico rimangono in gran parte disoccupate (tranne nel mascheramento dell'attenzione dai vicini di un hop). In questo articolo, proponiamo un modello `````````````````````````````"ADaptive Structural Fingerprint" (ADSF) per sfruttare pienamente sia i dettagli topologici del grafico che le caratteristiche del contenuto dei nodi. L'idea chiave è quella di contestualizzare ogni nodo con un campo ricettivo ponderato e apprendibile che codifica le strutture locali ricche e diverse del grafico. Facendo questo, le interazioni strutturali tra i nodi possono essere dedotte accuratamente, migliorando così il successivo livello di attenzione così come la convergenza dell'apprendimento.Inoltre, il nostro modello fornisce una piattaforma utile per diversi sottospazi di caratteristiche del nodo e varie scale di strutture del grafico per ``cross-talk'' tra di loro attraverso l'apprendimento dell'attenzione multitesta, essendo particolarmente utile nella gestione di dati complessi del mondo reale.  Si osservano prestazioni incoraggianti su una serie di set di dati di riferimento nella classificazione dei nodi.
Il processo decisionale informato e robusto di fronte all'incertezza Ã¨ critico per i robot che eseguono compiti fisici accanto alle persone. Formuliamo questo come un problema di apprendimento di rinforzo bayesiano sui processi decisionali di Markov latenti (MDPs). Mentre l'ottimalitÃ di Bayes Ã¨ teoricamente il gold standard, gli algoritmi esistenti non scalano bene agli spazi continui di azione e di stato.Proponiamo una soluzione scalabile che si basa sulla seguente intuizione: in assenza di incertezza, ogni MDP latente Ã¨ piÃ¹ facile da risolvere. Il nostro algoritmo, Bayesian Residual Policy Optimization (BRPO), importa la scalabilità dei metodi di gradiente della politica così come l'inizializzazione dai modelli precedenti.BRPO migliora significativamente l'insieme di esperti e supera drasticamente i metodi RL adattivi esistenti.
Uno dei misteri del successo delle reti neurali è che i metodi di primo ordine inizializzati in modo casuale come la discesa del gradiente possono raggiungere una perdita di formazione pari a zero anche se la funzione obiettivo è non convessa e non liscia. Per una rete neurale superficiale con nodi nascosti da $m$ con attivazione ReLU e $n$ di dati di addestramento, mostriamo che se $m$ è abbastanza grande e non ci sono due ingressi paralleli, la discesa del gradiente inizializzata in modo casuale converge verso una soluzione globalmente ottimale ad un tasso di convergenza lineare per la funzione di perdita quadratica. La nostra analisi si basa sulla seguente osservazione: l'iperparametrizzazione e l'inizializzazione casuale limitano ogni vettore di peso ad essere vicino alla sua inizializzazione per tutte le iterazioni, il che ci permette di sfruttare una forte proprietà simile alla convessità per mostrare che la discesa del gradiente converge ad un tasso lineare globale verso l'optimum globale.Crediamo che queste intuizioni siano utili anche per analizzare i modelli profondi e altri metodi del primo ordine.
Per molte applicazioni, in particolare nelle scienze naturali, il compito è quello di determinare i parametri nascosti del sistema da un insieme di misurazioni.Spesso, il processo in avanti dallo spazio dei parametri a quello delle misurazioni è ben definito, mentre il problema inverso è ambiguo: più set di parametri possono risultare nella stessa misurazione.Per caratterizzare pienamente questa ambiguità, la distribuzione completa dei parametri posteriori, condizionata da una misurazione osservata, deve essere determinata.Noi sosteniamo che una particolare classe di reti neurali è ben adatta a questo compito - le cosiddette reti neurali invertibili (INNs). A differenza delle reti neurali classiche, che tentano di risolvere direttamente il problema dell'inverso ambiguo, le INN si concentrano sull'apprendimento del processo in avanti, utilizzando variabili di uscita latenti aggiuntive per catturare l'informazione altrimenti persa.A causa dell'invertibilità, un modello del processo inverso corrispondente viene appreso implicitamente. Dimostriamo teoricamente e verifichiamo sperimentalmente, su dati artificiali e problemi del mondo reale della medicina e dell'astrofisica, che le INN sono un potente strumento di analisi per trovare multi-modalità nello spazio dei parametri, scoprire correlazioni di parametri e identificare parametri non recuperabili.
Un esempio è l'uso dell'ipotesi i.i.d. nell'apprendimento online per applicazioni come la raccomandazione dei contenuti, dove la (scelta dei) contenuti visualizzati può cambiare le percezioni e le preferenze degli utenti, o addirittura allontanarli, causando uno spostamento nella distribuzione degli utenti.In generale, è possibile per un algoritmo cambiare la distribuzione dei suoi stessi input.Introduciamo il termine self-induced distributional shift (SIDS) per descrivere questo fenomeno. Un gran numero di lavori nell'apprendimento di rinforzo e nell'apprendimento automatico causale mira ad affrontare lo spostamento distributivo causato dall'implementazione di sistemi di apprendimento precedentemente addestrati offline.Il nostro obiettivo è simile, ma distinto: sottolineiamo che i cambiamenti all'algoritmo di apprendimento, come l'introduzione del meta-apprendimento, possono rivelare incentivi nascosti per lo spostamento distributivo (HIDS), e miriamo a diagnosticare e prevenire i problemi associati agli incentivi nascosti. Progettiamo un ambiente semplice come "prova dell'unitÃ " per il HIDS, cosÃ¬ come un ambiente di raccomandazione del soddisfare che permette che noi disentangle i tipi differenti di SIDS.Â dimostriamo il potenziale affinchÃ¨ il HIDS causi il comportamento inatteso o indesiderabile in questi ambienti e proponiamo e proviamo una strategia di attenuazione.Â 
Nelle mansioni di apprendimento di una classe, soltanto il caso normale puÃ² essere modellato con i dati, mentre la variazione di tutte le anomalie possibili Ã¨ troppo grande per essere descritta sufficientemente dai campioni. cosÃ¬, dovuto la mancanza di dati rappresentativi, gli approcci discriminativi ampiamente diffusi non possono riguardare tali mansioni di apprendimento e piuttosto i modelli generativi, che tentano di imparare la densitÃ dell'input dei casi normali, sono usati. tuttavia, i modelli generativi soffrono da una grande dimensionalitÃ dell'input (come nelle immagini) e sono tipicamente allievi inefficienti. Proponiamo di imparare la distribuzione dei dati in modo più efficiente con un autocodificatore multi-ipotesi.Inoltre, il modello è criticato da un discriminatore, che impedisce modalità artificiali non supportate dai dati, e che impone la diversità tra le ipotesi. Questa struttura di rilevamento delle anomalie basata sulla coerenza (ConAD) permette l'identificazione affidabile dei campioni fuori distribuzione. Per il rilevamento delle anomalie su CIFAR-10, produce fino al 3,9% di miglioramento rispetto ai risultati precedentemente riportati. Su un compito reale di rilevamento delle anomalie, l'approccio riduce l'errore dei modelli di base dal 6,8% all'1,5%.
Generative Adversarial Networks (GAN) può raggiungere prestazioni promettenti nell'apprendimento di distribuzioni di dati complessi su diversi tipi di dati.In questo articolo, mostriamo innanzitutto che un'estensione diretta di un algoritmo GAN esistente non è applicabile alle nuvole di punti, perché il vincolo richiesto per i discriminatori è indefinito per i dati impostati. Proponiamo una duplice modifica a un algoritmo GAN per essere in grado di generare nuvole di punti (PC-GAN). In primo luogo, combiniamo le idee della modellazione gerarchica bayesiana e dei modelli generativi impliciti imparando un processo di campionamento gerarchico e interpretabile.Una componente chiave del nostro metodo è che alleniamo una rete di inferenza posteriore per le variabili nascoste. In secondo luogo, PC-GAN definisce una struttura generica che può incorporare molti algoritmi GAN esistenti.Proponiamo inoltre un obiettivo sandwiching, che si traduce in una stima della distanza Wasserstein più stretta rispetto alla forma duale comunemente usata in WGAN.Convalidiamo le nostre affermazioni sul set di dati di riferimento ModelNet40 e osserviamo che PC-GAN addestrato dall'obiettivo sandwiching ottiene risultati migliori sui dati di test rispetto ai metodi esistenti. Abbiamo anche condotto studi su diversi compiti, tra cui la generalizzazione su nuvole di punti non visti, l'interpolazione dello spazio latente, la classificazione e la trasformazione da immagine a nuvole di punti, per dimostrare la versatilità dell'algoritmo PC-GAN proposto.
I meccanismi di attenzione esistenti, sono per lo più basati su elementi, nel senso che un modello è addestrato a partecipare a singoli elementi in una collezione (la memoria) dove ogni elemento ha una granularità predefinita e fissa, ad es, Intuitivamente, un'area nella memoria che consiste di più elementi può valere la pena di partecipare come un tutto.Proponiamo l'attenzione ad area: un modo per partecipare ad un'area della memoria, dove ogni area contiene un gruppo di elementi che sono o spazialmente adiacenti quando la memoria ha una struttura bidimensionale, come le immagini, o temporalmente adiacenti per la memoria 1-dimensionale, come le frasi del linguaggio naturale.Importante, la dimensione di un'area, vale a dire Il numero di elementi in un'area o il livello di aggregazione è determinato dinamicamente attraverso l'apprendimento, che può variare a seconda della coerenza appresa degli elementi adiacenti. Dando al modello la possibilità di partecipare a un'area di elementi, invece che solo a singoli elementi, un modello può partecipare a informazioni con granularità variabile. Valutiamo l'attenzione ad area su due compiti: traduzione automatica neurale (sia a livello di caratteri che di token) e didascalie di immagini, e miglioriamo rispetto alle basi forti (allo stato dell'arte) in tutti i casi. Questi miglioramenti sono ottenibili con una forma base di attenzione ad area che è priva di parametri.
Identifichiamo un fenomeno, a cui ci riferiamo come *dimenticanza di più modelli*, che si verifica quando si addestrano sequenzialmente più reti profonde con parametri parzialmente condivisi; le prestazioni dei modelli precedentemente addestrati si degradano quando si ottimizza un modello successivo, a causa della sovrascrittura dei parametri condivisi. Per superare questo problema, introduciamo una perdita di plasticità del peso statisticamente giustificata che regolarizza l'apprendimento dei parametri condivisi di un modello in base alla loro importanza per i modelli precedenti, e dimostriamo la sua efficacia quando si addestrano due modelli in modo sequenziale e per la ricerca dell'architettura neurale.Aggiungendo la plasticità del peso nella ricerca dell'architettura neurale si conservano i modelli migliori fino alla fine della ricerca e si ottengono risultati migliori sia nell'elaborazione del linguaggio naturale che nelle attività di visione artificiale.
Rivelare la struttura latente nei dati è un campo di ricerca attivo, avendo introdotto tecnologie interessanti come gli autoencoder variazionali e le reti avversarie, ed è essenziale per spingere l'apprendimento automatico verso la scoperta della conoscenza non supervisionata.Tuttavia, una sfida importante è la mancanza di benchmark adatti per una valutazione oggettiva e quantitativa delle rappresentazioni apprese.Per affrontare questo problema introduciamo Morpho-MNIST, un framework che mira a rispondere: "Estendiamo il popolare dataset MNIST aggiungendo un'analisi morfometrica che consente il confronto quantitativo dei modelli addestrati, l'identificazione dei ruoli delle variabili latenti e la caratterizzazione della diversità del campione. Proponiamo inoltre un set di perturbazioni quantificabili per valutare le prestazioni dei metodi non supervisionati e supervisionati su compiti impegnativi come il rilevamento degli outlier e l'adattamento al dominio.
L'esplorazione in ambienti con ricompense sparse è una sfida chiave per l'apprendimento di rinforzo.Come possiamo progettare agenti con pregiudizi induttivi generici in modo che possano esplorare in modo coerente invece di usare solo schemi di esplorazione locale come epsilon-greedy? Proponiamo un agente di apprendimento di rinforzo non supervisionato che impara un modello di raggruppamento discreto di pixel che conserva la geometria spaziale dei sensori e implicitamente anche dell'ambiente. Usiamo questa rappresentazione per derivare funzioni di ricompensa geometriche intrinseche, come le coordinate del centroide e l'area, e impariamo le politiche per controllare ognuna di esse con l'apprendimento off-policy.Queste politiche formano un set di base di comportamenti (opzioni) che ci permette di esplorare in modo coerente e usarle in un setup di apprendimento di rinforzo gerarchico per risolvere per ricompense estrinsecamente definite.Mostriamo che il nostro approccio può scalare a una varietà di domini con prestazioni competitive, compresa la navigazione in ambienti 3D e giochi Atari con ricompense sparse.
Mentre in generale tali problemi sono NP-Hard, da un punto di vista pratico, le soluzioni localmente ottimali possono essere utili. In alcuni problemi combinatoriali, tuttavia, può essere difficile definire quartieri di soluzioni significative che collegano ampie porzioni dello spazio di ricerca, ostacolando così i metodi che cercano direttamente questo spazio. suggeriamo di aggirare tali casi utilizzando un algoritmo di gradiente politico che trasforma il problema nel dominio continuo, e di ottimizzare un nuovo obiettivo surrogato che rende il primo come ottimizzatore stocastico generico. Questo si ottiene producendo un obiettivo surrogato la cui distribuzione è fissa e predeterminata, rimuovendo così la necessità di mettere a punto vari iper-parametri in un modo caso per caso. Poiché siamo interessati a metodi che possono recuperare con successo soluzioni localmente ottimali, usiamo il problema di trovare cricche localmente massime come un impegnativo benchmark sperimentale, e riportiamo i risultati su un grande dataset di grafi che è progettato per testare gli algoritmi di ricerca delle cricche. In particolare, mostriamo in questo benchmark che fissare la distribuzione del surrogato è la chiave per recuperare in modo coerente soluzioni localmente ottimali, e che il nostro obiettivo surrogato porta ad un algoritmo che supera gli altri metodi che abbiamo testato in una serie di misure.
Le reti neurali deterministiche (NN) sono sempre più impiegate in domini critici per la sicurezza, dove misure calibrate, robuste ed efficienti di incertezza sono cruciali. Mentre è possibile addestrare reti di regressione per produrre i parametri di una distribuzione di probabilità massimizzando una funzione di verosimiglianza gaussiana, il modello risultante rimane ignaro della fiducia sottostante alle sue previsioni. Ciò si ottiene ponendo dei priori probatori sulla nostra funzione di verosimiglianza gaussiana originale e addestrando il nostro NN a dedurre gli iperparametri della nostra distribuzione probatoria. Imponiamo dei priori durante l'addestramento in modo tale che il modello sia penalizzato quando la sua prova prevista non è allineata con l'output corretto. Così il modello stima non solo la media e la varianza probabilistica del nostro obiettivo, ma anche l'incertezza sottostante associata a ciascuno di quei parametri. Osserviamo che il nostro metodo di regressione probatoria impara misure ben calibrate di incertezza su vari benchmark, scala a compiti complessi di computer vision ed è robusto alle perturbazioni avversarie dell'input.
L'ipotesi del biglietto della lotteria di Frankle & Carbin (2019) ipotizza che, per reti neurali di dimensioni tipiche, sia possibile trovare piccole sottoreti che si allenano più velocemente e forniscono prestazioni superiori alle loro controparti originali. L'algoritmo proposto per cercare tali sottoreti (biglietti vincenti), Iterative Magnitude Pruning (IMP), trova costantemente sottoreti con il 90-95% di parametri in meno che si allenano più velocemente e meglio dei modelli iperparametrizzati da cui sono stati estratti, creando potenziali applicazioni a problemi come l'apprendimento di trasferimento. In questo articolo, proponiamo un nuovo algoritmo per la ricerca di biglietti vincenti, Continuous Sparsification, che rimuove continuamente i parametri da una rete durante l'addestramento, e impara la struttura della sottorete con metodi basati sul gradiente invece di affidarsi a strategie di pruning.Mostriamo empiricamente che il nostro metodo è in grado di trovare biglietti che superano quelli appresi da Iterative Magnitude Pruning, e allo stesso tempo fornendo una ricerca fino a 5 volte più veloce, se misurata in numero di epoche di addestramento.
Nella maggior parte delle impostazioni pratiche e delle analisi teoriche, si assume che un modello possa essere addestrato fino alla convergenza.Tuttavia, la crescente complessità dei set di dati e dei modelli di apprendimento automatico può violare tali ipotesi.Infatti, gli approcci attuali per la sintonizzazione dell'iperparametro e la ricerca dell'architettura neurale tendono ad essere limitati da vincoli pratici di risorse.Pertanto, introduciamo un'impostazione formale per studiare l'addestramento sotto il regime non asintotico e con risorse limitate, cioè, Analizziamo il seguente problema: "dato un set di dati, un algoritmo e un budget di risorse fisso, qual è la migliore prestazione ottenibile? "Ci concentriamo sul numero di iterazioni di ottimizzazione come risorsa rappresentativa.In tale contesto, dimostriamo che è fondamentale regolare il programma di tasso di apprendimento in base al budget dato.Tra i programmi di apprendimento consapevoli del budget, troviamo che il semplice decadimento lineare è sia robusto che ad alte prestazioni. Abbiamo anche analizzato i nostri risultati e scoperto che la chiave per un buon programma è la convergenza a budget, un fenomeno per cui il gradiente svanisce alla fine di ogni budget consentito. Abbiamo anche rivisto gli approcci esistenti per la convergenza veloce e mostrato che i programmi di apprendimento attenti al budget superano facilmente tali approcci sotto (l'impostazione pratica ma inesplorata) di formazione a budget.
Presentiamo un nuovo approccio per un'esplorazione efficiente che sfrutta una codifica bidimensionale dell'ambiente appresa con una combinazione di obiettivi basati sul modello e senza modello. Il nostro approccio utilizza ricompense intrinseche che si basano su una distanza ponderata dei vicini più vicini nello spazio di rappresentazione bidimensionale per valutare la novità. Un elemento chiave del nostro approccio è che eseguiamo più passi di gradiente tra ogni passo dell'ambiente per garantire l'accuratezza del modello. Testiamo il nostro approccio su una serie di compiti di labirinto, così come un problema di controllo e dimostriamo che il nostro approccio di esplorazione è più efficiente rispetto alle linee di base forti.
Le reti neurali sono vulnerabili a piccole perturbazioni avversarie.Mentre la letteratura esistente si concentra in gran parte sulla vulnerabilità dei modelli appresi, dimostriamo un fenomeno intrigante che la robustezza avversaria, a differenza dell'accuratezza pulita, è sensibile alla distribuzione dei dati di input.Anche una trasformazione che preserva la semantica sulla distribuzione dei dati di input può causare una robustezza significativamente diversa per il modello addestrato avversariamente che è sia addestrato che valutato sulla nuova distribuzione. Lo dimostriamo costruendo varianti semanticamente identiche per MNIST e CIFAR10 rispettivamente, e mostriamo che i modelli addestrati in modo standard raggiungono accuratezze pulite simili su di essi, ma i modelli addestrati in modo avverso raggiungono accuratezze di robustezza significativamente diverse.Questo fenomeno controintuitivo indica che la sola distribuzione dei dati di input può influenzare la robustezza avversaria delle reti neurali addestrate, non necessariamente i compiti stessi.Infine, discutiamo le implicazioni pratiche sulla valutazione della robustezza avversaria, e facciamo i primi tentativi di comprendere questo complesso fenomeno.
L'inefficienza del campione è un problema di lunga durata nell'apprendimento per rinforzo (RL).  Lo stato dell'arte utilizza la funzione di valore dell'azione per derivare la politica, mentre di solito comporta una ricerca estesa sullo spazio stato-azione e un'ottimizzazione instabile.Verso la RL efficiente dal punto di vista del campione, proponiamo il ranking policy gradient (RPG), un metodo di gradiente della politica che impara il rango ottimale di un insieme di azioni discrete.  Per accelerare l'apprendimento dei metodi di gradiente della politica, stabiliamo l'equivalenza tra la massimizzazione del limite inferiore del ritorno e l'imitazione di una politica quasi-ottimale senza accedere ad alcun oracolo.Questi risultati portano ad un quadro generale di apprendimento off-policy, che conserva l'ottimalità, riduce la varianza, e migliora l'efficienza del campione.conduciamo ampi esperimenti che mostrano che quando si consolida con il quadro di apprendimento off-policy, RPG riduce sostanzialmente la complessità del campione, rispetto allo state-of-the-art.
Introduciamo MultiGrain, un'architettura di rete neurale che genera vettori compatti di incorporamento dell'immagine che risolvono più compiti di diversa granularità: classe, istanza e riconoscimento di copia.MultiGrain è addestrato congiuntamente per la classificazione ottimizzando la perdita di cross-entropia e per il riconoscimento di istanza/copia ottimizzando una perdita di classifica auto-supervisionata.La perdita auto-supervisionata utilizza solo l'aumento dei dati e quindi non richiede etichette aggiuntive.Notevolmente, le incorporazioni unificate non solo sono molto più compatte rispetto all'utilizzo di diverse incorporazioni specializzate, ma hanno anche la stessa o migliore accuratezza. Quando viene alimentato a un classificatore lineare, MultiGrain usando ResNet-50 raggiunge il 79,4% di accuratezza top-1 su ImageNet, un miglioramento assoluto del +1,8% rispetto all'attuale metodo AutoAugment allo stato dell'arte.Le stesse embeddings si comportano alla pari con il recupero di istanze allo stato dell'arte con immagini di risoluzione moderata.Uno studio di ablazione mostra che il nostro approccio beneficia dell'auto-supervisione, del metodo di pooling e dei mini-batches con ripetuti incrementi della stessa immagine.
 In questo articolo, studiamo la mappatura della relazione di iponimia di wordnet ai vettori di caratteristiche.  Il nostro obiettivo è quello di modellare la conoscenza lessicale in modo tale che possa essere utilizzata come input in modelli generici di apprendimento automatico, come i predittori di entailment delle frasi.  Proponiamo due modelli: il primo sfrutta una mappatura esistente di parole a vettori di caratteristiche (fasttext), e tenta di classificare tali vettori come all'interno o all'esterno di ogni classe; il secondo modello è completamente supervisionato, usando solo wordnet come verità di base, e mappa ogni concetto a un intervallo o una sua disgiunzione.  Con il primo modello, ci avviciniamo, ma non raggiungiamo del tutto lo stato dell'arte, mentre il secondo modello può raggiungere una precisione quasi perfetta.
Le reti neurali ricorrenti (RNN) sono potenti modelli di sequenze autoregressive per l'apprendimento di modelli prevalenti nel linguaggio naturale.   Tuttavia, il linguaggio generato dalle RNN mostra spesso diverse caratteristiche degenerate che non sono comuni nel linguaggio umano; pur essendo fluente, la produzione linguistica delle RNN può essere eccessivamente generica, ripetitiva e persino autocontraddittoria.  Noi postuliamo che la funzione obiettivo ottimizzata dai modelli linguistici RNN, che ammonta alla perplessità complessiva di un testo, non è abbastanza espressiva per catturare le qualità astratte di una buona generazione, come le massime di Grice. In questo articolo, introduciamo un quadro generale di apprendimento che può costruire un obiettivo di decodifica più adatto alla generazione, partendo da un modello linguistico RNN generativamente addestrato, il nostro quadro impara a costruire un generatore sostanzialmente più forte combinando diversi modelli discriminativamente addestrati che possono affrontare collettivamente i limiti della generazione RNN.  La valutazione umana dimostra che il testo generato dal generatore risultante è preferito rispetto a quello delle linee di base con un ampio margine e migliora significativamente la coerenza complessiva, lo stile e il contenuto informativo del testo generato.
Negli ultimi anni, l'efficienza e persino la fattibilità delle tradizionali politiche di bilanciamento del carico sono messe in discussione dalla rapida crescita dell'infrastruttura cloud con livelli crescenti di eterogeneità dei server e dimensioni crescenti dei servizi e delle applicazioni cloud.In tali sistemi eterogenei software-load-balancer, le soluzioni tradizionali, come JSQ, incorrono in un crescente overhead di comunicazione, mentre le alternative a bassa comunicazione, come JSQ(d) e lo schema JIQ recentemente proposto sono instabili o forniscono prestazioni scarse. Noi sosteniamo che un migliore schema di bilanciamento del carico a bassa comunicazione può essere stabilito permettendo ad ogni dispatcher di avere una visione diversa del sistema e continuare ad usare JSQ, piuttosto che cercare avidamente di evitare lo starvation su una base per decisione. di conseguenza, introduciamo la famiglia Loosely-Shortest -Queue di algoritmi di bilanciamento del carico. in parole povere, in Loosely-shortest -Queue, ogni dispatcher mantiene una diversa approssimazione della lunghezza delle code dei server e indirizza i lavori al più corto tra questi. Stabiliamo formalmente la forte stabilità di qualsiasi politica Loosely-Shortest -Queue e forniamo una condizione sufficiente facile da verificare per verificare che una politica sia Loosely-Shortest -Queue.dimostriamo inoltre che l'approccio Loosely-Shortest -Queue permette di costruire politiche ottimali per il rendimento con un budget di comunicazione arbitrariamente basso. Infine, utilizzando ampie simulazioni che considerano sistemi omogenei, eterogenei e altamente skewed eterogenei in scenari con un singolo dispatcher così come con dispatcher multipli, dimostriamo che le politiche di esempio Loosely-Shortest -Queueue esaminate sono sempre stabili come dettato dalla teoria, inoltre, esibisce una performance interessante e supera significativamente le ben note politiche a bassa comunicazione, come JSQ(d) e JIQ, mentre utilizza un budget di comunicazione simile.
Proponiamo una nuova misura quantitativa per prevedere le prestazioni di un classificatore di rete neurale profonda, dove la misura è derivata esclusivamente dalla struttura del grafico della rete. Ci aspettiamo che questa misura sia un primo passo fondamentale nello sviluppo di un metodo per valutare nuove architetture di rete e ridurre la dipendenza dai processi di ottimizzazione per tentativi ed errori o "forza bruta" computazionalmente costosi coinvolti nella selezione del modello. La misura è derivata nel contesto dei perceptron multistrato (MLP), ma le definizioni si dimostrano utili anche nel contesto delle reti neurali convoluzionali profonde (CNN), dove è in grado di stimare e confrontare le prestazioni relative di diversi tipi di reti neurali, come VGG, ResNet e DenseNet. La nostra misura è anche usata per studiare gli effetti di alcuni importanti iper-parametri "nascosti" dell'architettura DenseNet, come il numero di strati, il tasso di crescita e la dimensione delle convoluzioni 1x1 in DenseNet-BC.In definitiva, la nostra misura facilita l'ottimizzazione del design DenseNet, che mostra risultati migliori rispetto alla linea di base.
C'è una forte disparità tra i tassi di apprendimento utilizzati nella pratica dell'apprendimento automatico su larga scala e quelli che sono considerati ammissibili nella teoria dell'approssimazione stocastica. I risultati recenti, come i metodi "super-convergenza" che utilizzano tassi di apprendimento oscillanti, servono a sottolineare ancora di più questo punto. Una spiegazione plausibile è che le procedure di addestramento delle reti neurali non convesse sono più adatte all'uso di programmi di apprendimento fondamentalmente diversi, come il metodo ``tagliare il tasso di apprendimento ogni numero costante di epoche'' (che assomiglia più da vicino a un programma di apprendimento a decadimento esponenziale); si noti che questo programma ampiamente utilizzato è in netto contrasto con gli schemi di decadimento polinomiale prescritti nella letteratura sull'approssimazione stocastica, che hanno dimostrato di essere (nel caso peggiore) ottimali per classi di problemi di ottimizzazione convessi. Il contributo principale di questo lavoro mostra che il quadro è molto più sfumato, dove non abbiamo nemmeno bisogno di passare all'ottimizzazione non convessa per mostrare che altri schemi di tasso di apprendimento possono essere molto più efficaci. Infatti, anche per il semplice caso della regressione lineare stocastica con un orizzonte temporale fisso, il tasso raggiunto da qualsiasi schema di decadimento polinomiale è sub-ottimale rispetto al tasso statistico minimax (di un fattore del numero di condizioni); al contrario il ```taglio del tasso di apprendimento ogni numero costante di epoche'' fornisce un miglioramento esponenziale (dipendente solo logaritmicamente dal numero di condizioni) rispetto a qualsiasi schema di decadimento polinomiale.  Infine, è importante chiedersi se le nostre intuizioni teoriche sono in qualche modo fondamentalmente legate alla minimizzazione delle perdite quadratiche (dove abbiamo aggirato i limiti inferiori minimax per problemi di ottimizzazione convessi più generali)? Qui, congetturiamo che i recenti risultati che rendono la norma del gradiente piccola ad un tasso quasi ottimale, sia per l'ottimizzazione convessa che non convessa, possono anche fornire maggiori intuizioni sugli schemi di apprendimento utilizzati nella pratica.
Presentiamo Value Propagation (VProp), un insieme di moduli di pianificazione differenziabili ed efficienti dal punto di vista dei parametri, costruiti su Value Iteration, che possono essere addestrati con successo utilizzando l'apprendimento di rinforzo per risolvere compiti non visti, hanno la capacità di generalizzarsi a mappe di dimensioni maggiori e possono imparare a navigare in ambienti dinamici. Mostriamo che i moduli permettono di imparare a pianificare quando l'ambiente include anche elementi stocastici, fornendo un sistema di apprendimento efficiente in termini di costi per costruire pianificatori invarianti di basso livello per una varietà di problemi di navigazione interattiva. Valutiamo su configurazioni statiche e dinamiche di MazeBase grid-worlds, con ambienti generati casualmente di diverse dimensioni, e su uno scenario di navigazione StarCraft, con dinamiche più complesse, e pixel come input.
L'apprendimento di embeddings di parole di alta qualità è di notevole importanza per ottenere prestazioni migliori in molte attività di apprendimento a valle. Da un lato, le embeddings di parole tradizionali sono addestrate su un corpus su larga scala per compiti di uso generale, che spesso sono sub-ottimali per molti compiti specifici di un dominio. D'altra parte, molti compiti specifici del dominio non hanno un corpus di dominio abbastanza grande per ottenere embeddings di alta qualità.Osserviamo che i domini non sono isolati e un piccolo corpus di dominio può sfruttare la conoscenza appresa da molti domini precedenti per aumentare quel corpus al fine di generare embeddings di alta qualità.In questo articolo, formuliamo l'apprendimento di embeddings di parole come un processo di apprendimento permanente. Data la conoscenza appresa da molti domini precedenti e un piccolo corpus di nuovi domini, il metodo proposto può effettivamente generare nuove embeddings di dominio sfruttando un algoritmo semplice ma efficace e un meta-learner, dove il meta-learner è in grado di fornire informazioni sulla similarità del contesto delle parole a livello di dominio. I risultati sperimentali dimostrano che il metodo proposto può imparare efficacemente nuove embeddings di dominio da un piccolo corpus e da conoscenze di dominio passate. Dimostriamo anche che le embeddings generiche addestrate da un corpus su larga scala sono sub-ottimali in compiti specifici del dominio.
La potatura dei parametri è un approccio promettente per la compressione e l'accelerazione di CNN eliminando i parametri ridondanti del modello con una perdita di prestazioni tollerabile. Nonostante la sua efficacia, i metodi di potatura dei parametri basati sulla regolarizzazione esistenti di solito guidano i pesi verso lo zero con fattori di regolarizzazione grandi e costanti, il che trascura il fatto che l'espressività di CNN è fragile e ha bisogno di un modo più delicato di regolarizzazione per le reti di adattarsi durante la potatura. Per risolvere questo problema, proponiamo un nuovo metodo di potatura basato sulla regolarizzazione (chiamato IncReg) per assegnare in modo incrementale diversi fattori di regolarizzazione a diversi gruppi di pesi in base alla loro importanza relativa, la cui efficacia è dimostrata su CNN popolari rispetto ai metodi all'avanguardia.
I metodi a gradiente stocastico basati sul momento, come Heavy Ball (HB) e Nesterov's accelerated gradient descent (NAG) sono ampiamente utilizzati nella pratica per l'addestramento di reti profonde e altri modelli di apprendimento supervisionato, in quanto spesso forniscono miglioramenti significativi rispetto alla discesa del gradiente stocastico (SGD).Rigorosamente parlando, i metodi a gradiente veloce hanno miglioramenti dimostrabili rispetto alla discesa del gradiente solo per il caso deterministico, dove i gradienti sono esatti. Nel caso stocastico, la spiegazione popolare per la loro ampia applicabilità è che quando questi metodi a gradiente veloce sono applicati nel caso stocastico, imitano parzialmente le loro controparti a gradiente esatto, risultando in qualche guadagno pratico. Questo lavoro fornisce un contrappunto a questa credenza dimostrando che esistono istanze di problemi semplici in cui questi metodi non possono superare SGD nonostante la migliore impostazione dei suoi parametri. Queste istanze problematiche negative sono, in senso informale, generiche; non sembrano istanze patologiche accuratamente costruite.Questi risultati suggeriscono (insieme all'evidenza empirica) che i guadagni di prestazioni pratiche di HB o NAG sono un sottoprodotto del minibatching.Inoltre, questo lavoro fornisce una valida (e dimostrabile) alternativa, che, sullo stesso insieme di istanze problematiche, migliora significativamente le prestazioni di HB, NAG e SGD. Questo algoritmo, chiamato Accelerated Stochastic Gradient Descent (ASGD), è un algoritmo stocastico semplice da implementare, basato su una variante relativamente meno popolare dell'accelerazione di Nesterov. I risultati empirici estesi in questo lavoro mostrano che ASGD ha guadagni di prestazioni rispetto a HB, NAG e SGD. Il codice per implementare l'algoritmo ASGD può essere trovato su https://github.com/rahulkidambi/AccSGD.
Oversubscription planning (OSP) è il problema di trovare piani che massimizzano il valore di utilità del loro stato finale, pur rimanendo entro un limite di costo specificato.Recentemente, è stato dimostrato che i problemi OSP possono essere riformulati come problemi di pianificazione classici con funzioni di costo multiple ma senza utilità.  Qui approfittiamo di questa riformulazione per mostrare che i problemi OSP possono essere risolti in modo ottimale usando l'algoritmo di ricerca A*, in contrasto con gli approcci precedenti che hanno usato variazioni della ricerca branch-and-bound. Introduciamo anche nuove euristiche sensibili ai limiti, che sono in grado di ragionare sul costo primario di una soluzione tenendo conto delle funzioni di costo secondarie e dei limiti, per fornire una guida superiore rispetto alle euristiche che non tengono conto di questi limiti. Implementiamo due varianti sensibili ai limiti delle euristiche di pianificazione classica esistenti, e dimostriamo sperimentalmente che la ricerca risultante è significativamente più informata delle euristiche comparabili che non considerano i limiti.
Il lavoro precedente sulle reti neurali adversamente robuste richiede grandi insiemi di formazione e procedure di formazione computazionalmente costose.  D'altra parte, i metodi di apprendimento a pochi colpi sono altamente vulnerabili agli esempi avversari.  L'obiettivo del nostro lavoro è quello di produrre reti che si comportino bene in compiti di pochi scatti e che siano contemporaneamente robuste agli esempi avversari.  Adattiamo l'addestramento avversario per il meta-apprendimento, adattiamo le caratteristiche architettoniche robuste alle piccole reti per il meta-apprendimento, testiamo le difese di pre-elaborazione come alternativa all'addestramento avversario per il meta-apprendimento, e studiamo i vantaggi del meta-apprendimento robusto rispetto al transfer-learning robusto per compiti a pochi colpi.  Questo lavoro fornisce un'analisi approfondita dei metodi adversarialmente robusti nel contesto del meta-apprendimento, e gettiamo le basi per il lavoro futuro sulle difese per compiti a pochi colpi.
Uno dei presupposti comuni è che le reti neurali convoluzionali devono essere stabili alle piccole traslazioni e deformazioni per risolvere i compiti di riconoscimento delle immagini. Per molti anni, questa stabilità è stata inserita nelle architetture CNN incorporando strati di pooling interfogliati: Le nostre intuizioni sulla stabilità di deformazione sono giuste? È importante? Il pooling è necessario per l'invarianza di deformazione? Se no, come si ottiene l'invarianza di deformazione in sua assenza? In questo lavoro, testiamo rigorosamente queste domande, e scopriamo che la stabilità di deformazione nelle reti convoluzionali è più sfumata di quanto sembri: (1) L'invarianza di deformazione non è una proprietà binaria, ma piuttosto che diversi compiti richiedono diversi gradi di stabilità di deformazione a diversi livelli. (2) La stabilità di deformazione non è una proprietà fissa di una rete e viene pesantemente regolata nel corso dell'addestramento, in gran parte attraverso la morbidezza dei filtri convoluzionali. (3) I livelli di pooling interfogliati non sono né necessari né sufficienti per raggiungere la forma ottimale di stabilità di deformazione per la classificazione delle immagini naturali. (4) Il pooling conferisce troppa stabilità di deformazione per la classificazione delle immagini all'inizializzazione, e durante l'addestramento le reti devono imparare a contrastare questo bias induttivo. Insieme, questi risultati forniscono nuove intuizioni sul ruolo del pooling interfogliato e sull'invarianza di deformazione nelle CNN, e dimostrano l'importanza di rigorosi test empirici anche delle nostre ipotesi più basilari sul funzionamento delle reti neurali.
È stato dimostrato che le reti neurali profonde (DNN) si adattano eccessivamente a un set di dati quando vengono addestrate con etichette rumorose per un periodo di tempo abbastanza lungo. Per superare questo problema, presentiamo un metodo semplice ed efficace di filtraggio delle etichette auto-assemblate (SELF) per filtrare progressivamente le etichette sbagliate durante l'addestramento. Il nostro metodo migliora le prestazioni del compito consentendo gradualmente la supervisione solo dalle etichette potenzialmente non rumorose (pulite) e ferma l'apprendimento sulle etichette rumorose filtrate. Mostriamo che queste stime d'insieme producono un'identificazione più accurata delle previsioni incoerenti durante l'addestramento rispetto alle singole stime della rete all'epoca di addestramento più recente.Mentre i campioni filtrati vengono rimossi interamente dalla perdita di addestramento supervisionato, li sfruttiamo dinamicamente tramite l'apprendimento semi-supervisionato nella perdita non supervisionata. Dimostriamo l'effetto positivo di un tale approccio su vari compiti di classificazione delle immagini sotto entrambi i rumori simmetrici e asimmetrici dell'etichetta e con diversi rapporti di rumore, superando sostanzialmente tutti i lavori precedenti sull'apprendimento consapevole del rumore attraverso diversi set di dati e può essere applicato a un ampio set di architetture di rete.
I lunghi tempi di addestramento delle reti neurali profonde sono un collo di bottiglia nella ricerca sull'apprendimento automatico. L'impedimento principale all'addestramento veloce è la crescita quadratica sia della memoria che dei requisiti di calcolo degli strati densi e convoluzionali rispetto alla loro larghezza di banda di informazioni. Recentemente, l'addestramento di reti sparse "a priori" è stato proposto come un metodo per permettere agli strati di mantenere un'elevata larghezza di banda di informazioni, mantenendo la memoria e il calcolo bassi. Tuttavia, la scelta di quale topologia sparsa dovrebbe essere usata in queste reti non è chiara. Per spiegare queste differenze, sviluppiamo un'euristica priva di dati in grado di valutare una topologia indipendentemente dal set di dati su cui la rete sarà addestrata, quindi deriviamo una serie di requisiti che fanno una buona topologia e arriviamo a una singola topologia che li soddisfa tutti.
I modelli di apprendimento profondo richiedono un'ampia esplorazione del design dell'architettura e l'ottimizzazione degli iperparametri per eseguire bene un dato compito.L'esplorazione dello spazio di design del modello è spesso fatta da un esperto umano, e ottimizzata usando una combinazione di ricerca a griglia ed euristica su un ampio spazio di scelte possibili.Neural Architecture Search (NAS) è un approccio di Reinforcement Learning che è stato proposto per automatizzare il design dell'architettura. NAS è stato applicato con successo per generare reti neurali che rivaleggiano con le migliori architetture progettate dall'uomo.Tuttavia, NAS richiede il campionamento, la costruzione e l'addestramento di centinaia o migliaia di modelli per ottenere architetture ben performanti.Questa procedura deve essere eseguita da zero per ogni nuovo compito.L'applicazione di NAS a un ampio insieme di compiti attualmente manca di un modo per trasferire la conoscenza generalizzabile tra i compiti. Il nostro obiettivo è quello di apprendere una struttura generalizzabile che possa condizionare la costruzione del modello alla ricerca di modelli di successo per compiti già visti, accelerando così significativamente la ricerca di nuovi compiti. Sfruttando la conoscenza delle ricerche precedenti, troviamo che i modelli MNMS pre-addestrati partono da una posizione migliore nello spazio di ricerca e riducono il tempo di ricerca su compiti mai visti, mentre continuano a scoprire modelli che superano i modelli progettati dall'uomo pubblicati.
Questo lavoro studia il problema della modellazione dei processi visivi non lineari sfruttando le architetture generative profonde per l'apprendimento di modelli lineari e gaussiani delle sequenze osservate, proponendo un quadro di apprendimento congiunto che combina un modello autoregressivo multivariato e reti generative convoluzionali profonde. Dopo aver giustificato i presupposti teorici dell'inearizzazione, proponiamo un'architettura che permette agli autocodificatori variazionali e alle reti generative adversariali di imparare simultaneamente l'osservazione non lineare e il modello lineare di transizione di stato da una sequenza di fotogrammi osservati.Infine, dimostriamo il nostro approccio su esempi giocattolo concettuali e texture dinamiche.
Le equazioni differenziali parziali (PDE) giocano un ruolo di primo piano in molte discipline come la matematica applicata, la fisica, la chimica, la scienza dei materiali, l'informatica, etc.PDEs sono comunemente derivate sulla base di leggi fisiche o osservazioni empiriche.Tuttavia, le equazioni di governo per molti sistemi complessi nelle applicazioni moderne non sono ancora completamente note.Con il rapido sviluppo di sensori, potenza di calcolo e archiviazione dei dati nell'ultimo decennio, enormi quantità di dati possono essere facilmente raccolti e memorizzati in modo efficiente. Ispirati dagli ultimi sviluppi dei progetti di reti neurali nell'apprendimento profondo, proponiamo una nuova rete profonda feed-forward, chiamata PDE-Net, per soddisfare due obiettivi allo stesso tempo: prevedere accuratamente le dinamiche dei sistemi complessi e scoprire i modelli PDE nascosti sottostanti. L'idea di base della PDE-Net proposta è quella di imparare gli operatori differenziali imparando i kernel di convoluzione (filtri), e applicare le reti neurali o altri metodi di apprendimento automatico per approssimare le risposte non lineari sconosciute. Confrontando con gli approcci esistenti, che presuppongono che la forma della risposta non lineare sia nota o che fissano alcune approssimazioni a differenza finita degli operatori differenziali, il nostro approccio ha la massima flessibilità imparando sia gli operatori differenziali che le risposte non lineari. Una caratteristica speciale della rete PDE proposta è che tutti i filtri sono adeguatamente vincolati, il che ci permette di identificare facilmente i modelli PDE governanti, pur mantenendo la potenza espressiva e predittiva della rete. Questi vincoli sono accuratamente progettati sfruttando appieno la relazione tra gli ordini degli operatori differenziali e gli ordini delle regole di somma dei filtri (un concetto importante originato dalla teoria delle wavelet). Discutiamo anche le relazioni della PDE-Net con alcune reti esistenti nella computer vision come la Network-In-Network (NIN) e la Residual Neural Network (ResNet).Gli esperimenti numerici mostrano che la PDE-Net ha il potenziale per scoprire la PDE nascosta della dinamica osservata, e prevedere il comportamento dinamico per un tempo relativamente lungo, anche in un ambiente rumoroso.
Ogni passo di addestramento per un autocodificatore variazionale (VAE) ci richiede di campionare dal posteriore approssimato, quindi di solito scegliamo posteriori approssimati semplici (ad esempio fattorizzati) in cui il campionamento è un calcolo efficiente che sfrutta pienamente il parallelismo della GPU.  Tuttavia, tali posteriori approssimati semplici sono spesso insufficienti, poiché eliminano le dipendenze statistiche nel posteriore.  L'approccio più naturale per modellare le dipendenze discrete è una distribuzione autoregressiva, ma il campionamento da tali distribuzioni è intrinsecamente sequenziale e quindi lento.  Sviluppiamo una procedura di campionamento veloce e parallela per le distribuzioni autoregressive basata su iterazioni a punto fisso che consente un'inferenza variazionale efficiente e accurata nei modelli discreti di spazio di stato.  Per ottimizzare il limite variazionale, abbiamo considerato due modi per valutare le probabilità: inserendo i campioni rilassati direttamente nel pmf per la distribuzione discreta, o convertendo a variabili latenti logistiche continue e interpretando le iterazioni a punto fisso a K passi come un flusso di normalizzazione.  Abbiamo scoperto che la conversione a variabili latenti continue ha dato un considerevole margine aggiuntivo per il mismatch tra i posteriori veri e approssimati, che ha portato a inferenze distorte, abbiamo quindi utilizzato il primo approccio.  Abbiamo testato il nostro approccio sul problema delle neuroscienze di dedurre l'attività discreta di spike da dati rumorosi di calcium-imaging, e abbiamo scoperto che ha dato stime accurate di connettività in un ordine di grandezza inferiore.
Le reti neurali profonde (DNN) hanno avuto un grande successo in compiti NLP come la modellazione del linguaggio, la traduzione automatica e alcuni compiti di risposta alle domande (QA).Tuttavia, il successo è limitato a compiti più intensivi di conoscenza come la QA da un grande corpus.I modelli esistenti di QA profonda end-to-end (Miller et al., 2016; Weston et al, 2014) hanno bisogno di leggere l'intero testo dopo aver osservato la domanda, e quindi la loro complessità nel rispondere a una domanda è lineare nella dimensione del testo.Questo è proibitivo per compiti pratici come la QA da Wikipedia, un romanzo, o il Web.Noi proponiamo di risolvere questo problema di scalabilità utilizzando rappresentazioni di significato simbolico, che possono essere indicizzate e recuperate in modo efficiente con una complessità che è indipendente dalla dimensione del testo. Più specificamente, usiamo modelli sequenza-sequenza per codificare simbolicamente la conoscenza e generare programmi per rispondere a domande dalla conoscenza codificata.Applichiamo il nostro approccio, chiamato N-Gram Machine (NGM), ai compiti bAbI (Weston et al, 2015) e una versione speciale di essi ("life-long bAbI") che ha storie fino a 10 milioni di frasi.I nostri esperimenti mostrano che NGM puÃ² risolvere con successo entrambi questi compiti in modo accurato ed efficiente.A differenza dei modelli di memoria completamente differenziabili, la complessitÃ temporale e la qualitÃ della risposta di NGM non sono influenzate dalla lunghezza della storia. L'intero sistema di NGM è addestrato end-to-end con REINFORCE (Williams, 1992).Per evitare l'alta varianza nella stima del gradiente, che è tipica nei modelli di variabili latenti discrete, usiamo la ricerca a fascio invece del campionamento.Per affrontare lo spazio di ricerca esponenzialmente grande, usiamo un obiettivo di autocodifica stabilizzato e una procedura di modifica della struttura per ridurre e raffinare iterativamente lo spazio di ricerca.
Proponiamo di usare un obiettivo di meta-apprendimento che massimizza la velocità di trasferimento su una distribuzione modificata per imparare come modulare la conoscenza acquisita. In particolare, ci concentriamo su come fattorizzare una distribuzione congiunta in condizionali appropriati, coerenti con le direzioni causali. Spieghiamo quando questo può funzionare, utilizzando l'ipotesi che i cambiamenti nelle distribuzioni siano localizzati (ad esempio ad uno dei marginali, per esempio a causa di un intervento su una delle variabili).Dimostriamo che sotto questa ipotesi di cambiamenti localizzati nei meccanismi causali, il grafico causale corretto tenderà ad avere solo alcuni dei suoi parametri con gradiente non nullo, cioè che devono essere adattati (e che non sono stati modificati). Sosteniamo e osserviamo sperimentalmente che questo porta a un adattamento più veloce, e usiamo questa proprietà per definire un punteggio surrogato di meta-apprendimento che, oltre a una parametrizzazione continua dei grafi, favorirebbe i grafi causali corretti.Infine, motivato dal punto di vista dell'agente AI (ad es. Infine, motivati dal punto di vista di un agente IA (ad esempio un robot che scopre autonomamente il suo ambiente), consideriamo come lo stesso obiettivo possa scoprire le variabili causali stesse, come una trasformazione di variabili di basso livello osservate senza significato causale.Gli esperimenti nel caso di due variabili convalidano le idee proposte e i risultati teorici.
L'apprendimento continuo è un obiettivo di lunga data dell'intelligenza artificiale, ma è spesso ostacolato dalla dimenticanza catastrofica che impedisce alle reti neurali di imparare i compiti in modo sequenziale.I metodi precedenti nell'apprendimento continuo hanno dimostrato come mitigare la dimenticanza catastrofica e imparare nuovi compiti mantenendo le prestazioni sui compiti precedenti. Analizziamo la dimenticanza catastrofica dal punto di vista del cambiamento nella probabilità del classificatore e proponiamo un semplice criterio di minimizzazione L1 che può essere adattato a diversi casi d'uso.Indaghiamo ulteriormente due modi per minimizzare la dimenticanza come quantificato da questo criterio e proponiamo strategie per ottenere un controllo più fine sulla dimenticanza.Infine, valutiamo le nostre strategie su 3 set di dati di varia difficoltà e dimostriamo miglioramenti rispetto alle strategie L2 precedentemente note per mitigare la dimenticanza catastrofica.
Proponiamo un approccio per costruire modelli realistici 3D morphable facciale (3DMM) che permette un flusso di lavoro intuitivo attributo faccialeediting.Current metodi di modellazione del viso utilizzando 3DMM soffrono della mancanza di controllo locale.We quindi creare un 3DMM bycombining 3DMM basato su parti locali per gli occhi, naso, bocca, orecchie, e regioni maschera facciale. Il nostro approccio locale basato su PCA utilizza un nuovo metodo per selezionare i migliori autovettori dalle 3DMM locali per garantire che la 3DMM combinata sia espressiva e consenta una ricostruzione accurata. I controlli di modifica che forniamo all'utente sono intuitivi, poiché sono estratti da misure antropometriche trovate in letteratura. Da un grande insieme di possibili misure antropometriche, filtriamo quelle che hanno un potere generativo significativo dato il set di dati del viso, e leghiamo le misure al 3DMM basato sulle parti attraverso matrici di mappatura derivate dal nostro set di dati di scansioni facciali. Il nostro 3DMM basato sulle parti è compatto ma accurato e, rispetto ad altri metodi 3DMM, fornisce un nuovo compromesso tra controllo locale e globale. Abbiamo testato il nostro approccio su un set di dati di 135 scansioni utilizzate per derivare il 3DMM, più 19 scansioni che servivano per la convalida. I risultati mostrano che il nostro approccio 3DMM basato sulle parti ha eccellenti proprietà generative e permette un controllo locale intuitivo all'utente.
Esaminiamo otto algoritmi di classificazione di apprendimento automatico per analizzare i segnali elettroencefalografici (EEG) al fine di distinguere i modelli EEG associati a cinque compiti educativi di base.C'è una grande varietà di classificatori utilizzati in questo campo EEG-based Brain-Computer Interface (BCI). Mentre i precedenti esperimenti EEG hanno utilizzato diversi classificatori negli stessi esperimenti o hanno esaminato diversi algoritmi su set di dati da esperimenti diversi, il nostro approccio si concentra sulla revisione di otto categorie di classificatori sullo stesso set di dati, compresi i classificatori lineari, i classificatori bayesiani non lineari, i classificatori più vicini, i metodi di ensemble, i classificatori adattivi, i classificatori tensori, l'apprendimento di trasferimento e l'apprendimento profondo.Inoltre, abbiamo intenzione di trovare un approccio che può funzionare senza problemi sugli attuali personal computer e smartphone mainstream.  La valutazione empirica ha dimostrato che Random Forest e LSTM (Long Short-Term Memory) superano gli altri approcci.Abbiamo usato un set di dati in cui gli utenti stavano conducendo cinque compiti legati all'apprendimento frequentemente, tra cui leggere, scrivere e digitare.I risultati hanno mostrato che questi due migliori algoritmi potrebbero classificare correttamente diversi utenti con un aumento della precisione dal 5% al 9%, utilizzando ogni compito in modo indipendente. Questo lavoro suggerisce che Random Forest potrebbe essere un approccio raccomandato (veloce e accurato) per l'attuale hardware mainstream, mentre LSTM ha il potenziale per essere l'approccio di prima scelta quando i computer e gli smartphone mainstream potranno elaborare più dati in un tempo più breve.
L'apprendimento di rinforzo multi-agente offre un modo per studiare come la comunicazione potrebbe emergere in comunità di agenti che hanno bisogno di risolvere problemi specifici. In questo articolo, studiamo l'emergere della comunicazione nell'ambiente di negoziazione, un modello semi-cooperativo di interazione tra agenti.  Mostriamo che gli agenti auto-interessati possono usare il canale di comunicazione pre-fondato per negoziare in modo equo, ma non sono in grado di usare efficacemente il canale di conversazione non fondato per fare lo stesso.  Tuttavia, gli agenti prosociali imparano a usare il cheap talk per trovare una strategia di negoziazione ottimale, suggerendo che la cooperazione è necessaria per far emergere il linguaggio. Studiamo anche il comportamento di comunicazione in un ambiente in cui un agente interagisce con gli agenti di una comunità con diversi livelli di prosocialità e mostriamo come l'identificabilità dell'agente possa aiutare la negoziazione.
Gli approcci di meta-apprendimento recentemente introdotti affrontano questo problema imparando un classificatore generico su un gran numero di compiti di classificazione multiclasse e generalizzando il modello a un nuovo compito. In questo articolo, proponiamo Transductive Propagation Network (TPN), una nuova struttura di meta-apprendimento per l'inferenza trasduttiva che classifica l'intero set di test in una sola volta per alleviare il problema dei dati bassi. In particolare, proponiamo di imparare a propagare le etichette dalle istanze etichettate alle istanze di test senza etichetta, imparando un modulo di costruzione del grafico che sfrutta la struttura del manifold nei dati.  Convalidiamo TPN su più set di dati di riferimento, sui quali supera ampiamente gli approcci di apprendimento a pochi colpi esistenti e raggiunge lo stato dell'arte dei risultati.
Descriviamo l'uso di un sistema automatico di programmazione per la progettazione della politica di osservazione e per programmare le operazioni del NASA (National Aeronautics and Space Administration) ECOSystem Spaceborne Thermal Radiometer Experiment on Space Station (ECOSTRESS). Descriviamo l'adattamento del sistema di programmazione Compressed Large-scale Activity Scheduler and Planner (CLASP) al problema di programmazione di ECOSTRESS, evidenziando molteplici casi d'uso per la programmazione automatizzata e diverse sfide per la tecnologia di programmazione: la gestione di campagne a lungo termine con informazioni mutevoli, le sfide delle operazioni di Mass Storage Unit Ring Buffer e l'incertezza dell'orbita.Il sistema di programmazione descritto è stato utilizzato per le operazioni dello strumento ECOSTRESS dal suo inizio delle operazioni nominali nel luglio 2018 e si prevede di operare fino alla fine della missione nell'estate 2019.
Gli esempi avversari sono campioni modificati che conservano le strutture originali dell'immagine ma deviano i classificatori.I ricercatori hanno messo sforzi nello sviluppo di metodi per generare esempi avversari e scoprire le origini.La ricerca passata ha messo molta attenzione sui cambiamenti dei confini decisionali causati da questi metodi.Questo articolo, al contrario, discute l'origine degli esempi avversari da un punto di vista della rappresentazione della conoscenza più sottostante. Gli esseri umani possono imparare e classificare i prototipi così come le trasformazioni degli oggetti.Mentre le reti neurali memorizzano la conoscenza appresa in un modo più ibrido di combinare tutti i prototipi e le trasformazioni come un'intera distribuzione.La memorizzazione ibrida può portare a distanze inferiori tra le diverse classi in modo che piccole modifiche possano fuorviare il classificatore. Un metodo di imitazione della distribuzione in un solo passo è progettato per imitare la distribuzione del vicino di classe diverso più vicino.Gli esperimenti mostrano che semplicemente imitando le distribuzioni da un set di allenamento senza alcuna conoscenza del classificatore può ancora portare a impatti evidenti sui risultati di classificazione da reti profonde.Implica anche che gli esempi avversi possono essere in più forme che piccole perturbazioni. I potenziali modi per alleviare gli esempi avversi sono discussi dal punto di vista della rappresentazione.Il primo percorso è quello di cambiare la codifica dei dati inviati alla fase di formazione.I dati di formazione che sono più prototipici possono aiutare a cogliere una conoscenza strutturale più robusta e accurata.Il secondo percorso richiede la costruzione di quadri di apprendimento con rappresentazioni migliorate.
A differenza del popolare apprendimento Deep Q-Network (DQN), l'apprendimento a Q alternato (AltQ) non si adatta completamente a una funzione Q di destinazione a ogni iterazione, ed è generalmente noto per essere instabile e inefficiente.Le applicazioni limitate di AltQ si basano per lo più sulla modifica sostanziale dell'architettura dell'algoritmo per migliorare le sue prestazioni.Anche se Adam sembra essere una soluzione naturale, le sue prestazioni in AltQ sono state raramente studiate prima.In questo articolo, forniamo prima una solida esplorazione su come AltQ funziona con Adam. Più specificamente, gli algoritmi proposti sono testati su un lotto di giochi Atari 2600 e mostrano prestazioni superiori a quelle del metodo di apprendimento DQN. Il tasso di convergenza della versione leggermente modificata degli algoritmi proposti è caratterizzato sotto l'approssimazione della funzione lineare.Per quanto ne sappiamo, questo è il primo studio teorico sugli algoritmi di tipo Adam nell'apprendimento Q.
Nella ricerca di modelli predittivi più accurati, personalizziamo le reti di capsule per l'apprendimento per diagnosticare il problema.Proponiamo anche le reti di capsule spettrali, una nuova variante delle reti di capsule, che convergono più velocemente della rete di capsule con il routing EM.Le reti di capsule spettrali consistono in filtri di coincidenza spaziale che individuano le entità basate sull'allineamento delle caratteristiche estratte su un sottospazio lineare unidimensionale.Gli esperimenti su un benchmark pubblico di apprendimento per diagnosticare il dataset non solo mostrano il successo delle reti di capsule su questo compito, ma confermano anche la convergenza più veloce delle reti di capsule spettrali.
Una delle grandi sfide nelle applicazioni di apprendimento automatico è che i dati di formazione possono essere diversi dai dati del mondo reale affrontati dall'algoritmo.Nella modellazione del linguaggio, il linguaggio degli utenti (ad esempio nella messaggistica privata) potrebbe cambiare in un anno ed essere completamente diverso da quello che osserviamo nei dati pubblicamente disponibili.Allo stesso tempo, i dati pubblici possono essere utilizzati per ottenere la conoscenza generale (cioè il modello generale dell'inglese).Studiamo approcci per distribuire il fine-tuning di un modello generale sui dati privati degli utenti con i requisiti aggiuntivi di mantenere la qualità sui dati generali e minimizzare i costi di comunicazione. Proponiamo una nuova tecnica che migliora significativamente la qualità della predizione sulla lingua degli utenti rispetto a un modello generale e supera i metodi di compressione del gradiente in termini di efficienza della comunicazione.La procedura proposta è veloce e porta a una riduzione della perplessità di quasi il 70% e a un miglioramento di 8,7 punti percentuali nel tasso di risparmio dei tasti su testi informali in inglese.Infine, proponiamo un quadro sperimentale per valutare la privacy differenziale dell'allenamento distribuito dei modelli linguistici e dimostriamo che il nostro approccio ha buone garanzie di privacy.
Proponiamo che gli algoritmi approssimativi bayesiani ottimizzino un nuovo criterio, direttamente derivato dalla perdita, per calcolare il loro posteriore approssimativo che chiamiamo pseudo-posteriore.A differenza dell'inferenza variazionale standard che ottimizza un limite inferiore sulla probabilità marginale log, i nuovi algoritmi possono essere analizzati per fornire garanzie di perdita sulle previsioni con lo pseudo-posteriore.Il nostro criterio può essere usato per derivare nuovi algoritmi di processo gaussiano sparse che hanno garanzie di errore applicabili a varie probabilità.
In questo articolo, proponiamo un nuovo metodo di regolarizzazione, RotationOut, per le reti neurali. Diverso da Dropout che gestisce ogni neurone/canale indipendentemente, RotationOut considera il suo strato di input come un intero vettore e introduce la regolarizzazione ruotando casualmente il vettore. RotationOut può anche essere usato in strati convoluzionali e ricorrenti con una piccola modifica. Usiamo inoltre un metodo di analisi del rumore per interpretare la differenza tra RotationOut e Dropout nella riduzione del co-adattamento. Usando questo metodo, mostriamo anche come usare RotationOut/Dropout insieme a Batch Normalization. Vasti esperimenti in compiti di visione e di lingua sono condotti per mostrare l'efficacia del metodo proposto. I codici saranno disponibili.
Formulare il problema del reinforcement learning (RL) nel quadro dell'inferenza probabilistica non solo offre una nuova prospettiva sul RL, ma produce anche algoritmi pratici che sono più robusti e più facili da addestrare.Mentre questa connessione tra RL e inferenza probabilistica è stata ampiamente studiata nell'impostazione a singolo agente, non è stata ancora pienamente compresa nella configurazione multi-agente. In questo articolo, poniamo il problema dell'apprendimento di rinforzo multi-agente come il problema di eseguire l'inferenza in un particolare modello grafico. modelliamo l'ambiente, come visto da ciascuno degli agenti, usando processi decisionali di Markov separati ma correlati. Deriviamo un algoritmo pratico off-policy maximum-entropy actor-critic che chiamiamo Multi-agent Soft Actor-Critic (MA-SAC) per eseguire l'inferenza approssimativa nel modello proposto usando l'inferenza variazionale.MA-SAC può essere impiegato in entrambe le impostazioni cooperative e competitive. Attraverso gli esperimenti, dimostriamo che MA-SAC supera una linea di base forte su diversi scenari multi-agente.Mentre MA-SAC è un algoritmo RL multi-agente risultante che può essere derivato dalla struttura probabilistica proposta, il nostro lavoro fornisce una visione unificata degli algoritmi di massima entropia nell'impostazione multi-agente.
Tuttavia, l'operatore di ordinamento non è differenziabile rispetto ai suoi input, il che proibisce l'ottimizzazione basata sul gradiente end-to-end. In questo lavoro, proponiamo NeuralSort, un rilassamento continuo per tutti gli usi dell'output dell'operatore di ordinamento da matrici di permutazione all'insieme di matrici unimodali row-stocastiche, dove ogni riga somma a uno e ha un argmax distinto. Inoltre, usiamo questo rilassamento per permettere l'ottimizzazione stocastica basata sul gradiente sopra lo spazio combinatoriamente grande delle permutazioni derivando uno stimatore di gradiente riparametrizzato per la famiglia di Plackett-Luce delle distribuzioni sopra le permutazioni.Dimostriamo l'utilità della nostra struttura su tre compiti che richiedono l'apprendimento degli ordinamenti semantici degli oggetti alto-dimensionali, compreso un'estensione completamente differenziabile e parametrizzata dell'algoritmo di k-nearest neighbors
Trasferire la conoscenza tra i compiti per migliorare l'efficienza dei dati è una delle sfide chiave aperte nell'area degli algoritmi di ottimizzazione globale. Gli algoritmi facilmente disponibili sono tipicamente progettati per essere ottimizzatori universali e, quindi, spesso subottimali per compiti specifici. Noi proponiamo un nuovo metodo di apprendimento di trasferimento per ottenere ottimizzatori personalizzati nel quadro consolidato dell'ottimizzazione bayesiana, permettendo al nostro algoritmo di utilizzare le capacità di generalizzazione provate dei processi gaussiani. Usando l'apprendimento di rinforzo per meta-allenare una funzione di acquisizione (AF) su un insieme di compiti correlati, il metodo proposto impara a estrarre informazioni strutturali implicite e a sfruttarle per migliorare l'efficienza dei dati. Presentiamo esperimenti su un compito di trasferimento da simulato a reale, nonché su diverse funzioni simulate e due problemi di ricerca iperparametrica. I risultati mostrano che il nostro algoritmo (1) identifica automaticamente le proprietà strutturali delle funzioni obiettivo dai compiti o dalle simulazioni di origine disponibili, (2) si comporta favorevolmente in ambienti con dati di origine sia scarsi che abbondanti, e (3) ricade al livello di prestazioni delle AF generali se non è presente alcuna struttura.
Studiamo l'evoluzione delle rappresentazioni interne durante l'addestramento delle reti neurali profonde (DNN), con l'obiettivo di demistificare l'aspetto della compressione della teoria del collo di bottiglia dell'informazione. La teoria suggerisce che l'addestramento DNN comprende una rapida fase di adattamento seguita da una fase di compressione più lenta, in cui l'informazione reciproca I(X;T) tra l'input X e le rappresentazioni interne T diminuisce. Diversi articoli osservano la compressione dell'informazione reciproca stimata su diversi modelli DNN, ma il vero I(X;T) su queste reti è dimostrabilmente costante (X discreto) o infinito (X continuo).Questo lavoro spiega la discrepanza tra la teoria e gli esperimenti, e chiarisce ciò che è stato effettivamente misurato da questi lavori passati.A tal fine, introduciamo un quadro DNN ausiliario (rumoroso) per cui I(X;T) è una quantità significativa che dipende dai parametri della rete. Sviluppiamo poi uno stimatore rigoroso per I(X;T) nelle DNN rumorose e osserviamo la compressione in vari modelli.Mettendo in relazione I(X;T) nella DNN rumorosa con un problema di comunicazione teorico dell'informazione, mostriamo che la compressione è guidata dal progressivo raggruppamento delle rappresentazioni nascoste degli input della stessa classe. Diversi metodi per monitorare direttamente il clustering delle rappresentazioni nascoste, sia nelle DNN rumorose che in quelle deterministiche, sono usati per mostrare che si formano cluster significativi nello spazio T. Infine, torniamo allo stimatore di I(X;T) impiegato nei lavori passati, e dimostriamo che mentre non riesce a catturare la vera informazione reciproca (vacua), serve come misura per il clustering, il che chiarisce le osservazioni passate sulla compressione e isola il clustering geometrico delle rappresentazioni nascoste come vero fenomeno di interesse.
Una sfida centrale nell'apprendimento di rinforzo multi-agente è l'induzione della coordinazione tra gli agenti di una squadra.In questo lavoro, indaghiamo su come promuovere la coordinazione inter-agente usando la regolarizzazione della politica e discutiamo due possibili strade basate rispettivamente sulla modellazione inter-agente e sulla selezione sincronizzata delle sub-politiche.Testiamo ogni approccio in quattro impegnativi compiti di controllo continuo con ricompense sparse e li confrontiamo con tre linee di base tra cui MADDPG, un algoritmo di apprendimento di rinforzo multi-agente all'avanguardia. Per garantire un confronto equo, ci basiamo su un'accurata selezione di iperparametri e su una metodologia di addestramento che consente un budget di ricerca fisso di iperparametri per ogni algoritmo e ambiente. Di conseguenza, valutiamo sia la sensibilità dell'iperparametro che l'efficienza del campione e le prestazioni asintotiche di ogni metodo di apprendimento.
L'analisi multimodale del sentimento è un'area di ricerca centrale che studia il sentimento dell'oratore espresso dalle modalità linguistiche, visive e acustiche. La sfida centrale nell'apprendimento multimodale coinvolge l'inferenza di rappresentazioni congiunte che possono elaborare e mettere in relazione le informazioni da queste modalità.Tuttavia, il lavoro esistente impara rappresentazioni congiunte usando più modalità come input e può essere sensibile alle modalità rumorose o mancanti al momento del test. Con il recente successo dei modelli sequenza per sequenza nella traduzione automatica, c'è l'opportunità di esplorare nuovi modi di imparare rappresentazioni congiunte che potrebbero non richiedere tutte le modalità di input al momento del test. Il nostro metodo si basa sull'intuizione chiave che la traduzione da una modalità di origine a una di destinazione fornisce un metodo di apprendimento delle rappresentazioni congiunte utilizzando solo la modalità di origine come input. Aumentiamo le traduzioni di modalità con una perdita di coerenza del ciclo per garantire che le nostre rappresentazioni congiunte mantengano la massima informazione da tutte le modalità. Una volta che il nostro modello di traduzione è addestrato con dati multimodali accoppiati, abbiamo bisogno solo dei dati della modalità di origine al momento del test per la predizione, il che assicura che il nostro modello rimanga robusto dalle perturbazioni o dalle modalità di destinazione mancanti.Addestriamo il nostro modello con un obiettivo di traduzione-predizione accoppiato e raggiunge nuovi risultati all'avanguardia su set di dati di analisi del sentimento multimodali: Ulteriori esperimenti mostrano che il nostro modello impara rappresentazioni congiunte sempre più discriminanti con più modalità di input, mantenendo la robustezza alle perturbazioni di tutte le altre modalità.
Le proprietà geometriche delle superfici di perdita, come la planarità locale di una soluzione, sono associate alla generalizzazione nell'apprendimento profondo. L'Hessiano è spesso usato per comprendere queste proprietà geometriche. Studiamo le differenze tra gli autovalori dell'Hessiano della rete neurale valutati sul set di dati empirico, l'Hessiano empirico, e gli autovalori dell'Hessiano sotto la distribuzione generatrice di dati, che chiamiamo il vero Hessiano. Per eseguire questi esperimenti proponiamo una struttura per la visualizzazione spettrale, basata sulla quadratura stocastica di Lanczos accelerata dalla GPU. Questo approccio è un ordine di grandezza più veloce dei metodi all'avanguardia per la visualizzazione spettrale, e può essere genericamente utilizzato per indagare le proprietà spettrali delle matrici nell'apprendimento profondo.
Sulla base dei promettenti risultati delle reti neurali a grafo su dati altamente strutturati, sviluppiamo una struttura per estendere i codificatori di sequenze esistenti con una componente a grafo che può ragionare sulle relazioni a lunga distanza in dati debolmente strutturati come il testo. In un'ampia valutazione, dimostriamo che i modelli ibridi sequenza-grafo risultanti superano sia i modelli di sequenza puri che i modelli a grafo puri su una serie di compiti di sintesi.
Nella classificazione probabilistica, un modello discriminativo basato sulla miscela gaussiana esibisce una capacità di adattamento flessibile; tuttavia, è difficile determinare il numero di componenti. Proponiamo un classificatore rado basato su un modello discriminativo di miscela gaussiana (GMM), chiamato miscela gaussiana discriminativa rada (SDGM). Questo algoritmo di apprendimento migliora la capacità di generalizzazione ottenendo una soluzione sparsa e determina automaticamente il numero di componenti rimuovendo i componenti ridondanti.Il SDGM può essere incorporato nelle reti neurali (NN) come le NN convoluzionali e può essere addestrato in un modo end-to-end.I risultati sperimentali hanno indicato che il metodo proposto ha impedito l'overfitting ottenendo la sparsità.Inoltre, abbiamo dimostrato che il metodo proposto ha superato uno strato completamente connesso con la funzione softmax in alcuni casi quando è stato usato come ultimo strato di una NN profonda.
Recentemente abbiamo osservato che i filtri convoluzionali inizializzati più lontano l'uno dall'altro usando i codebook di Grassmannian subspacepacking precompilati hanno funzionato sorprendentemente bene in molti set di dati. Attraverso questo breve articolo, vorremmo diffondere alcuni risultati iniziali a questo proposito nella speranza di stimolare la curiosità della comunità di deep-learning a considerare i risultati classici di Grassmannian subspace packing come una fonte di nuove idee per strategie di inizializzazione più efficienti.
L'adattamento al dominio è fondamentale per avere successo in ambienti nuovi e non visti. I modelli di adattamento adversariali applicati agli spazi di caratteristiche scoprono rappresentazioni invarianti al dominio, ma sono difficili da visualizzare e a volte non riescono a catturare gli spostamenti di dominio a livello di pixel e a basso livello. Un lavoro recente ha dimostrato che le reti generative avversarie combinate con i vincoli di coerenza del ciclo sono sorprendentemente efficaci nella mappatura delle immagini tra i domini, anche senza l'uso di coppie di immagini allineate.Proponiamo un nuovo modello di adattamento di dominio discriminatorio-allenato Cycle-Consistent Adversarial.CyCADA adatta le rappresentazioni sia a livello di pixel che a livello di caratteristica, fa rispettare la coerenza del ciclo mentre sfrutta una perdita di compito e non richiede coppie allineate.  Il nostro modello può essere applicato in una varietà di riconoscimenti visivi e impostazioni di previsione. Mostriamo nuovi risultati allo stato dell'arte attraverso molteplici compiti di adattamento, tra cui la classificazione delle cifre e la segmentazione semantica delle scene stradali che dimostrano il trasferimento dai domini sintetici al mondo reale.
Stemming è il processo di rimozione degli affissi (cioè prefissi, infissi e suffissi) che migliorano l'accuratezza e le prestazioni dei sistemi di information retrieval.Questo articolo presenta la riduzione delle parole amariche al gambo corrispondente dove con l'intenzione di conservare le informazioni semantiche. Il processo di rimozione di tali affissi (prefissi, infissi e suffissi) da una parola alla sua forma base è chiamato stemming.Mentre molti stemmers esistono per le lingue dominanti come l'inglese, le lingue con poche risorse come l'amarico mancano di un supporto così potente. In questo articolo, progettiamo uno stemmer leggero per l'amarico basandoci sulle regole che riceve una parola amarica e poi trova una corrispondenza all'inizio di una parola con i possibili prefissi e alla sua fine con i possibili suffissi e infine controlla se ha infissi.Il risultato finale è lo stem se c'è qualche prefisso, infisso o/e suffisso, altrimenti rimane in uno degli stati precedenti. La tecnica non si basa su alcuna risorsa aggiuntiva (ad esempio un dizionario) per verificare lo stemma generato. Le prestazioni dello stemmer generato sono valutate utilizzando parole amariche annotate manualmente e il risultato è confrontato con lo stemmer attuale allo stato dell'arte per l'amarico, mostrando un aumento del 7% nella correttezza dello stemmer.
Insieme alle celle concettuali, esse permettono agli esseri umani di formare una rappresentazione interna del mondo esterno, cioè lo spazio concettuale, e indaghiamo la presenza di un tale spazio nelle reti neurali profonde tracciando il profilo di attivazione dei suoi neuroni di livello nascosto. Sebbene si trovino proprietà simili a quelle delle celle di luogo e delle celle concettuali, i modelli di attivazione delle celle a griglia sono assenti, indicando così una mancanza di integrazione dei percorsi o di funzionalità di trasformazione delle caratteristiche nelle reti addestrate.Nel complesso, presentiamo un'inadeguatezza plausibile nelle attuali pratiche di apprendimento profondo che limitano le reti profonde dall'eseguire ragionamenti analogici e compiti di recupero della memoria.
Sviluppiamo una descrizione completa del quadro di inferenza attiva, come proposto da Friston (2010), in una prospettiva conforme all'apprendimento automatico, partendo da un'ispirazione biologica e dai principi di autocodifica, viene proposto uno schizzo di un'architettura cognitiva che dovrebbe fornire modi per implementare politiche di controllo orientate alla stima.  I pro e i contro della politica di controllo sono analizzati in dettaglio, mostrando promesse interessanti in termini di compressione dell'elaborazione. Sebbene l'ottimizzazione dell'entropia posteriore futura sull'insieme delle azioni sia dimostrata sufficiente per raggiungere una selezione dell'azione localmente ottimale, il calcolo offline utilizzando mappe di salienza specifiche della classe è mostrato migliore perché risparmia i costi di elaborazione attraverso la pre-elaborazione dei percorsi di saccade, con un effetto trascurabile sui tassi di riconoscimento/compressione.
I grafi possiedono caratteristiche esotiche come la dimensione variabile e l'assenza di ordinamento naturale dei nodi che li rendono difficili da analizzare e confrontare.Per aggirare questo problema e imparare sui grafi, è necessaria una rappresentazione delle caratteristiche dei grafi.Le difficoltà principali con l'estrazione delle caratteristiche risiedono nel trade-off tra espressività, coerenza ed efficienza, cioè Mentre i metodi all'avanguardia migliorano l'espressività con potenti reti neurali di grafi, noi proponiamo di sfruttare le proprietà spettrali naturali dei grafi per studiare una semplice caratteristica dei grafi: lo spettro di Laplacian dei grafi (GLS). Analizziamo il potere rappresentazionale di questo oggetto che soddisfa sia l'isomorfismo-invarianza, l'espressività e la deformazione-consistenza. In particolare, proponiamo un'analisi teorica basata sulla perturbazione del grafico per capire che tipo di confronto tra i grafi facciamo quando confrontiamo GLS. Per fare ciÃ², deriviamo i limiti per la distanza fra GLS che sono relativi alla divergenza all'isomorfismo, una divergenza computazionalmente costosa standard del grafico. infine, sperimentiamo GLS come rappresentazione del grafico attraverso le prove di consistenza e le mansioni di classificazione e mostriamo che Ã¨ una linea di base forte della rappresentazione della caratteristica del grafico.
L'addestramento avversario, un metodo per l'apprendimento delle reti profonde robuste, Ã¨ presupposto tipicamente per essere piÃ¹ costoso di addestramento tradizionale dovuto la necessitÃ di costruzione degli esempi avversari via un metodo di primo ordine come gradiente proiettato decente (PGD).  In questo articolo, facciamo la sorprendente scoperta che è possibile addestrare modelli empiricamente robusti usando un avversario molto più debole ed economico, un approccio che in precedenza si credeva inefficace, rendendo il metodo non più costoso dell'addestramento standard nella pratica.  In particolare, mostriamo che l'addestramento avversario con il metodo del segno del gradiente veloce (FGSM), quando combinato con l'inizializzazione casuale, è efficace quanto l'addestramento basato su PGD ma ha un costo significativamente inferiore.  Inoltre dimostriamo che l'addestramento avversario FGSM può essere ulteriormente accelerato utilizzando tecniche standard per l'addestramento efficiente delle reti profonde, permettendoci di imparare un classificatore robusto CIFAR10 con il 45% di accuratezza robusta a epsilon=8/255 in 6 minuti, e un classificatore robusto ImageNet con il 43% di accuratezza robusta a epsilon=2/255 in 12 ore, in confronto al lavoro passato basato sull'addestramento avversario "libero" che ha richiesto 10 e 50 ore per raggiungere le stesse soglie rispettive.
Il regolatore L0 misura direttamente la sparsità dei parametri ed è invariante alla scala dei valori dei parametri, ma non può fornire gradienti utili e quindi richiede tecniche di ottimizzazione complesse. Il regolatore L1 è quasi ovunque differenziabile e può essere facilmente ottimizzato con la discesa del gradiente, ma non è invariante alla scala e causa lo stesso tasso di restringimento a tutti i parametri, il che è inefficiente per aumentare la sparsità. Ispirandoci alla misura di Hoyer (il rapporto tra le norme L1 e L2) utilizzata nei tradizionali problemi di rilevamento compresso, presentiamo DeepHoyer, un insieme di regolatori che inducono la sparsità e che sono sia differenziabili quasi ovunque che invarianti in scala. I nostri esperimenti mostrano che l'applicazione dei regolatori DeepHoyer può produrre modelli di reti neurali ancora più sparsi rispetto ai lavori precedenti, a parità di livello di accuratezza.
L'autosupervisione, in cui un'attività di destinazione viene migliorata senza supervisione esterna, è stata esplorata principalmente in impostazioni che presuppongono la disponibilità di dati aggiuntivi, ma in molti casi, in particolare nel settore sanitario, si può non avere accesso a dati aggiuntivi (etichettati o meno), Dimostriamo l'utilità dell'autosupervisione limitata su tre compiti di classificazione a livello di sequenza, due relativi a dati clinici reali e uno che utilizza dati sintetici. All'interno di questo quadro, introduciamo nuove forme di autosupervisione e dimostriamo la loro utilità nel migliorare le prestazioni sul compito target. In particolare, per il compito di identificare la fibrillazione atriale da piccole quantità di dati elettrocardiografici, osserviamo un miglioramento di quasi il 13% nell'area sotto la curva delle caratteristiche operative del ricevitore (AUC-ROC) rispetto alla linea di base (AUC-ROC=0.55 vs AUC-ROC=0.62).
Le reti neurali sono orientate verso funzioni semplici? La profondità aiuta sempre ad apprendere caratteristiche più complesse? L'addestramento dell'ultimo strato di una rete è buono come l'addestramento di tutti gli strati? Queste domande sembrano non correlate a prima vista, ma in questo lavoro diamo a tutte loro un trattamento comune dalla prospettiva spettrale. Studieremo gli spettri del *Kernel coniugato, CK,* (chiamato anche *Kernel del processo di reti neurali-gaussiane*), e del *Kernel di tangenti neurali, NTK*. Approssimativamente, il CK e l'NTK ci dicono rispettivamente ``come appare una rete all'inizializzazione'' e ``come appare una rete durante e dopo l'allenamento''. "I loro spettri codificano quindi preziose informazioni sulla distribuzione iniziale e sulle proprietà di addestramento e generalizzazione delle reti neurali. Analizzando gli autovalori, forniamo nuove intuizioni sulle domande poste all'inizio, e verifichiamo queste intuizioni con ampi esperimenti di reti neurali. Crediamo che gli strumenti computazionali che sviluppiamo qui per analizzare gli spettri di CK e NTK servano come una solida base per gli studi futuri sulle reti neurali profonde. Abbiamo reso open-source il codice per esso e per generare i grafici in questo articolo su github.com/jxVmnLgedVwv6mNcGCBy/NNspectra.
Per comunicare, per fondare le ipotesi, per analizzare i dati, i neuroscienziati fanno spesso riferimento a divisioni del cervello. Qui consideriamo gli atlanti usati per parcellizzare il cervello quando si studiano le funzioni cerebrali. Discutiamo il significato e la validità di queste parcelle, sia da un punto di vista concettuale che eseguendo vari compiti analitici su popolari parcelle funzionali del cervello.
I compiti di ricompensa ad alta densità presentano grandi sfide per gli agenti di apprendimento del rinforzo.  In questo lavoro usiamo l'apprendimento per imitazione per affrontare due di queste sfide: come imparare una rappresentazione utile del mondo, ad esempio dai pixel, e come esplorare in modo efficiente data la rarità di un segnale di ricompensa? Mostriamo che l'imitazione avversaria può funzionare bene anche in questo spazio di osservazione ad alta dimensione. Il nostro approccio rimuove le limitazioni presenti nella maggior parte degli approcci di imitazione contemporanei: non richiede azioni del dimostratore (solo video), non richiede condizioni iniziali speciali o partenze a caldo, e nessun inseguimento esplicito di qualsiasi singolo dimostratore.L'agente proposto può risolvere un compito impegnativo di manipolazione del robot di impilamento dei blocchi da sole dimostrazioni video e ricompense sparse, in cui gli agenti non imitanti non riescono ad imparare completamente.  Inoltre, il nostro agente impara molto più velocemente rispetto agli approcci concorrenti che dipendono da funzioni di ricompensa dense fatte a mano, e anche meglio rispetto alle basi GAIL standard.Infine, sviluppiamo un nuovo riconoscitore di obiettivi adversariali che in alcuni casi permette all'agente di imparare l'impilamento senza alcuna ricompensa del compito, puramente dall'imitazione.
In questo articolo mostriamo strategie per identificare facilmente i campioni falsi generati con il framework Generative Adversarial Network.Una strategia si basa sull'analisi statistica e sul confronto dei valori dei pixel grezzi e delle caratteristiche estratte da essi.L'altra strategia impara specifiche formali dai dati reali e mostra che i campioni falsi violano le specifiche dei dati reali.Mostriamo che i campioni falsi prodotti con le GAN hanno una firma universale che può essere usata per identificare i campioni falsi.Forniamo risultati su MNIST, CIFAR10, dati musicali e del parlato.
Gli sforzi per ridurre la precisione numerica dei calcoli nell'addestramento dell'apprendimento profondo hanno prodotto sistemi che quantizzano aggressivamente i pesi e le attivazioni, ma impiegano ampi accumulatori ad alta precisione per le somme parziali nelle operazioni di prodotto interno per preservare la qualità della convergenza.L'assenza di qualsiasi quadro per analizzare i requisiti di precisione degli accumuli di somma parziale si traduce in scelte di progettazione conservative.Questo impone un limite superiore alla riduzione della complessità delle unità di accumulo multiplo. Presentiamo un approccio statistico per analizzare l'impatto di una ridotta precisione di accumulazione sull'addestramento dell'apprendimento profondo.Osservando che una cattiva scelta per la precisione di accumulazione si traduce in una perdita di informazioni che si manifesta come una riduzione della varianza in un insieme di somme parziali, deriviamo una serie di equazioni che mettono in relazione questa varianza con la lunghezza di accumulazione e il numero minimo di bit necessari per l'accumulazione.Applichiamo la nostra analisi a tre reti di riferimento: CIFAR-10 ResNet 32, ImageNet ResNet 18 e ImageNet AlexNet.In ogni caso, con la precisione di accumulazione impostata secondo le nostre equazioni proposte, le reti convergono con successo alla linea di base in virgola mobile a precisione singola.Mostriamo anche che la riduzione della precisione di accumulazione degrada ulteriormente la qualità della rete addestrata, dimostrando che le nostre equazioni producono limiti stretti.Nel complesso questa analisi consente un adattamento preciso dell'hardware di calcolo all'applicazione, ottenendo sistemi ottimali per area e potenza.
L'adattamento non supervisionato del dominio è una strada promettente per migliorare le prestazioni delle reti neurali profonde su un dominio di destinazione, utilizzando le etichette solo da un dominio di origine. Tuttavia, i due metodi predominanti, l'apprendimento con riduzione della discrepanza del dominio e l'apprendimento semi-supervisionato, non sono facilmente applicabili quando i domini di origine e di destinazione non condividono uno spazio comune di etichette. Questo articolo affronta lo scenario di cui sopra imparando uno spazio di rappresentazione che mantiene il potere discriminatorio sia sul dominio di origine (etichettato) che su quello di destinazione (non etichettato), mantenendo le rappresentazioni per i due domini ben separate.Ispirati da un'analisi teorica, riformuliamo prima il compito di classificazione disgiunto, dove i domini di origine e di destinazione corrispondono a etichette di classe non sovrapposte, in un compito di verifica. Per gestire le verifiche sia all'interno che tra domini incrociati, proponiamo una rete di trasferimento delle caratteristiche (FTN) per separare lo spazio delle caratteristiche di destinazione dallo spazio di origine originale mentre è allineato con uno spazio di origine trasformato.Inoltre, presentiamo una perdita non parametrica di minimizzazione dell'entropia multiclasse per aumentare ulteriormente il potere discriminatorio delle FTN sul dominio di destinazione. Negli esperimenti, dapprima illustriamo come FTN funziona in un'impostazione controllata di adattamento da MNIST-M a MNIST con classi di cifre disgiunte tra i due domini e poi dimostriamo l'efficacia di FTNs attraverso prestazioni allo stato dell'arte su un problema di riconoscimento facciale di etnia incrociata.
In questo articolo, consideriamo il problema dell'addestramento delle reti neurali (NN); per promuovere una NN con strutture specifiche, prendiamo esplicitamente in considerazione la regolarizzazione nonsmooth (come L1-norm) e i vincoli (come il vincolo di intervallo); questo è formulato come un problema di ottimizzazione nonsmooth non convesso vincolato, e proponiamo un algoritmo di discesa del gradiente stocastico di tipo prossimale (Prox-SGD) convergente. Mostriamo che sotto tassi di apprendimento opportunamente selezionati, il momento alla fine assomiglia al gradiente reale sconosciuto e quindi è cruciale nell'analisi della convergenza. stabiliamo che con probabilità 1, ogni punto limite della sequenza generata dal Prox-SGD proposto è un punto stazionario. poi il Prox-SGD è adattato per addestrare una rete neurale sparsa e una rete neurale binaria, e l'analisi teorica è anche supportata da ampi test numerici.
La perdita di pochi neuroni in un cervello raramente si traduce in una perdita visibile di funzione, ma non è chiaro cosa significhi "pochi" in questo contesto: quanti fallimenti casuali di neuroni ci vogliono per portare a una perdita visibile di funzione? In questo articolo, affrontiamo la questione fondamentale dell'impatto del crash di un sottoinsieme casuale di neuroni sul calcolo complessivo di una rete neurale e l'errore nell'output che produce. Studiamo la tolleranza ai guasti delle reti neurali soggette a piccoli crash casuali di neuroni/peso in un ambiente probabilistico e diamo garanzie dimostrabili sulla robustezza della rete a questi crash. Il nostro contributo principale è un limite sull'errore nell'output di una rete sotto piccoli crash casuali di Bernoulli dimostrato usando un'espansione di Taylor nel limite continuo, dove i neuroni vicini in uno strato sono simili. La modalità di fallimento che adottiamo nel nostro modello è caratteristica dell'hardware neuromorfo, una tecnologia promettente per accelerare le reti neurali artificiali, così come delle reti biologiche. Mostriamo che i nostri limiti teorici possono essere utilizzati per confrontare la tolleranza ai guasti di diverse architetture e per progettare un regolatore che migliori la tolleranza ai guasti di una data architettura.Progettiamo un algoritmo che raggiunge la tolleranza ai guasti utilizzando un numero ragionevole di neuroni.Oltre alla prova teorica, forniamo anche una validazione sperimentale dei nostri risultati e suggeriamo una connessione al problema della capacità di generalizzazione.
Gli agenti veramente intelligenti hanno bisogno di catturare l'interazione di tutti i loro sensi per costruire una ricca comprensione fisica del loro mondo.In robotica, abbiamo visto un enorme progresso nell'utilizzo della percezione visiva e tattile; tuttavia abbiamo spesso ignorato un senso chiave: il suono.Questo è dovuto principalmente alla mancanza di dati che cattura l'interazione tra azione e suono.In questo lavoro, eseguiamo il primo studio su larga scala delle interazioni tra suono e azione robotica. Per fare questo, creiamo il più grande set di dati suono-azione-visione disponibile con 15.000 interazioni su 60 oggetti utilizzando la nostra piattaforma robotica Tilt-Bot.Inclinando gli oggetti e permettendo loro di sbattere contro le pareti di un vassoio robotico, raccogliamo ricche informazioni audio a quattro canali.Utilizzando questi dati, esploriamo le sinergie tra suono e azione, e presentiamo tre intuizioni chiave.Primo, il suono è indicativo di informazioni di classe oggetto a grana fine, ad es, In secondo luogo, il suono contiene anche informazioni sugli effetti causali di un'azione, cioè, dato il suono prodotto, possiamo prevedere quale azione è stata applicata all'oggetto. Infine, le rappresentazioni dell'oggetto derivate dalle embeddings audio sono indicative delle proprietà fisiche implicite. Dimostriamo che su oggetti precedentemente non visti, le embeddings audio generate attraverso le interazioni possono prevedere i modelli forward del 24% meglio delle embeddings visive passive.
Le strutture gerarchiche delle etichette esistono ampiamente in molte attività di apprendimento automatico, da quelle con gerarchie di etichette esplicite come la classificazione delle immagini a quelle che hanno gerarchie di etichette latenti come la segmentazione semantica.Sfortunatamente, i metodi allo stato dell'arte utilizzano spesso la perdita di cross-entropia che presuppone in modo esplicito l'indipendenza tra le etichette di classe.Motivati dal fatto che i membri delle classi della stessa gerarchia devono essere simili tra loro, progettiamo un nuovo schema di allenamento chiamato Hierarchical Complement Objective Training (HCOT). In HCOT, oltre a massimizzare la probabilità della classe di verità di base, neutralizziamo anche le probabilità del resto delle classi in modo gerarchico, facendo sì che il modello tragga vantaggio dalla gerarchia delle etichette in modo esplicito. conduciamo il nostro metodo sia sulla classificazione delle immagini che sulla segmentazione semantica. i risultati mostrano che HCOT supera i modelli all'avanguardia in CIFAR100, Imagenet e PASCAL-context. i nostri esperimenti dimostrano anche che HCOT può essere applicato a compiti con gerarchie di etichette latenti, che è una caratteristica comune in molti compiti di apprendimento automatico.
C'è un crescente interesse nella ricerca automatizzata di architetture neurali (NAS).Per migliorare l'efficienza della NAS, gli approcci precedenti adottano il metodo di condivisione dei pesi per forzare tutti i modelli a condividere lo stesso set di pesi.  Tuttavia, è stato osservato che un modello che funziona meglio con i pesi condivisi non necessariamente esegue meglio quando è addestrato da solo.In questo articolo, analizziamo gli approcci esistenti di NAS one-shot di condivisione dei pesi da un punto di vista bayesiano e identifichiamo il problema di dissolvenza posteriore, che compromette l'efficacia dei pesi condivisi.Per alleviare questo problema, presentiamo un approccio pratico per guidare il parametro posteriore verso la sua vera distribuzione.Inoltre, un vincolo di latenza duro è introdotto durante la ricerca in modo che la latenza desiderata possa essere realizzata. Il metodo risultante, vale a dire Posterior Convergent NAS (PC-NAS), raggiunge prestazioni all'avanguardia sotto il vincolo di latenza standard della GPU su ImageNet.Nel nostro piccolo spazio di ricerca, il nostro modello PC-NAS-S raggiunge il 76,8% di accuratezza top-1, il 2,1% in più di MobileNetV2 (1,4x) con la stessa latenza.Quando viene adottato al nostro grande spazio di ricerca, PC-NAS-L raggiunge il 78,1% di accuratezza top-1 entro 11ms.L'architettura scoperta si trasferisce bene anche ad altre applicazioni di computer vision come il rilevamento di oggetti e la re-identificazione di persone.
Le etichette rumorose sono molto comuni nei dati di allenamento del mondo reale, che portano a una scarsa generalizzazione sui dati di test a causa dell'overfitting alle etichette rumorose. In questo articolo, sosteniamo che tale overfitting può essere evitato "fermando in anticipo" l'addestramento di una rete neurale profonda prima che le etichette rumorose siano pesantemente memorizzate; quindi, riprendiamo l'addestramento della rete fermata in anticipo usando un "set massimo sicuro", che mantiene una collezione di campioni quasi certamente con etichetta vera ad ogni epoca dal punto di arresto iniziale. Mettendo tutto insieme, il nostro nuovo metodo di addestramento a due fasi, chiamato Prestopping, realizza un addestramento senza rumore sotto qualsiasi tipo di rumore di etichetta per l'uso pratico. esperimenti estesi usando quattro set di dati di riferimento delle immagini verificano che il nostro metodo supera significativamente quattro metodi all'avanguardia nell'errore di prova di 0.4â€"8.2 punti percentuali in presenza di rumore del mondo reale.
Imparare quando comunicare e farlo in modo efficace Ã¨ essenziale in compiti multi-agente.lavori recenti mostrano che la comunicazione continua permette una formazione efficiente con back-propagation in scenari multi-agente, ma sono stati limitati a compiti completamente cooperativi.in questo documento, presentiamo Individualizzato controllato modello di comunicazione continua (IC3Net) che ha una migliore efficienza di formazione di semplice modello di comunicazione continua, e puÃ² essere applicato alle impostazioni semi-cooperative e competitive insieme con le impostazioni cooperative. IC3Net controlla la comunicazione continua con un meccanismo di gating e usa ricompense individualizzate per ogni agente per ottenere migliori prestazioni e scalabilità, mentre fissa i problemi di assegnazione dei crediti. Usando una varietà di compiti tra cui StarCraft BroodWars esplora e combatte gli scenari, dimostriamo che la nostra rete produce prestazioni migliori e tassi di convergenza rispetto alle linee di base quando la scala aumenta.I nostri risultati comunicano che gli agenti IC3Net imparano quando comunicare in base allo scenario e alla redditività.
I modelli neurali sequenza-sequenza sono una famiglia recentemente proposta di approcci utilizzati nella sintesi astrattiva di documenti di testo, utili per produrre versioni condensate di narrazioni del testo sorgente senza essere limitati ad usare solo parole del testo originale.Nonostante i progressi nella sintesi astrattiva, la generazione personalizzata di riassunti (ad esempio verso le preferenze dell'utente) rimane inesplorata. In questo articolo, presentiamo CATS, un modello di riassunto neurale astrattivo, che riassume il contenuto in modo sequenza per sequenza, ma introduce anche un nuovo meccanismo per controllare la distribuzione latente dei temi sottostanti ai riassunti prodotti. I nostri risultati sperimentali sul noto dataset CNN/DailyMail mostrano che il nostro modello raggiunge prestazioni all'avanguardia.
Proponiamo una struttura software basata sulle idee dell'algoritmo Learning-Compression, che permette di comprimere qualsiasi rete neurale con diversi meccanismi di compressione (pruning, quantizzazione, low-rank, ecc.).Per progettazione, l'apprendimento della rete neurale (gestito da SGD) è disaccoppiato dalla compressione dei suoi parametri (gestita da una funzione di compressione del segnale), così che la struttura può essere facilmente estesa per gestire diverse combinazioni di rete neurale e tipo di compressione. Inoltre, ha altri vantaggi, come la facile integrazione con framework di deep learning, tempi di addestramento efficienti, prestazioni pratiche competitive nel tradeoff perdita-compressione, e garanzie di convergenza ragionevoli. Il nostro toolkit è scritto in Python e Pytorch e abbiamo intenzione di renderlo disponibile entro il tempo del workshop, ed eventualmente aprirlo ai contributi della comunità.
Questo lavoro cerca la possibilità di generare il volto umano dalla voce solo sulla base dei dati audiovisivi senza alcuna annotazione etichettata dall'uomo.A tal fine, proponiamo una struttura di apprendimento multimodale che collega la fase di inferenza e la fase di generazione.In primo luogo, le reti di inferenza sono addestrate per abbinare l'identità del parlante tra le due diverse modalità.Poi le reti di inferenza pre-addestrate collaborano con la rete di generazione dando informazioni condizionali sulla voce.
Presentiamo un semplice modello neurale che, data una formula e una proprietà, cerca di rispondere alla domanda se la formula ha la proprietà data, per esempio se una formula proposizionale è sempre vera.La struttura della formula è catturata da una rete neurale feedforward costruita ricorsivamente per la formula data in modo top-down.I risultati di questa rete sono poi elaborati da due reti neurali ricorrenti.Uno degli aspetti interessanti del nostro modello è come vengono trattati gli atomi proposizionali.Per esempio, il modello è insensibile ai loro nomi, importa solo se sono uguali o distinti.
Nonostante i significativi progressi nel campo del Reinforcement Learning (RL) profondo, gli algoritmi di oggi non sono ancora in grado di imparare politiche di livello umano in modo coerente su un insieme di compiti diversi come i giochi dell'Atari 2600. Identifichiamo tre sfide chiave che ogni algoritmo deve padroneggiare per avere buone prestazioni su tutti i giochi: elaborare diverse distribuzioni di ricompensa, ragionare su orizzonti temporali lunghi ed esplorare in modo efficiente.  In questo articolo, proponiamo un algoritmo che affronta ciascuna di queste sfide ed è in grado di apprendere politiche di livello umano su quasi tutti i giochi Atari.Un nuovo operatore di Bellman trasformato permette al nostro algoritmo di elaborare ricompense di densità e scale variabili; una perdita di coerenza temporale ausiliaria ci permette di allenarci in modo stabile usando un fattore di sconto di 0.999 (invece di 0.99). 999 (invece di 0.99) estendendo l'orizzonte di pianificazione effettivo di un ordine di grandezza; e facilitiamo il problema dell'esplorazione usando dimostrazioni umane che guidano l'agente verso stati gratificanti. Quando testato su un set di 42 giochi Atari, il nostro algoritmo supera le prestazioni di un umano medio su 40 giochi usando un set comune di iper parametri.
Mentre il successo dell'apprendimento profondo si basa principalmente sull'addestramento supervisionato, importanti proprietà non possono essere dedotte in modo efficiente dalle sole annotazioni end-to-end, per esempio le relazioni causali o le invarianze specifiche del dominio.Presentiamo una tecnica generale per integrare l'addestramento supervisionato con la conoscenza precedente espressa come relazioni tra istanze di addestramento. Illustriamo il metodo sul compito di risposta alle domande visive per sfruttare varie annotazioni ausiliarie, comprese le relazioni di equivalenza e di implicazione logica tra le domande.I metodi esistenti per utilizzare queste annotazioni, comprese le perdite ausiliarie e l'aumento dei dati, non possono garantire la stretta inclusione di queste relazioni nel modello poiché richiedono un attento bilanciamento rispetto all'obiettivo end-to-end. Il nostro metodo usa queste relazioni per modellare lo spazio di incorporazione del modello, e le tratta come vincoli rigorosi sulle sue rappresentazioni apprese.% Il modello risultante codifica le relazioni che generalizzano meglio attraverso le istanze.Nel contesto di VQA, questo approccio porta miglioramenti significativi in termini di precisione e robustezza, in particolare rispetto alla pratica comune di incorporare i vincoli come un regolatore morbido. Mostriamo anche che incorporare questo tipo di conoscenza preliminare con il nostro metodo porta miglioramenti consistenti, indipendentemente dalla quantità di dati supervisionati utilizzati, dimostrando il valore di un segnale di formazione aggiuntivo che è altrimenti difficile da estrarre dalle sole annotazioni end-to-end.
Le reti neurali artificiali hanno rivoluzionato molte aree dell'informatica negli ultimi anni in quanto forniscono soluzioni a un certo numero di problemi precedentemente irrisolti.D'altra parte, per molti problemi, esistono algoritmi classici, che tipicamente superano la precisione e la stabilità delle reti neurali.Per combinare questi due concetti, presentiamo un nuovo tipo di reti neurali, le reti neurali algoritmiche (AlgoNets).Queste reti integrano versioni lisce di algoritmi classici nella topologia delle reti neurali.La nostra nuova rete reconstructive adversarial (RAN) permette di risolvere problemi inversi senza o con solo debole supervisione.
La localizzazione puntuale permette una localizzazione più precisa e un'accurata interpretabilità, rispetto al bounding box, in applicazioni in cui gli oggetti sono altamente destrutturati come nel dominio medico.In questo lavoro, ci concentriamo sulla localizzazione debolmente supervisionata (WSL) dove un modello è addestrato per classificare un'immagine e localizzare le regioni di interesse a livello di pixel usando solo l'annotazione globale dell'immagine.Le tipiche mappe di attenzione convoluzionali sono povere di regioni ad alto rischio di falsi positivi. Per alleviare questo problema, proponiamo un nuovo metodo di apprendimento profondo per WSL, composto da un localizzatore e un classificatore, dove il localizzatore è costretto a determinare le regioni rilevanti e irrilevanti utilizzando l'entropia condizionale (CE) con lo scopo di ridurre le regioni false positive. I risultati sperimentali su un dataset medico pubblico e due dataset naturali, utilizzando l'indice Dice, mostrano che, rispetto ai metodi WSL allo stato dell'arte, la nostra proposta può fornire miglioramenti significativi in termini di classificazione a livello di immagine e localizzazione a livello di pixel (bassi falsi positivi) con robustezza all'overfitting.
L'apprendimento di rinforzo basato sul modello è stato empiricamente dimostrato come una strategia di successo per migliorare l'efficienza del campione.In particolare, l'architettura Dyna, come un'elegante architettura basata sul modello che integra apprendimento e pianificazione, fornisce un'enorme flessibilità di utilizzo di un modello.Uno dei componenti più importanti in Dyna è chiamato ricerca-controllo, che si riferisce al processo di generazione di stato o di coppie stato-azione da cui interroghiamo il modello per acquisire esperienze simulate.Ricerca-controllo è fondamentale per migliorare l'efficienza di apprendimento.In questo lavoro, proponiamo una semplice e nuova strategia di ricerca-controllo cercando regione ad alta frequenza sulla funzione valore. La nostra intuizione principale è costruita sul teorema del campionamento di Shannon dall'elaborazione dei segnali, che indica che un segnale ad alta frequenza richiede più campioni per essere ricostruito.Mostriamo empiricamente che una funzione ad alta frequenza è più difficile da approssimare.Questo suggerisce una strategia di ricerca-controllo: dovremmo usare gli stati nella regione ad alta frequenza della funzione di valore per interrogare il modello per acquisire più campioni. Sviluppiamo una semplice strategia per misurare localmente la frequenza di una funzione tramite la norma del gradiente e forniamo una giustificazione teorica per questo approccio, quindi applichiamo la nostra strategia alla ricerca-controllo in Dyna e conduciamo esperimenti per mostrare la sua proprietà ed efficacia su domini di riferimento.
L'architettura proposta, che chiamiamo Distributed Recurrent Autoencoder for Scalable Image Compression (DRASIC), è in grado di addestrare codificatori distribuiti e un decoder congiunto su fonti di dati correlati. La sua capacità di compressione è molto migliore rispetto al metodo di addestramento dei codec separatamente. Nel frattempo, per 10 fonti distribuite, il nostro sistema distribuito esegue notevolmente entro 2 dB il rapporto segnale-rumore di picco (PSNR) di quello di un singolo codec addestrato con tutte le fonti di dati. Sperimentiamo fonti distribuite con diverse correlazioni e mostriamo come la nostra metodologia si adatti bene al teorema di Slepian-Wolf nel Distributed Source Coding (DSC).Il nostro metodo si dimostra anche robusto alla mancanza di presenza di dati codificati da un certo numero di fonti distribuite.Inoltre, è scalabile nel senso che i codici possono essere decodificati simultaneamente a più di un livello di qualità di compressione.Al meglio delle nostre conoscenze, questo è il primo quadro DSC guidato dai dati per la progettazione di codici distribuiti generali con apprendimento profondo.
Le reti di memoria a breve termine (LSTMs) sono state introdotte per combattere i gradienti che svaniscono nelle reti neurali ricorrenti semplici (S-RNNs) aumentandole con connessioni ricorrenti additive controllate da cancelli.Presentiamo una visione alternativa per spiegare il successo delle LSTMs: i cancelli stessi sono potenti modelli ricorrenti che forniscono più potere rappresentazionale di quanto precedentemente apprezzato. Lo facciamo mostrando che i gate della LSTM possono essere disaccoppiati dalla S-RNN incorporata, producendo una classe ristretta di RNN in cui la ricorrenza principale calcola una somma ponderata elementare di funzioni indipendenti dal contesto degli input. Gli esperimenti su una serie di problemi NLP impegnativi dimostrano che i modelli semplificati basati sui gate funzionano sostanzialmente meglio delle S-RNN, e spesso altrettanto bene come le LSTM originali, suggerendo fortemente che i gate stanno facendo molto di più in pratica che alleviare semplicemente i gradienti di vanità.
Gli algoritmi di apprendimento automatico progettati per caratterizzare, monitorare e intervenire sulla salute umana (ML4H) dovrebbero funzionare in modo sicuro e affidabile quando operano su scala, potenzialmente al di fuori della stretta supervisione umana. Questo requisito giustifica un'attenzione più rigorosa alle questioni di riproducibilità rispetto ad altri campi di apprendimento automatico. In questo lavoro, conduciamo una valutazione sistematica di oltre 100 articoli di ricerca ML4H pubblicati recentemente lungo diverse dimensioni relative alla riproducibilità che abbiamo identificato.  Infine, attingendo dal successo in altri campi della scienza, proponiamo raccomandazioni ai fornitori di dati, agli editori accademici e alla comunità di ricerca ML4H al fine di promuovere la ricerca riproducibile andando avanti.
Proponiamo una soluzione per la valutazione delle espressioni matematiche, ma invece di progettare un singolo modello end-to-end, proponiamo un'architettura in stile Lego bricks. In questa architettura, invece di addestrare una complessa rete neurale end-to-end, molte piccole reti possono essere addestrate indipendentemente, ognuna per compiere una specifica operazione e agire come un singolo lego brick. Questa strategia bottom-up non solo introduce la riutilizzabilità, ma mostra anche che permette di generalizzare per i calcoli che coinvolgono n cifre e mostriamo risultati fino a 7 cifre, a differenza dei metodi esistenti, la nostra soluzione generalizza anche per i numeri positivi e negativi.
Nella rete generativa avversaria standard (SGAN), il discriminatore stima la probabilità che i dati di input siano reali.Il generatore è addestrato per aumentare la probabilità che i dati falsi siano reali.Noi sosteniamo che dovrebbe anche diminuire simultaneamente la probabilità che i dati reali siano reali perché1) questo renderebbe conto della conoscenza a priori che metà dei dati nel mini-batch è falso,2) questo sarebbe osservato con la minimizzazione della divergenza, e3) nelle impostazioni ottimali, SGAN sarebbe equivalente alle GAN a probabilità metrica integrale (IPM). Mostriamo che questa proprietà può essere indotta utilizzando un discriminatore relativistico che stima la probabilità che il dato reale sia più realistico di un dato falso campionato a caso, e presentiamo anche una variante in cui il discriminatore stima la probabilità che il dato reale sia più realistico del dato falso, in media. Generalizziamo entrambi gli approcci a funzioni di perdita GAN non standard e ci riferiamo a loro rispettivamente come Relativistic GANs (RGANs) e Relativistic average GANs (RaGANs).Mostriamo che le GANs basate su IPM sono un sottoinsieme di RGANs che usano la funzione identità. Empiricamente, osserviamo che1) le RGAN e le RaGAN sono significativamente più stabili e generano campioni di dati di qualità superiore rispetto alle loro controparti non relativistiche,2) le RaGAN standard con penalità di gradiente generano dati di qualità migliore rispetto alle WGAN-GP pur richiedendo un solo aggiornamento del discriminatore per ogni aggiornamento del generatore (riducendo il tempo impiegato per raggiungere lo stato dell'arte del 400%), e3) le RaGAN sono in grado di generare immagini plausibili ad alta risoluzione (256x256) da un campione molto piccolo (N=2011), mentre GAN e LSGAN non possono; queste immagini sono di qualità significativamente migliore di quelle generate da WGAN-GP e SGAN con normalizzazione spettrale. Il codice è liberamente disponibile su https://github.com/AlexiaJM/RelativisticGAN.
Alcune delle applicazioni di maggior successo dell'apprendimento profondo di rinforzo ai domini challenging nel controllo discreto e continuo hanno usato i metodi del gradiente di politica nell'impostazione on-policy.However, i gradienti di politica possono soffrire di grande varianza che può limitare la prestazione ed in pratica richiedono la regolarizzazione attentamente sintonizzata di entropia per impedire il collasso di politica.As un'alternativa agli algoritmi del gradiente di politica, introduciamo V-MPO, un adattamento on-policy di ottimizzazione massima di politica di Posteriori (MPO) che effettua l'iterazione di politica basata su una funzione imparata del stato-valore. Mostriamo che V-MPO supera i punteggi precedentemente riportati per entrambe le suite di benchmark Atari-57 e DMLab-30 nell'impostazione multi-task, e lo fa in modo affidabile senza ponderazione dell'importanza, regolarizzazione dell'entropia, o sintonizzazione basata sulla popolazione degli iperparametri.sui singoli livelli DMLab e Atari, l'algoritmo proposto può raggiungere punteggi che sono sostanzialmente superiori a quelli precedentemente riportati. V-MPO è anche applicabile a problemi con spazi d'azione continui e ad alta densità, che dimostriamo nel contesto dell'apprendimento del controllo di umanoidi simulati con 22 gradi di libertà da osservazioni di stato complete e 56 gradi di libertà da osservazioni di pixel, così come esempi di compiti OpenAI Gym dove V-MPO raggiunge punteggi asintotici sostanzialmente più alti di quelli precedentemente riportati.
C'è stato un corpo significativo di lavoro che studia le reti neurali che imitano la computazione generale, ma queste reti non riescono a generalizzare alle distribuzioni di dati che sono al di fuori del loro set di allenamento.studiamo questo problema attraverso la lente dei problemi fondamentali dell'informatica: l'ordinamento e l'elaborazione dei grafici. Modifichiamo il meccanismo di mascheramento di un trasformatore per permettergli di implementare funzioni rudimentali con una forte generalizzazione.Chiamiamo questo modello il Motore di Esecuzione Neurale, e mostriamo che impara, attraverso la supervisione, a calcolare numericamente le subroutine di base che comprendono questi algoritmi con una precisione quasi perfetta.Inoltre, mantiene questo livello di precisione mentre generalizza a dati non visti e lunghe sequenze al di fuori della distribuzione di addestramento.
Tuttavia, la letteratura sul meta-apprendimento finora si è concentrata sull'impostazione segmentata, dove in tempo di treno, si presume che i dati offline siano divisi in base all'attività sottostante, e in tempo di test, gli algoritmi sono ottimizzati per imparare in una singola attività.In questo lavoro, consentiamo l'applicazione di algoritmi generici di meta-apprendimento alle impostazioni in cui questa segmentazione delle attività non è disponibile, come l'apprendimento online continuo con un'attività variabile nel tempo. Presentiamo il meta-apprendimento tramite l'analisi online del punto di cambiamento (MOCA), un approccio che aumenta un algoritmo di meta-apprendimento con uno schema di rilevamento bayesiano differenziabile del punto di cambiamento. La struttura permette sia l'addestramento che il test direttamente sui dati della serie temporale senza segmentarli in compiti discreti.
Le persone con perdita uditiva ad alta frequenza si affidano ad apparecchi acustici che impiegano algoritmi di abbassamento della frequenza.Questi algoritmi spostano alcuni dei suoni dalla banda di alta frequenza alla banda di frequenza inferiore dove i suoni diventano più percepibili per le persone con la condizione.I fonemi fricativi hanno una parte importante del loro contenuto concentrato nelle bande di alta frequenza.È importante che l'algoritmo di abbassamento della frequenza sia attivato esattamente per la durata di un fonema fricativo, e tenuto spento in tutti gli altri momenti. Pertanto, il rilevamento tempestivo (con zero ritardo) e accurato dei fonemi fricativi è un problema chiave per gli apparecchi acustici di alta qualità.In questo articolo presentiamo un algoritmo di rilevamento dei fonemi fricativi basato sull'apprendimento profondo che ha zero ritardo di rilevamento e raggiunge un'accuratezza di rilevamento dei fonemi fricativi allo stato dell'arte sul TIMIT Speech Corpus.Tutti i risultati riportati sono riproducibili e sono dotati di un codice facile da usare che potrebbe servire come base per la ricerca futura.
I modelli sequenza-sequenza con attenzione morbida sono stati applicati con successo a un'ampia varietà di problemi, ma il loro processo di decodifica comporta un costo quadratico di tempo e spazio ed è inapplicabile alla trasduzione di sequenze in tempo reale.Per affrontare questi problemi, proponiamo Monotonic Chunkwise Attention (MoChA), che divide in modo adattivo la sequenza di input in piccoli pezzi su cui viene calcolata l'attenzione morbida. Dimostriamo che i modelli che utilizzano MoChA possono essere addestrati in modo efficiente con la backpropagation standard, consentendo allo stesso tempo la decodifica online e in tempo lineare al momento del test. Quando viene applicato al riconoscimento vocale online, otteniamo risultati allo stato dell'arte e uguagliamo le prestazioni di un modello che utilizza un meccanismo di attenzione morbida offline.Negli esperimenti di sintesi dei documenti in cui non ci aspettiamo allineamenti monotonici, mostriamo prestazioni significativamente migliorate rispetto a un modello base basato sull'attenzione monotonica.
Presentiamo una struttura per ordinare automaticamente le patch di immagine che permette un'analisi approfondita della relazione tra il dataset e l'apprendibilità di un compito di classificazione utilizzando una rete neurale convoluzionale.Una patch di immagine è un gruppo di pixel che risiedono in un'area continua contenuta nel campione.I nostri risultati sperimentali preliminari mostrano che un rimescolamento intelligente informato delle patch a livello di campione può accelerare la formazione esponendo caratteristiche importanti nelle prime fasi della formazione.Inoltre, conduciamo esperimenti sistematici e forniamo prove che le capacità di generalizzazione della CNN non sono correlate alle caratteristiche umane riconoscibili presenti nei campioni di formazione. Abbiamo utilizzato il framework non solo per dimostrare che la localizzazione spaziale delle caratteristiche all'interno dei campioni non è correlata alla generalizzazione, ma anche per accelerare la convergenza pur ottenendo prestazioni di generalizzazione simili. Utilizzando più architetture di rete e set di dati, dimostriamo che ordinare le regioni dell'immagine utilizzando la misura dell'informazione reciproca tra patch adiacenti, permette alle CNN di convergere in un terzo dei passi totali richiesti per addestrare la stessa rete senza ordinare le patch.
Un metodo per superare questo problema è la randomizzazione del dominio, per cui all'inizio di ogni episodio di addestramento alcuni parametri dell'ambiente sono randomizzati in modo che l'agente sia esposto a molte possibili variazioni, ma la randomizzazione del dominio è altamente inefficiente e può portare a politiche con alta varianza tra i domini. In questo lavoro, formalizziamo il problema della randomizzazione del dominio e dimostriamo che la minimizzazione della costante di Lipschitz della politica rispetto ai parametri di randomizzazione porta a una bassa varianza nelle politiche apprese. Proponiamo un metodo in cui l'agente deve essere addestrato solo su una variazione dell'ambiente, e le sue rappresentazioni di stato apprese sono regolarizzate durante l'addestramento per minimizzare questa costante.
Le affermazioni provenienti dai campi delle neuroscienze di rete e della connettomica suggeriscono che i modelli topologici del cervello che coinvolgono reti complesse sono di particolare utilità e interesse.Il campo delle reti neurali profonde ha per lo più lasciato fuori l'ispirazione da queste affermazioni.In questo articolo, proponiamo tre architetture e usiamo ciascuna di esse per esplorare l'intersezione delle neuroscienze di rete e dell'apprendimento profondo nel tentativo di colmare il divario tra i due campi. Utilizzando gli insegnamenti della neuroscienza di rete e della connettomica, mostriamo miglioramenti rispetto all'architettura ResNet, mostriamo una possibile connessione tra l'addestramento precoce e le proprietà spettrali della rete, e mostriamo l'addestrabilità di una DNN basata sulla rete neuronale di C.Elegans.
Creare una base di conoscenza che sia accurata, aggiornata e completa rimane una sfida significativa nonostante i notevoli sforzi nella costruzione automatica di basi di conoscenza.  In questo articolo, presentiamo Alexandria -- un sistema per la costruzione non supervisionata e di alta precisione della base di conoscenza. Alexandria usa un programma probabilistico per definire un processo di conversione dei fatti della base di conoscenza in testo non strutturato.  Usando l'inferenza probabilistica, possiamo invertire questo programma e quindi recuperare fatti, schemi ed entità dal testo web.L'uso di un programma probabilistico permette all'incertezza nel testo di essere propagata attraverso i fatti recuperati, il che aumenta l'accuratezza e aiuta a unire fatti provenienti da fonti multiple.Poiché Alexandria non richiede dati di formazione etichettati, le basi di conoscenza possono essere costruite con il minimo di input manuale.Dimostriamo questo costruendo una base di conoscenza ad alta precisione (tipicamente 97%+) per le persone da un singolo fatto seme.
I recenti progressi hanno reso possibile la creazione di reti neurali complesse-valutate profonde.Nonostante questo progresso, molti compiti di apprendimento impegnativi devono ancora sfruttare la potenza delle rappresentazioni complesse.Basandosi sui recenti progressi, proponiamo un nuovo metodo profondo complesso-valutato per il recupero e l'estrazione del segnale nel dominio della frequenza.Come caso di studio, eseguiamo la separazione delle fonti audio nel dominio di Fourier.Il nostro nuovo metodo sfrutta il teorema della convoluzione che afferma che la trasformata di Fourier di due segnali convoluti è il prodotto elementare delle loro trasformate di Fourier. Il nostro nuovo metodo si basa su una versione a valore complesso di Feature-Wise Linear Modulation (FiLM) e serve come chiave di volta del nostro metodo di estrazione del segnale proposto.Introduciamo anche una nuova ed esplicita perdita consapevole dell'ampiezza e della fase, che è invariante di scala e di tempo, tenendo conto delle componenti a valore complesso dello spettrogramma.Utilizzando il Wall Street Journal Dataset, abbiamo confrontato la nostra perdita consapevole della fase con diverse altre che operano sia nel dominio del tempo che in quello della frequenza e dimostriamo l'efficacia del nostro metodo di estrazione del segnale proposto e della perdita proposta.
Proponiamo un'implementazione di GNN che predice e imita i fattori di movimento dai dati osservati della traiettoria dello sciame. La capacitÃ della rete di catturare le dinamiche di interazione negli sciami Ã¨ dimostrata attraverso il transfer learning. Discutiamo infine la disponibilitÃ intrinseca e le sfide nella scalabilitÃ di GNN, e abbiamo proposto un metodo per migliorarla con la sintonizzazione a strati e la miscelazione dei dati abilitata dal padding.
Nonostante la loro efficacia, il numero di parametri in uno strato di incorporazione aumenta linearmente con il numero di simboli e rappresenta una sfida critica per la memoria e i vincoli di archiviazione. In questo lavoro, proponiamo una struttura di compressione generica ed end-to-end imparabile denominata quantizzazione differenziabile del prodotto (DPQ). Presentiamo due istanziazioni di DPQ che sfruttano diverse tecniche di approssimazione per consentire la differenziabilità nell'apprendimento end-to-end.Il nostro metodo può facilmente servire come alternativa drop-in per qualsiasi strato di incorporazione esistente.Empiricamente, DPQ offre rapporti di compressione significativi (14-238x) a un costo di prestazione trascurabile o nullo su 10 set di dati attraverso tre diversi compiti linguistici.
Per le funzioni multi-valutate - come quando la distribuzione condizionale sugli obiettivi dati gli ingressi è multi-modale - gli approcci di regressione standard non sono sempre desiderabili perché forniscono la media condizionale.Gli approcci di regressione modale mirano invece a trovare la modalità condizionale, ma sono limitati agli approcci non parametrici. Tali approcci possono essere difficili da scalare, e rendono difficile beneficiare dell'approssimazione della funzione parametrica, come le reti neurali, che possono imparare relazioni complesse tra gli input e gli obiettivi. In questo lavoro, proponiamo un algoritmo di regressione modale parametrica, utilizzando il teorema della funzione implicita per sviluppare un obiettivo per l'apprendimento di una funzione parametrizzata congiunta su input e obiettivi. Dimostriamo empiricamente su diversi problemi sintetici che il nostro metodo (i) può imparare funzioni multi-valutate e produrre le modalità condizionali, (ii) scala bene a input ad alta densità e (iii) è ancora più efficace per alcuni problemi unimodali, in particolare per i dati ad alta frequenza in cui la funzione congiunta su input e target può catturare meglio la complessa relazione tra di loro.Concludiamo mostrando che il nostro metodo fornisce piccoli miglioramenti su due dataset di regressione che hanno distribuzioni asimmetriche sui target.
Gli algoritmi di apprendimento di rinforzo profondo richiedono grandi quantità di esperienza per imparare un singolo compito.Mentre in linea di principio gli algoritmi di apprendimento di rinforzo (meta-RL) permettono agli agenti di imparare nuove abilità da piccole quantità di esperienza, diverse sfide importanti precludono la loro praticità. I metodi attuali si basano pesantemente sull'esperienza on-policy, limitando la loro efficienza del campione.mancano anche di meccanismi per ragionare sull'incertezza del compito quando si adattano a nuovi compiti, limitando la loro efficacia in problemi di ricompensa sparsi.in questo documento, affrontiamo queste sfide sviluppando un algoritmo off-policy meta-RL che separa l'inferenza del compito e il controllo. Nel nostro approccio, eseguiamo un filtraggio probabilistico online delle variabili latenti dei compiti per dedurre come risolvere un nuovo compito da piccole quantità di esperienza.Questa interpretazione probabilistica permette il campionamento a posteriori per un'esplorazione strutturata ed efficiente.Dimostriamo come integrare queste variabili dei compiti con algoritmi RL off-policy per ottenere sia meta-training che efficienza di adattamento.Il nostro metodo supera gli algoritmi precedenti in efficienza del campione di 20-100X così come in prestazioni asintotiche su diversi benchmark meta-RL.
Le basi di conoscenza, massicce collezioni di fatti (triple RDF) su diversi argomenti, supportano applicazioni moderne vitali.Tuttavia, le basi di conoscenza esistenti contengono pochissimi dati rispetto alla ricchezza di informazioni sul Web.Questo perché lo standard industriale nella creazione e nell'aumento delle basi di conoscenza soffre di un serio collo di bottiglia: si affidano agli esperti di dominio per identificare le fonti web appropriate da cui estrarre i dati. Gli sforzi per automatizzare completamente l'estrazione della conoscenza non sono riusciti a migliorare questo standard: questi sistemi automatici sono in grado di recuperare molti più dati e da una gamma più ampia di fonti, ma soffrono di precisione e richiamo molto bassi. In questo articolo, presentiamo MIDAS, un sistema che sfrutta i risultati delle pipeline automatizzate di estrazione della conoscenza per riparare il collo di bottiglia nella creazione di conoscenza industriale e nei processi di incremento.MIDAS automatizza il suggerimento di fonti web di buona qualità e descrive cosa estrarre rispetto all'incremento di una base di conoscenza esistente.Diamo tre contributi principali. In primo luogo, introduciamo un nuovo concetto, le fette di fonti web, per descrivere il contenuto di una fonte web; in secondo luogo, definiamo una funzione di profitto per quantificare il valore di una fetta di fonte web rispetto all'incremento di una base di conoscenza esistente; in terzo luogo, sviluppiamo algoritmi efficaci e altamente scalabili per derivare fette di fonti web ad alto profitto; dimostriamo che MIDAS produce risultati ad alto profitto e supera significativamente le prestazioni di base sia su parole reali che su set di dati sintetici.
Esploriamo il problema della predizione della corrispondenza in cui si cerca di stimare la probabilità che un gruppo di elementi M sia preferito a un altro, sulla base di dati parziali di confronto di gruppo.Le sfide sorgono nella pratica.Poiché gli algoritmi esistenti allo stato dell'arte sono adattati a determinati modelli statistici, abbiamo diversi algoritmi migliori in scenari diversi. Peggio ancora, non abbiamo alcuna conoscenza preliminare sul modello sottostante per un dato scenario.Questi richiedono un approccio unificato che può essere universalmente applicato a una vasta gamma di scenari e raggiungere prestazioni costantemente elevate.A tal fine, incorporiamo architetture di apprendimento profondo in modo da riflettere le caratteristiche strutturali chiave che la maggior parte degli algoritmi all'avanguardia, alcuni dei quali sono ottimali in determinate impostazioni, hanno in comune. Questo ci permette di dedurre i modelli nascosti alla base di un dato set di dati, che governano le interazioni in-gruppo e i modelli statistici di confronto, e quindi di concepire il miglior algoritmo su misura per il set di dati a portata di mano. Risulta che la nostra struttura porta costantemente alle migliori prestazioni su tutti i set di dati in termini di perdita di entropia incrociata e accuratezza della previsione, mentre gli algoritmi allo stato dell'arte soffrono di prestazioni incoerenti su diversi set di dati. Inoltre, dimostriamo che può essere facilmente esteso per raggiungere prestazioni soddisfacenti in compiti di aggregazione di rango, suggerendo che può essere adattabile anche per altri compiti.
Le reti neurali ricorrenti (RNN) sono progettate per gestire dati sequenziali, ma soffrono di gradienti che svaniscono o esplodono.  I recenti lavori sulle reti neurali ricorrenti unitarie (uRNN) sono stati utilizzati per affrontare questo problema e, in alcuni casi, superano le capacità delle reti a memoria lunga e breve (LSTM).  Proponiamo uno schema di aggiornamento più semplice e innovativo per mantenere le matrici di peso ricorrenti ortogonali senza utilizzare matrici complesse, parametrizzando con una matrice asimmetrica utilizzando la trasformata di Cayley. Tale parametrizzazione non è in grado di rappresentare matrici con autovalori negativi, ma questa limitazione viene superata scalando la matrice di peso ricorrente da una matrice diagonale composta da uno e uno negativo.  In diversi esperimenti, la rete neurale ricorrente ortogonale Cayley scalata proposta (scoRNN) raggiunge risultati superiori con meno parametri addestrabili rispetto ad altre RNN unitarie.
Un gran numero di compiti di elaborazione del linguaggio naturale esiste per analizzare la sintassi, la semantica e il contenuto informativo del linguaggio umano. Questi compiti apparentemente molto diversi sono di solito risolti da architetture appositamente progettate. In questo documento, forniamo la semplice intuizione che una grande varietà di compiti può essere rappresentata in un unico formato unificato che consiste nell'etichettare gli span e le relazioni tra gli span, quindi un singolo modello indipendente dal compito può essere usato attraverso diversi compiti. Eseguiamo ampi esperimenti per testare questa intuizione su 10 compiti disparati come il parsing delle dipendenze (sintassi), l'etichettatura dei ruoli semantici (semantica), l'estrazione delle relazioni (contenuto informativo), l'analisi del sentimento basata sugli aspetti (sentimento) e molti altri, ottenendo prestazioni comparabili con i modelli specializzati allo stato dell'arte.
Con l'uso dei GP come blocchi di costruzione per modelli di apprendimento profondo bayesiani sempre più sofisticati, la rimozione di questi impedimenti è un passo necessario per raggiungere risultati su larga scala. Presentiamo un'approssimazione variazionale per una vasta gamma di modelli GP che non richiede l'inversione della matrice ad ogni passo di ottimizzazione. Il nostro limite invece parametrizza direttamente una matrice libera, che è un parametro variazionale aggiuntivo. Ai massimi locali del limite, questa matrice è uguale all'inverso della matrice. Dimostriamo che il nostro limite dà le stesse garanzie delle approssimazioni variazionali precedenti.
È stato dimostrato che l'utilizzo di spazi geometrici con curvatura non nulla invece di semplici spazi euclidei con curvatura zero migliora le prestazioni su una serie di compiti di apprendimento automatico per l'apprendimento di rappresentazioni. Un lavoro recente ha sfruttato queste geometrie per imparare modelli di variabili latenti come gli autocodificatori variazionali (VAE) in spazi sferici e iperbolici con curvatura costante. ~Sviluppiamo un Mixed-curvature Variational Autoencoder, un modo efficiente per addestrare un VAE il cui spazio latente è un prodotto di collettori Riemanniani a curvatura costante, dove la curvatura per componente può essere appresa. Questo generalizza il VAE euclideo agli spazi latenti curvi, poiché il modello si riduce essenzialmente al VAE euclideo se le curvature di tutte le componenti dello spazio latente vanno a 0.
Algoritmi di apprendimento automatico per la generazione di strutture molecolari offrono un nuovo e promettente approccio alla scoperta della droga. Abbiamo lanciato l'ottimizzazione molecolare come un problema di traduzione, dove l'obiettivo è quello di mappare un composto di input a un composto di destinazione con proprietà biochimiche migliorate. Chiamiamo questo metodo Black Box Recursive Translation (BBRT), un nuovo metodo di inferenza per l'ottimizzazione delle proprietà molecolari. Questa semplice e potente tecnica opera rigorosamente sugli input e sugli output di qualsiasi modello di traduzione. Otteniamo nuovi risultati allo stato dell'arte per compiti di ottimizzazione delle proprietà molecolari usando la nostra semplice sostituzione drop-in con noti modelli basati su sequenze e grafi. Il nostro metodo fornisce un significativo aumento delle prestazioni rispetto ai suoi colleghi non ricorsivi con un semplice ciclo "``for".
Le reti neurali profonde (DNN) sono sempre più utilizzate nei server cloud e negli agenti autonomi a causa delle loro prestazioni superiori. La DNN distribuita viene sfruttata in un ambiente white-box (gli interni del modello sono noti al pubblico) o in un ambiente black-box (solo gli output del modello sono noti) a seconda dell'applicazione. Proponiamo BlackMarks, il primo framework di watermarking end-to-end multi-bit applicabile nello scenario black-box.BlackMarks prende come input il modello non marcato pre-addestrato e la firma binaria del proprietario.L'output è il modello marcato corrispondente con chiavi specifiche che possono essere successivamente utilizzate per attivare la filigrana incorporata. Per fare ciÃ², BlackMarks prima progetta uno schema di codifica dipendente dal modello che mappa tutte le possibili classi nel compito a bit â€˜0â€™ e bit â€˜1â€™. Data la firma di filigrana del proprietario (una stringa binaria), un insieme di immagini chiave e coppie di etichette Ã¨ progettato utilizzando attacchi avversari mirati. La filigrana (WM) Ã¨ quindi codificata nella distribuzione delle attivazioni di uscita della DNN mettendo a punto il modello con una perdita regolarizzata specifica WM. Per estrarre la WM, BlackMarks interroga il modello con le immagini chiave WM e decodifica la firma del proprietario dalle previsioni corrispondenti utilizzando lo schema di codifica progettato.Eseguiamo una valutazione completa delle prestazioni di BlackMarks su MNIST, CIFAR-10, dataset ImageNet e corroborare la sua efficacia e robustezza.BlackMarks conserva la funzionalità della DNN originale e incorre in un overhead di incorporazione WM trascurabile come il 2,054%.
L'addestramento avversario fornisce un approccio di principio per l'addestramento di reti neurali robuste.Da una prospettiva di ottimizzazione, l'addestramento avversario sta essenzialmente risolvendo un problema di ottimizzazione robusto minmax.La minimizzazione esterna sta cercando di imparare un classificatore robusto, mentre la massimizzazione interna sta cercando di generare campioni avversari.Purtroppo, un tale problema minmax è molto difficile da risolvere a causa della mancanza di struttura convessa-concava.Questo lavoro propone un nuovo metodo di addestramento avversario basato su un quadro generale di apprendimento-apprendere. In particolare, invece di applicare gli algoritmi di progettazione a mano esistenti per il problema interno, impariamo un ottimizzatore, che è parametrizzato come una rete neurale convoluzionale.Allo stesso tempo, un classificatore robusto viene appreso per difendere l'attacco avversario generato dall'ottimizzatore imparato. Dal punto di vista dell'apprendimento generativo, il nostro metodo proposto può essere visto come l'apprendimento di un modello generativo profondo per la generazione di campioni avversari, che è adattivo alla classificazione robusta.I nostri esperimenti dimostrano che il nostro metodo proposto supera significativamente i metodi di formazione avversari esistenti sui dataset CIFAR-10 e CIFAR-100.
In questo lavoro introduciamo una nuova struttura per l'esecuzione di previsioni temporali in presenza di incertezza, basata su una semplice idea di separare le componenti dello stato futuro che sono prevedibili da quelle che sono intrinsecamente imprevedibili, e codificare le componenti imprevedibili in una variabile a bassa dimensione che viene alimentata nel modello forward. Il nostro metodo utilizza un semplice obiettivo di addestramento su-pervisionato che è veloce e facile da addestrare. Lo valutiamo nel contesto della predizione video su più set di dati e dimostriamo che è in grado di generare consi-tentemente predizioni diverse senza la necessità di minimizzazione alternata su uno spazio latente o di addestramento avversario.
Una pipeline sperimentale completa consisterà tipicamente in una simulazione di un ambiente, un'implementazione di uno o più algoritmi di apprendimento, una varietà di componenti aggiuntivi progettati per facilitare l'interazione agente-ambiente, e qualsiasi analisi richiesta, tracciatura e registrazione. Alla luce di questa complessità, questo articolo introduce simple_rl, una nuova libreria open source per l'esecuzione di esperimenti di apprendimento per rinforzo in Python 2 e 3. L'obiettivo di simple_rl è quello di supportare metodi senza soluzione di continuità e riproducibili per l'esecuzione di esperimenti di apprendimento per rinforzo.Questo articolo fornisce una panoramica della filosofia di progettazione di base del pacchetto, come si differenzia dalle librerie esistenti, e mostra le sue caratteristiche centrali.
Wasserstein GAN(WGAN) è un modello che minimizza la distanza di Wasserstein tra una distribuzione di dati e una distribuzione campione.Studi recenti hanno proposto di stabilizzare il processo di formazione per il WGAN e di implementare il vincolo di Lipschitz.In questo studio, dimostriamo la stabilità locale dell'ottimizzazione della semplice penalità di gradiente $\mu$-WGAN(SGP $\mu$-WGAN) sotto opportune ipotesi sull'equilibrio e sulla misura della penalità $\mu$. Il concetto di differenziazione con valore di misura è impiegato per trattare la derivata dei termini di penalità, che è utile per gestire misure astratte singolari con supporto dimensionale inferiore. Sulla base di questa analisi, sosteniamo che la penalizzazione del collettore di dati o del collettore di campioni è la chiave per regolarizzare la WGAN originale con una penalità a gradiente.I risultati sperimentali ottenuti con misure di penalità non intuitive che soddisfano le nostre ipotesi sono anche forniti per sostenere i nostri risultati teorici.
Presentiamo Random Partition Relaxation (RPR), un metodo per la quantizzazione forte dei parametri delle reti neurali convoluzionali a valori binari (+1/-1) e ternari (+1/0/-1).Partendo da un modello preaddestrato, prima quantizziamo i pesi e poi rilassiamo partizioni casuali di essi ai loro valori continui per il retraining prima di quantizzarli nuovamente e passare a un'altra partizione di peso per un ulteriore adattamento.  Valutiamo empiricamente le prestazioni di RPR con ResNet-18, ResNet-50 e GoogLeNet sul compito di classificazione ImageNet per reti a peso binario e ternario. Mostriamo accuratezze oltre lo stato dell'arte per GoogLeNet a peso binario e ternario e prestazioni competitive per ResNet-18 e ResNet-50 utilizzando un metodo di formazione basato su SGD che può essere facilmente integrato in strutture esistenti.
L'apprendimento delle dipendenze a lungo termine è una sfida chiave di lunga data delle reti neurali ricorrenti (RNNs).Le reti neurali ricorrenti gerarchiche (HRNNs) sono state considerate un approccio promettente in quanto le dipendenze a lungo termine sono risolte attraverso scorciatoie su e giù per la gerarchia.Eppure, i requisiti di memoria di Truncated Backpropagation Through Time (TBPTT) impediscono ancora l'allenamento su sequenze molto lunghe. In questo articolo, dimostriamo empiricamente che nelle HRNN (profonde), la propagazione dei gradienti indietro dai livelli superiori a quelli inferiori può essere sostituita da perdite calcolabili localmente, senza danneggiare la capacità di apprendimento della rete, su una vasta gamma di compiti.
In un tipico approccio di deep learning a un compito di computer vision, le reti neurali convoluzionali (CNN) vengono utilizzate per estrarre le caratteristiche a vari livelli di astrazione da un'immagine e comprimere un input ad alta dimensione in uno spazio decisionale di dimensione inferiore attraverso una serie di trasformazioni. Queste variazioni sono formalizzate come la dimensione effettiva dell'incorporamento.Consideriamo come la dimensione effettiva varia attraverso gli strati all'interno della classe.Mostriamo che attraverso i set di dati e le architetture, la dimensione effettiva di una classe aumenta prima di diminuire ulteriormente nella rete, suggerendo una sorta di trasformazione di sbiancamento iniziale.Inoltre, il tasso di diminuzione della dimensione effettiva più in profondità nella rete corrisponde alle prestazioni di formazione del modello.
I metodi di apprendimento profondo hanno raggiunto alte prestazioni nei compiti di riconoscimento del suono.Decidere come alimentare i dati di allenamento è importante per un ulteriore miglioramento delle prestazioni.Proponiamo un nuovo metodo di apprendimento per il riconoscimento profondo del suono: La nostra strategia consiste nell'apprendere uno spazio di caratteristiche discriminanti riconoscendo i suoni inter-classe come suoni inter-classe.Generiamo suoni inter-classe mescolando due suoni appartenenti a classi diverse con un rapporto casuale.Inseriamo quindi il suono mescolato nel modello e addestriamo il modello a produrre il rapporto di miscelazione.I vantaggi dell'apprendimento BC non si limitano solo all'aumento della variazione dei dati di formazione; l'apprendimento BC porta a un ampliamento del criterio di Fisher nello spazio delle caratteristiche e a una regolarizzazione della relazione di posizione tra le distribuzioni delle caratteristiche delle classi. I risultati sperimentali mostrano che l'apprendimento BC migliora le prestazioni su varie reti di riconoscimento del suono, set di dati e schemi di aumento dei dati, in cui l'apprendimento BC si dimostra sempre vantaggioso. Inoltre, costruiamo una nuova rete profonda di riconoscimento del suono (EnvNet-v2) e la addestriamo con l'apprendimento BC, ottenendo come risultato una prestazione che supera il livello umano.
La previsione spazio-temporale è diventata un compito di previsione sempre più importante nell'apprendimento automatico e nelle statistiche a causa delle sue vaste applicazioni, come la modellazione del clima, la previsione del traffico, le previsioni di caching video, e così via.Mentre sono stati condotti numerosi studi, la maggior parte dei lavori esistenti presuppone che i dati provenienti da fonti diverse o da luoghi diversi siano ugualmente affidabili.A causa del costo, dell'accessibilità o di altri fattori, è inevitabile che la qualità dei dati possa variare, il che introduce bias significativi nel modello e porta a risultati di previsione non affidabili. Il problema potrebbe essere esacerbato nei modelli di previsione black-box, come le reti neurali profonde. In questo articolo, proponiamo una nuova soluzione che può dedurre automaticamente i livelli di qualità dei dati di diverse fonti attraverso le variazioni locali dei segnali spazio-temporali senza etichette esplicite. Inoltre, integriamo la stima del livello di qualità dei dati con reti convoluzionali a grafo per sfruttare le loro strutture efficienti.
La percezione umana delle forme 3D va oltre la ricostruzione come un insieme di punti o una composizione di primitivi geometrici: comprendiamo anche senza sforzo la struttura di forma di livello superiore, come la ripetizione e la simmetria riflessiva delle parti dell'oggetto.Al contrario, i recenti progressi nel rilevamento delle forme 3D si concentrano maggiormente sulla geometria di basso livello ma meno su queste relazioni di livello superiore.In questo articolo, proponiamo programmi di forma 3D, integrando sistemi di riconoscimento bottom-up con una struttura di programma simbolico top-down per catturare sia la geometria di basso livello che priori strutturali di alto livello per le forme 3D. Poiché non ci sono annotazioni di programmi di forma per le forme reali, sviluppiamo moduli neurali che non solo imparano a dedurre programmi di forma 3D da forme grezze, non annotate, ma anche a eseguire questi programmi per la ricostruzione della forma.Dopo il bootstrapping iniziale, il nostro modello differenziabile end-to-end impara i programmi di forma 3D ricostruendo le forme in modo auto-supervisionato. Gli esperimenti dimostrano che il nostro modello infonde ed esegue accuratamente programmi di forma 3D per forme altamente complesse di varie categorie e può anche essere integrato con un modulo image-to-shape per inferire programmi di forma 3D direttamente da un'immagine RGB, portando a ricostruzioni di forma 3D che sono sia più accurate che più fisicamente plausibili.
Il Deep Reinforcement Learning (Deep RL) sta ricevendo sempre più attenzione grazie alle sue incoraggianti prestazioni su una varietà di compiti di controllo.Tuttavia, le tecniche di regolarizzazione convenzionali nell'addestramento delle reti neurali (ad es, In questo lavoro, presentiamo il primo studio completo delle tecniche di regolarizzazione con più algoritmi di ottimizzazione delle politiche su compiti di controllo continui. È interessante notare che le tecniche di regolarizzazione convenzionali sulle reti di politiche possono spesso portare grandi miglioramenti nelle prestazioni dei compiti, e il miglioramento è tipicamente più significativo quando il compito è più difficile. Confrontiamo anche con la regolarizzazione dell'entropia ampiamente utilizzata e troviamo che la regolarizzazione L_2$ è generalmente migliore. I nostri risultati sono ulteriormente confermati per essere robusti rispetto alla scelta degli iperparametri di addestramento. Studiamo anche gli effetti della regolarizzazione dei diversi componenti e troviamo che solo la regolarizzazione della rete di politiche è tipicamente sufficiente.
Introduciamo FigureQA, un corpus di ragionamento visivo di oltre un milione di coppie domanda-risposta basate su oltre 100.000 immagini. Le immagini sono figure sintetiche in stile scientifico di cinque classi: grafici a linee, grafici a punti, grafici a barre verticali e orizzontali e grafici a torta. Formuliamo il nostro compito di ragionamento generando domande da 15 modelli; le domande riguardano varie relazioni tra gli elementi della trama ed esaminano caratteristiche come il massimo, il minimo, l'area sotto la curva, la levigatezza e l'intersezione.Per risolvere, tali domande spesso richiedono il riferimento a più elementi della trama e la sintesi di informazioni distribuite spazialmente in tutta una figura. Per facilitare l'addestramento dei sistemi di apprendimento automatico, il corpus include anche dati laterali che possono essere utilizzati per formulare obiettivi ausiliari.In particolare, forniamo i dati numerici utilizzati per generare ogni figura così come le annotazioni bounding-box per tutti gli elementi della trama.Studiamo il compito di ragionamento visivo proposto addestrando diversi modelli, tra cui la rete di relazioni recentemente proposta come base forte.I risultati preliminari indicano che il compito pone una sfida significativa di apprendimento automatico.Consideriamo FigureQA come un primo passo verso lo sviluppo di modelli che possono riconoscere intuitivamente i modelli dalle rappresentazioni visive dei dati.
In questo articolo, discuto alcune varietà di spiegazioni che possono sorgere in agenti intelligenti.Distinguo tra i conti di processo, che affrontano le decisioni dettagliate prese durante la ricerca euristica, e i conti di preferenza, che chiariscono l'ordine delle alternative indipendenti da come sono state generate.Ipotizzo anche quali tipi di utenti apprezzeranno quali tipi di spiegazioni.Inoltre, discuto tre aspetti del processo decisionale multi-fase - inferenza concettuale, generazione del piano ed esecuzione del piano - in cui le spiegazioni possono sorgere.Considero anche modi alternativi per presentare domande agli agenti e per loro fornire le loro risposte.
L'apprendimento profondo generativo ha scatenato una nuova ondata di algoritmi di super-risoluzione (SR) che migliorano le singole immagini con risultati estetici impressionanti, anche se con dettagli immaginari.Multi-frame Super-Resolution (MFSR) offre un approccio più fondato al problema mal posto, condizionando su più viste a bassa risoluzione. Questo è importante per il monitoraggio satellitare dell'impatto umano sul pianeta - dalla deforestazione, alle violazioni dei diritti umani - che dipendono da immagini affidabili. A tal fine, presentiamo HighRes-net, il primo approccio di deep learning a MFSR che impara i suoi sotto-compiti in un modo end-to-end: (i) co-registrazione, (ii) fusione, (iii) up-sampling, e (iv) registrazione-at-the-loss. La co-registrazione delle viste a bassa risoluzione viene appresa implicitamente attraverso un canale di riferimento, senza un meccanismo di registrazione esplicito.Impariamo un operatore di fusione globale che viene applicato ricorsivamente su un numero arbitrario di coppie a bassa risoluzione.Introduciamo una perdita registrata, imparando ad allineare l'uscita SR a una verità a terra attraverso ShiftNet.Mostriamo che imparando rappresentazioni profonde di viste multiple, possiamo super-risolvere i segnali a bassa risoluzione e migliorare i dati di osservazione della Terra su scala.Il nostro approccio ha recentemente superato la competizione MFSR dell'Agenzia Spaziale Europea su immagini satellitari reali.
Gli approcci che utilizzano una media distribuita esatta strettamente accoppiata basata su AllReduce sono sensibili ai nodi lenti e alle comunicazioni ad alta latenza. In questo lavoro mostriamo l'applicabilità di Stochastic Gradient Push (SGP) per la formazione distribuita. SGP utilizza un algoritmo di gossip chiamato PushSum per la media distribuita approssimativa, permettendo comunicazioni molto più liberamente accoppiate che possono essere utili in scenari ad alta latenza o ad alta variabilità. Il compromesso è che la media approssimativa distribuita inietta ulteriore rumore nel gradiente che può influenzare le accuratezze di addestramento e di test. dimostriamo che SGP converge a un punto stazionario di funzioni obiettivo lisce e non convesse. inoltre, validiamo empiricamente il potenziale di SGP. Per esempio, usando 32 nodi con 8 GPU per nodo per addestrare ResNet-50 su ImageNet, dove i nodi comunicano su 10Gbps Ethernet, SGP completa 90 epoche in circa 1,5 ore mentre AllReduce SGD impiega oltre 5 ore, e l'accuratezza di validazione top-1 di SGP rimane entro l'1,2% di quella ottenuta usando AllReduce SGD.
In questo articolo, estendiamo il modello di conversazione a rete neurale basato sulla persona da sequenza a sequenza (Seq2Seq) a uno scenario di dialogo a più turni, modificando l'architettura hredGAN allo stato dell'arte per catturare simultaneamente gli attributi dell'enunciato come l'identità del parlante, l'argomento del dialogo, i sentimenti del parlante e così via.Il sistema proposto, phredGAN ha un generatore HRED basato sulla persona (PHRED) e un discriminatore condizionale: (1) $phredGAN_a$, un sistema che passa la rappresentazione dell'attributo come un input aggiuntivo in un discriminatore avversario tradizionale, e (2) $phredGAN_d$, un sistema a doppio discriminatore che, oltre al discriminatore avversario, predice in modo collaborativo l'attributo o gli attributi che hanno generato l'enunciato in ingresso. Per dimostrare le prestazioni superiori di phredGAN rispetto al modello Persona SeqSeq, sperimentiamo con due dataset di conversazioni, l'Ubuntu Dialogue Corpus (UDC) e le trascrizioni delle serie TV Big Bang Theory e Friends. Il confronto delle prestazioni viene fatto rispetto ad una varietà di misure quantitative così come la valutazione umana crowd-sourced. Esploriamo anche i compromessi dall'uso di entrambe le varianti di $phredGAN$ su dataset con molte ma deboli modalità di attributo (come con Big Bang Theory e Friends) e quelli con poche ma forti modalità di attributo (interazioni cliente-agente nel dataset Ubuntu).
Per simulare le proprietà dei sistemi biologici aggiungiamo i costi che penalizzano le connessioni lunghe e la vicinanza dei neuroni in uno spazio bidimensionale. I nostri esperimenti mostrano che nel caso in cui la rete esegue due compiti diversi, i neuroni si dividono naturalmente in cluster, dove ogni cluster è responsabile dell'elaborazione di un compito diverso.
Il suo successo dimostra l'efficacia dell'attenzione impilata come un sostituto della ricorrenza per molti compiti. In teoria l'attenzione offre anche una maggiore comprensione delle decisioni interne del modello; tuttavia, in pratica, quando è impilata diventa rapidamente quasi completamente connessa come i modelli ricorrenti. Il modello utilizza l'attenzione dura per garantire che ogni passo dipenda solo da un contesto fisso; inoltre, il modello utilizza un controller "sintattico" separato per separare la struttura della rete dal processo decisionale; infine, mostriamo che questo approccio può essere ulteriormente sparsificato con la regolarizzazione diretta.
Le reti profonde di codifica predittiva sono modelli di apprendimento non supervisionato ispirati alle neuroscienze che imparano a prevedere gli stati sensoriali futuri.Ci basiamo sull'implementazione PredNet di Lotter, Kreiman e Cox (2016) per indagare se le rappresentazioni di codifica predittiva sono utili per prevedere l'attività cerebrale nella corteccia visiva.Usiamo l'analisi di similarità rappresentazionale (RSA) per confrontare le rappresentazioni PredNet alla risonanza magnetica funzionale (fMRI) e ai dati magnetoencefalografici (MEG) del progetto Algonauts (Cichy et al., 2019).In contrasto con i risultati precedenti in letteratura (Khaligh-Razavi & Kriegeskorte, 2014), riportiamo dati empirici che suggeriscono che i modelli non supervisionati addestrati per prevedere i fotogrammi dei video senza ulteriore messa a punto possono superare le linee di base di classificazione delle immagini supervisionate in termini di correlazione ai dati spaziali (fMRI) e temporali (MEG).
L'incorporazione della conoscenza precedente nell'apprendimento è essenziale per ottenere buone prestazioni basate su piccoli campioni rumorosi. Tale conoscenza è spesso incorporata attraverso la disponibilità di dati correlati derivanti da domini e compiti simili a quello di interesse corrente. Idealmente si vorrebbe consentire sia i dati per il compito corrente che per i compiti precedenti correlati per auto-organizzare il sistema di apprendimento in modo tale che i punti in comune e le differenze tra i compiti siano appresi in modo guidato dai dati. Sviluppiamo una struttura per l'apprendimento simultaneo di più compiti, basata sulla condivisione di caratteristiche che sono comuni a tutti i compiti, ottenuta attraverso l'uso di una rete neurale profonda modulare a feedforward composta da rami condivisi, che si occupano delle caratteristiche comuni a tutti i compiti, e rami privati, che imparano gli aspetti unici specifici di ciascun compito, Il metodo si occupa di meta-apprendimento (come l'adattamento al dominio, il trasferimento e l'apprendimento multi-task) in modo unificato, e può facilmente trattare i dati provenienti da diversi tipi di fonti. Esperimenti numerici dimostrano l'efficacia dell'apprendimento nell'adattamento al dominio e nelle configurazioni di apprendimento di trasferimento, e forniscono prove per le rappresentazioni flessibili e orientate ai compiti che emergono nella rete.
Le reti neurali profonde e gli alberi decisionali operano su paradigmi largamente separati; tipicamente, il primo esegue l'apprendimento della rappresentazione con architetture prestabilite, mentre il secondo è caratterizzato dall'apprendimento di gerarchie su caratteristiche prestabilite con architetture guidate dai dati.Uniamo i due tramite alberi neurali adattivi (ANTs), un modello che incorpora l'apprendimento della rappresentazione in bordi, funzioni di routing e nodi foglia di un albero decisionale, insieme a un algoritmo di formazione basato sulla backpropagation che cresce in modo adattivo l'architettura da moduli primitivi (ad es, Lo dimostriamo su compiti di classificazione e regressione, raggiungendo oltre il 99% e il 90% di accuratezza sui set di dati MNIST e CIFAR-10, e superando le reti neurali standard, le foreste casuali e gli alberi potenziati dal gradiente sul set di dati SARCOS.Inoltre, l'ottimizzazione ANT adatta naturalmente l'architettura alle dimensioni e alla complessità dei dati di formazione.
Mentre i sistemi di elaborazione del linguaggio naturale spesso si concentrano su una singola lingua, l'apprendimento di trasferimento multilingue ha il potenziale per migliorare le prestazioni, soprattutto per le lingue a bassa risorsa. Introduciamo XLDA, cross-lingual data augmentation, un metodo che sostituisce un segmento del testo di input con la sua traduzione in un'altra lingua. XLDA migliora le prestazioni di tutte le 14 lingue testate del benchmark cross-lingual natural language inference (XNLI), con miglioramenti fino a 4.8, l'addestramento con XLDA raggiunge prestazioni allo stato dell'arte per greco, turco e urdu. XLDA è in contrasto con un approccio più ingenuo che aggrega esempi in varie lingue in modo che ogni esempio sia solo in una lingua, e ha prestazioni nettamente migliori rispetto ad esso.Sul compito di risposta alle domande di SQuAD, vediamo che XLDA fornisce un aumento delle prestazioni di 1,0 sul set di valutazione inglese.Gli esperimenti completi suggeriscono che la maggior parte delle lingue sono efficaci come aumentatori interlinguistici, che XLDA è robusto per una vasta gamma di qualità di traduzione, e che XLDA è anche più efficace per i modelli inizializzati in modo casuale che per i modelli preaddestrati.
L'addestramento di modelli generativi condizionali a variabili latenti è impegnativo negli scenari in cui il segnale di condizionamento è molto forte e il decodificatore è abbastanza espressivo da generare un output plausibile data solo la condizione; il modello generativo tende a ignorare la variabile latente, soffrendo di collasso posteriore. Troviamo, e dimostriamo empiricamente, che una delle ragioni principali dietro il collasso posteriore è radicata nel modo in cui i modelli generativi sono condizionati, cioè, attraverso la concatenazione della variabile latente e la condizione. Per mitigare questo problema, proponiamo di far dipendere esplicitamente le variabili latenti dalla condizione unificando il condizionamento e il campionamento della variabile latente, accoppiandoli in modo da evitare che il modello scarti la radice delle variazioni. Per ottenere questo, sviluppiamo un'architettura di autocodificatore variazionale condizionale che impara una distribuzione non solo delle variabili latenti, ma anche della condizione, quest'ultima agendo come priore sulla prima. I nostri esperimenti sui compiti impegnativi della predizione condizionata del movimento umano e delle didascalie delle immagini dimostrano l'efficacia del nostro approccio nell'evitare il collasso del posteriore. I risultati video del nostro approccio sono forniti in forma anonima in http://bit.ly/iclr2020
Proponiamo uno studio della stabilità di diversi algoritmi di apprendimento a pochi colpi soggetti a variazioni negli iper-parametri e negli schemi di ottimizzazione mentre controlliamo il seme casuale.  Proponiamo una metodologia per testare le differenze statistiche nelle prestazioni dei modelli sotto diverse repliche.Per studiare questo disegno specifico, cerchiamo di riprodurre i risultati di tre articoli importanti: Analizziamo sul dataset miniImagenet sul compito di classificazione standard nell'impostazione di apprendimento a 5 vie e 5 colpi al momento del test e troviamo che le implementazioni selezionate mostrano stabilità attraverso il seme casuale e le repliche.
In tali strutture gerarchiche, un controllore di livello superiore risolve le mansioni comunicando iterativamente gli obiettivi che una politica di livello inferiore Ã¨ addestrata per raggiungere. Di conseguenza, la scelta della rappresentazione -- la mappatura dello spazio di osservazione allo spazio dell'obiettivo -- Ã¨ cruciale. Deriviamo espressioni che delimitano la sub-ottimalità e mostriamo come queste espressioni possono essere tradotte in obiettivi di apprendimento della rappresentazione che possono essere ottimizzati in pratica. I risultati su un certo numero di compiti difficili a controllo continuo mostrano che il nostro approccio all'apprendimento della rappresentazione produce rappresentazioni qualitativamente migliori e politiche gerarchiche quantitativamente migliori, rispetto ai metodi esistenti.
La ricerca sulla ricerca euristica spesso si occupa di trovare algoritmi per la pianificazione offline che mirano a minimizzare il numero di nodi espansi o il tempo di pianificazione.Nella pianificazione online, sono stati considerati in precedenza algoritmi per la ricerca in tempo reale o la ricerca consapevole delle scadenze.Tuttavia, in questo articolo, siamo interessati al problema della {em situated temporal planning} in cui il piano di un agente può dipendere da eventi esogeni nel mondo esterno, e quindi diventa importante prendere in considerazione il passare del tempo durante il processo di pianificazione.  I lavori precedenti sulla pianificazione temporale situata hanno proposto semplici strategie di potatura, così come schemi complessi per una versione semplificata del problema di metareasoning associato. In questo articolo, proponiamo una semplice tecnica di metareasoning, chiamata schema gredo greedy, che può essere applicata in un pianificatore temporale situato. La nostra valutazione empirica mostra che lo schema gredo greedy supera la ricerca euristica standard basata sulle stime di costo-viaggio.
Le reti neurali sono vulnerabili alle piccole perturbazioni avversarie.La letteratura esistente si è in gran parte concentrata sulla comprensione e l'attenuazione della vulnerabilità dei modelli appresi.In questo articolo, dimostriamo un fenomeno intrigante sul metodo di formazione robusto più popolare in letteratura, la formazione avversaria: La robustezza avversaria, a differenza dell'accuratezza pulita, è sensibile alla distribuzione dei dati di input; anche una trasformazione che preserva la semantica sulla distribuzione dei dati di input può causare una robustezza significativamente diversa per il modello addestrato avversaria che è sia addestrato che valutato sulla nuova distribuzione. La nostra scoperta di tale sensibilità sulla distribuzione dei dati si basa su uno studio che distingue i comportamenti di accuratezza pulita e accuratezza robusta del classificatore di Bayes. Costruiamo varianti semanticamente identiche per MNIST e CIFAR10 rispettivamente, e mostriamo che i modelli addestrati in modo standard raggiungono accuratezze pulite comparabili su di essi, ma i modelli addestrati in modo avverso raggiungono accuratezze di robustezza significativamente diverse.Questo fenomeno controintuitivo indica che la sola distribuzione dei dati di input può influenzare la robustezza avversa delle reti neurali addestrate, non necessariamente i compiti stessi.Infine, discutiamo le implicazioni pratiche sulla valutazione della robustezza avversa, e facciamo i primi tentativi per comprendere questo fenomeno complesso.
 Molti compiti nell'elaborazione del linguaggio naturale comportano il confronto di due frasi per calcolare una qualche nozione di rilevanza, implicazione o somiglianza.Tipicamente questo confronto viene fatto o a livello di parola o a livello di frase, senza alcun tentativo di sfruttare la struttura intrinseca della frase.Quando la struttura della frase viene utilizzata per il confronto, essa viene ottenuta durante una fase di pre-elaborazione non differenziabile, portando alla propagazione degli errori.Introduciamo un modello di allineamenti strutturati tra frasi, mostrando come confrontare due frasi facendo corrispondere le loro strutture latenti. Utilizzando un meccanismo di attenzione strutturata, il nostro modello abbina possibili span nella prima frase a possibili span nella seconda frase, scoprendo simultaneamente la struttura ad albero di ogni frase ed eseguendo un confronto, in un modello che è completamente differenziabile ed è addestrato solo sull'obiettivo del confronto.Valutiamo questo modello su due compiti di confronto delle frasi: il dataset di inferenza del linguaggio naturale di Stanford e il dataset TREC-QA.Troviamo che confrontare gli span porta a prestazioni superiori al confronto delle parole singolarmente, e che gli alberi appresi sono coerenti con le strutture linguistiche reali.
Imparare una rappresentazione distinta da qualsiasi dato non etichettato è un problema non banale. In questo articolo proponiamo Information Maximising Autoencoder (InfoAE) dove il codificatore impara una potente rappresentazione distinta attraverso la massimizzazione dell'informazione reciproca tra la rappresentazione e l'informazione data in modo non supervisionato. Abbiamo valutato il nostro modello sul dataset MNIST e raggiunto circa il 98,9% di accuratezza del test utilizzando un addestramento completo non supervisionato.
L'addestramento efficace delle reti neurali richiede molti dati. Nel regime di bassi dati, i parametri sono sottodeterminati, e le reti apprese generalizzano poco.DataAugmentation (Krizhevsky et al, Tuttavia, l'aumento dei dati standard produce solo dati alternativi plausibili limitati. Dato che c'è il potenziale per generare un set di aumenti molto più ampio, progettiamo e addestriamo un modello generativo per fare l'aumento dei dati. Il modello, basato su reti generative adversariali condizionali di immagini, prende i dati da un dominio di origine e impara a prendere qualsiasi elemento di dati e generalizzarlo per generare altri elementi di dati all'interno della classe.Poiché questo processo generativo non dipende dalle classi stesse, può essere applicato a nuove classi non viste di dati. Dimostriamo che un Data Augmentation Generative Adversarial Network (DAGAN) aumenta bene i classificatori standard vaniglia e che un DAGAN può migliorare i sistemi di apprendimento a pochi colpi come Matching Networks, dimostrando questi approcci su Omniglot, su EMNIST dopo aver imparato il DAGAN su Omniglot e sui dati VGG-Face. Nei nostri esperimenti possiamo vedere oltre il 13% di aumento della precisione negli esperimenti a basso regime di dati in Omniglot (dal 69% all'82%), EMNIST (dal 73,9% al 76%) e VGG-Face (dal 4,5% al 12%); in Matching Networks per Omniglot osserviamo un aumento dello 0,5% (dal 96,9% al 97,4%) e un aumento dell'1,8% in EMNIST (dal 59,5% al 61,3%).
Rispondere alle domande sui dati può richiedere la comprensione di quali parti di un input X influenzano la risposta Y. Trovare tale comprensione può essere costruito testando le relazioni tra le variabili attraverso un modello di apprendimento automatico.Per esempio, i test di randomizzazione condizionale aiutano a determinare se una variabile si riferisce alla risposta dato il resto delle variabili. Noi formalizziamo una classe di statistiche di test appropriate che sono garantite per selezionare una caratteristica quando fornisce informazioni sulla risposta anche quando il resto delle caratteristiche sono note.Mostriamo che le f-divergenze forniscono un'ampia classe di statistiche di test appropriate.Nella classe delle f-divergenze, la KL-divergenza produce una statistica di test appropriata facile da calcolare che si riferisce all'AMI.Domande sull'importanza delle caratteristiche possono essere poste a livello di un campione individuale.  Mostriamo che gli stimatori dello stesso test AMI possono anche essere usati per trovare le caratteristiche importanti in una particolare istanza.Forniamo un esempio per mostrare che i modelli predittivi perfetti sono insufficienti per la selezione delle caratteristiche instance-wise.Valutiamo il nostro metodo su diversi esperimenti di simulazione, su un dataset genomico, un dataset clinico di riammissione ospedaliera, e su un sottoinsieme di classi in ImageNet. Il nostro metodo supera diverse linee di base in vari set di dati simulati, è in grado di identificare geni biologicamente significativi, può selezionare i più importanti predittori di un evento di riammissione ospedaliera, ed è in grado di identificare caratteristiche distintive in un compito di classificazione delle immagini.
L'apprendimento supervisionato dipende da esempi annotati, che sono considerati la verità di base.Ma queste etichette spesso provengono da piattaforme di crowdsourcing rumorose, come Amazon Mechanical Turk.I professionisti raccolgono tipicamente più etichette per esempio e aggregano i risultati per mitigare il rumore (il classico problema del crowdsourcing).Dato un budget fisso per le annotazioni e un numero illimitato di dati non etichettati, l'annotazione ridondante avviene a spese di un minor numero di esempi etichettati.Questo solleva due domande fondamentali: (1) Come possiamo imparare al meglio dai lavoratori rumorosi?(2) Come dovremmo allocare il nostro budget di etichettatura per massimizzare le prestazioni di un classificatore? Proponiamo un nuovo algoritmo per modellare congiuntamente le etichette e la qualità dei lavoratori da dati rumorosi crowd-sourced.La minimizzazione alternata procede a turni, stimando la qualità dei lavoratori dal disaccordo con il modello corrente e quindi aggiornando il modello ottimizzando una funzione di perdita che tiene conto della stima corrente della qualità dei lavoratori. A differenza degli approcci precedenti, anche con una sola annotazione per esempio, il nostro algoritmo può stimare la qualità del lavoratore. Stabiliamo un limite di errore di generalizzazione per i modelli appresi con il nostro algoritmo e stabiliamo teoricamente che è meglio etichettare molti esempi una volta (vs meno moltiplicare) quando la qualità del lavoratore supera una soglia.Gli esperimenti condotti sia su ImageNet (con lavoratori rumorosi simulati) che su MS-COCOCO (usando le vere etichette crowdsourced) confermano i benefici del nostro algoritmo.
Le reti neurali commettono errori e la ragione per cui un errore viene commesso rimane spesso un mistero, per cui le reti neurali sono spesso considerate una scatola nera. Sarebbe utile avere un metodo che possa dare una spiegazione intuitiva all'utente sul perché un'immagine viene classificata male. Il nostro lavoro combina i campi degli esempi avversari, la modellazione generativa e una tecnica di correzione basata sulla propagazione delle differenze di target per creare una tecnica che crea spiegazioni del perché un'immagine è classificata male.In questo articolo spieghiamo il nostro metodo e lo dimostriamo su MNIST e CelebA.Questo approccio potrebbe aiutare a demistificare le reti neurali per un utente.
Nel contesto dell'apprendimento multi-task, le reti neurali con architetture ramificate sono state spesso impiegate per affrontare congiuntamente i compiti a portata di mano. Tali reti ramificate iniziano tipicamente con un certo numero di strati condivisi, dopodiché i diversi compiti si ramificano in una propria sequenza di strati. Comprensibilmente, poiché il numero di possibili configurazioni di rete è combinatoriamente grande, decidere quali strati condividere e dove ramificare diventa ingombrante. I lavori precedenti si sono affidati a metodi ad hoc per determinare il livello di condivisione degli strati, che è subottimale, o hanno utilizzato tecniche di ricerca dell'architettura neurale per stabilire il design della rete, che è notevolmente costoso. Dato un budget specifico, cioè il numero di parametri apprendibili, l'approccio proposto genera architetture in cui gli strati più superficiali sono indipendenti dal compito, mentre quelli più profondi diventano gradualmente più specifici per il compito. Un'ampia analisi sperimentale su numerosi e diversi set di dati multi-tasking mostra che, per un dato budget, il nostro metodo produce costantemente reti con le migliori prestazioni, mentre per una certa soglia di prestazioni richiede la minor quantità di parametri apprendibili.
I tipici progetti recenti di reti neurali sono principalmente strati convoluzionali, ma i trucchi che consentono strati lineari efficienti strutturati (SELL) non sono ancora stati adattati all'impostazione convoluzionale. Presentiamo un metodo per esprimere il tensore dei pesi in uno strato convoluzionale usando matrici diagonali, trasformate coseno discrete (DCT) e permutazioni che possono essere ottimizzate usando i metodi stocastici standard del gradiente.Una rete composta da tali strati convoluzionali efficienti strutturati (SECL) supera le reti esistenti a basso rango e dimostra un'efficienza computazionale competitiva.
La deblurring dei documenti ciechi è un compito fondamentale nel campo dell'elaborazione e del restauro dei documenti, con ampie applicazioni di valorizzazione nei sistemi di riconoscimento ottico dei caratteri, nella medicina legale, ecc. Poiché questo problema è altamente mal posto, i metodi di apprendimento supervisionati e non supervisionati sono adatti per questa applicazione. Tuttavia, queste caratteristiche estratte non sono adatte per le immagini dei documenti.Presentiamo SVDocNet, una rete neurale ricorrente spaziale (RNN) addestrabile end-to-end basata su U-Net per la deblurring cieca dei documenti dove i pesi delle RNN sono determinati da diverse reti neurali convoluzionali (CNNs).Questa rete raggiunge lo stato dell'arte delle prestazioni in termini di misure quantitative e risultati qualitativi.
In contrasto con le architetture profonde monolitiche utilizzate oggi nel deep learning per la visione artificiale, la corteccia visiva elabora le immagini retiniche attraverso due reti funzionalmente distinte ma interconnesse: la via ventrale per elaborare le informazioni relative agli oggetti e la via dorsale per elaborare il movimento e le trasformazioni. Ispirati da questa divisione corticale del lavoro e dalle proprietà dei sistemi magno- e parvocellulari, esploriamo un approccio non supervisionato all'apprendimento delle caratteristiche che impara congiuntamente le caratteristiche dell'oggetto e le loro trasformazioni dai video naturali. Proponiamo un nuovo modello di codifica sparso bilineare convoluzionale che (1) permette trasformazioni indipendenti delle caratteristiche e (2) è capace di elaborare immagini di grandi dimensioni. I nostri risultati mostrano che il nostro modello può imparare gruppi di caratteristiche e le loro trasformazioni direttamente dai video naturali in modo completamente non supervisionato. I "filtri dinamici" appresi mostrano certe proprietà di equivarianza, assomigliano ai filtri spazio-temporali corticali e catturano le statistiche delle transizioni tra i frame video. Il nostro modello può essere visto come uno dei primi approcci per dimostrare l'apprendimento non supervisionato di "capsule" primarie (proposto da Hinton e colleghi per l'apprendimento supervisionato) e ha forti connessioni con l'approccio Lie group alla percezione visiva.
 Gli schemi convenzionali di rilevazione fuori distribuzione (OOD) basati sull'autoencoder variazionale o sulla distillazione a rete casuale (RND) sono noti per assegnare un'incertezza inferiore ai dati OOD rispetto alla distribuzione di destinazione.In questo lavoro, scopriamo che tali schemi convenzionali di rilevazione delle novità sono anche vulnerabili alle immagini sfocate. Sulla base dell'osservazione, costruiamo un nuovo rivelatore OOD basato su RND, SVD-RND, che utilizza immagini sfocate durante la formazione. Il nostro rivelatore è semplice, efficiente nel tempo di prova e supera i rivelatori OOD di base in vari domini. Ulteriori risultati mostrano che SVD-RND impara una migliore rappresentazione della distribuzione di destinazione rispetto alle linee di base.
L'addestramento di grandi reti neurali profonde su insiemi di dati massicci Ã¨ computazionalmente molto challenging.There Ã¨ stato impulso recente nell'interesse nell'uso dei metodi stocastici di ottimizzazione del grande lotto per affrontare questo problema.The piÃ¹ prominente algoritmo in questa linea di ricerca Ã¨ LARS, che da Â impiegando i tassi adattivi di apprendimento di strato allena ResNet su ImageNet in alcuni minuti. Tuttavia, LARS esegue male per i modelli di attenzione come BERT, indicando che i suoi guadagni di prestazioni non sono coerenti attraverso compiti.In questo documento, abbiamo prima studiare una strategia di adattamento layerwise principled per accelerare la formazione di reti neurali profonde utilizzando grandi mini-batch. Usando questa strategia, sviluppiamo una nuova tecnica adattabile layerwise di grande lotto di ottimizzazione chiamata LAMB; allora forniamo l'analisi di convergenza di LAMB cosÃ¬ come LARS, mostrando la convergenza ad un punto stazionario nelle regolazioni non convesse generali. I nostri risultati empirici dimostrano la prestazione superiore di LAMB attraverso le varie mansioni quali BERT e l'addestramento ResNet-50 con molto poco hyperparameter tuning.In particolare, per addestramento di BERT, il nostro ottimizzatore permette l'uso dei formati molto grandi del lotto di 32868 senza alcuna degradazione di prestazione. Aumentando la dimensione del batch al limite di memoria di un TPUv3 Pod, il tempo di addestramento di BERT puÃ² essere ridotto da 3 giorni a soli 76 minuti (Tabella 1).
Il meta-apprendimento modello-agnostico (MAML) Ã¨ conosciuto come un metodo potente di meta-apprendimento. Tuttavia, MAML Ã¨ notorio per essere difficile da addestrare a causa dell'esistenza di due tassi di apprendimento. Pertanto, in questo articolo, deriviamo le condizioni che il tasso di apprendimento interno $\alpha$ e il tasso di meta-apprendimento $\beta$ devono soddisfare affinché MAML converga ai minimi con alcune semplificazioni. Troviamo che il limite superiore di $\beta$ dipende da $ \alpha$, in contrasto con il caso di utilizzo del normale metodo di discesa del gradiente. Inoltre, mostriamo che la soglia di $\beta$ aumenta man mano che $\alpha$ si avvicina al suo limite superiore.Questo risultato è verificato da esperimenti su vari compiti e architetture a pochi scatti; in particolare, eseguiamo la regressione sinusoidale e la classificazione dei dataset Omniglot e MiniImagenet con un perceptron multistrato e una rete neurale convoluzionale. Sulla base di questo risultato, presentiamo una linea guida per determinare i tassi di apprendimento: in primo luogo, cercare il più grande possibile $\alfa$; successivamente, sintonizzare $\beta$ in base al valore scelto di $\alfa$.
Presentiamo una struttura neurale per l'apprendimento di associazioni tra gruppi di parole interrelate, come quelle che si trovano nelle strutture Soggetto-Verbo-Oggetto (SVO). Il nostro modello induce uno spazio vettoriale di parole specifico per la funzione congiunta, dove i vettori delle composizioni SVO plausibili, ad esempio, sono vicini. Il modello mantiene le informazioni sull'appartenenza al gruppo di parole anche nello spazio congiunto, e può quindi essere efficacemente applicato a un certo numero di compiti che ragionano sulla struttura SVO.Mostriamo la robustezza e la versatilità del quadro proposto riportando risultati allo stato dell'arte sui compiti di stima della preferenza selettiva (cioè, I risultati indicano che le combinazioni di rappresentazioni apprese con il nostro modello indipendente dal compito superano le architetture specifiche del compito del lavoro precedente, riducendo il numero di parametri fino al 95%. Il quadro proposto è versatile e promette di supportare l'apprendimento di rappresentazioni specifiche della funzione oltre le strutture SVO.
La fabbricazione di semiconduttori coinvolge il processo di incisione per rimuovere aree selezionate dai wafer.Tuttavia, la misurazione della struttura incisa nella micro-grafia si basa pesantemente su routine manuali che richiedono tempo.L'elaborazione tradizionale delle immagini di solito richiede un gran numero di dati annotati e le prestazioni sono ancora scarse.Trattiamo questa sfida come problema di segmentazione e usiamo un approccio di apprendimento profondo per rilevare le maschere di oggetti nella struttura incisa del wafer.Poi, usiamo l'elaborazione semplice dell'immagine per effettuare la misurazione automatica sugli oggetti. Tentiamo la Generative Adversarial Network (GAN) per generare più dati per superare il problema del dataset molto limitato.Scarichiamo 10 immagini SEM (Scanning Electron Microscope) di 4 tipi da Internet, sulla base delle quali effettuiamo i nostri esperimenti.Il nostro metodo basato sull'apprendimento profondo dimostra la superiorità rispetto all'approccio di elaborazione delle immagini con una precisione media che raggiunge oltre il 96% per le misure, rispetto alla verità di base.Per quanto ne sappiamo, è la prima volta che il deep learning è stato applicato nell'industria dei semiconduttori per la misurazione automatica.
Presentiamo tre metodi per determinare gli intervalli di posizionamento temporali validi per un'attività in un piano temporalmente fondato in presenza di tali vincoli. Introduciamo gli algoritmi Max Duration e Probe che sono validi, ma incompleti, e l'algoritmo Linear che è valido e completo per il consumo di risorse a tasso lineare. Applichiamo queste tecniche al problema della programmazione dei risvegli per un rover planetario in cui le durate dei risvegli sono influenzate dalle attività esistenti e dimostriamo come l'algoritmo Probe si comporta in modo competitivo con l'algoritmo Linear, dato uno spazio problematico vantaggioso e una euristica ben definita. Mostriamo che gli algoritmi Probe e Linear superano empiricamente l'algoritmo Max Duration e poi presentiamo empiricamente le differenze di runtime tra i tre algoritmi. L'algoritmo Probe è attualmente basato sull'uso nello scheduler di bordo del prossimo rover planetario della NASA, il Mars 2020.
Una rappresentazione disentangled di un set di dati dovrebbe essere in grado di recuperare i fattori sottostanti che lo hanno generato.Una questione che si pone è se l'utilizzo dello spazio euclideo per i modelli di variabili latenti può produrre una rappresentazione disentangled quando i fattori generatori sottostanti hanno una certa struttura geometrica.Prendiamo ad esempio le immagini di un'auto vista da diverse angolazioni.L'angolo ha una struttura periodica ma una rappresentazione 1-dimensionale non riuscirebbe a catturare questa topologia. Le proposte presentate per la prima fase del NeurIPS2019 Disentanglement Challenge consistono in un Diffusion Variational Autoencoder ($\Delta$VAE) con uno spazio latente ipersferico che può ad esempio recuperare fattori veri periodici.L'addestramento del $\Delta$VAE è migliorato incorporando una versione modificata dell'Evidence Lower Bound (ELBO) per personalizzare la capacità di codifica dell'approssimazione posteriore.
In questo lavoro, presentiamo una visione unificante e proponiamo un metodo open-set per rilassare gli attuali presupposti di generalizzazione; inoltre, estendiamo l'applicabilità dei metodi basati sulla trasformazione ai dati non-immagine usando trasformazioni affini casuali; il nostro metodo ha dimostrato di ottenere un'accuratezza all'avanguardia ed è applicabile ad ampi tipi di dati; la forte prestazione del nostro metodo è ampiamente convalidata su più set di dati da diversi domini.
I recenti miglioramenti nei modelli linguistici su larga scala hanno guidato il progresso nella generazione automatica di testi sintatticamente e semanticamente coerenti per molte applicazioni del mondo reale.Molti di questi progressi sfruttano la disponibilità di grandi corpora.Mentre l'addestramento su tali corpora incoraggia il modello a comprendere le dipendenze a lungo raggio nel testo, può anche portare i modelli a interiorizzare i bias sociali presenti nei corpora. Questo articolo mira a quantificare e ridurre le distorsioni esibite dai modelli linguistici: dato un contesto condizionante (ad esempio, una richiesta di scrittura) e un modello linguistico, analizziamo se (e come) il sentiment del testo generato è influenzato dai cambiamenti nei valori degli attributi sensibili (ad es. Quantifichiamo queste distorsioni adattando le metriche di equità individuale e di gruppo dalla letteratura sull'apprendimento automatico equo. Un'ampia valutazione su due diversi corpora (articoli di notizie e Wikipedia) mostra che i modelli linguistici allo stato dell'arte basati su Transformer presentano distorsioni apprese dai dati. Proponiamo metodi di regolarizzazione di embedding-similarity e sentiment-similarity che migliorano entrambe le metriche di equità individuale e di gruppo senza sacrificare la perplessità e la similarità semantica--un passo positivo verso lo sviluppo e l'implementazione di modelli linguistici più equi per le applicazioni del mondo reale.
La modellazione dell'argomento dei documenti di testo è uno dei compiti più importanti nell'apprendimento delle rappresentazioni. In questo lavoro, proponiamo iTM-VAE, che è un modello di argomento Bayesiano nonparametrico (BNP) con autocodificatori variazionali. Da un lato, come modello BNP, iTM-VAE ha potenzialmente infiniti argomenti e può adattare automaticamente il numero di argomenti ai dati; dall'altro, diversamente dagli altri modelli BNP, l'inferenza di iTM-VAE è modellata da reti neurali, che hanno una ricca capacità di rappresentazione e possono essere calcolate in un semplice modo feed-forward. Due varianti di iTM-VAE sono anche proposte in questo documento, dove iTM-VAE-Prod modella il processo generativo in modo prodotti-di-esperti per una migliore performance e iTM-VAE-G pone un priore sul parametro di concentrazione in modo che il modello possa adattare automaticamente un parametro di concentrazione adatto ai dati. I risultati sperimentali su 20News e Reuters RCV1-V2 datasets mostrano che i modelli proposti superano lo stato dell'arte in termini di perplessità, coerenza dell'argomento e compiti di recupero dei documenti.
Knowledge Distillation (KD) è una tecnica ampiamente utilizzata nella recente ricerca sull'apprendimento profondo per ottenere modelli piccoli e semplici le cui prestazioni sono alla pari con le loro controparti grandi e complesse.Knowledge Distillation standard tende ad essere dispendioso in termini di tempo a causa del tempo di formazione speso per ottenere un modello di insegnante che dovrebbe poi fornire una guida per il modello studente.Potrebbe essere possibile ridurre il tempo addestrando un modello di insegnante al volo, ma non è banale avere un insegnante ad alta capacità che dia una guida di qualità ai modelli studente in questo modo. Per migliorare questo, presentiamo un nuovo framework di Knowledge Distillation che sfrutta la conoscenza oscura dall'intero set di training.In questo framework, proponiamo un'implementazione semplice ed efficace chiamata Distillation by Utilizing Peer Samples (DUPS) in una generazione.Verifichiamo il nostro algoritmo su numerosi esperimenti.Rispetto al training standard sulle architetture moderne, DUPS raggiunge un miglioramento medio dell'1%-2% su vari compiti con un costo extra quasi nullo.Considerando alcuni metodi tipici di Knowledge Distillation che sono molto più lunghi, otteniamo anche prestazioni paragonabili o addirittura migliori usando DUPS.
Sviluppiamo un approccio di metalearning per l'apprendimento di politiche gerarchicamente strutturate, migliorando l'efficienza del campione su compiti non visti attraverso l'uso di primitive condivise, ovvero politiche che vengono eseguite per un gran numero di timeteps. Abbiamo poi presentato un algoritmo per risolvere questo problema end-to-end attraverso l'uso di qualsiasi metodo di apprendimento di rinforzo off-the-shelf, campionando ripetutamente nuovi compiti e resettando le politiche task-specific.Abbiamo scoperto con successo primitive motorie significative per il movimento direzionale di robot a quattro zampe, solo interagendo con distribuzioni di labirinti.Dimostriamo anche la trasferibilità delle primitive per risolvere percorsi a ostacoli a lunga scala temporale a ricompensa sparsa, e consentiamo ai robot umanoidi 3D di camminare e strisciare in modo robusto con la stessa politica.
Questo articolo propone un nuovo modello per l'incorporazione dei documenti. Gli approcci esistenti richiedono un'inferenza complessa o usano reti neurali ricorrenti che sono difficili da parallelizzare. Noi prendiamo una strada diversa e usiamo i recenti progressi nella modellazione del linguaggio per sviluppare un modello di incorporazione a rete neurale convoluzionale, il che ci permette di formare architetture più profonde che sono completamente parallelizzabili. Impilare gli strati insieme aumenta il campo ricettivo permettendo ad ogni strato successivo di modellare dipendenze semantiche sempre più lunghe all'interno del documento.Empiricamente dimostriamo risultati superiori su due benchmark pubblicamente disponibili.Il codice completo sarà rilasciato con la versione finale di questo documento.
I limiti sono in termini di perdita di addestramento, il numero di parametri, la costante Lipschitz della perdita e la distanza dai pesi ai pesi iniziali. Sono indipendenti dal numero di pixel nell'input e dall'altezza e dalla larghezza delle mappe di caratteristiche nascoste. Presentiamo esperimenti con CIFAR-10, insieme a variperparametri di una rete convoluzionale profonda, confrontando i nostri limiti con le lacune di generalizzazione pratiche.
La famiglia MobileNets di reti neurali di computer vision ha alimentato un enorme progresso nella progettazione e organizzazione di architetture efficienti dal punto di vista delle risorse negli ultimi anni.Nuove applicazioni con requisiti rigorosi in tempo reale in dispositivi altamente vincolati richiedono un'ulteriore compressione delle reti MobileNets-like già computeefficient. La quantizzazione del modello è una tecnica ampiamente utilizzata per comprimere e accelerare l'inferenza delle reti neurali e i lavori precedenti hanno quantizzato le reti mobili a 4 ¤ 6 bit, anche se con un calo da modesto a significativo nella precisione. Mentre la quantizzazione a valori sub-byte (cioè precisione ¤ 8 bit) è stato prezioso, ancora ulteriore quantizzazione di reti mobili a valori binari o ternari è necessario per realizzare risparmi energetici significativi e possibilmente accelerazione di runtime su hardware specializzato, come ASICs e FPGAs. Sotto l'osservazione chiave che i filtri convoluzionali in ogni strato di una rete neurale profonda possono rispondere in modo diverso alla quantizzazione ternaria, proponiamo un nuovo metodo di quantizzazione che genera banchi di filtri ibridi per strato costituiti da filtri a precisione completa e a peso ternario per MobileNets. Usando questo metodo di quantizzazione proposto, abbiamo quantizzato una parte sostanziale dei filtri di peso delle reti mobili a valori ternari, ottenendo un risparmio energetico del 27,98% e una riduzione del 51,07% delle dimensioni del modello, pur ottenendo una precisione comparabile e nessuna degradazione del throughput su hardware specializzato rispetto alle reti mobili di base a precisione completa.
Eseguire esperimenti controllati su dati rumorosi è essenziale per comprendere a fondo l'apprendimento profondo attraverso uno spettro di livelli di rumore.A causa della mancanza di set di dati adatti, la ricerca precedente ha esaminato solo l'apprendimento profondo sul rumore sintetico controllato, e il rumore del mondo reale non è mai stato studiato sistematicamente in un ambiente controllato.A tal fine, questo documento stabilisce un benchmark di etichette rumorose del mondo reale a 10 livelli di rumore controllato.Poiché il rumore del mondo reale possiede proprietà uniche, per capire la differenza, conduciamo uno studio su larga scala attraverso una varietà di livelli e tipi di rumore, architetture, metodi e impostazioni di formazione.Il nostro studio mostra che: (1) Le reti neurali profonde (DNN) generalizzano molto meglio sul rumore del mondo reale.(2) Le DNN potrebbero non imparare prima i modelli sui dati rumorosi del mondo reale.(3) Quando le reti sono messe a punto, le architetture ImageNet generalizzano bene sui dati rumorosi. (4) Il rumore del mondo reale sembra essere meno dannoso, ma è più difficile da migliorare per i metodi DNN robusti.(5) I metodi di apprendimento robusti che funzionano bene sul rumore sintetico possono non funzionare altrettanto bene sul rumore del mondo reale, e viceversa.
La progettazione di molecole di RNA ha suscitato un interesse recente in medicina, biologia sintetica, biotecnologia e bioinformatica, poiché molte molecole di RNA funzionali hanno dimostrato di essere coinvolte nei processi di regolazione della trascrizione, epigenetica e di traduzione. Poiché la funzione di un RNA dipende dalle sue proprietà strutturali, il problema di RNA Design consiste nel trovare una sequenza di RNA che soddisfi determinati vincoli strutturali. Qui proponiamo un nuovo algoritmo per il problema di RNA Design, chiamato LEARNA.LEARNA utilizza un profondo apprendimento di rinforzo per addestrare una rete politica a progettare sequenzialmente un'intera sequenza di RNA data una specifica struttura target. Con il meta-apprendimento su 65000 diversi compiti di RNA Design per un'ora su 20 core della CPU, la nostra estensione Meta-LEARNA costruisce una politica di RNA Design che può essere applicata out of the box per risolvere nuovi compiti di RNA Design.Metodologicamente, per quella che crediamo essere la prima volta, ottimizziamo congiuntamente su un ricco spazio di architetture per la rete di policy, gli iperparametri della procedura di allenamento e la formulazione del processo di decisione. Risultati empirici completi su due benchmark di RNA Design ampiamente utilizzati, così come un terzo che introduciamo, mostrano che il nostro approccio raggiunge nuove prestazioni allo stato dell'arte sul primo mentre è anche ordini di grandezza più veloce nel raggiungere le precedenti prestazioni allo stato dell'arte.In uno studio di ablazione, analizziamo l'importanza dei diversi componenti del nostro metodo.
La potatura è una tecnica popolare per comprimere una rete neurale: una grande rete pre-addestrata viene messa a punto mentre le connessioni vengono successivamente rimosse.Tuttavia, il valore della potatura ha in gran parte eluso lo scrutinio.In questo abstract esteso, esaminiamo le reti residue ottenute attraverso la potatura di Fisher e facciamo due osservazioni interessanti.Innanzitutto, quando il tempo è limitato, è meglio addestrare una rete semplice e più piccola da zero che potare una grande rete. In secondo luogo, sono le architetture ottenute attraverso il processo di sfrondamento - non i pesi appresi - che si rivelano preziose. Tali architetture sono potenti se addestrate da zero. Inoltre, queste architetture sono facili da approssimare senza ulteriori sfrondamenti: possiamo sfrondare una volta e ottenere una famiglia di nuove architetture di rete scalabili per diversi requisiti di memoria.
Cioè, i lettori umani, guardando gli stessi dati, potrebbero giungere a conclusioni legittime, ma completamente diverse, basate sulle loro esperienze personali. Eppure, nelle impostazioni di apprendimento automatico, il feedback di più annotatori umani è spesso ridotto a una singola etichetta di "verità di base", nascondendo così le vere, potenzialmente ricche e diverse interpretazioni dei dati trovate nello spettro sociale. Un costo importante e critico di questo approccio è il numero di esseri umani necessari per fornire abbastanza etichette non solo per ottenere campioni rappresentativi, ma anche per addestrare una macchina a prevedere distribuzioni rappresentative su dati non etichettati.Proponiamo di aggregare le distribuzioni di etichette su, non solo individui, ma anche elementi di dati, al fine di massimizzare i costi degli esseri umani nel ciclo.Testiamo diversi approcci di aggregazione su modelli di apprendimento profondo all'avanguardia.I nostri risultati suggeriscono che i metodi di aggregazione attenta delle etichette possono ridurre notevolmente il numero di campioni necessari per ottenere distribuzioni rappresentative.
I recenti progressi nelle tecniche di apprendimento profondo come le reti neurali convoluzionali (CNN) e le reti generative adversariali (GAN) hanno raggiunto dei progressi nel problema dell'inpainting semantico delle immagini, il compito di ricostruire i pixel mancanti in immagini date.Mentre sono molto più efficaci degli approcci convenzionali, i modelli di apprendimento profondo richiedono grandi set di dati e grandi risorse computazionali per la formazione, e la qualità dell'inpainting varia notevolmente quando i dati di formazione variano in dimensioni e diversità. Per affrontare questi problemi, presentiamo in questo documento una strategia di inpainting di \textit{Comparative Sample Augmentation}, che migliora la qualità del set di allenamento filtrando le immagini irrilevanti e costruendo immagini aggiuntive utilizzando le informazioni sulle regioni circostanti delle immagini da inpainting.Experiments su più set di dati dimostrano che il nostro metodo estende l'applicabilità dei modelli di inpainting profondo a set di allenamento con dimensioni variabili, mantenendo la qualità di inpainting misurata da metriche qualitative e quantitative per una vasta classe di modelli profondi, con poca necessità di considerazioni specifiche del modello.
Le reti generative avversarie (GAN) sono una famiglia di modelli generativi che non minimizzano un singolo criterio di formazione; a differenza di altri modelli generativi, la distribuzione dei dati viene appresa attraverso un gioco tra un generatore (il modello generativo) e un discriminatore (un insegnante che fornisce il segnale di formazione) che minimizzano ciascuno il proprio costo; le GAN sono progettate per raggiungere un equilibrio Nash in cui ogni giocatore non può ridurre il proprio costo senza cambiare i parametri degli altri giocatori. Un approccio utile per la teoria dei GAN è quello di mostrare che una divergenza tra la distribuzione di addestramento e la distribuzione del modello ottiene il suo valore minimo all'equilibrio. Molte direzioni di ricerca recenti sono state motivate dall'idea che questa divergenza sia la guida primaria per il processo di apprendimento e che ogni passo di apprendimento dovrebbe diminuire la divergenza. Durante l'addestramento GAN, il discriminatore fornisce un segnale di apprendimento in situazioni in cui i gradienti delle divergenze tra le distribuzioni non sarebbero utili.Forniamo controesempi empirici alla visione dell'addestramento GAN come minimizzazione della divergenza.In particolare, dimostriamo che i GAN sono in grado di imparare le distribuzioni in situazioni in cui il punto di vista della minimizzazione della divergenza prevede che fallirebbero. Dimostriamo anche che le penalità di gradiente motivate dalla prospettiva di minimizzazione della divergenza sono ugualmente utili quando applicate in altri contesti in cui la prospettiva di minimizzazione della divergenza non predice che sarebbero utili. Questo contribuisce a un crescente corpo di prove che l'addestramento GAN può essere più utilmente visto come avvicinamento agli equilibri di Nash attraverso traiettorie che non necessariamente minimizzano una divergenza specifica ad ogni passo.
Misurare la Mutua Informazione (MI) tra variabili casuali ad alta dimensione, continue, da campioni osservati ha ampie applicazioni teoriche e pratiche. Lavori recenti hanno sviluppato stimatori MI accurati attraverso approssimazioni provatamente low-bias e stretti limiti inferiori variazionali assumendo un'abbondante fornitura di campioni, ma richiedono un numero non realistico di campioni per garantire la significatività statistica della stima. In questo lavoro, ci concentriamo sul miglioramento dell'efficienza dei dati e proponiamo un Data-Efficient MINE Estimator (DEMINE) che può fornire uno stretto intervallo inferiore sicuro di MI sotto dati limitati, attraverso l'aggiunta di cross-validazione al lower bound di MINE (Belghazi et al, 2018).La ricerca di iperparametri è impiegata e un nuovo approccio di meta-apprendimento con l'aumento dei compiti è sviluppato per aumentare la robustezza agli iperparametri, ridurre l'overfitting e migliorare la precisione.Con una migliore efficienza dei dati, il nostro stimatore DEMINE consente di testare statisticamente la dipendenza a dimensioni pratiche del dataset.Dimostriamo l'efficacia di DEMINE su benchmark sintetici e un dataset fMRI del mondo reale, con applicazione di analisi di correlazione inter-soggetto.
Il linguaggio e la visione sono trattati come due diversi modali nel lavoro attuale per la didascalia delle immagini.Tuttavia, il recente lavoro sul metodo Super Characters mostra l'efficacia dell'incorporazione di parole bidimensionali, che converte il problema di classificazione del testo in un problema di classificazione dell'immagine. In questo articolo, proponiamo il metodo SuperCaptioning, che prende in prestito l'idea del word embedding bidimensionale dal metodo Super Characters, ed elabora le informazioni del linguaggio e della visione insieme in un unico modello CNN.I risultati sperimentali su dati Flickr30k mostrano che il metodo proposto fornisce didascalie di immagini di alta qualità.Una demo interattiva è pronta per essere mostrata al workshop.
Determinare l'ordine ottimale in cui gli esempi di dati sono presentati alle reti neurali profonde durante l'addestramento è un problema non banale, ma scegliere un metodo di programmazione non banale può migliorare drasticamente la convergenza. Il nostro metodo parametrizza dinamicamente i mini-batch in base alla facilità e alla vera diversità del campione all'interno di uno spazio di rappresentazione delle caratteristiche salienti. Convolutional Neural Network (CNN) per imparare uno spazio di rappresentazione espressivo attraverso la discriminazione adattiva della densità usando la perdita di magnete. Il classificatore CNN seleziona dinamicamente i campioni per formare un mini-batch basato sulla "facilità" delle perdite di cross-entropia e sulla "vera diversità" degli esempi dallo spazio di rappresentazione scolpito dalla CNN. Valutiamo LEAP usando architetture CNN profonde per il compito di classificazione supervisionata delle immagini su MNIST, FashionMNIST, CIFAR-10, CIFAR-100, e SVHN.Mostriamo che la struttura LEAP converge più velocemente rispetto al numero di aggiornamenti mini-batch richiesti per raggiungere una performance di test comparabile o migliore su ciascuno dei set di dati.
L'apprendimento di rinforzo profondo convenzionale determina tipicamente un'azione primitiva appropriata ad ogni passo temporale, il che richiede un'enorme quantità di tempo e di sforzo per l'apprendimento di una politica efficace, specialmente in ambienti grandi e complessi.Per affrontare il problema in modo fondamentale, incorporiamo le macro azioni, definite come sequenze di azioni primitive, nello spazio di azione primitiva per formare uno spazio di azione aumentato.Il problema sta nel come trovare una macro azione appropriata per aumentare lo spazio di azione primitiva.  L'agente che usa uno spazio d'azione aumentato appropriato è in grado di saltare a uno stato più lontano e quindi di accelerare il processo di esplorazione e facilitare la procedura di apprendimento.Nelle ricerche precedenti, le macro azioni sono sviluppate estraendo le sequenze di azioni più frequentemente usate o ripetendo le azioni precedenti. Tuttavia, le sequenze di azioni più frequentemente usate sono estratte da una politica passata, che può solo rinforzare il comportamento originale di quella politica.D'altra parte, ripetere le azioni può limitare la diversità dei comportamenti dell'agente.Invece, noi proponiamo di costruire le macro azioni tramite un algoritmo genetico, che elimina la dipendenza della procedura di derivazione delle macro azioni dalle politiche passate dell'agente.  Il nostro approccio aggiunge una macroazione allo spazio d'azione primitivo una volta alla volta e valuta se lo spazio d'azione aumentato porta a prestazioni promettenti o meno.   Eseguiamo ampi esperimenti e dimostriamo che le macro azioni costruite sono in grado di accelerare il processo di apprendimento per una varietà di metodi di apprendimento di rinforzo profondo.I nostri risultati sperimentali dimostrano anche che le macro azioni suggerite dal nostro approccio sono trasferibili tra metodi di apprendimento di rinforzo profondo e ambienti simili.Forniamo inoltre un set completo di analisi di ablazione per convalidare la nostra metodologia.
Un problema chiave nelle neuroscienze e nelle scienze della vita più in generale è che il processo di generazione dei dati è spesso meglio pensato come una gerarchia di sistemi dinamici.Un esempio di questo è in-vivo calcium imaging dati, dove osservati transitori di calcio sono guidati da una combinazione di cinetica elettrochimica dove ipotizzato traiettorie intorno a collettori che determinano la frequenza di questi transienti. Un recente approccio utilizzando autocodificatori variazionali sequenziali ha dimostrato che era possibile imparare la struttura dinamica latente del comportamento di raggiungimento dai dati di spike modellati come un processo di Poisson. Qui estendiamo questo approccio utilizzando un metodo ladder per dedurre gli eventi di spike che guidano i transienti di calcio insieme al sistema dinamico latente più profondo.
Nonostante il recente successo della traduzione automatica neurale (NMT) nei benchmark standard, la mancanza di grandi corpora paralleli pone un grande problema pratico per molte coppie di lingue. Ci sono state diverse proposte per alleviare questo problema con, per esempio, la triangolazione e le tecniche di apprendimento semi-supervisionato, ma richiedono ancora un forte segnale interlinguistico. In questo lavoro, eliminiamo completamente la necessità di dati paralleli e proponiamo un nuovo metodo per formare un sistema NMT in modo completamente non supervisionato, basandoci solo su corpora monolingue. Il nostro modello si basa sul recente lavoro sulle mappature di embedding non supervisionate, e consiste in un modello di codifica-decodifica attenzionale leggermente modificato che può essere addestrato solo su corpora monolingue usando una combinazione di denoising e backtranslation.Nonostante la semplicità dell'approccio, il nostro sistema ottiene 15. 56 e 10,21 punti BLEU nella traduzione da francese a inglese e da tedesco a inglese WMT 2014.Il modello può anche trarre vantaggio da piccoli corpora paralleli, e raggiunge 21,81 e 15,24 punti quando è combinato con 100.000 frasi parallele, rispettivamente.La nostra implementazione è rilasciata come progetto open source.
Descriviamo una nuova metodologia di addestramento per le reti generative avversarie.L'idea chiave è di far crescere progressivamente sia il generatore che il discriminatore: partendo da una bassa risoluzione, aggiungiamo nuovi strati che modellano dettagli sempre più fini man mano che l'addestramento procede.Questo accelera sia l'addestramento che lo stabilizza notevolmente, permettendoci di produrre immagini di qualità senza precedenti, ad es, CelebA a 1024^2.Proponiamo anche un modo semplice per aumentare la variazione nelle immagini generate, e raggiungiamo un punteggio di inizio record di 8.80 in CIFAR10 non supervisionato.Inoltre, descriviamo diversi dettagli di implementazione che sono importanti per scoraggiare la concorrenza malsana tra il generatore e il discriminatore.Infine, suggeriamo una nuova metrica per valutare i risultati GAN, sia in termini di qualità dell'immagine che di variazione.Come ulteriore contributo, costruiamo una versione di qualità superiore del dataset CelebA.
Progettare una convoluzione per una rete neurale sferica richiede un delicato compromesso tra efficienza ed equivarianza di rotazione.DeepSphere, un metodo basato su una rappresentazione grafica della sfera discretizzata, trova un equilibrio controllabile tra questi due desiderata.Questo contributo è duplice. In primo luogo, studiamo sia teoricamente che empiricamente come l'equivarianza è influenzata dal grafico sottostante rispetto al numero di pixel e di vicini.In secondo luogo, valutiamo DeepSphere su problemi rilevanti.Gli esperimenti mostrano prestazioni allo stato dell'arte e dimostrano l'efficienza e la flessibilità di questa formulazione.Forse sorprendentemente, il confronto con il lavoro precedente suggerisce che i filtri anisotropi potrebbero essere un prezzo non necessario da pagare.
La nozione di insieme di equilibrio stazionario ha giocato un ruolo centrale nella meccanica statistica.Nell'apprendimento automatico pure, l'addestramento serve come equilibrio generalizzato che guida la distribuzione di probabilità dei parametri del modello verso la stazionarietà.Qui, deriviamo le relazioni stazionarie di fluttuazione-dissipazione che collegano le quantità misurabili e gli iperparametri nell'algoritmo di discesa del gradiente stocastico. Queste relazioni tengono esattamente per qualsiasi stato stazionario e possono in particolare essere utilizzate per impostare in modo adattivo il programma di addestramento. Possiamo inoltre utilizzare le relazioni per estrarre in modo efficiente le informazioni relative a un paesaggio della funzione di perdita, come le grandezze della sua Hessiana e l'anarmonicità.
Le reti neurali ricorrenti (RNN) sono difficili da addestrare su compiti di elaborazione di sequenze, non solo perché il rumore in ingresso può essere amplificato attraverso il feedback, ma anche perché qualsiasi imprecisione nei pesi ha conseguenze simili al rumore in ingresso. Descriviamo un metodo per denoising dello stato nascosto durante l'addestramento per ottenere rappresentazioni più robuste migliorando così le prestazioni di generalizzazione. Questa rete neurale ricorrente state-denoised (SDRNN) esegue più passi di elaborazione interna per ogni passo di sequenza esterna.Su una serie di compiti, mostriamo che la SDRNN supera una RNN generica così come una variante della SDRNN con dinamiche attrattive sullo stato nascosto ma senza la perdita ausiliaria. Sosteniamo che le dinamiche attrattive - e i corrispondenti vincoli di connettività - sono una componente essenziale dell'arsenale dell'apprendimento profondo e dovrebbero essere invocati non solo per le reti ricorrenti ma anche per migliorare le reti feedforward profonde e il trasferimento intertask.
Consideriamo l'apprendimento di rinforzo in ambienti guidati dall'input, dove un processo di input esogeno e stocastico influenza la dinamica del sistema. I processi di input si presentano in molte applicazioni, compresi i sistemi di coda, il controllo della robotica con disturbi e l'inseguimento degli oggetti, poiché la dinamica dello stato e i premi dipendono dal processo di input, lo stato da solo fornisce informazioni limitate per i rendimenti futuri attesi. I nostri risultati sperimentali mostrano che in ambienti che vanno dai sistemi di accodamento, alle reti di computer e alla locomozione robotica MuJoCo, le linee di base dipendenti dall'input migliorano costantemente la stabilità dell'addestramento e portano a migliori politiche finali.
Le reti profonde hanno mostrato grandi prestazioni nei compiti di classificazione.Tuttavia, i parametri appresi dalle reti classificatrici di solito scartano le informazioni stilistiche dell'input, a favore delle informazioni strettamente rilevanti per la classificazione.Introduciamo una rete che ha la capacità di fare sia la classificazione che la ricostruzione aggiungendo una "memoria di stile" allo strato di uscita della rete. La capacità generativa della nostra rete dimostra che la combinazione di neuroni con memoria di stile e neuroni classificatori produce buone ricostruzioni degli input quando la classificazione è corretta.
I modelli di routing, una forma di calcolo condizionale in cui gli esempi sono instradati attraverso un sottoinsieme di componenti in una rete più grande, hanno mostrato risultati promettenti in lavori recenti. Sorprendentemente, i modelli di routing fino ad oggi hanno mancato di proprietà importanti, come la diversità architettonica e un gran numero di decisioni di routing. Nei nostri esperimenti, troviamo che l'aggiunta della diversità architettonica ai modelli di routing migliora significativamente le prestazioni, tagliando i tassi di errore di una linea di base forte del 35% su una configurazione Omniglot.Tuttavia, quando si scala la profondità di routing, troviamo che le moderne tecniche di routing lottano con l'ottimizzazione.Concludiamo discutendo i risultati positivi e negativi, e suggeriamo direzioni per la ricerca futura.
In numerose applicazioni, le previsioni si basano su solutori numerici per le equazioni differenziali parziali (PDE). Sebbene sia stato proposto l'uso di tecniche di apprendimento profondo, gli usi sono stati limitati dal fatto che i dati di addestramento sono ottenuti utilizzando solutori PDE, quindi gli usi sono stati limitati a domini in cui il solutore PDE era applicabile, ma non oltre. Presentiamo metodi per l'addestramento su piccoli domini, mentre applichiamo i modelli addestrati su domini più grandi, con vincoli di coerenza che assicurano che le soluzioni siano fisicamente significative anche al confine dei piccoli domini.dimostriamo i risultati su un modello di previsione dell'inquinamento atmosferico per Dublino, Irlanda.
Affrontiamo la questione del comportamento dei limiti ciclici nell'addestramento delle Reti Generative Adversariali e proponiamo l'uso di Optimistic Mirror Decent (OMD) per l'addestramento di Wasserstein GANs.Recenti risultati teorici hanno dimostrato che optimistic mirror decent (OMD) può godere di tassi di rammarico più veloci nel contesto dei giochi a somma zero.WGANs è esattamente un contesto di risoluzione di un gioco a somma zero con dinamiche simultanee no-regret.  Mostriamo formalmente che nel caso di giochi bi-lineari a somma zero l'ultimo iterato della dinamica OMD converge a un equilibrio, in contrasto con la dinamica GD che è vincolata al ciclo. Mostriamo anche l'enorme differenza qualitativa tra la dinamica GD e OMD con esempi giocattolo, anche quando GD è modificata con molti adattamenti proposti nella letteratura recente, come la penalità di gradiente o il momentum. Applichiamo l'addestramento OMD WGAN a un problema bioinformatico di generazione di sequenze di DNA e osserviamo che i modelli addestrati con OMD raggiungono una divergenza KL costantemente più piccola rispetto alla vera distribuzione sottostante, rispetto ai modelli addestrati con le varianti GD. Infine, introduciamo un nuovo algoritmo, Optimistic Adam, che è una variante ottimistica di Adam.
L'apprendimento di buone rappresentazioni degli utenti e degli oggetti è di fondamentale importanza per la raccomandazione con feedback implicito. La fattorizzazione della matrice è l'idea di base per derivare le rappresentazioni degli utenti e degli oggetti decomponendo la matrice di interazione data. Tuttavia, gli approcci esistenti basati sulla fattorizzazione della matrice condividono la limitazione che l'interazione tra l'incorporazione dell'utente e l'incorporazione dell'oggetto è solo debolmente applicata adattando il valore di valutazione individuale dato, che può perdere informazioni potenzialmente utili. In questo articolo, proponiamo un nuovo approccio di Augmented Generalized Matrix Factorization (AGMF) che è in grado di incorporare le informazioni sull'interazione storica di utenti e oggetti per l'apprendimento di rappresentazioni efficaci di utenti e oggetti. Nonostante la semplicità del nostro approccio proposto, ampi esperimenti su quattro set di dati pubblici di feedback impliciti dimostrano che il nostro approccio supera le controparti allo stato dell'arte. Inoltre, lo studio di ablazione dimostra che utilizzando la codifica multi-caldo per arricchire l'incorporazione di utenti e oggetti per la Generalized Matrix Factorization, si possono ottenere prestazioni migliori, una convergenza più veloce e una perdita di formazione inferiore.
Proponiamo un metodo non supervisionato per la costruzione di rappresentazioni dinamiche di dati sequenziali, in particolare di interazioni osservate.Il metodo acquisisce simultaneamente le rappresentazioni dei dati di input e le sue dinamiche.Si basa su un modello generativo gerarchico composto da due livelli.Nel primo livello, un modello impara rappresentazioni per generare dati osservati.Nel secondo livello, gli stati di rappresentazione codificano le dinamiche di quello inferiore.Il modello è progettato come una rete bayesiana con variabili di commutazione rappresentate nel livello superiore, e che genera modelli di transizione. Il metodo esplora attivamente lo spazio latente guidato dalla sua conoscenza e dall'incertezza su di esso.Questo si ottiene aggiornando le variabili latenti dai segnali di errore di predizione retropropagati nello spazio latente.Quindi, nessun codificatore o modelli di inferenza sono usati poiché i generatori servono anche come loro trasformazioni inverse.Il metodo è valutato in due scenari, con immagini statiche e con video.I risultati mostrano che l'adattamento nel tempo porta a prestazioni migliori che con architetture simili senza dipendenze temporali, es, Con i video, si dimostra che il sistema estrae la dinamica dei dati in stati che sono altamente correlati con la verità di base delle azioni osservate.
L'attivazione è una funzione di non linearità che gioca un ruolo predominante nella convergenza e nelle prestazioni delle reti neurali profonde.Mentre Rectified Linear Unit (ReLU) è la funzione di attivazione di maggior successo, i suoi derivati hanno mostrato prestazioni superiori su set di dati di riferimento.In questo lavoro, esploriamo i polinomi come funzioni di attivazione (ordine ¥ 2) che possono approssimare una funzione continua di valore reale entro un dato intervallo.Sfruttando questa proprietà, l'idea principale è di imparare la non linearità, accettando che la funzione risultante possa non essere monotona. Pur avendo la capacità di imparare la non linearità più adatta, non possiamo ignorare il fatto che è una sfida ottenere prestazioni stabili a causa dei gradienti che esplodono - che è prominente con l'aumento dell'ordine.Per gestire questo problema, introduciamo un input scaling dinamico, un output scaling e un tasso di apprendimento inferiore per i pesi polinomiali.Inoltre, un tasso di apprendimento inferiore controllerà le brusche fluttuazioni dei polinomi tra gli aggiornamenti dei pesi.Negli esperimenti su tre set di dati pubblici, il nostro metodo proposto corrisponde alle prestazioni delle funzioni di attivazione precedenti, fornendo così una visione della preferenza della non linearità della rete.
Introduciamo CBF, un metodo di esplorazione che funziona in assenza di ricompense o del segnale di fine episodio.CBF si basa sulla ricompensa intrinseca derivata dall'errore di un modello dinamico che opera nello spazio delle caratteristiche.È stato ispirato da (Pathak et al., 2017), è facile da implementare, e può raggiungere risultati come il superamento di quattro livelli di Super Mario Bros, la navigazione dei labirinti di VizDoom e il superamento di due livelli di SpaceInvaders.Abbiamo studiato l'effetto della combinazione del metodo con diversi compiti ausiliari, ma troviamo miglioramenti inconsistenti rispetto alla linea base CBF.
Questo articolo si occupa della robustezza dei VAE agli attacchi avversari.Evidenziamo che i VAE convenzionali sono fragili sotto attacco, ma che i metodi recentemente introdotti per il disentanglement come Î²-TCVAE (Chen et al., 2018) migliorano la robustezza, come dimostrato attraverso una varietà di attacchi avversari precedentemente proposti (Tabacof et al. (2016); Gondim-Ribeiro et al. (2018); Kos et al.(2018)).Questo ci ha motivato a sviluppare Seatbelt-VAE, un nuovo VAE gerarchico disentangled che è progettato per essere significativamente più robusto agli attacchi avversari rispetto agli approcci esistenti, pur mantenendo ricostruzioni di alta qualità.
L'algoritmo di backpropagation è lo standard de-facto per l'assegnazione dei crediti nelle reti neurali artificiali grazie ai suoi risultati empirici.Dalla sua concezione, sono emerse varianti dell'algoritmo di backpropagation.Più specificamente, varianti che sfruttano i cambiamenti di funzione nelle equazioni di backpropagation per soddisfare i loro requisiti specifici.Feedback Alignment è uno di questi esempi, che sostituisce la matrice di trasposizione del peso nelle equazioni di backpropagation con una matrice casuale alla ricerca di un algoritmo di assegnazione dei crediti più biologicamente plausibile. In questo lavoro, dimostriamo che i cambiamenti di funzione nella procedura di backpropagation è equivalente all'aggiunta di un tasso di apprendimento implicito a una rete neurale artificiale.Inoltre, impariamo le derivate della funzione di attivazione nelle equazioni di backpropagation per dimostrare la convergenza anticipata in queste reti neurali artificiali.Il nostro lavoro riporta prestazioni competitive con convergenza anticipata su MNIST e CIFAR10 su architetture di rete neurale profonda sufficientemente grandi.
I sistemi di trasferimento di stile vengono valutati in base alla loro capacità di generare frasi che1) possiedono lo stile di destinazione, 2) sono fluenti e dal suono naturale, e3) conservano le parti non stilistiche (contenuto) della frase di origine. Il nostro approccio non tenta di separare lo stile e il contenuto, e sfrutta la potenza dei modelli linguistici massicciamente pre-addestrati, così come il Transformer. Il nostro sistema supera significativamente i sistemi esistenti allo stato dell'arte, basati su valutazioni umane e automatiche su stile, fluidità e conservazione del contenuto, così come sul successo complessivo del trasferimento di stile, su una varietà di set di dati.
Nonostante il successo delle Generative Adversarial Networks (GANs) nella sintesi delle immagini, manca una comprensione sufficiente di ciò che le reti hanno imparato all'interno delle rappresentazioni generative profonde e di come le immagini foto-realistiche siano in grado di essere composte da rumori casuali. In questo lavoro, dimostriamo che la gerarchia semantica altamente strutturata emerge dalle rappresentazioni generative come i fattori di variazione per la sintesi delle scene. sondando le rappresentazioni a strati con un ampio set di concetti visivi a diversi livelli di astrazione, siamo in grado di quantificare la causalità tra le attivazioni e la semantica che si verifica nell'immagine in uscita. I risultati qualitativi e quantitativi suggeriscono che le rappresentazioni generative apprese dai GAN sono specializzate per sintetizzare diverse semantiche gerarchiche: i primi strati tendono a determinare il layout spaziale e la configurazione, gli strati intermedi controllano gli oggetti categorici, e gli strati successivi infine rendono gli attributi della scena e lo schema dei colori.
Gli autocodificatori variazionali (VAE) definiti sulla stringa SMILES e sulle rappresentazioni basate su grafici delle molecole promettono di migliorare l'ottimizzazione delle proprietà molecolari, rivoluzionando così l'industria farmaceutica e dei materiali.Tuttavia, questi VAE sono ostacolati dalla natura non unica delle stringhe SMILES e dal costo computazionale delle convoluzioni dei grafici. Per passare in modo efficiente i messaggi lungo tutti i percorsi attraverso il grafo molecolare, codifichiamo più stringhe SMILES di una singola molecola utilizzando un insieme di reti neurali ricorrenti impilate, armonizzando le rappresentazioni nascoste di ogni atomo tra le rappresentazioni SMILES, e usiamo il pooling attenzionale per costruire una rappresentazione latente finale a lunghezza fissa. Decodificando poi un insieme disgiunto di stringhe SMILES della molecola, il nostro All SMILES VAE impara una mappatura quasi bijettiva tra le molecole e le rappresentazioni latenti vicino al sottospazio di massa ad alta probabilità del priore.Le nostre rappresentazioni latenti derivate da SMILES ma basate sulla molecola superano significativamente lo stato dell'arte in una varietà di regressione delle proprietà completamente e semi-supervisionata e compiti di ottimizzazione delle proprietà molecolari.
Proponiamo un metodo semplice ma altamente efficace che affronta il problema del mode-collapse nella Conditional Generative Adversarial Network (cGAN).Sebbene le distribuzioni condizionali siano multi-modali (cioè, avere molte modalità) in pratica, la maggior parte degli approcci cGAN tendono ad apprendere una distribuzione troppo semplificata in cui un input è sempre mappato ad un singolo output indipendentemente dalle variazioni del codice latente.Per affrontare tale problema, proponiamo di regolarizzare esplicitamente il generatore per produrre output diversi a seconda dei codici latenti.La regolarizzazione proposta è semplice, generale, e può essere facilmente integrata nella maggior parte degli obiettivi GAN condizionali. Inoltre, la regolarizzazione esplicita sul generatore permette al nostro metodo di controllare un equilibrio tra qualità visiva e diversità.Dimostriamo l'efficacia del nostro metodo su tre compiti di generazione condizionale: traduzione immagine-immagine, inpainting dell'immagine e predizione video futura.Mostriamo che la semplice aggiunta della nostra regolarizzazione ai modelli esistenti porta a generazioni sorprendentemente diverse, superando sostanzialmente i precedenti approcci per la generazione condizionale multimodale specificamente progettata in ogni singolo compito.
Il trasformatore è un modello di traduzione neurale allo stato dell'arte che usa l'attenzione per raffinare iterativamente le rappresentazioni lessicali con informazioni tratte dal contesto circostante.Le caratteristiche lessicali sono alimentate nel primo strato e propagate attraverso una profonda rete di strati nascosti.Noi sosteniamo che la necessità di rappresentare e propagare le caratteristiche lessicali in ogni strato limita la capacità del modello di apprendere e rappresentare altre informazioni rilevanti per il compito.Per alleviare questo collo di bottiglia, introduciamo connessioni gated shortcut tra lo strato di embedding e ogni strato successivo all'interno del codificatore e decoder. Questo permette al modello di accedere al contenuto lessicale rilevante in modo dinamico, senza spendere risorse limitate per memorizzarlo all'interno degli stati intermedi.Mostriamo che la modifica proposta produce miglioramenti coerenti su compiti di traduzione WMT standard e riduce la quantità di informazioni lessicali passate lungo gli strati nascosti.Valutiamo inoltre diversi modi per integrare i collegamenti lessicali nell'architettura del trasformatore e presentiamo esperimenti di ablazione che esplorano l'effetto dei collegamenti proposti sul comportamento del modello.
La stima della densità di probabilità è un problema classico e ben studiato, ma i metodi standard di stima della densità hanno storicamente mancato del potere di modellare distribuzioni di immagini complesse e altamente dimensionali.  Modelli generativi più recenti sfruttano la potenza delle reti neurali per imparare e rappresentare implicitamente modelli di probabilità su immagini complesse.  Descriviamo metodi per estrarre stime esplicite della densità di probabilità dai GAN ed esploriamo le proprietà di queste funzioni di densità dell'immagine.  Eseguiamo esperimenti di controllo di sanità mentale per fornire la prova che queste probabilità sono ragionevoli.  Tuttavia, mostriamo anche che le funzioni di densità delle immagini naturali sono difficili da interpretare e quindi limitate nell'uso.  Studiamo le ragioni di questa mancanza di interpretabilità, e suggeriamo che possiamo ottenere una migliore interpretabilità facendo la stima della densità su rappresentazioni latenti delle immagini.  
Le reti neurali convoluzionali (CNN) sono composte da più strati di convoluzione e mostrano prestazioni eleganti nei compiti di visione.Il design della convoluzione regolare è basato sul campo recettivo (RF) dove le informazioni all'interno di una regione specifica vengono elaborate.Nella visione del RF della convoluzione regolare, le uscite dei neuroni negli strati inferiori con RF più piccolo sono raggruppate per creare neuroni negli strati superiori con RF più grande. Come risultato, i neuroni negli strati alti sono in grado di catturare il contesto globale anche se i neuroni negli strati bassi vedono solo l'informazione locale.Tuttavia, negli strati inferiori del cervello biologico, l'informazione al di fuori della RF cambia le proprietà dei neuroni.In questo lavoro, estendiamo la convoluzione regolare e proponiamo la convoluzione spazialmente mescolata (convoluzione ss). Nella convoluzione ss, la convoluzione regolare è in grado di utilizzare le informazioni al di fuori della sua RF attraverso il rimescolamento spaziale che è un'operazione semplice e leggera.Eseguiamo esperimenti su CIFAR-10 e ImageNet-1k dataset, e dimostriamo che la convoluzione ss migliora le prestazioni di classificazione attraverso varie CNN.
Proponiamo un framework per modellare la distribuzione dei dati sequenziali provenienti da un insieme di entità connesse in un grafo con una topologia nota.Il metodo è basato su una miscela di modelli di Markov nascosti condivisi (HMM), che vengono addestrati per sfruttare la conoscenza della struttura del grafo e in modo tale che le miscele ottenute tendano ad essere sparse.Gli esperimenti in diversi domini applicativi dimostrano l'efficacia e la versatilità del metodo.
Per ottenere alte ricompense in scene di muti-agenti, a volte è necessario capire gli altri agenti e prendere decisioni ottimali corrispondenti.Possiamo risolvere questi compiti costruendo prima modelli per gli altri agenti e poi trovando la politica ottimale con questi modelli.Per ottenere un modello accurato, sono necessarie molte osservazioni e questo può essere inefficiente dal punto di vista del campione.Inoltre, il modello e la politica appresi possono adattarsi troppo agli agenti attuali e non possono generalizzarsi se gli altri agenti sono sostituiti da nuovi agenti. In molte situazioni pratiche, ogni agente che affrontiamo può essere considerato come un campione da una popolazione con una distribuzione fissa ma sconosciuta.Quindi possiamo trattare il compito contro alcuni agenti specifici come un compito campionato da una distribuzione di compiti.Applichiamo il metodo di meta-apprendimento per costruire modelli e imparare politiche.Quindi quando arrivano nuovi agenti, possiamo adattarci a loro in modo efficiente.Gli esperimenti sui giochi a griglia mostrano che il nostro metodo può ottenere rapidamente alte ricompense.
Caratterizziamo i valori singolari della trasformazione lineare associata ad uno strato convoluzionario standard 2D multicanale, permettendo il loro calcolo efficiente.  Questa caratterizzazione porta anche a un algoritmo per proiettare uno strato convoluzionale su una sfera operatore-normale, dimostrando che questo è un regolatore efficace; per esempio, migliora l'errore di test di una rete profonda residuale usando la normalizzazione batch su CIFAR-10 dal 6,2% al 5,3%.
Una politica Bayes-optimale, che lo fa in modo ottimale, condiziona le sue azioni non solo sullo stato dell'ambiente ma anche sull'incertezza dell'agente riguardo all'ambiente. In questo articolo, introduciamo il variational Bayes-Adaptive Deep RL (variBAD), un modo di meta-apprendere per eseguire l'inferenza approssimativa in un ambiente sconosciuto, e incorporare l'incertezza del compito direttamente durante la selezione dell'azione.In un dominio grid-world, illustriamo come variBAD esegue l'esplorazione online strutturata in funzione dell'incertezza del compito.Valutiamo anche variBAD sui domini MuJoCo ampiamente utilizzati in meta-RL e dimostriamo che raggiunge un rendimento più elevato durante l'addestramento rispetto ai metodi esistenti.
In un contesto di apprendimento continuo, nuove categorie possono essere introdotte nel tempo, e un sistema di apprendimento ideale dovrebbe funzionare bene sia sulle categorie originali che su quelle nuove.Mentre le reti neurali profonde hanno ottenuto un successo clamoroso nell'impostazione classica, sono note per dimenticare la conoscenza acquisita in episodi precedenti di apprendimento se gli esempi incontrati nell'episodio corrente di apprendimento sono drasticamente diversi da quelli incontrati negli episodi precedenti. Questo rende le reti neurali profonde poco adatte all'apprendimento continuo. In questo articolo, proponiamo un nuovo modello che può sia sfruttare la potenza espressiva delle reti neurali profonde sia essere resiliente alla dimenticanza quando vengono introdotte nuove categorie, dimostrando un miglioramento in termini di precisione sulle classi originali rispetto a una rete neurale profonda vaniglia.
Le basi di conoscenza biomediche sono cruciali nelle moderne scienze biomediche guidate dai dati, ma la costruzione di basi di conoscenza biomediche auto-mated rimane impegnativa.In questo articolo, consideriamo il problema della normalizzazione delle entità delle malattie, un compito essenziale nella costruzione di una base di conoscenza biomedica.  Presentiamo NormCo, un modello di coerenza profondo che considera la semantica di una menzione di entità, così come la coerenza topica delle menzioni all'interno di un singolo documento.NormCo modella le menzioni di entità usando un semplice modello semantico che compone rappresentazioni di frasi da embeddings di parole, e tratta la coerenza come una sequenza di co-menzioni di concetti di malattia usando una RNN piuttosto che modellare la probabilità congiunta di tutti i concetti in un documento, che richiede un'inferenza NP-hard.  Per superare il problema della scarsità dei dati, abbiamo usato dati supervisionati a distanza e dati sintetici generati da priori derivati dal dataset BioASQ.  I nostri risultati sperimentali mostrano cheNormCo supera i metodi di base dello stato dell'arte su due corpora di normalizzazione delle malattie in termini di (1) qualità della previsione e (2) efficienza, ed è almeno altrettanto performante in termini di accuratezza e punteggio F1 sui documenti con tag.
Esploriamo il ruolo dell'interazione moltiplicativa come quadro unificante per descrivere una serie di motivi architettonici di reti neurali classiche e moderne, come gating, livelli di attenzione, hypernetwork e convoluzioni dinamiche, tra gli altri. Gli strati di interazione moltiplicativa come operazioni primitive hanno una presenza consolidata nella letteratura, anche se questo spesso non viene sottolineato e quindi sottovalutato. Iniziamo mostrando che tali strati arricchiscono strettamente le classi di funzioni rappresentabili delle reti neurali e ipotizziamo che le interazioni moltiplicative offrano un bias induttivo particolarmente potente quando si fondono più flussi di informazioni o quando è richiesta una computazione condizionata. Infine, sosteniamo le nostre affermazioni e dimostriamo il potenziale delle interazioni moltiplicative applicandole in compiti di modellazione di sequenze e RL complessi su larga scala, dove il loro uso ci permette di fornire risultati all'avanguardia, e quindi fornisce nuove prove a sostegno delle interazioni moltiplicative che giocano un ruolo più importante nella progettazione di nuove architetture di reti neurali.
Sviluppare modelli generativi condizionali per la sintesi testo-video è un argomento di ricerca estremamente impegnativo ma importante nell'apprendimento automatico. In questo lavoro, affrontiamo questo problema introducendo Text-Filter conditioning Generative Adversarial Network (TFGAN), un modello GAN con un nuovo schema di condizionamento che aiuta a migliorare le associazioni testo-video. Con una combinazione di questo schema di condizionamento e un'architettura GAN profonda, TFGAN genera video foto-realistici dal testo su set di dati video del mondo reale molto impegnativi. Inoltre, costruiamo un set di dati sintetici di riferimento di forme in movimento per valutare sistematicamente il nostro schema di condizionamento.esperimenti estesi dimostrano che TFGAN supera significativamente gli approcci esistenti, e può anche generare video di nuove categorie non viste durante la formazione.
L'iperparametrizzazione è onnipresente al giorno d'oggi nell'addestramento delle reti neurali per beneficiare sia dell'ottimizzazione nella ricerca di ottimizzazioni globali che della generalizzazione nella riduzione dell'errore di previsione. Tuttavia, le reti compressive sono desiderate in molte applicazioni del mondo reale e l'addestramento diretto di piccole reti può essere intrappolato in ottimizzazioni locali. In questo articolo, invece di sfrondare o distillare i modelli iper-parametrizzati in modelli compressivi, proponiamo un nuovo approccio basato su \emph{inclusioni differenziali di spazi di scala inversi}, che genera una famiglia di modelli da quelli semplici a quelli complessi accoppiando la discesa a gradiente e la discesa a specchio per esplorare la sparsità strutturale del modello. Ha una discretizzazione semplice, chiamata Split Linearized Bregman Iteration (SplitLBI), la cui analisi di convergenza globale nell'apprendimento profondo è stabilita che da qualsiasi inizializzazione, le iterazioni algoritmiche convergono verso un punto critico di rischi empirici, mentre con \emph{arresto anticipato} rivela un'efficace architettura di subnet con accuratezze di test paragonabili ai modelli densi dopo la riqualificazione invece di potare quelli ben addestrati.
In questo articolo, studiamo l'algoritmo di soglia di restringimento iterativo appreso (LISTA) per risolvere problemi di codifica sparsa.  Seguendo le ipotesi fatte dai lavori precedenti, scopriamo prima che le componenti del codice nelle sue stime possono essere più basse del previsto, cioè, richiedono guadagni, e per affrontare questo problema, viene poi introdotto un meccanismo gated suscettibile di analisi teorica.Il design specifico dei gates è ispirato dalle analisi di convergenza del meccanismo e quindi la sua efficacia può essere formalmente garantita.Oltre ai gates di guadagno, introduciamo ulteriormente gates di overshoot per compensare la dimensione insufficiente del passo in LISTA.Estesi risultati empirici confermano i nostri risultati teorici e verificano l'efficacia del nostro metodo.
L'apprendimento di rappresentazioni gerarchiche per la classificazione delle immagini ha sperimentato una serie impressionante di successi dovuti in parte alla disponibilità di dati etichettati su larga scala per l'addestramento.D'altra parte, i classificatori addestrati sono stati tradizionalmente valutati su una manciata di immagini di prova, che si ritiene siano estremamente sparsamente distribuiti nello spazio di tutte le immagini naturali. È quindi discutibile se i recenti miglioramenti delle prestazioni sui set di test eccessivamente riutilizzati siano generalizzabili alle immagini naturali del mondo reale con variazioni di contenuto molto più ricche.Inoltre, gli studi sull'apprendimento avversario mostrano che è facile costruire esempi avversari che ingannano quasi tutti i classificatori di immagini, aggiungendo ulteriori complicazioni al confronto delle prestazioni relative dei modelli esistenti. Questo lavoro presenta un quadro efficiente per confrontare i classificatori di immagini, che chiamiamo la competizione MAximum Discrepancy (MAD). Piuttosto che confrontare i classificatori di immagini su set di test fissi, campioniamo in modo adattivo un set di test da un corpus arbitrariamente grande di immagini non etichettate in modo da massimizzare le discrepanze tra i classificatori, misurate dalla distanza sulla gerarchia WordNet. L'etichettatura umana sui set di immagini risultanti, piccoli e dipendenti dal modello, rivela le prestazioni relative dei classificatori concorrenti e fornisce indicazioni utili sui potenziali modi per migliorarli. Riportiamo i risultati della competizione MAD di undici classificatori ImageNet, notando che il quadro è facilmente estensibile e conveniente per aggiungere futuri classificatori alla competizione.
La robustezza delle reti neurali è stata recentemente evidenziata dagli esempi avversari, cioè, inputs aggiunti con perturbazioni ben progettate che sono impercettibili all'uomo ma possono far sì che la rete dia output errati.In questo articolo, progettiamo una nuova architettura CNN che di per sé ha una buona robustezza.Introduciamo una tecnica semplice ma potente, Random Mask, per modificare le strutture CNN esistenti. Dimostriamo che la CNN con Random Mask raggiunge prestazioni allo stato dell'arte contro gli attacchi black-box adversarial senza applicare alcun training adversarial.Indaghiamo poi gli esempi adversarial che "fregano" una CNN con Random Mask.Surprisingly, troviamo che questi esempi adversarial spesso "fregano" anche gli umani.Questo solleva questioni fondamentali su come definire correttamente gli esempi adversarial e la robustezza.
I metodi di apprendimento profondo supervisionati richiedono set di dati su larga scala etichettati in modo pulito, ma la raccolta di tali dati è difficile e talvolta impossibile. Esistono due quadri popolari per alleviare questo problema: l'apprendimento semi-supervisionato e l'apprendimento robusto al rumore delle etichette. In questo studio, consideriamo l'apprendimento da dati di bi-qualità come una generalizzazione di questi studi, in cui una piccola porzione di dati è etichettata in modo pulito, e il resto è corrotto.In questo quadro, confrontiamo algoritmi recenti per l'apprendimento semi-supervisionato e robusto.I risultati suggeriscono che l'apprendimento semi-supervisionato supera l'apprendimento robusto con etichette rumorose.Proponiamo anche una strategia di formazione per mescolare le tecniche di mixup per imparare da tali dati di bi-qualità in modo efficace.
Hierarchical Sparse Coding (HSC) è un modello potente per rappresentare in modo efficiente dati multidimensionali e strutturati come le immagini. La soluzione più semplice per risolvere questo problema computazionalmente difficile è quella di decomporlo in sottoproblemi indipendenti a strati, ma l'evidenza neuroscientifica suggerisce di interconnettere questi sottoproblemi come nella teoria Predictive Coding (PC), che aggiunge collegamenti top-down tra strati consecutivi. In questo studio, un nuovo modello chiamato Sparse Deep Predictive Coding (SDPC) viene introdotto per valutare l'impatto di questa connessione di feedback inter-strato. In particolare, la SDPC viene confrontata con una rete Hierarchical Lasso (Hi-La) composta da una sequenza di strati Lasso. Una SDPC a 2 strati e una rete Hi-La sono addestrate su 3 diversi database e con diversi parametri di sparsità su ogni strato. In primo luogo, dimostriamo che l'errore generale di predizione generato dalla SDPC è inferiore grazie al meccanismo di feedback che trasferisce l'errore di predizione tra gli strati. In secondo luogo, dimostriamo che la fase di inferenza della SDPC è più veloce a convergere rispetto al modello Hi-La.In terzo luogo, dimostriamo che la SDPC accelera anche il processo di apprendimento.Infine, l'analisi qualitativa dei dizionari di entrambi i modelli, supportata dalla loro probabilità di attivazione, mostra che le caratteristiche della SDPC sono più generiche e informative.
Spiegare un modello di deep learning può aiutare gli utenti a capire il suo comportamento e permettere ai ricercatori di discernere le sue carenze.Il lavoro recente si è concentrato principalmente sulla spiegazione di modelli per compiti come la classificazione delle immagini o la risposta a domande visive.  In questo articolo, introduciamo un approccio di spiegazione per i modelli di somiglianza delle immagini, dove l'output di un modello è un punteggio che misura la somiglianza di due input piuttosto che una classificazione.  In questo compito, una spiegazione dipende da entrambe le immagini di input, quindi i metodi standard non si applicano. Proponiamo un metodo di spiegazione che accoppia una mappa di salienza che identifica le regioni importanti dell'immagine con un attributo che spiega meglio la corrispondenza.  Troviamo che le nostre spiegazioni forniscono informazioni aggiuntive non tipicamente catturate dalle sole mappe di salienza, e possono anche migliorare le prestazioni sul classico compito di riconoscimento degli attributi.La capacità del nostro approccio di generalizzare è dimostrata su due set di dati da domini diversi, Polyvore Outfits e Animals with Attributes 2.
È stato dimostrato che gli esempi avversari sono un modo efficace per valutare la robustezza dei modelli neurali sequenza-sequenza (seq2seq), applicando perturbazioni all'input di un modello che portano a una grande degradazione delle prestazioni, ma queste perturbazioni sono solo indicative di una debolezza del modello se non cambiano la semantica dell'input in modo da modificare l'output previsto. Utilizzando l'esempio della traduzione automatica (MT), proponiamo un nuovo quadro di valutazione per gli attacchi avversari ai modelli seq2seq tenendo conto della conservazione del significato e dimostriamo che i metodi esistenti potrebbero non preservare il significato in generale.Sulla base di questi risultati, proponiamo nuovi vincoli per gli attacchi ai sistemi MT basati sulle parole e dimostriamo, attraverso la valutazione umana e automatica, che producono input avversari semanticamente più simili.Inoltre, dimostriamo che l'esecuzione dell'addestramento avversario con attacchi che preservano il significato è vantaggioso per il modello in termini di robustezza avversaria senza danneggiare le prestazioni dei test.
Introduciamo una nuova tecnica di normalizzazione che esibisce le proprietà di convergenza veloce della normalizzazione in batch utilizzando una trasformazione dei pesi di strato invece degli output di strato.La tecnica proposta mantiene il contributo dei pesi positivi e negativi all'output di strato in equilibrio.Validiamo il nostro metodo su un set di benchmark standard tra cui CIFAR-10/100, SVHN e ILSVRC 2012 ImageNet.
Presentiamo una struttura per la costruzione di rappresentazioni non supervisionate di entità e delle loro composizioni, dove ogni entità è vista come una distribuzione di probabilità piuttosto che un vettore di lunghezza fissa, in particolare, questa distribuzione è supportata sui contesti che co-occorrono con l'entità e sono incorporati in uno spazio bidimensionale adatto. Questo ci permette di considerare il problema dell'apprendimento della rappresentazione con una prospettiva di Trasporto Ottimale e di approfittare dei suoi numerosi strumenti come la distanza di Wasserstein e i baricentri di Wasserstein.Elaboriamo come il metodo può essere applicato per ottenere rappresentazioni non supervisionate del testo e illustriamo le prestazioni quantitativamente e qualitativamente su compiti come la misurazione della similarità delle frasi e l'implicazione delle parole, dove osserviamo empiricamente guadagni significativi (es, I benefici chiave dell'approccio proposto includono:(a) catturare l'incertezza e la polisemia attraverso la modellazione delle entità come distribuzioni,(b) utilizzare la geometria sottostante del particolare compito (con il costo del terreno),(c) fornire simultaneamente l'interpretabilità con la nozione di trasporto ottimale tra i contesti e(d) la facile applicabilità sopra i metodi esistenti di incorporazione dei punti. In sostanza, il framework può essere utile per qualsiasi problema non supervisionato o supervisionato (su testo o altre modalità); e richiede solo una struttura di co-occorrenze inerente a molti problemi. Il codice, così come gli istogrammi precostruiti, sono disponibili sotto https://github.com/context-mover.
    Negli ultimi anni, il fenomeno degli esempi avversari - input costruiti maliziosamente che ingannano i modelli di apprendimento automatico - ha catturato l'attenzione della comunità di ricerca, specialmente quando l'avversario si limita a fare piccole modifiche di un input gestito correttamente. Allo stesso tempo, meno sorprendentemente, i classificatori di immagini mancano di prestazioni di livello umano su immagini casualmente corrotte, come le immagini con rumore gaussiano additivo.In questo lavoro, mostriamo che queste sono due manifestazioni dello stesso fenomeno sottostante.Stabiliamo questa connessione in diversi modi.Innanzitutto, troviamo che gli esempi avversari esistono alle stesse scale di distanza che ci aspetteremmo da un modello lineare con le stesse prestazioni su immagini corrotte. Infine, presentiamo un limite superiore indipendente dal modello sulla distanza da un'immagine corrotta al suo errore più vicino data la performance del test e mostriamo che in pratica siamo già vicini a raggiungere il limite, così che migliorare ulteriormente la robustezza per la distribuzione dell'immagine corrotta richiede una riduzione significativa dell'errore del test. Tutto ciò suggerisce che il miglioramento della robustezza avversaria dovrebbe andare di pari passo con il miglioramento delle prestazioni in presenza di corruzioni d'immagine più generali e realistiche, il che produce una metrica di valutazione computazionalmente trattabile per le difese da considerare: l'errore di prova nelle distribuzioni d'immagine rumorose.
I recenti sviluppi nelle rappresentazioni del linguaggio naturale sono stati accompagnati da modelli grandi e costosi che sfruttano grandi quantità di testo di dominio generale attraverso il pre-training auto-supervisionato.A causa del costo dell'applicazione di tali modelli ai compiti a valle, sono state proposte diverse tecniche di compressione del modello su rappresentazioni linguistiche pre-trainate (Sun et al, 2019; Sanh, 2019).Tuttavia, sorprendentemente, la semplice linea di base di solo pre-addestramento e fine-tuning dei modelli compatti è stata trascurata.In questo documento, dimostriamo innanzitutto che il pre-addestramento rimane importante nel contesto delle architetture più piccole, e il fine-tuning dei modelli compatti pre-addestrati può essere competitivo con i metodi più elaborati proposti nel lavoro concorrente.Partendo da modelli compatti pre-addestrati, esploriamo quindi il trasferimento della conoscenza delle attività da grandi modelli fine-tuned attraverso la distillazione della conoscenza standard. Il risultante algoritmo semplice, ma efficace e generale, Pre-trained Distillation, porta ulteriori miglioramenti.Attraverso ampi esperimenti, esploriamo più in generale l'interazione tra pre-addestramento e distillazione sotto due variabili che sono state poco studiate: la dimensione del modello e le proprietà dei dati di attività non etichettati.Un'osservazione sorprendente è che hanno un effetto composto anche quando applicato sequenzialmente sugli stessi dati.Per accelerare la ricerca futura, faremo i nostri 24 modelli BERT in miniatura pre-addestrati pubblicamente disponibili.
Mentre il lavoro precedente ha affrontato la quantizzazione scalare non universale e la codifica dell'entropia dei pesi DNN, noi per la prima volta introduciamo la compressione DNN universale tramite la quantizzazione vettoriale universale e la codifica universale delle fonti. In particolare, esaminiamo la quantizzazione reticolare randomizzata universale delle DNN, che randomizza i pesi DNN con un dithering casuale uniforme prima della quantizzazione reticolare e può essere eseguita in modo quasi ottimale su qualsiasi sorgente senza basarsi sulla conoscenza della sua distribuzione di probabilità. I nostri risultati sperimentali mostrano che lo schema di compressione DNN universale proposto comprime il ResNet a 32 strati (addestrato su CIFAR-10) e l'AlexNet (addestrato su ImageNet) con rapporti di compressione di 47,1$ e 42,5$, rispettivamente.
Cosa verrebbe appreso dal variational autoencoder (VAE) e cosa influenza il disentanglement di VAE? Questo articolo cerca di affrontare preliminarmente la dimensione intrinseca di VAE, il fattore reale, il disentanglement e i problemi di indicatore teoricamente nella situazione idealistica e il problema di implementazione praticamente attraverso la prospettiva di modellazione del rumore nel caso realistico.  Sulla questione della dimensione intrinseca, a causa della conservazione dell'informazione, il VAE idealistico impara e impara solo la dimensione intrinseca del fattore.Inoltre, suggerito dalla proprietà di separazione dell'informazione reciproca, il vincolo indotto dalla Gaussiana prima dell'obiettivo VAE incoraggia la sparsità dell'informazione nella dimensione.Sulla questione del disentanglement, successivamente, ispirato dal teorema di conservazione dell'informazione, il chiarimento sul disentanglement in questo articolo è fatto.Sulla questione del fattore reale, a causa dell'equivalenza del fattore, il VAE idealistico impara possibilmente qualsiasi fattore impostato nella classe di equivalenza.  Sulla questione dell'indicatore, il comportamento della metrica di disentanglement corrente è discusso, e diversi indicatori di performance riguardanti il disentanglement e l'influenza generatrice sono successivamente sollevati per valutare la performance del modello VAE e per supervisionare i fattori usati.Sulla questione dell'implementazione, gli esperimenti sotto la modellazione del rumore e i vincoli testimoniano empiricamente l'analisi teorica e mostrano anche la loro caratteristica nel perseguire il disentanglement.
Il decadimento dei pesi è uno dei trucchi standard nella cassetta degli attrezzi delle reti neurali, ma le ragioni del suo effetto di regolarizzazione sono poco conosciute, e i risultati recenti hanno messo in dubbio la tradizionale interpretazione in termini di regolarizzazione $L_2$. Indaghiamo empiricamente il decadimento dei pesi per tre algoritmi di ottimizzazione (SGD, Adam e K-FAC) e una varietà di architetture di rete, identificando tre meccanismi distinti attraverso i quali il decadimento dei pesi esercita un effetto di regolarizzazione, a seconda del particolare algoritmo di ottimizzazione e dell'architettura: (1) aumentando il tasso di apprendimento effettivo, (2) regolarizzando approssimativamente la norma Jacobiana input-output, e (3) riducendo il coefficiente di smorzamento effettivo per l'ottimizzazione del secondo ordine. I nostri risultati forniscono indicazioni su come migliorare la regolarizzazione delle reti neurali.
Il dataset contiene 40 energie log mel-band estratte da 100$ diverse tracce sintetiche di eventi sonori, con rumore additivo da nove diverse scene acustiche (da ambienti interni, esterni e veicoli), mescolate a sei diversi rapporti suono-rumore, SNR, (da -12 a -27 dB con un passo di -3 dB), per un totale di 5400 (9 * 100 * 6) file sonori e una lunghezza totale di 30 564 minuti. Forniamo il dataset così com'è, il codice per ricreare il dataset e rimescolare le tracce degli eventi sonori e le scene acustiche con diversi SNR, e un metodo di base che testa le prestazioni di adattamento con il dataset proposto e stabilisce alcuni primi risultati.
Ridefinendo il costo utilizzando funzioni generalizzate dalla meccanica statistica non estensiva, aumentiamo il limite superiore degli stimatori precedenti e permettiamo il controllo del trade off della varianza bias. Gli stimatori basati sulla varianza superano i metodi precedenti soprattutto negli scenari dimensionali ad alta dipendenza che si trovano nelle impostazioni di apprendimento automatico. Il nostro approccio, ispirato dalla meccanica statistica non estensiva, utilizza diverse generalizzazioni per il logaritmo e l'esponenziale nella funzione di partizione, il che permette allo stimatore di catturare i cambiamenti nell'informazione reciproca su una gamma più ampia di dimensioni e correlazioni delle variabili di input, mentre i precedenti stimatori li saturano.
Wasserstein GANs (WGANs), una delle varianti di maggior successo di GANs, richiede la risoluzione di un problema minmax all'ottimalità globale, ma in pratica, sono addestrati con successo con il gradiente stocastico descent-ascent.In questo articolo, mostriamo che, quando il generatore è una rete a uno strato, il gradiente stocastico descent-ascent converge a una soluzione globale in tempo polinomiale e complessità del campione.
È stato dimostrato che i classificatori come le reti neurali profonde sono vulnerabili alle perturbazioni avversarie su problemi con uno spazio di input altamente dimensionale. Mentre l'addestramento avversariale migliora la robustezza dei classificatori contro tali perturbazioni avversarie, lascia i classificatori sensibili ad esse su una frazione non trascurabile degli input. Noi sosteniamo che ci sono due diversi tipi di perturbazioni avversarie: perturbazioni condivise che ingannano un classificatore su molti input e perturbazioni singolari che ingannano il classificatore solo su una piccola frazione dei dati.Troviamo che la formazione avversaria aumenta la robustezza dei classificatori contro le perturbazioni condivise. Inoltre, è particolarmente efficace nel rimuovere le perturbazioni universali, che possono essere viste come una forma estrema di perturbazioni condivise. Tuttavia, troviamo che l'addestramento avversario diminuisce la robustezza delle perturbazioni rimanenti contro le trasformazioni dell'immagine come i cambiamenti del contrasto e della luminosità o la sfocatura gaussiana, rendendo così meno probabile il successo degli attacchi al classificatore nel mondo fisico.
La maggior parte degli approcci tradizionali progettano manualmente o utilizzano la ricerca di architetture neurali (NAS) per trovare una rete neurale specializzata e addestrarla da zero per ogni caso, il che è computazionalmente costoso e non scalabile. La nostra idea chiave è quella di disaccoppiare l'addestramento del modello dalla ricerca dell'architettura per risparmiare i costi. A tal fine, proponiamo di addestrare una rete una volta per tutte (OFA) che supporta diverse impostazioni architettoniche (profondità, larghezza, dimensione del kernel e risoluzione).Dato uno scenario di implementazione, possiamo quindi ottenere rapidamente una sottorete specializzata selezionando dalla rete OFA senza ulteriore formazione. Per evitare interferenze tra molte sottoreti durante la formazione, proponiamo anche un nuovo algoritmo di restringimento progressivo, che può formare un numero sorprendentemente grande di sottoreti ($> 10^{19}$) simultaneamente. esperimenti estesi su varie piattaforme hardware (CPU, GPU, mCPU, mGPU, acceleratore FPGA) mostrano che OFA supera costantemente i metodi SOTA NAS (fino al 4. 0% di miglioramento dell'accuratezza di ImageNet top1 rispetto a MobileNetV3) riducendo al contempo gli ordini di grandezza delle ore di GPU e l'emissione di $CO_2$. In particolare, OFA raggiunge una nuova accuratezza SOTA 80.0% di ImageNet top1 nell'impostazione mobile ($<600M FLOPs). Il codice e i modelli pre-addestrati sono rilasciati su https://github.com/mit-han-lab/once-for-all.
Un modello generativo profondo è un potente metodo di apprendimento di una distribuzione di dati, che ha ottenuto un enorme successo in numerosi scenari.Tuttavia, non è banale per un singolo modello generativo catturare fedelmente le distribuzioni dei dati complessi come le immagini con strutture complicate.In questo articolo, proponiamo un nuovo approccio di boosting in cascata per il boosting dei modelli generativi, dove i meta-modelli (cioè gli apprendisti deboli) sono in cascata, Possiamo migliorare ulteriormente il potere di apprendimento dei modelli generativi combinando la nostra struttura di boosting in cascata con la struttura di boosting moltiplicativo.
I modelli di rappresentazione contestualizzati come ELMo (Peters et al., 2018a) e BERT (Devlin et al, Basandoci sul recente lavoro di sondaggio a livello di token, introduciamo un nuovo design di compito di sondaggio dei bordi e costruiamo un'ampia suite di compiti di sub-sentenza derivati dalla tradizionale pipeline NLP strutturata. Abbiamo sondato le rappresentazioni contestuali a livello di parola di quattro modelli recenti e studiato come codificano la struttura della frase in una gamma di fenomeni sintattici, semantici, locali e a lungo raggio. Abbiamo scoperto che i modelli esistenti addestrati sulla modellazione e traduzione del linguaggio producono forti rappresentazioni per i fenomeni sintattici, ma offrono solo miglioramenti relativamente piccoli sui compiti semantici rispetto a una linea di base non contestuale.
L'apprendimento di rinforzo profondo ha avuto successo in giochi sofisticati come Atari, Go, ecc. Il processo decisionale nel mondo reale, tuttavia, spesso richiede di ragionare con informazioni parziali estratte da osservazioni visive complesse. Questo articolo presenta Discriminative Particle Filter Reinforcement Learning (DPFRL), una nuova struttura di apprendimento di rinforzo per osservazioni parziali e complesse. DPFRL codifica un filtro a particelle differenziabile con modelli di transizione e osservazione appresi in una rete neurale, che consente di ragionare con osservazioni parziali su più passi temporali. Mentre un filtro a particelle standard si basa su un modello di osservazione generativo, DPFRL impara un modello discriminativamente parametrizzato che si allena direttamente per il processo decisionale. Mostriamo che la parametrizzazione discriminativa porta a prestazioni significativamente migliorate, specialmente per compiti con osservazioni visive complesse, perché aggira la difficoltà di modellare esplicitamente le osservazioni. Nella maggior parte dei casi, DPFRL supera lo stato dell'arte dei modelli POMDP RL in Flickering Atari Games, un benchmark POMDP RL esistente, e in Natural Flickering Atari Games, un nuovo e più impegnativo benchmark POMDP RL che introduciamo.
Estendere i modelli con variabili latenti ausiliarie è una tecnica ben nota per aumentare l'espressività del modello.Bachman & Precup (2015); Naesseth et al. (2018); Cremer et al. (2017); Domke & Sheldon (2018) mostrano che Importance Weighted Autoencoders (IWAE) (Burda et al, 2015) possono essere visti come estensione della famiglia variazionale con variabili latenti ausiliarie.Allo stesso modo, mostriamo che questa visione comprende molti dei recenti sviluppi nei limiti variazionali (Maddisonet al., 2017; Naesseth et al., 2018; Le et al., 2017; Yin & Zhou, 2018; Molchanovet al, 2018; Sobolev & Vetrov, 2018).Il successo dell'arricchimento della famiglia variazionale con variabili latenti ausiliarie motiva l'applicazione delle stesse tecniche al modello generativo.Sviluppiamo un modello generativo analogo all'IWAE bound e dimostriamo empiricamente che supera l'algoritmo Learned Accept/Reject Sampling recentemente proposto (Bauer & Mnih, 2018), pur essendo sostanzialmente più semplice da implementare.Inoltre, dimostriamo che questo processo generativo fornisce nuove intuizioni sulla classifica Noise Contrastive Estimation (Jozefowicz et al.,2016 Ma & Collins, 2018) e Contrastive Predictive Coding (Oord et al., 2018).
Stochastic Gradient Descent o SGD è l'algoritmo di ottimizzazione più popolare per problemi su larga scala.SGD stima il gradiente per campionamento uniforme con dimensione del campione uno.Ci sono stati diversi altri lavori che suggeriscono una convergenza più veloce epocale saggio utilizzando il campionamento ponderato non uniforme per una migliore stima del gradiente.Sfortunatamente, il costo per iterazione di mantenere questa distribuzione adattiva per la stima del gradiente è più che calcolare il gradiente completo.Di conseguenza, la falsa impressione di una convergenza più veloce in iterazioni porta a una convergenza più lenta nel tempo, che chiamiamo un loop di pollo e uova. In questo articolo, rompiamo questa barriera fornendo la prima dimostrazione di uno schema di campionamento, che porta a una stima del gradiente superiore, mantenendo il costo di campionamento per iterazione simile a quello del campionamento uniforme.Un tale algoritmo è possibile grazie alla visione di campionamento del Locality Sensitive Hashing (LSH), che è venuto alla luce recentemente.Come conseguenza della stima superiore e veloce, riduciamo il tempo di esecuzione di tutti gli algoritmi di discesa del gradiente esistenti.Dimostriamo i benefici della nostra proposta sia su SGD che su AdaGrad.
Negli ultimi anni abbiamo fatto progressi significativi nell'identificare i principi computazionali che sono alla base della funzione neurale.Anche se non è ancora completo, abbiamo prove sufficienti che una sintesi di queste idee potrebbe portare ad una comprensione di come la computazione neurale emerge da una combinazione di dinamiche innate e plasticità, e che potrebbe potenzialmente essere usata per costruire nuove tecnologie di IA con capacità uniche.Discuto i principi rilevanti, i vantaggi che hanno per la computazione, e come possono beneficiare dell'IA.I limiti dell'attuale IA sono generalmente riconosciuti, ma meno persone sono consapevoli che abbiamo capito abbastanza sul cervello per offrire immediatamente nuove formulazioni di IA.
Un lavoro recente ha dimostrato come la modellazione predittiva possa dotare gli agenti di una ricca conoscenza dell'ambiente circostante, migliorando la loro capacità di agire in ambienti complessi.Proponiamo il question-answering come paradigma generale per decodificare e comprendere le rappresentazioni che tali agenti sviluppano, applicando il nostro metodo a due approcci recenti alla modellazione predittiva - action-conditional CPC (Guo et al., 2018) e SimCore (Gregor et al., Dopo aver addestrato gli agenti con questi obiettivi predittivi in un ambiente 3D visivamente ricco con un assortimento di oggetti, colori, forme e configurazioni spaziali, sondiamo le loro rappresentazioni di stato interne con una serie di domande sintetiche (in inglese), senza retropropagare i gradienti dal decoder di risposta alle domande nell'agente. Il nostro approccio è intuitivo, cioè gli esseri umani possono facilmente interpretare le risposte del modello al contrario di ispezionare i vettori continui, e modello-agnostico, cioè applicabile a qualsiasi approccio di modellazione.Rivelando la conoscenza implicita di oggetti, quantità, proprietà e relazioni acquisite dagli agenti mentre apprendono, il probing agente domanda-condizionale può stimolare la progettazione e lo sviluppo di obiettivi di apprendimento predittivo più forti.
Nella maggior parte degli scenari del mondo reale, i set di dati di addestramento sono altamente sbilanciati in classi, dove le reti neurali profonde soffrono nel generalizzare a un criterio di test bilanciato. In questo articolo, esploriamo un modo nuovo ma semplice per alleviare questo problema attraverso la sintesi di classi meno frequenti con esempi avversari di altre classi. I nostri risultati sperimentali su vari tipi di set di dati con classi sbilanciate nella classificazione delle immagini e nell'elaborazione del linguaggio naturale mostrano che il metodo proposto non solo migliora la generalizzazione delle classi minoritarie in modo significativo rispetto ad altri metodi di ricampionamento o riponderazione, ma supera anche altri metodi di livello avanzato per la classificazione con classi sbilanciate.
La materia attiva è costituita da agenti attivi che trasformano l'energia estratta dall'ambiente circostante in quantità di moto, producendo una varietà di fenomeni collettivi. Un modello, un sistema attivo sintetico composto da polimeri di microtubuli guidati da motori proteici forma spontaneamente una fase nematica liquido-cristallina.lo stress di trazione creato dai motori proteici fa precipitare l'instabilità continua e la piegatura dei microtubuli creando difetti topologici mobili e flussi fluidi turbolenti. Il movimento dei difetti è determinato dalle proprietà reologiche del materiale; tuttavia, queste rimangono in gran parte non quantificate.Misurare la dinamica dei difetti può produrre intuizioni fondamentali nella nematica attiva, una classe di materiali che includono pellicole batteriche e cellule animali.I metodi attuali per il rilevamento dei difetti mancano di robustezza e precisione, e richiedono una messa a punto per set di dati con diversa qualità visiva.  In questo studio, abbiamo applicato Deep Learning per addestrare un rilevatore di difetti per analizzare automaticamente i video di microscopia del microtubulo attivo nematico.  I risultati sperimentali indicano che il nostro metodo è robusto e accurato e si prevede che aumenterà significativamente la quantità di dati video che possono essere elaborati.
In questo lavoro studiamo località e compositività nel contesto delle rappresentazioni di apprendimento per lo Zero Shot Learning (ZSL). Al fine di isolare bene l'importanza di queste proprietà nelle rappresentazioni apprese, imponiamo il vincolo aggiuntivo che, diversamente dalla maggior parte dei lavori recenti in ZSL, non viene eseguito alcun pre-addestramento su diversi dataset (ad esempio ImageNet). I risultati del nostro esperimento mostrano come la località, in termini di piccole parti dell'input, e la compositività, cioè quanto bene possono essere espresse le rappresentazioni apprese in funzione di un vocabolario più piccolo, sono entrambe profondamente legate alla generalizzazione e motivano l'attenzione su modelli più local-aware nelle future direzioni di ricerca per l'apprendimento delle rappresentazioni.
Nel tentativo di spiegare l'origine degli esempi avversi, gli studi precedenti si sono tipicamente concentrati sul fatto che le reti neurali operano su dati ad alta dimensione, che si adattano eccessivamente, o che sono troppo lineari. Qui mostriamo che le distribuzioni delle differenze logit hanno una forma funzionale universale, indipendente dall'architettura, dal set di dati e dal protocollo di allenamento, e che non cambia durante l'allenamento. Questo porta l'errore avversario ad avere una scalatura universale, come una legge di potenza, rispetto alla dimensione della perturbazione avversaria.Mostriamo che questa universalità vale per una vasta gamma di set di dati (MNIST, CIFAR10, ImageNet, e dati casuali), modelli (comprese le reti profonde allo stato dell'arte, modelli lineari, reti addestrate avversariamente e reti addestrate su etichette mescolate casualmente), e attacchi (FGSM, passo l.l., Infine, studiamo l'effetto delle architetture di rete sulla sensibilità avversaria. Per fare questo, usiamo la ricerca di architetture neurali con l'apprendimento per rinforzo per trovare architetture avversariamente robuste su CIFAR10. La nostra architettura risultante è più robusta agli attacchi white emph e black box rispetto ai tentativi precedenti.
    L'apprendimento di rinforzo (RL) ha portato a un comportamento sempre più complesso in cerca negli ultimi anni.Tuttavia, tale complessità può essere fuorviante e nasconde over-fitting.Troviamo che le rappresentazioni visive possono essere una metrica utile di complessità, e sia correla bene l'ottimizzazione obiettivo e causalmente effetti di ottimizzazione ricompensa. Proponiamo quindi l'apprendimento della rappresentazione curiosa (CRL) che ci permette di utilizzare migliori algoritmi di apprendimento della rappresentazione visiva per aumentare corrispondentemente la rappresentazione visiva nella politica attraverso un obiettivo intrinseco sia sugli ambienti simulati che sul trasferimento alle immagini reali.Infine, mostriamo che le migliori rappresentazioni visive indotte da CRL ci permettono di ottenere prestazioni migliori su Atari senza alcuna ricompensa rispetto ad altri obiettivi di curiosità.
Questo articolo introduce il compito di completamento semantico dell'istanza: da una scansione RGB-D incompleta di una scena, miriamo a rilevare le singole istanze dell'oggetto che compongono la scena e a dedurre la loro completa geometria dell'oggetto.Questo permette una decomposizione semanticamente significativa di una scena scansionata in singoli oggetti 3D completi, comprese le parti di oggetto nascoste e non osservate. Questo aprirà nuove possibilità di interazione con gli oggetti in una scena, per esempio per agenti virtuali o robotici. Per affrontare questo compito, proponiamo 3D-SIC, un nuovo approccio guidato dai dati che rileva congiuntamente le istanze degli oggetti e predice la loro geometria completa. L'idea centrale di 3D-SIC è una nuova architettura di rete neurale 3D end-to-end che sfrutta l'apprendimento congiunto delle caratteristiche di colore e geometria.La natura completamente rivoluzionaria della nostra rete 3D consente un'inferenza efficiente del completamento semantico dell'istanza per le scansioni 3D su scala di grandi ambienti interni in un singolo passaggio in avanti.In una valutazione in serie, valutiamo sia i dati di riferimento reali che quelli sintetici della scansione, dove superiamo gli approcci all'avanguardia di oltre 15 in mAP@0.5 su ScanNet, e oltre 18 in mAP@0.5 su SUNCG.
Il trasferimento di stile di solito si riferisce al compito di applicare le informazioni di colore e texture da una specifica immagine di stile a una data immagine di contenuto, preservando la struttura di quest'ultima. Qui affrontiamo il problema più generico del trasferimento di stile semantico: date due collezioni di immagini non accoppiate, miriamo a imparare una mappatura tra lo stile a livello di corpus di ciascuna collezione, preservando il contenuto semantico condiviso tra i due domini. Introduciamo XGAN ("Cross-GAN"), un doppio autocodificatore avversario, che cattura una rappresentazione condivisa del contenuto semantico del dominio comune in modo non supervisionato, mentre apprende congiuntamente le traduzioni delle immagini da dominio a dominio in entrambe le direzioni.  Sfruttiamo le idee della letteratura sull'adattamento del dominio e definiamo una perdita di coerenza semantica che incoraggia il modello a preservare la semantica nello spazio di incorporazione appreso. Segnaliamo risultati qualitativi promettenti per il compito di traduzione da faccia a cartone animato.
L'addestramento delle reti neurali su grandi insiemi di dati può essere accelerato distribuendo il carico di lavoro su una rete di macchine.Man mano che gli insiemi di dati diventano sempre più grandi, reti di centinaia o migliaia di macchine diventano economicamente sostenibili.Il costo temporale della comunicazione dei gradienti limita l'efficacia dell'uso di un numero così grande di macchine, così come la maggiore possibilità di guasti della rete. Esploriamo un algoritmo particolarmente semplice per un apprendimento robusto ed efficiente dal punto di vista della comunicazione---signSGD.I lavoratori trasmettono solo il segno del loro vettore di gradiente a un server, e l'aggiornamento generale è deciso da un voto di maggioranza.Questo algoritmo usa 32 volte meno comunicazione per iterazione rispetto alla SGD distribuita a piena precisione. In condizioni naturali verificate dall'esperimento, dimostriamo che signSGD converge nelle impostazioni grandi e mini-batch, stabilendo la convergenza per un regime di parametri di Adam come sottoprodotto.Aggregare i gradienti di segno con il voto di maggioranza significa che nessun lavoratore individuale ha troppo potere.Proviamo che a differenza di SGD, il voto di maggioranza è robusto quando fino al 50% dei lavoratori si comportano in modo avverso. La classe di avversari che consideriamo include come casi speciali quelli che invertono o randomizzano la loro stima del gradiente.Sul lato pratico, abbiamo costruito il nostro sistema di formazione distribuito in Pytorch.Benchmarking contro lo stato dell'arte della libreria di comunicazione collettiva (NCCL), il nostro quadro - con il server dei parametri ospitato interamente su una macchina - ha portato a una riduzione del 25% del tempo per la formazione resnet50 su Imagenet quando si utilizzano 15 macchine AWS p3.2xlarge.
La profilazione dei fenotipi cellulari dall'imaging microscopico può fornire informazioni biologiche significative derivanti da vari fattori che influenzano le cellule. Un'applicazione motivante è lo sviluppo di farmaci: le caratteristiche morfologiche delle cellule possono essere catturate dalle immagini, da cui possono essere quantificate le somiglianze tra diversi farmaci applicati a diversi dosaggi. L'approccio generale è quello di trovare una funzione che mappi le immagini in uno spazio di incorporazione di dimensione gestibile la cui geometria catturi le caratteristiche rilevanti delle immagini di input.Un importante problema noto per tali metodi è la separazione del segnale biologico rilevante dalla variazione di disturbo.Per esempio, i vettori di incorporazione tendono ad essere più correlati per le cellule che sono state coltivate e fotografate durante la stessa settimana che per le cellule di una settimana diversa, pur avendo gli stessi composti di droga applicati in entrambi i casi. In questo caso, il particolare lotto in cui è stato condotto un set di esperimenti costituisce il dominio dei dati; un set ideale di incorporazioni di immagini dovrebbe contenere solo le informazioni biologiche rilevanti (ad esempio gli effetti dei farmaci). Sviluppiamo un quadro generale per regolare le incorporazioni di immagini al fine di "dimenticare" le informazioni specifiche del dominio preservando le informazioni biologiche rilevanti. Per fare questo, minimizziamo una funzione di perdita basata sulle distanze tra le distribuzioni marginali (come la distanza di Wasserstein) delle embeddings attraverso i domini per ogni trattamento replicato.Per il set di dati presentato, il trattamento replicato è il controllo negativo.Troviamo che per le nostre embeddings trasformate (1) la struttura geometrica sottostante non solo è conservata ma le embeddings portano anche un segnale biologico migliorato (2) sono presenti meno informazioni dominio-specifiche.
Questo articolo presenta un Mutual Information Neural Estimator (MINE) che è linearmente scalabile nella dimensionalità così come nella dimensione del campione.MINE è back-propable e dimostriamo che è fortemente coerente.Illustriamo una manciata di applicazioni in cui MINE è applicato con successo per migliorare la proprietà dei modelli generativi in entrambe le impostazioni non supervisionate e supervisionate.Applichiamo il nostro quadro per stimare il collo di bottiglia dell'informazione, e lo applichiamo in compiti relativi a problemi di classificazione supervisionata.I nostri risultati dimostrano una sostanziale flessibilità e miglioramento aggiunto in queste impostazioni.
 I metodi di apprendimento per rinforzo hanno recentemente raggiunto risultati impressionanti su una vasta gamma di problemi di controllo, ma, specialmente con input complessi, richiedono ancora una grande quantità di dati di allenamento per convergere verso una soluzione significativa. Questa limitazione proibisce in gran parte il loro utilizzo per spazi di input complessi come i segnali video, ed è ancora impossibile utilizzarlo per un certo numero di problemi complessi in ambienti del mondo reale, inclusi molti di quelli per il controllo basato su video.L'apprendimento supervisionato, al contrario, è capace di imparare su un numero relativamente piccolo di campioni, tuttavia non prende in considerazione le politiche di controllo basate sui premi e non è capace di fornire politiche di controllo indipendenti.  In questo articolo proponiamo un metodo di controllo senza modello, che utilizza una combinazione di apprendimento supervisionato e di rinforzo per il controllo autonomo e apre la strada verso un controllo basato su politiche in ambienti reali.Usiamo il videogioco SpeedDreams/TORCS per dimostrare che il nostro approccio richiede molti meno campioni (centinaia di migliaia contro milioni o decine di milioni) rispetto alle tecniche di apprendimento di rinforzo allo stato dell'arte su dati simili, e allo stesso tempo supera sia gli approcci di apprendimento supervisionato che di rinforzo in termini di qualità.Inoltre, dimostriamo l'applicabilità del metodo ai problemi di controllo MuJoCo.
Un tipico esperimento per studiare le funzioni cognitive è quello di addestrare gli animali ad eseguire dei compiti, mentre il ricercatore registra l'attività elettrica dei neuroni degli animali.Il principale ostacolo affrontato, quando si utilizza questo tipo di esperimento elettrofisiologico per scoprire i meccanismi circuitali alla base di comportamenti complessi, è il nostro accesso incompleto ai circuiti rilevanti nel cervello.Un approccio promettente è quello di modellare i circuiti neurali utilizzando una rete neurale artificiale (ANN), che può fornire accesso completo ai "circuiti neurali" responsabili di un comportamento. Più recentemente, i modelli di apprendimento di rinforzo sono stati adottati per comprendere le funzioni dei circuiti cortico-basali dei gangli come apprendimento basato sulla ricompensa è stato trovato nel cervello dei mammiferi.In questo articolo, proponiamo un quadro Biologically-plausible Actor-Critic with Episodic Memory (B-ACEM) per modellare un circuito corteccia prefrontale-basal ganglia-hippocampus (PFC-BG), che è verificato per catturare i risultati comportamentali da un ben noto compito di decisione percettiva, cioè, Gli esperimenti sono condotti utilizzando diverse impostazioni della memoria episodica e i risultati mostrano che tutti i modelli di memorie episodiche possono accelerare l'apprendimento. In particolare, gli eventi salienti sono prioritari per propagare le informazioni di ricompensa e guidare le decisioni. La nostra struttura B-ACEM e gli esperimenti costruiti danno ispirazione sia ai progetti per modelli decisionali più standard nel sistema biologico sia a una RNA più biologicamente plausibile.
Comprendere il potere di rappresentazione delle Reti Neurali Profonde (DNN) e come le loro proprietà strutturali (es, In un articolo seminale, Telgarsky ha evidenziato i benefici della profondità presentando una famiglia di funzioni (basate su onde triangolari) per le quali le DNN raggiungono un errore di classificazione pari a zero, mentre le reti poco profonde con meno di un numero esponenziale di nodi incorrono in un errore costante. Anche se il lavoro di Telgarsky rivela i limiti delle reti neurali poco profonde, non ci informa sul perché queste funzioni sono difficili da rappresentare e infatti egli afferma che è un'allettante questione aperta caratterizzare quelle funzioni che non possono essere ben approssimate da profondità minori. In questo lavoro, indichiamo una nuova connessione tra l'espressività delle DNN e il Teorema di Sharkovsky dei sistemi dinamici, che ci permette di caratterizzare i trade-off di profondità-larghezza delle reti ReLU per rappresentare funzioni basate sulla presenza di una nozione generalizzata di punti fissi, chiamati punti periodici (un punto fisso è un punto di periodo 1). Motivati dalla nostra osservazione che le onde triangolari utilizzate nel lavoro di Telgarsky contengono punti di periodo 3 - un periodo che è speciale in quanto implica un comportamento caotico basato sul celebre risultato di Li-Yorke - procediamo a dare limiti inferiori generali per la larghezza necessaria a rappresentare le funzioni periodiche in funzione della profondità.Tecnicamente, il fulcro del nostro approccio si basa su un'analisi degli autovalori dei sistemi dinamici associati a tali funzioni.
Studiamo la quantizzazione a basso bit per ridurre il costo computazionale delle reti neurali profonde (DNN) basate su keyword spotting (KWS) e proponiamo approcci per ridurre ulteriormente i bit di quantizzazione integrando la quantizzazione nella formazione del modello di keyword spotting, che chiamiamo formazione consapevole della quantizzazione. Combinando l'addestramento quantization-aware e la fattorizzazione della matrice dei pesi, siamo in grado di ridurre significativamente le dimensioni del modello e il calcolo per il keyword spotting di piccole dimensioni, pur mantenendo le prestazioni.
Single-cell RNA-sequencing (scRNA-seq) è un potente strumento per l'analisi dei sistemi biologici.Tuttavia, a causa del rumore biologico e tecnico, quantificare gli effetti di più condizioni sperimentali presenta una sfida analitica.Per superare questa sfida, abbiamo sviluppato MELD: Manifold Enhancement of Latent Dimensions.MELD sfrutta strumenti di elaborazione del segnale grafico per imparare una dimensione latente all'interno dei dati che segna la prototipicità di ogni datapoint rispetto alle condizioni sperimentali o di controllo.Noi chiamiamo questa dimensione il segnale sperimentale avanzata (EES). MELD impara la EES filtrando l'etichetta sperimentale categorica rumorosa nel dominio della frequenza del grafico per recuperare un segnale liscio con valori continui.Questo metodo può essere utilizzato per identificare i geni di firma che variano tra le condizioni e identificare quali tipi di cellule sono più colpiti da una data perturbazione.Dimostriamo i vantaggi dell'analisi MELD in due set di dati biologici, tra cui l'attivazione delle cellule T in risposta a perline rivestite di anticorpi e il trattamento delle cellule isteriche pancreatiche umane con interferone gamma.
I modelli di comportamento dell'utente sono input critici in molte impostazioni prescrittive e possono essere visti come regole di decisione che trasformano le informazioni di stato disponibili per l'utente in azioni. processi gaussiani (GPs), così come estensioni non lineari, forniscono un quadro flessibile per imparare modelli di utente in combinazione con inferenza bayesiana approssimativa. Proponiamo i GP di decisione-regola (DRGP) che applicano i GP in uno spazio trasformato definito da regole di decisione che hanno un'immediata interpretabilità per i professionisti. Illustriamo questo strumento di modellazione su un'applicazione reale e mostriamo che le tecniche di inferenza variazionale strutturale possono essere utilizzate con i DRGP.
Mentre l'ottimizzazione bayesiana (BO) ha ottenuto un grande successo nell'ottimizzazione di funzioni black-box costose da valutare, in particolare la sintonizzazione degli iperparametri delle reti neurali, metodi come la ricerca casuale (Li et al., 2016) e multi-fidelity BO (ad esempio Klein et al. (2017)) che sfruttano approssimazioni a buon mercato, ad esempio l'addestramento su dati di formazione più piccoli o con un minor numero di iterazioni, possono superare gli approcci standard BO che utilizzano solo osservazioni a piena fedeltà.In questo articolo, proponiamo un nuovo algoritmo di ottimizzazione bayesiana, il metodo continuous-fidelity knowledge gradient (cfKG), che può essere utilizzato quando la fedeltà è controllata da una o più impostazioni continue come la dimensione dei dati di formazione e il numero di iterazioni di formazione. cfKG caratterizza il valore dell'informazione ottenuta campionando un punto ad una data fedeltà, scegliendo di campionare al punto e alla fedeltà con il maggior valore per unità di costo.Inoltre, cfKG può essere generalizzato, seguendo Wu et al. (2017), alle impostazioni in cui le derivate sono disponibili nel processo di ottimizzazione, ad es. Esperimenti numerici mostrano che cfKG supera gli algoritmi allo stato dell'arte nell'ottimizzazione di funzioni sintetiche, nel tuning di reti neurali convoluzionali (CNN) su CIFAR-10 e SVHN, e nell'apprendimento di kernel su larga scala.
Le reti neurali addestrate solo per ottimizzare l'accuratezza dell'addestramento possono spesso essere ingannate da esempi avversi --- ingressi leggermente perturbati classificati in modo errato con alta fiducia.La verifica delle reti ci permette di valutare la loro vulnerabilità a tali esempi avversi.Formuliamo la verifica delle reti neurali piecewise-lineari come un programma intero misto. Su un compito rappresentativo di trovare distorsioni minime avversarie, il nostro verificatore è da due a tre ordini di grandezza più veloce rispetto allo stato dell'arte. otteniamo questa accelerazione computazionale attraverso formulazioni strette per le non linearità, così come un nuovo algoritmo di presolve che fa pieno uso di tutte le informazioni disponibili. L'accelerazione computazionale ci permette di verificare le proprietà su reti convoluzionali e residuali con oltre 100.000 ReLUs --- diversi ordini di grandezza in più rispetto alle reti precedentemente verificate da qualsiasi verificatore completo.In particolare, determiniamo per la prima volta l'esatta precisione avversaria di un classificatore MNIST a perturbazioni con norma l-âˆž delimitata Îµ=0. 1: per questo classificatore, troviamo un esempio avversario per il 4,38% dei campioni, e un certificato di robustezza alle perturbazioni con norma delimitata per il resto.Attraverso tutte le procedure di addestramento robusto e le architetture di rete considerate, e per entrambi i dataset MNIST e CIFAR-10, siamo in grado di certificare più campioni rispetto allo state-of-the-art e trovare più esempi avversari di un forte attacco di primo ordine.
La stima dell'incertezza è un passo essenziale nella valutazione della robustezza dei modelli di deep learning nella computer vision, specialmente se applicata in aree sensibili al rischio. Tuttavia, la maggior parte dei modelli di deep learning allo stato dell'arte non riesce a ottenere la stima dell'incertezza o necessita di modifiche significative (ad esempio, la formulazione di un trattamento bayesiano adeguato) per ottenerla. Nessuno dei metodi precedenti è in grado di prendere un modello arbitrario dallo scaffale e generare la stima dell'incertezza senza riqualificarlo o riprogettarlo. Proponiamo tre metodi semplici e scalabili per analizzare la varianza dell'output di una rete addestrata sotto perturbazioni tollerabili: infer-trasformazione, infer-noise e infer-dropout, che operano esclusivamente durante l'inferenza, senza la necessità di ri-addestrare, riprogettare o mettere a punto il modello, come tipicamente richiesto da altri metodi di stima dell'incertezza all'avanguardia. Sorprendentemente, anche senza coinvolgere tali perturbazioni nell'addestramento, i nostri metodi producono una stima dell'incertezza paragonabile o addirittura migliore rispetto ad altri metodi all'avanguardia richiesti dall'addestramento.
Catturare le dinamiche spazio-temporali è un argomento essenziale nel riconoscimento video. In questo articolo, presentiamo un'operazione di ordine superiore apprendibile come una famiglia generica di blocchi di costruzione per catturare le correlazioni di ordine superiore dallo spazio video di input ad alta dimensione.  Sul compito di riconoscimento video, anche usando solo RGB senza messa a punto con altri set di dati video, i nostri modelli di ordine superiore possono raggiungere risultati alla pari o migliori dei metodi esistenti allo stato dell'arte sia su Something-Something (V1 e V2) che sui set di dati Charades.
Attualmente gli approcci di maggior successo all'apprendimento semi-supervisionato sono basati sulla regolarizzazione della coerenza, per cui un modello è addestrato per essere robusto a piccole perturbazioni dei suoi input e parametri. Per capire la regolarizzazione della coerenza, esploriamo concettualmente come la geometria della perdita interagisce con le procedure di addestramento. La perdita di coerenza migliora notevolmente le prestazioni di generalizzazione rispetto all'addestramento solo supervisionato; tuttavia, mostriamo che SGD fatica a convergere sulla perdita di coerenza e continua a fare grandi passi che portano a cambiamenti nelle previsioni sui dati di prova. Motivati da queste osservazioni, proponiamo di addestrare i metodi basati sulla coerenza con Stochastic Weight Averaging (SWA), un approccio recente che fa la media dei pesi lungo la traiettoria di SGD con un programma di apprendimento modificato.Proponiamo anche fast-SWA, che accelera ulteriormente la convergenza facendo la media di più punti all'interno di ogni ciclo di un programma ciclico di apprendimento. Con la media dei pesi, raggiungiamo i migliori risultati semi-supervisionati conosciuti su CIFAR-10 e CIFAR-100, su diverse quantità di dati di formazione etichettati. Per esempio, raggiungiamo il 5,0% di errore su CIFAR-10 con solo 4000 etichette, rispetto al precedente miglior risultato in letteratura del 6,3%.
In questo articolo, troviamo che progettando una nuova funzione di perdita intitolata "tracking loss", i rilevatori di oggetti basati su reti neurali convoluzionali (CNN) possono essere convertiti con successo in inseguitori visivi ben funzionanti senza alcun costo computazionale aggiuntivo. Questa proprietà è preferibile all'inseguimento visivo dove le sequenze video annotate per la formazione sono sempre assenti, perché le caratteristiche ricche apprese dai rilevatori da immagini fisse potrebbero essere utilizzate dagli inseguitori dinamici. La perdita di inseguimento raggiunge questa proprietà sfruttando la struttura interna delle mappe di caratteristiche all'interno della rete di rilevamento e trattando diversi punti di caratteristiche in modo discriminatorio. Tale struttura ci permette di considerare simultaneamente la qualità della discriminazione e l'accuratezza del bounding box che si trova ad essere cruciale per il successo.Proponiamo anche un metodo di compressione della rete per accelerare la velocità di tracciamento senza riduzione delle prestazioni.Questo verifica anche che la perdita di tracciamento rimane altamente efficace anche se la rete è drasticamente compressa. Inoltre, se impieghiamo un ensemble di perdita di tracciamento attentamente progettato, il tracker sarebbe molto più robusto e accurato.I risultati della valutazione mostrano che i nostri tracker (tra cui il tracker ensemble e due tracker di base), superano tutti i metodi all'avanguardia su VOT 2016 Challenge in termini di Expected Average Overlap (EAO) e robustezza.Renderemo il codice pubblicamente disponibile.
Studiamo il problema della riparazione del codice semantico, che può essere ampiamente definito come la correzione automatica dei bug non sintattici nel codice sorgente.La maggior parte del lavoro passato nella riparazione del codice semantico presupponeva l'accesso a test unitari rispetto ai quali le riparazioni candidate potevano essere validate. Al contrario, l'obiettivo qui è quello di sviluppare un forte modello statistico per prevedere accuratamente sia la posizione dei bug che le esatte correzioni senza accesso alle informazioni sul comportamento corretto previsto del programma. Il raggiungimento di tale obiettivo richiede un robusto modello di riparazione contestuale, che noi addestriamo su un grande corpus di codice sorgente del mondo reale che è stato aumentato con bug iniettati sinteticamente. La nostra struttura adotta un approccio a due stadi in cui prima un grande insieme di candidati alla riparazione viene generato da processori basati su regole, e poi questi candidati vengono valutati da un modello statistico che utilizza una nuova architettura di rete neurale a cui ci riferiamo come Share, Specialize, and Compete. In particolare, l'architettura (1) genera una codifica condivisa del codice sorgente utilizzando una RNN sull'albero sintattico astratto, (2) assegna un punteggio a ogni riparazione candidata utilizzando moduli di rete specializzati, e (3) quindi normalizza questi punteggi insieme in modo che possano competere l'uno contro l'altro in uno spazio di probabilità comparabile.valutiamo il nostro modello su un set di test del mondo reale raccolto da GitHub contenente quattro categorie comuni di bug. il nostro modello è in grado di prevedere l'esatta riparazione corretta il 41% delle volte con un solo tentativo, rispetto al 13% di precisione per un modello attenzionale sequenza per sequenza.
Le reti profonde sono state recentemente suggerite per affrontare le probabilità tra accuratezza (su immagini naturali pulite) e robustezza (su immagini perturbate avversariamente) (Tsipras et al., 2019).Tale dilemma è dimostrato essere radicato nella complessità del campione intrinsecamente più elevata (Schmidt et al, 2018) e / o capacità del modello (Nakkiran, 2019), per l'apprendimento di un classificatore ad alta precisione e robusto.In considerazione di ciò, dare un compito di classificazione, aumentare la capacità del modello sembra aiutare a disegnare un win-win tra precisione e robustezza, ma a scapito delle dimensioni del modello e della latenza, ponendo quindi sfide per le applicazioni con risorse limitate. E' possibile co-progettare l'accuratezza del modello, la robustezza e l'efficienza per raggiungere la loro triplice vittoria? Questo articolo studia le reti multi-uscita associate all'inferenza efficiente input-adaptive, mostrando la loro forte promessa nel raggiungere un "punto dolce" nella coottimizzazione dell'accuratezza del modello, della robustezza e dell'efficienza. La nostra soluzione proposta, soprannominata Robust Dynamic Inference Networks (RDI-Nets), permette ad ogni input (sia pulito che avversario) di scegliere in modo adattivo uno dei molteplici strati di output (rami iniziali o quello finale) per produrre la sua previsione. Mostriamo sperimentalmente che dotando le dorsali esistenti di tale robusta inferenza adattiva, le RDI-Net risultanti possono raggiungere una migliore accuratezza e robustezza, ma con oltre il 30% di risparmio computazionale, rispetto ai modelli originali difesi.
Sebbene le reti convoluzionali profonde abbiano ottenuto prestazioni migliori in molti compiti di linguaggio naturale, sono state trattate come scatole nere perché sono difficili da interpretare. In particolare, si sa poco su come rappresentano il linguaggio nei loro strati intermedi. Nel tentativo di comprendere le rappresentazioni delle reti convoluzionali profonde addestrate su compiti linguistici, mostriamo che le singole unità rispondono selettivamente a morfemi, parole e frasi specifiche, piuttosto che rispondere a modelli arbitrari e non interpretabili. Al fine di analizzare quantitativamente tale fenomeno intrigante, proponiamo un metodo di allineamento concettuale basato su come le unità rispondono al testo replicato.conduciamo analisi con diverse architetture su più dataset per compiti di classificazione e traduzione e forniamo nuove intuizioni su come i modelli profondi comprendono il linguaggio naturale.
Come dati usiamo un set di allenamento debolmente etichettato, dove le etichette indicano quale singolo fattore è cambiato tra due campioni di dati, anche se il valore relativo del cambiamento è sconosciuto.Questa etichettatura è di particolare interesse perché può essere facilmente disponibile senza costi di annotazione.Introduciamo un modello autoencoder e lo addestriamo attraverso vincoli su coppie e terzine di immagini. Mostriamo il ruolo della dimensionalità della caratteristica e dell'addestramento avversario teoricamente e sperimentalmente.Dimostriamo formalmente l'esistenza dell'ambiguità di riferimento, che è intrinsecamente presente nel compito di disentangling quando vengono utilizzati dati debolmente etichettati.Il valore numerico di un fattore ha un significato diverso in diversi frame di riferimento.Quando il riferimento dipende da altri fattori, il trasferimento di quel fattore diventa ambiguo.Dimostriamo sperimentalmente che il modello proposto può trasferire con successo gli attributi su diversi dataset, ma mostriamo anche casi in cui si verifica l'ambiguità di riferimento.
Nell'information retrieval, l'apprendimento per classificare costruisce un modello di classificazione basato sulla macchina che, data una query, ordina i risultati della ricerca in base al loro grado di rilevanza o importanza per la query.Le reti neurali sono state applicate con successo a questo problema, e in questo articolo, proponiamo una rete neurale profonda basata sull'attenzione che incorpora meglio le diverse incorporazioni delle query e dei risultati della ricerca con un meccanismo basato sull'attenzione. Questo modello applica anche un meccanismo di decodifica per apprendere i ranghi dei risultati di ricerca in un modo a lista.Le incorporazioni sono addestrate con reti neurali convoluzionali o con il modello word2vec.Dimostriamo le prestazioni di questo modello con set di dati di recupero delle immagini e di interrogazione del testo.
Il lavoro recente ha dimostrato che la diversità funzionale dei neuroni può essere limitata a quella di relativamente pochi tipi di cellule; altri lavori hanno dimostrato che incorporare vincoli nelle reti neurali artificiali (ANNs) può migliorare la loro capacità di imitare i dati neurali. Qui sviluppiamo un algoritmo che prende come input registrazioni di attività neurale e restituisce cluster di neuroni per tipo di cellula e modelli di attività neurale vincolati da questi cluster. I modelli risultanti sono sia più predittivi che più interpretabili, rivelando i contributi dei tipi di cellule funzionali alla computazione neurale e in ultima analisi informando la progettazione di future RNA.
Le reti neurali a grafo (GNN) sono un potente strumento di rappresentazione per la risoluzione di problemi su input strutturati a grafo. In quasi tutti i casi finora, tuttavia, sono state applicate per recuperare direttamente una soluzione finale da input grezzi, senza una guida esplicita su come strutturare il loro problem-solving. Qui, invece, ci concentriamo sull'apprendimento nello spazio degli algoritmi: addestriamo diverse architetture GNN all'avanguardia per imitare i singoli passi degli algoritmi a grafo classici, sia paralleli (ricerca per gradi, Bellman-Ford) che sequenziali (algoritmo di Prim). Poiché gli algoritmi a grafo di solito si basano sul prendere decisioni discrete all'interno delle vicinanze, ipotizziamo che le reti neurali basate sulla massimizzazione del passaggio dei messaggi siano le più adatte per tali obiettivi, e convalidiamo questa affermazione empiricamente. Dimostriamo anche come l'apprendimento nello spazio degli algoritmi possa produrre nuove opportunità di trasferimento positivo tra i compiti - mostrando come l'apprendimento di un algoritmo del percorso più breve possa essere sostanzialmente migliorato quando si apprende simultaneamente un algoritmo di raggiungibilità.
La prospettiva è una parte importante di come gli esseri umani si avvicinano a nuovi piani di attività, ma non è stata esplorata in profondità nella robotica. Prevedere più attività a livello è un problema impegnativo che comporta la cattura sia della semantica delle attività che della variabilità continua sullo stato del mondo. idealmente, vorremmo combinare la capacità del machine learning di sfruttare i grandi dati per imparare la semantica di un'attività, mentre si utilizzano tecniche di pianificazione delle attività per generalizzare in modo affidabile al nuovo ambiente. Impariamo una rete neurale che codifica i k risultati più probabili dalle azioni di alto livello da un mondo dato.Il nostro approccio crea piani di attività comprensibili che ci permettono di prevedere i cambiamenti all'ambiente molti passi di tempo nel futuro.Dimostriamo questo approccio tramite l'applicazione a un compito di impilamento in un ambiente disordinato, dove il robot deve selezionare tra diversi blocchi colorati evitando gli ostacoli, al fine di eseguire un compito.Mostriamo anche i risultati su un compito semplice navigazione.Il nostro algoritmo genera immagini realistiche e previsioni di posa in più punti in un compito dato.
Gli algoritmi di gradiente adattivo eseguono aggiornamenti basati sul gradiente utilizzando la storia dei gradienti e sono onnipresenti nell'addestramento delle reti neurali profonde.Mentre la teoria dei metodi di gradiente adattivo è ben compresa per i problemi di minimizzazione, i fattori sottostanti che guidano il loro successo empirico nei problemi di min-max come i GAN rimangono poco chiari.In questo articolo, miriamo a colmare questo divario sia dal punto di vista teorico che empirico. In primo luogo, analizziamo una variante di Optimistic Stochastic Gradient (OSG) proposta in~~~citep{daskalakis2017training} per risolvere una classe di problemi min-max non convessi e stabiliamo $O(\epsilon^{-4})$ complessità per trovare il punto stazionario di primo ordine, in cui l'algoritmo richiede solo l'invocazione di un oracolo stocastico di primo ordine, mentre gode di una complessità di iterazione allo stato dell'arte raggiunta dal metodo extragradiente stocastico di~\citep{iusem2017extragradient}. Poi proponiamo una variante adattiva di OSG chiamata Optimistic Adagrad (OAdagrad) e riveliamo una complessità adattiva migliorata $widetilde{O} a sinistra (\epsilon^-\frac{2}{1-\alpha}}} a destra)$ ~~footnote{ Qui $widetilde{O}(\cdot)$ comprime un fattore logaritmico di $\epsilon$. }, dove $alpha$ caratterizza il tasso di crescita del gradiente stocastico cumulativo e $0\leq \alpha\leq 1/2$. Per quanto ne sappiamo, questo è il primo lavoro per stabilire la complessità adattiva nell'ottimizzazione min-max non-convessa non-concava.empiricamente, i nostri esperimenti mostrano che effettivamente gli algoritmi con gradiente adattivo superano i loro omologhi non-adattivi nella formazione GAN.inoltre, questa osservazione può essere spiegata dal lento tasso di crescita del gradiente stocastico cumulativo, come osservato empiricamente.
Consideriamo il problema dell'apprendimento non supervisionato di un basso dimensionale, interpretabile, stato latente di un video che contiene un oggetto in movimento.Il problema della distillazione delle dinamiche dai pixel è stato ampiamente considerato attraverso la lente dei modelli grafici/stato-spazio che sfruttano la struttura di Markov per il calcolo economico e i priori grafici strutturati del modello per imporre l'interpretabilità sulle rappresentazioni latenti.Facciamo un passo verso l'estensione di questi approcci scartando la struttura di Markov; invece, riproponendo il Gaussian Process Prior Variational Autoencoder recentemente proposto per imparare traiettorie latenti sofisticate. Descriviamo il modello ed eseguiamo esperimenti su un set di dati sintetico e vediamo che il modello ricostruisce in modo affidabile dinamiche lisce che esibiscono inversioni a U e loop.Osserviamo anche che questo modello può essere addestrato senza alcun beta-annealing o freeze-thaw dei parametri di addestramento.L'addestramento viene eseguito puramente end-to-end sull'obiettivo lower bound della prova non modificato.Questo è in contrasto con i lavori precedenti, anche se per casi d'uso leggermente diversi, dove spesso sono richiesti trucchi di addestramento specifici per l'applicazione.
I sogni e la nostra capacità di ricordarli sono tra le domande più sconcertanti nella ricerca sul sonno. In particolare, le differenze putative nelle dinamiche della rete cerebrale tra gli individui con alti e bassi tassi di richiamo del sogno, sono ancora poco comprese. In questo studio, abbiamo affrontato questa domanda come un problema di classificazione in cui abbiamo applicato le reti convoluzionali profonde (CNN) alle registrazioni EEG del sonno per prevedere se i soggetti appartenevano al gruppo alto o basso richiamo del sogno (HDR e LDR rispettivamente). Il nostro modello raggiunge livelli di accuratezza significativi in tutte le fasi del sonno, indicando così le sottili firme del richiamo dei sogni nella microstruttura del sonno. Abbiamo anche visualizzato lo spazio delle caratteristiche per ispezionare la specificità del soggetto delle caratteristiche apprese, garantendo così che la rete catturasse le differenze a livello di popolazione. Oltre ad essere il primo studio ad applicare l'apprendimento profondo all'EEG del sonno per classificare HDR e LDR, la backpropagation guidata ci ha permesso di visualizzare le caratteristiche più discriminanti in ogni fase del sonno.
In particolare, ogni agente impara una politica di controllo decentralizzata basata sulle osservazioni locali e sui messaggi dei vicini collegati. Formuliamo un problema MARL in rete (NMARL) come un processo decisionale di Markov spazio-temporale e introduciamo un fattore di sconto spaziale per stabilizzare la formazione di ogni agente locale. Inoltre, proponiamo un nuovo protocollo di comunicazione differenziabile, chiamato NeurComm, per ridurre la perdita di informazioni e la non stazionarietà in NMARL. Sulla base di esperimenti in scenari NMARL realistici di controllo adattativo dei segnali stradali e di controllo cooperativo di crociera adattativo, un fattore di sconto spaziale appropriato migliora efficacemente le curve di apprendimento degli algoritmi MARL non comunicativi, mentre NeurComm supera i protocolli di comunicazione esistenti sia nell'efficienza di apprendimento che nelle prestazioni di controllo.
L'inferenza bayesiana variazionale è una metodologia popolare per approssimare le distribuzioni posteriori sui pesi delle reti neurali bayesiane. Il lavoro recente che sviluppa questa classe di metodi ha esplorato parametrizzazioni sempre più ricche del posteriore approssimato nella speranza di migliorare le prestazioni. Per una varietà di reti neurali bayesiane profonde addestrate utilizzando l'inferenza variazionale Gaussiana mean-field, troviamo che le deviazioni standard posteriori esibiscono costantemente una forte struttura a basso rango dopo la convergenza. Ciò significa che decomponendo questi parametri variazionali in una fattorizzazione a basso rango, possiamo rendere la nostra approssimazione variazionale più compatta senza diminuire le prestazioni dei modelli.Inoltre, troviamo che tali parametrizzazioni fattorizzate migliorano il rapporto segnale-rumore delle stime del gradiente stocastico del limite inferiore variazionale, con conseguente convergenza più veloce.
L'estrazione degli aspetti nelle recensioni dei prodotti online è un compito chiave nell'analisi del sentimento e nell'opinion mining. L'addestramento di reti neurali supervisionate per l'estrazione degli aspetti non è possibile quando non sono disponibili le etichette degli aspetti della verità di base, mentre i modelli neurali non supervisionati non riescono a catturare i particolari aspetti di interesse, I nostri contributi principali sono i seguenti: in primo luogo, dimostriamo che le attuali reti debolmente supervisionate non riescono a sfruttare il potere predittivo delle parole di partenza disponibili, confrontandole con un semplice classificatore di bag-of-words.  In secondo luogo, proponiamo un approccio di distillazione per l'estrazione degli aspetti in cui le parole seme sono considerate dal classificatore bag-of-words (insegnante) e distillate ai parametri di una rete neurale (studente).In terzo luogo, mostriamo che la regolarizzazione incoraggia lo studente a considerare le parole non seme per la classificazione e, come risultato, lo studente supera l'insegnante, che considera solo le parole seme. Infine, dimostriamo empiricamente che il nostro approccio di distillazione proposto supera (fino al 34,4% nel punteggio F1) i precedenti approcci debolmente supervisionati per l'estrazione di aspetti in sei domini di recensioni di prodotti Amazon.
Formare gruppi percettivi e individuare gli oggetti nelle scene visive è un passo essenziale verso l'intelligenza visiva. Si pensa che questa capacità nasca nel cervello da calcoli implementati da connessioni bottom-up, orizzontali e top-down tra i neuroni. Tuttavia, i contributi relativi di queste connessioni al raggruppamento percettivo sono poco conosciuti. Affrontiamo questa domanda valutando sistematicamente le architetture di rete neurale con combinazioni di queste connessioni su due compiti visivi sintetici, che sottolineano il basso livello "Gestalt" contro le indicazioni di alto livello degli oggetti per il raggruppamento percettivo. Le connessioni orizzontali risolvono questa limitazione nei compiti con spunti Gestalt sostenendo la propagazione spaziale incrementale delle attività, mentre le connessioni top-down salvano l'apprendimento nei compiti con spunti oggetto di alto livello modificando le previsioni grossolane sulla posizione dell'oggetto target.
Le reti generative avversarie hanno visto un rapido sviluppo negli ultimi anni e hanno portato a notevoli miglioramenti nella modellazione generativa delle immagini, ma la loro applicazione nel dominio audio ha ricevuto un'attenzione limitata e i modelli autoregressivi, come WaveNet, rimangono lo stato dell'arte nella modellazione generativa dei segnali audio come il parlato umano. La nostra architettura è composta da un generatore condizionato a feed-forward che produce audio grezzo, e da un insieme di discriminatori che operano su finestre casuali di diverse dimensioni. I discriminatori analizzano l'audio sia in termini di realismo generale, sia di quanto l'audio corrisponda all'enunciato che dovrebbe essere pronunciato.  Per misurare le prestazioni di GAN-TTS, impieghiamo sia la valutazione umana soggettiva (MOS - Mean Opinion Score), sia nuove metriche quantitative (Fréchet DeepSpeech Distance e Kernel DeepSpeech Distance), che troviamo essere ben correlate con MOS. Mostriamo che GAN-TTS è in grado di generare un discorso ad alta fedeltà con una naturalezza paragonabile ai modelli all'avanguardia, e a differenza dei modelli autoregressivi, è altamente parallelizzabile grazie a un efficiente generatore feed-forward.Ascolta GAN-TTS leggere questo abstract su http://tiny.cc/gantts.
Questo articolo propone un quadro di Pruning in Training (PiT) di apprendimento per ridurre la dimensione dei parametri delle reti.Diverso dai lavori esistenti, il nostro quadro PiT impiega le penalità sparse per formare le reti e quindi aiutare a classificare l'importanza dei pesi e dei filtri.I nostri algoritmi PiT possono direttamente potare la rete senza alcun fine-tuning.Le reti potate possono ancora raggiungere prestazioni comparabili alle reti originali. In particolare, introduciamo il (Gruppo) Lasso-tipo Penalità (L-P /GL-P), e (Gruppo) Split LBI Penalità (S-P / GS-P) per regolarizzare le reti, e una strategia di potatura proposta viene utilizzato in aiuto potare la rete.Conduciamo i vasti esperimenti su MNIST, Cifar-10, e miniImageNet.I risultati convalidare l'efficacia dei nostri metodi proposti.Notevolmente, su MNIST dataset, il nostro quadro PiT può salvare 17,5% dimensione del parametro di LeNet-5, che raggiunge il 98,47% precisione di riconoscimento.
Per prima cosa poniamo il problema dell'Unsupervised Continual Learning (UCL): imparare rappresentazioni salienti da un flusso non stazionario di dati non etichettati in cui il numero di classi di oggetti varia con il tempo.Dati dati etichettati limitati appena prima dell'inferenza, quelle rappresentazioni possono anche essere associate a tipi di oggetti specifici per eseguire la classificazione.Per risolvere il problema UCL, proponiamo un'architettura che coinvolge un singolo modulo, chiamato Self-Taught Associative Memory (STAM), che modella vagamente la funzione di una colonna corticale nel cervello dei mammiferi. Gerarchie di moduli STAM imparano sulla base di una combinazione di apprendimento Hebbian, clustering online, rilevamento di nuovi modelli e dimenticando gli outlier, e previsioni top-down. illustriamo il funzionamento di STAM nel contesto dell'apprendimento di cifre scritte a mano in modo continuo con solo 3-12 esempi etichettati per classe. STAM suggerisce una direzione promettente per risolvere il problema UCL senza dimenticare catastroficamente.
I recenti progressi hanno reso possibile la creazione di reti neurali complesse-valutate profonde.Nonostante questo progresso, il potere potenziale di computazioni e rappresentazioni intermedie completamente complesse non è stato ancora esplorato per molti problemi di apprendimento impegnativi.Basandosi sui recenti progressi, proponiamo un nuovo meccanismo per l'estrazione di segnali nel dominio della frequenza.Come caso di studio, eseguiamo la separazione delle fonti audio nel dominio di Fourier.Il nostro meccanismo di estrazione potrebbe essere considerato come un metodo di ensembling locale che combina una versione convoluzionaria a valore complesso di Feature-Wise Linear Modulation (FiLM) e un'operazione di media del segnale. Utilizzando il Wall Street Journal Dataset, confrontiamo la nostra perdita phase-aware con diverse altre che operano sia nel dominio del tempo che in quello della frequenza e dimostriamo l'efficacia del nostro metodo di estrazione del segnale e della perdita proposta. Quando si opera nel dominio della frequenza con valore complesso, la nostra rete profonda con valore complesso supera sostanzialmente le sue controparti con valore reale anche con metà della profondità e un terzo dei parametri.Il nostro meccanismo proposto migliora significativamente le prestazioni delle reti profonde con valore complesso e dimostriamo l'utilità del suo effetto di regolarizzazione.
È impegnativo distinguere un oggetto in due spazi ortogonali di contenuto e stile, poiché ciascuno può influenzare l'osservazione visiva in modo diverso e imprevedibile. è raro che si abbia accesso a un gran numero di dati che aiutino a separare le influenze. in questo articolo, presentiamo un nuovo quadro per apprendere questa rappresentazione distinta in modo completamente non supervisionato. affrontiamo questo problema in un quadro Autoencoder a due rami. per il ramo del contenuto strutturale, proiettiamo il fattore latente in un tensore morbido di punti strutturati e lo vincoliamo con perdite derivanti dalla conoscenza precedente. Questo incoraggia il ramo a distillare le informazioni sulla geometria.Un altro ramo impara le informazioni complementari sullo stile.I due rami formano una struttura efficace che può districare la rappresentazione contenuto-stile dell'oggetto senza alcuna annotazione umana.Valutiamo il nostro approccio su quattro set di dati di immagini, su cui dimostriamo la qualità superiore di disentanglement e analogia visiva sia nei dati sintetizzati che nel mondo reale.Siamo in grado di generare immagini foto-realistiche con risoluzione 256x256 che sono chiaramente distanziate in contenuto e stile.
Sviluppiamo l'Y-learner per stimare effetti di trattamento eterogenei in studi sperimentali e osservazionali.L'Y-learner è progettato per sfruttare le capacità delle reti neurali di ottimizzare obiettivi multipli e aggiornare continuamente, il che permette una migliore messa in comune delle informazioni delle caratteristiche sottostanti tra i gruppi di trattamento e di controllo.Valutiamo l'Y-learner su tre problemi di prova: (1) Un set di sei benchmark di dati simulati dalla letteratura.(2) Un esperimento reale su larga scala sulla persuasione degli elettori.(3) Un compito dalla letteratura che stima gli effetti di trattamento generati artificialmente su MNIST didgits.The Y-learner raggiunge lo stato dell'arte dei risultati su due dei tre compiti.Sul compito MNIST, ottiene il secondo miglior risultato.
Con la rapida proliferazione dei dispositivi IoT, il nostro cyberspazio è oggi dominato da miliardi di nodi di calcolo a basso costo, che espongono una eterogeneità senza precedenti ai nostri sistemi di calcolo.L'analisi dinamica, uno degli approcci più efficaci per trovare i bug del software, è diventata paralizzata a causa della mancanza di un emulatore generico in grado di eseguire diversi firmware mai visti prima. Negli ultimi anni, abbiamo assistito a devastanti violazioni della sicurezza che prendono di mira i dispositivi IoT.Queste preoccupazioni per la sicurezza hanno significativamente ostacolato l'ulteriore evoluzione della tecnologia IoT.In questo lavoro, presentiamo Laelaps, un emulatore di dispositivi specificamente progettato per eseguire diversi software su dispositivi IoT a basso costo. Non codifichiamo nel nostro emulatore alcuna informazione specifica su un dispositivo. Invece, Laelaps infonde il comportamento previsto del firmware attraverso l'emulazione periferica assistita dall'esecuzione simbolica e genera input adeguati per guidare l'esecuzione concreta al volo. Questa caratteristica di progettazione unica rende Laelaps il primo emulatore di dispositivi generici in grado di eseguire diversi firmware senza alcuna conoscenza a priori del dispositivo di destinazione.Per dimostrare le capacità di Laelaps, abbiamo distribuito due tecniche popolari di analisi dinamica---fuzzing testing e l'esecuzione simbolica dinamica-- sopra il nostro emulatore.Abbiamo identificato con successo sia le vulnerabilità auto-iniettate che quelle del mondo reale.
I modelli neurali profondi, come le reti convoluzionali e ricorrenti, raggiungono risultati fenomenali su dati spaziali come immagini e testo.Tuttavia, quando si considerano i dati tabulari, il gradient boosting degli alberi decisionali (GBDT) rimane il metodo di scelta.Mirando a colmare questo divario, proponiamo \emph{ foreste neurali profonde} (DNF) - una nuova architettura che combina elementi di alberi decisionali e connessioni residue dense. Presentiamo i risultati di un ampio studio empirico in cui esaminiamo le prestazioni di GBDTs, DNFs e reti (profonde) completamente connesse. Questi risultati indicano che le DNF raggiungono risultati paragonabili alle GBDT su dati tabulari, e aprono la porta alla modellazione neurale end-to-end di dati multimodali. A tal fine, presentiamo un'applicazione di successo delle DNF come parte di un'architettura ibrida per un compito di classificazione di comprensione della scena di guida multimodale.
Gli ottimizzatori allo stato dell'arte, come AdaGrad, RMSProp e Adam, riducono questo lavoro sintonizzando in modo adattivo un tasso di apprendimento individuale per ogni variabile. Recentemente i ricercatori hanno mostrato un rinnovato interesse per i metodi più semplici come momentum SGD in quanto possono dare risultati migliori. In seguito analizziamo la sua robustezza all'errata specificazione del tasso di apprendimento e alla variazione della curvatura dell'obiettivo. Sulla base di queste intuizioni, progettiamo YellowFin, un tuner automatico per il momentum e il tasso di apprendimento in SGD. YellowFin utilizza opzionalmente un ciclo di feedback negativo per compensare al volo le dinamiche del momentum in impostazioni asincrone. Mostriamo empiricamente che YellowFin può convergere in meno iterazioni di Adam su ResNets e LSTMs per il riconoscimento delle immagini, la modellazione del linguaggio e il parsing dei costituenti, con un incremento di velocità fino a $3.28$x in ambiente sincrono e fino a $2.69$x in ambiente asincrono.
La robustezza e la sicurezza dei sistemi di apprendimento automatico (ML) sono intrecciate, dove un sistema ML non robusto (classificatori, regressori, ecc.) può essere soggetto ad attacchi utilizzando un'ampia varietà di exploit.Con l'avvento di metodologie scalabili di apprendimento profondo, molta enfasi è stata posta sulla robustezza degli algoritmi di apprendimento supervisionati, non supervisionati e di rinforzo. Qui, studiamo la robustezza dello spazio latente di un deep variational autoencoder (dVAE), un framework generativo non supervisionato, per mostrare che è effettivamente possibile perturbare lo spazio latente, capovolgere le previsioni di classe e mantenere la probabilità di classificazione approssimativamente uguale prima e dopo un attacco.
Il parsing delle dipendenze basato sui grafici consiste in due passi: in primo luogo, un codificatore produce una rappresentazione delle caratteristiche per ogni sottostruttura di parsing della frase di input, che viene poi utilizzata per calcolare un punteggio per la sottostruttura; e in secondo luogo, un decodificatore} trova l'albero di parsing le cui sottostrutture hanno il punteggio totale più grande. Negli ultimi anni, sono state introdotte potenti tecniche neurali nella fase di codifica che aumentano sostanzialmente l'accuratezza del parsing; tuttavia, le tecniche di decodifica avanzate, in particolare la decodifica di alto ordine, hanno visto un declino nell'uso. È opinione diffusa che le caratteristiche contestualizzate prodotte dai codificatori neurali possano aiutare a catturare informazioni di alto ordine di decodifica e quindi diminuire la necessità di un decodificatore di alto ordine. In questo articolo, valutiamo empiricamente le combinazioni di diverse codifiche neurali e non neurali con decodificatori del primo e del secondo ordine e forniamo un'analisi completa sull'efficacia di queste combinazioni con varie dimensioni di dati di allenamento. Troviamo che: in primo luogo, quando ci sono grandi dati di formazione, un forte codificatore neurale con decodifica del primo ordine è sufficiente per raggiungere un'elevata accuratezza di parsing e solo leggermente in ritardo rispetto alla combinazione di codifica neurale e decodifica del secondo ordine; in secondo luogo, con piccoli dati di formazione, un codificatore non neurale con un decoder del secondo ordine supera le altre combinazioni nella maggior parte dei casi.   
Il meta-apprendimento sarà cruciale per creare un'intelligenza artificiale che duri tutta la vita e sia generalizzabile.In pratica, tuttavia, è difficile definire la distribuzione dei compiti di meta-formazione che viene utilizzata per addestrare i meta-apprendisti.Se fatta troppo piccola, i compiti sono troppo simili perché un modello possa generalizzare significativamente.Se fatta troppo grande, la generalizzazione diventa incredibilmente difficile. Sosteniamo che entrambi i problemi possono essere alleviati introducendo un modello di insegnante che controlla la sequenza di compiti su cui viene addestrato un meta-apprendente. Questo modello di insegnante è incentivato a iniziare lo studente meta-apprendente su compiti semplici e poi ad aumentare in modo adattivo la difficoltà del compito in risposta ai progressi dello studente.Mentre questo approccio è stato precedentemente studiato nella generazione del curriculum, il nostro contributo principale è nell'estenderlo al meta-apprendimento.
Utilizzando la conoscenza di ordine superiore per ridurre i dati di formazione è diventato un argomento di ricerca popolare.Tuttavia, la capacità dei metodi disponibili di disegnare i confini decisionali efficaci è ancora limitata: quando il set di formazione è piccolo, le reti neurali saranno distorte verso alcune etichette.Sulla base di questa osservazione, consideriamo la distribuzione di probabilità di uscita vincolante come conoscenza di dominio di ordine superiore.Progettiamo un nuovo algoritmo che ottimizza congiuntamente la distribuzione di probabilità di uscita su uno spazio clustered embedding per rendere le reti neurali disegnare confini decisionali efficaci.  Mentre l'applicazione diretta del vincolo di probabilità non è efficace, gli utenti hanno bisogno di fornire ulteriori supervisioni molto deboli: contrassegnare alcuni lotti che hanno una distribuzione di uscita molto diversa dalla distribuzione di probabilità di destinazione.Usiamo gli esperimenti per dimostrare empiricamente che il nostro modello può convergere a una precisione superiore ad altri modelli di apprendimento semi-supervisionato allo stato dell'arte con meno esempi di formazione etichettati di alta qualità.
Introduciamo un nuovo tipo di rappresentazione profonda contestualizzata delle parole che modella sia (1) le caratteristiche complesse dell'uso delle parole (per esempio, sintassi e semantica), sia (2) come questi usi variano attraverso i contesti linguistici (cioè, per modellare la polisemia).  I nostri vettori di parole sono funzioni apprese degli stati interni di un modello linguistico bidirezionale profondo (biLM), che è preaddestrato su un grande corpus di testo. Mostriamo che queste rappresentazioni possono essere facilmente aggiunte ai modelli esistenti e migliorano significativamente lo stato dell'arte in sei impegnativi problemi NLP, tra cui la risposta alle domande, l'entailment testuale e la sentiment analysis.  Presentiamo anche un'analisi che mostra che esporre gli interni profondi della rete preaddestrata è cruciale, permettendo ai modelli a valle di mescolare diversi tipi di segnali di semi-supervisione.
Questo lavoro affronta l'annoso problema della localizzazione robusta degli eventi in presenza di etichette disallineate temporalmente nei dati di formazione. Proponiamo una nuova funzione di perdita versatile che generalizza una serie di regimi di formazione, dalla cross-entropia standard completamente supervisionata all'apprendimento debolmente supervisionato basato sul conteggio. L'addestramento con questa nuova funzione di perdita mostra una forte robustezza al disallineamento temporale delle etichette, alleviando così l'onere dell'annotazione precisa delle sequenze temporali. Dimostriamo prestazioni allo stato dell'arte contro i benchmark standard in una serie di esperimenti impegnativi e dimostriamo inoltre che la robustezza al rumore delle etichette non si ottiene a spese delle prestazioni grezze.
La forza trainante delle reti profonde è la loro capacità di rappresentare in modo compatto classi ricche di funzioni. La nozione primaria per ragionare formalmente su questo fenomeno è l'efficienza espressiva, che si riferisce a una situazione in cui una rete deve crescere in modo insostenibile per replicare le funzioni di un'altra. Fino ad oggi, le analisi dell'efficienza espressiva si sono concentrate sulla caratteristica architetturale della profondità, mostrando che le reti profonde sono rappresentativamente superiori a quelle superficiali. In questo articolo studiamo l'efficienza espressiva portata avanti dalla connettività, motivata dall'osservazione che le reti moderne interconnettono i loro strati in modi elaborati.Ci concentriamo sulle reti convoluzionali dilatate, una famiglia di modelli profondi che offrono prestazioni allo stato dell'arte nei compiti di elaborazione delle sequenze. Introducendo e analizzando il concetto di decomposizioni tensoriali miste, dimostriamo che l'interconnessione delle reti convoluzionali dilatate può portare all'efficienza espressiva. In particolare, dimostriamo che anche una sola connessione tra gli strati intermedi può già portare a un divario quasi quadratico, che nelle impostazioni su larga scala fa tipicamente la differenza tra un modello che è pratico e uno che non lo è. La valutazione empirica dimostra come l'efficienza espressiva della connettività, similmente a quella della profondità, si traduca in guadagni di accuratezza. Questo ci porta a credere che l'efficienza espressiva possa servire un ruolo chiave nello sviluppo di nuovi strumenti per la progettazione di reti profonde.
Il set di dati MNIST è stato definito come la drosofila dell'apprendimento automatico ed è stato il banco di prova di molte teorie di apprendimento. Il set di dati NotMNIST e il set di dati FashionMNIST sono stati creati con il set di dati MNIST come riferimento.In questo lavoro, sfruttiamo questi set di dati MNIST-like per l'apprendimento multi-task. Il modello di riconoscimento di base è costituito da reti neurali a rivoluzione totale. Senza apprendimento multitasking, le accuratezze di riconoscimento per MNIST, NotMNIST e FashionMNIST sono del 99,56%, 97,22% e 94,32%. Con l'apprendimento multi-task per pre-addestrare le reti, le accuratezze di riconoscimento sono rispettivamente 99,70%, 97,46% e 95,25%. I risultati riaffermano che il quadro di apprendimento multi-task, anche con dati di generi diversi, porta a un miglioramento significativo.
Un lavoro recente ha dimostrato che le reti neurali sono vulnerabili agli esempi avversi, cioè Per affrontare questo problema, studiamo la robustezza avversaria delle reti neurali attraverso la lente dell'ottimizzazione robusta. Questo approccio ci fornisce una visione ampia e unificante su molti lavori precedenti su questo argomento. La sua natura di principio ci permette anche di identificare metodi sia per l'addestramento che per attaccare le reti neurali che sono affidabili e, in un certo senso, universali. Questi metodi ci permettono di addestrare reti con una resistenza significativamente migliorata a un'ampia gamma di attacchi avversari e suggeriscono la robustezza contro un avversario del primo ordine come una garanzia naturale di sicurezza, riteniamo che la robustezza contro tali classi ben definite di avversari sia un importante passo avanti verso modelli di apprendimento profondo completamente resistenti.
Negli ultimi anni c'è stato un rapido aumento dei metodi di classificazione su dati strutturati a grafo.Sia nei kernel a grafo che nelle reti neurali a grafo, uno dei presupposti impliciti dei modelli di successo allo stato dell'arte era che incorporare le caratteristiche di isomorfismo del grafo nell'architettura porta a migliori prestazioni empiriche.Tuttavia, come scopriamo in questo lavoro, i set di dati comunemente usati per la classificazione a grafo hanno istanze ripetute che causano il problema del bias di isomorfismo, cioè Questo impedisce una competizione leale tra gli algoritmi e solleva una questione sulla validità dei risultati ottenuti.Analizziamo 54 set di dati, precedentemente ampiamente utilizzati per compiti legati ai grafi, sull'esistenza del bias di isomorfismo, diamo una serie di raccomandazioni ai professionisti dell'apprendimento automatico per impostare correttamente i loro modelli, e apriamo nuovi set di dati per gli esperimenti futuri.
L'apprendimento per imitazione, seguito da algoritmi di apprendimento per rinforzo, è un paradigma promettente per risolvere compiti di controllo complessi in modo efficiente dal punto di vista campionario. Tuttavia, l'apprendimento dalle dimostrazioni spesso soffre del problema dello spostamento delle covariate, che si traduce in errori a cascata della politica appresa.Introduciamo una nozione di funzioni di valore estrapolate in modo conservativo, che portano provatamente a politiche con auto-correzione. Progettiamo un algoritmo Value Iteration with Negative Sampling (VINS) che praticamente impara tali funzioni di valore con estrapolazione conservativa.Mostriamo che VINS può correggere gli errori della politica di clonazione comportamentale su compiti di riferimento di robotica simulata.Proponiamo anche l'algoritmo di utilizzo di VINS per inizializzare un algoritmo di apprendimento di rinforzo, che è dimostrato di superare i lavori precedenti in efficienza del campione.
Una comprensione strutturata del nostro mondo in termini di oggetti, relazioni e gerarchie è una componente importante della cognizione umana.Imparare un tale modello strutturato del mondo dai dati sensoriali grezzi rimane una sfida.Come un passo verso questo obiettivo, introduciamo Contrastively-trained Structured World Models (C-SWMs).C-SWMs utilizzano un approccio contrastivo per l'apprendimento della rappresentazione in ambienti con struttura compositiva.Strutturiamo ogni incorporazione di stato come un insieme di rappresentazioni di oggetti e le loro relazioni, modellato da una rete neurale a grafo. I nostri esperimenti dimostrano che i C-SWM possono superare i limiti dei modelli basati sulla ricostruzione dei pixel e superare i tipici rappresentanti di questa classe di modelli in ambienti altamente strutturati, mentre imparano rappresentazioni interpretabili basate sugli oggetti.
I modelli di traduzione automatica neurale (NMT) imparano rappresentazioni contenenti informazioni linguistiche sostanziali, ma non è chiaro se tali informazioni siano completamente distribuite o se alcune di esse possano essere attribuite a singoli neuroni. I nostri metodi si basano sull'intuizione che diversi modelli apprendono proprietà simili, e non richiedono alcuna costosa supervisione esterna.Mostriamo sperimentalmente che la qualità della traduzione dipende dai neuroni scoperti, e troviamo che molti di essi catturano fenomeni linguistici comuni.Infine, mostriamo come controllare le traduzioni NMT in modi prevedibili, modificando le attivazioni dei singoli neuroni.
I calcoli per la funzione softmax nei modelli di rete neurale sono costosi quando il numero di classi di output è grande, il che può diventare un problema significativo sia nell'addestramento che nell'inferenza per tali modelli. In questo articolo, presentiamo Doubly Sparse Softmax (DS-Softmax), Sparse Mixture of Sparse of Sparse Experts, per migliorare l'efficienza dell'inferenza softmax. Ogni esperto è responsabile di un sottoinsieme appreso dello spazio delle classi di uscita e ogni classe di uscita appartiene solo a un piccolo numero di questi esperti.Durante l'inferenza, il nostro metodo individua rapidamente l'esperto più probabile per calcolare softmax su piccola scala.Il nostro metodo è basato sull'apprendimento e non richiede alcuna conoscenza dello spazio di partizione delle classi di uscita a priori.Valutiamo empiricamente il nostro metodo su diversi compiti del mondo reale e dimostriamo che possiamo ottenere significative riduzioni di calcolo senza perdita di
Il nostro lavoro presenta l'evidenza empirica che la rotazione degli strati, cioè l'evoluzione durante l'addestramento della distanza coseno tra il vettore dei pesi di ogni strato e la sua inizializzazione, costituisce un indicatore impressionantemente coerente delle prestazioni di generalizzazione. Rispetto agli indicatori di generalizzazione studiati in precedenza, dimostriamo che la rotazione degli strati ha l'ulteriore vantaggio di essere facilmente monitorata e controllata, oltre ad avere un optimum indipendente dalla rete: le procedure di addestramento durante le quali tutti i pesi degli strati raggiungono una distanza coseno di 1 dalla loro inizializzazione superano costantemente le altre configurazioni - fino al 20% di accuratezza del test.Infine, i nostri risultati suggeriscono anche che lo studio della rotazione degli strati può fornire un quadro unificato per spiegare l'impatto del decadimento del peso e dei metodi di gradiente adattivo sulla generalizzazione.
I modelli di codice possono imparare rappresentazioni distribuite della sintassi e della semantica di un programma per predire molte proprietà non banali di un programma. I recenti modelli all'avanguardia sfruttano rappresentazioni altamente strutturate dei programmi, come alberi, grafici e percorsi (ad esempio le relazioni di flusso di dati), che sono precise e abbondantemente disponibili per il codice, il che fornisce un forte bias induttivo verso relazioni semanticamente significative, producendo rappresentazioni più generalizzabili dei classici modelli basati sulla sequenza. Sfortunatamente, questi modelli si basano principalmente sul passaggio di messaggi basati su grafici per rappresentare le relazioni nel codice, il che li rende de facto locali a causa dell'alto costo dei passaggi di messaggi, in netto contrasto con i moderni modelli basati su sequenze globali, come il Transformer.In questo lavoro, colmiamo questo divario tra modelli globali e strutturati introducendo due nuove famiglie di modelli ibridi che sono sia globali che incorporano bias strutturali: Graph Sandwiches, che avvolgono i tradizionali livelli di message-passing a grafo (gated) in livelli di message-passing sequenziale; e Graph Relational Embedding Attention Transformers (GREAT in breve), che condizionano i Transformers tradizionali con informazioni relazionali dai tipi di bordo del grafico. Studiando un popolare e non banale compito di riparazione del programma, l'identificazione dell'abuso di variabili, esploriamo i meriti relativi delle famiglie di modelli tradizionali e ibridi per la rappresentazione del codice. Partendo da un modello basato sul grafico che già migliora del 20% lo stato dell'arte precedente per questo compito, dimostriamo che i nostri modelli ibridi proposti migliorano di un ulteriore 10-15%, mentre si allenano sia più velocemente che usando meno parametri.
Le reti neurali ricorrenti (RNN) sono particolarmente adatte a modellare le dipendenze a lungo termine nei dati sequenziali, ma sono notoriamente difficili da addestrare perché l'errore retropropagato nel tempo o svanisce o esplode ad un tasso esponenziale. Mentre un certo numero di lavori cerca di mitigare questo effetto attraverso unità ricorrenti gated, skip-connections, vincoli parametrici e scelte progettuali, noi proponiamo un nuovo RNN incrementale (iRNN), dove i vettori di stato nascosti tengono traccia dei cambiamenti incrementali, e come tali approssimano gli incrementi dei vettori di stato delle RNN a tempo continuo di Rosenblatt (1962). Dimostriamo che il nostro metodo è computazionalmente efficiente, superando le spese generali di molti metodi esistenti che tentano di migliorare l'addestramento RNN, senza subire alcun degrado delle prestazioni. Dimostriamo l'utilità del nostro approccio con ampi esperimenti e mostriamo prestazioni competitive contro le LSTM standard su compiti LTD e altri non-LTD.
I recenti risultati empirici sulle reti profonde iper-parametrizzate sono caratterizzati da una sorprendente assenza della classica curva di errore di test a forma di U: l'errore di test continua a diminuire in reti più ampie.I ricercatori stanno lavorando attivamente per colmare questa discrepanza proponendo misure di complessità migliori.Invece, misuriamo direttamente la distorsione e la varianza di predizione per quattro compiti di classificazione e regressione su reti profonde moderne.Troviamo che sia la distorsione che la varianza possono diminuire quando il numero di parametri cresce. Per comprendere meglio il ruolo dell'ottimizzazione, scomponiamo la varianza totale in varianza dovuta al campionamento del set di allenamento e varianza dovuta all'inizializzazione. La varianza dovuta all'inizializzazione è significativa nel regime sotto-parametrizzato, mentre nel regime sovra-parametrizzato la varianza totale è molto più bassa e dominata dalla varianza dovuta al campionamento.
Le immagini del mondo reale contengono spesso grandi quantità di informazioni private/sensibili che dovrebbero essere accuratamente protette senza ridurre le loro utilità. In questo articolo, proponiamo un quadro di apprendimento profondo che preserva la privacy con un offuscatore apprendibile per il compito di classificazione delle immagini, il nostro quadro consiste di tre modelli: offuscatore apprendibile, classificatore e ricostruttore. Al fine di proteggere al meglio la privacy degli utenti nelle immagini, progettiamo un metodo di addestramento avversario per la nostra struttura per ottimizzare l'offuscatore. Attraverso ampie valutazioni su set di dati del mondo reale, sia le metriche numeriche che i risultati di visualizzazione dimostrano che la nostra struttura è qualificata per proteggere la privacy degli utenti e raggiungere una precisione relativamente alta nel compito di classificazione delle immagini.
Bitcoin è un sistema di monete virtuali che permette agli utenti di commerciare virtualmente senza un'autorità centrale fidata.Tutte le transazioni sulla blockchain di Bitcoin sono pubblicamente disponibili per la visualizzazione, ma poiché Bitcoin è costruito principalmente per la sicurezza, la sua struttura originale non permette l'analisi diretta delle transazioni di indirizzi. I metodi di analisi esistenti della blockchain di Bitcoin possono essere complicati, computazionalmente costosi o imprecisi.Proponiamo un modello computazionalmente efficiente per analizzare gli indirizzi della blockchain di Bitcoin e permetterne l'uso con gli algoritmi di apprendimento automatico esistenti.Confrontiamo il nostro approccio contro i Multi Level Sequence Learners (MLSL), uno dei modelli con le migliori prestazioni sui dati degli indirizzi Bitcoin.
Nonostante il notevole successo empirico, la dinamica di formazione delle reti generative avversarie (GAN), che comporta la risoluzione di un gioco minimax utilizzando gradienti stocastici, è ancora poco compresa.In questo lavoro, analizziamo la convergenza all'ultimo istante della discesa simultanea del gradiente (simGD) e le sue varianti sotto l'assunzione di convessità-concavità, guidata da un'analisi a tempo continuo con equazioni differenziali. In primo luogo, mostriamo che simGD, così com'è, converge con sub-gradienti stocastici sotto stretta convessità nella variabile primaria.In secondo luogo, generalizziamo simGD ottimistico per ospitare un tasso di ottimismo separato dal tasso di apprendimento e mostriamo la sua convergenza con gradienti completi.Infine, presentiamo simGD ancorato, un nuovo metodo, e mostriamo la convergenza con subgradienti stocastici.
I piccoli veicoli spaziali ora hanno sistemi di controllo di atteggiamento precisi disponibili commercialmente, permettendo che slittino in 3 gradi di libertÃ e catturino le immagini entro breve preavviso.Quando combinato con software appropriato, questa agilitÃ puÃ² aumentare significativamente il tasso di risposta, il tempo di rivisitazione e coverage.In lavoro precedente, abbiamo dimostrato una struttura algoritmica che combina la meccanica orbitale, il controllo di atteggiamento e l'ottimizzazione di programmazione per pianificare il tempo-variabile, orientamento del corpo intero del veicolo spaziale agile e piccolo in una costellazione. L'algoritmo è generalizzabile su piccoli veicoli spaziali orientabili, capacità di controllo, specifiche dei sensori, requisiti di imaging e regioni di interesse. In questo articolo, modifichiamo l'algoritmo per l'esecuzione a bordo di piccoli veicoli spaziali, in modo che la costellazione possa prendere decisioni sensibili al tempo per ruotare e catturare immagini autonomamente, senza controllo a terra. Abbiamo sviluppato un modulo di comunicazione basato su Delay/Disruption Tolerant Networking (DTN) per la gestione dei dati a bordo e il routing tra i satelliti, che lavorerà in collaborazione con gli altri moduli per ottimizzare il programma di comunicazione agile e sterzo. Applichiamo poi questo quadro preliminare su costellazioni rappresentative per simulare misurazioni mirate di eventi di precipitazione episodica e successive inondazioni urbane.L'efficienza di comando e controllo del nostro algoritmo agile viene confrontata con costellazioni non agili (miglioramento 11.3x) e non-DTN (miglioramento 21%).
Il campionamento di importanza (IS) è uno strumento standard di Monte Carlo (MC) per calcolare informazioni su variabili casuali come momenti o quantili con distribuzioni sconosciute.  IS è asintoticamente coerente con il numero di campioni MC, e quindi delta (particelle) che parametrizzano la stima della densità, vanno all'infinito. Tuttavia, mantenere un numero infinito di particelle è intrattabile. Noi proponiamo uno schema per mantenere solo un sottoinsieme rappresentativo infinito di particelle e i loro pesi di importanza aumentati che è quasi coerente. Per farlo in {modo online}, approssimiamo il campionamento dell'importanza in due modi.  In primo luogo, sostituiamo i delta con i kernel, ottenendo stime di densità del kernel (KDE).  Caratterizziamo la distorsione asintotica di questo schema come determinata da un parametro di compressione e dalla larghezza di banda del kernel, che produce un compromesso sintonizzabile tra coerenza e memoria. Negli esperimenti, osserviamo un compromesso favorevole tra memoria e precisione, fornendo per la prima volta compressioni quasi coerenti di distribuzioni posteriori arbitrarie.
Studiamo i seguenti tre problemi fondamentali sulla regressione di cresta: (1) qual è la struttura dello stimatore? (2) come usare correttamente la convalida incrociata per scegliere il parametro di regolarizzazione? e (3) come accelerare il calcolo senza perdere troppa accuratezza? Consideriamo i tre problemi in un modello lineare unificato di grandi dati e diamo una rappresentazione precisa della regressione ridge come una combinazione lineare dipendente dalla matrice di covarianza del parametro vero e del rumore. Studiamo il bias di $K$-fold cross-validation per la scelta del parametro di regolarizzazione, e proponiamo una semplice bias-correzione.Analizziamo l'accuratezza di primal e dual sketching per la regressione ridge, mostrando che sono sorprendentemente accurati.I nostri risultati sono illustrati da simulazioni e dall'analisi di dati empirici.
I meccanismi di attenzione hanno avanzato lo stato dell'arte in diversi compiti di apprendimento automatico; nonostante i significativi guadagni empirici, c'è una mancanza di analisi teoriche sulla comprensione della loro efficacia. In questo articolo, affrontiamo questo problema studiando il paesaggio della popolazione e le funzioni di perdita empiriche delle reti neurali basate sull'attenzione; i nostri risultati mostrano che, sotto ipotesi blande, ogni minimo locale di un modello di attenzione globale a due strati ha un basso errore di predizione, e i modelli di attenzione richiedono una complessità del campione inferiore ai modelli che non utilizzano l'attenzione. Abbiamo poi esteso le nostre analisi al popolare modello di auto-attenzione, dimostrando che forniscono previsioni coerenti con una classe più espressiva di funzioni.Inoltre, i nostri risultati teorici forniscono diverse linee guida per la progettazione di meccanismi di attenzione.I nostri risultati sono convalidati con risultati sperimentali soddisfacenti su MNIST e IMDB recensioni dataset.
I recenti progressi nelle tecniche di apprendimento profondo hanno dimostrato l'utilità delle reti neurali profonde nell'estrarre le caratteristiche necessarie per eseguire il compito a portata di mano.Tuttavia, queste caratteristiche apprese sono in particolare utili solo per il compito iniziale.Questo è dovuto al fatto che le caratteristiche apprese sono molto specifiche del compito e non cattura le caratteristiche più generali e agnostiche del compito di input.Infatti il modo in cui gli esseri umani sono visti per imparare è da disentangling caratteristiche che compito agnostico. Questo indica che l'apprendimento di caratteristiche agnostiche al compito distingue solo le caratteristiche più informative dai dati di input.recentemente Variational Auto-Encoders (VAEs) hanno dimostrato di essere i modelli de-facto per catturare le variabili latenti in un senso generativo.come queste caratteristiche latenti possono essere rappresentate come variabili continue e/o discrete, questo ci indica di usare VAE con una miscela di variabili continue e discrete per lo spazio latente.otteniamo questo eseguendo i nostri esperimenti usando una versione modificata di joint-vae per imparare le caratteristiche disentangled.
La teoria del collo di bottiglia informativo dell'apprendimento profondo propone che le reti neurali raggiungano una buona generalizzazione comprimendo le loro rappresentazioni per ignorare le informazioni che non sono rilevanti per il compito, ma le prove empiriche di questa teoria sono contrastanti, poiché la compressione è stata osservata solo quando le reti hanno usato funzioni di attivazione saturanti. In questo lavoro abbiamo sviluppato tecniche di stima dell'informazione reciproca più robuste, che si adattano all'attività nascosta delle reti neurali e producono misurazioni più sensibili delle attivazioni di tutte le funzioni, specialmente quelle non vincolate. Utilizzando queste tecniche di stima adattiva, abbiamo esplorato la compressione nelle reti con una gamma di funzioni di attivazione diverse.Con due metodi migliorati di stima, in primo luogo, mostriamo che la saturazione della funzione di attivazione non è necessaria per la compressione, e la quantità di compressione varia tra le diverse funzioni di attivazione.Troviamo anche che c'è una grande quantità di variazione nella compressione tra diverse inizializzazioni di rete.In secondo luogo, vediamo che la regolarizzazione L2 porta ad una compressione significativamente aumentata, mentre impedisce l'overfitting.Infine, mostriamo che solo la compressione dell'ultimo strato è correlata positivamente con la generalizzazione.
In questo lavoro, affrontiamo il problema del trasferimento del timbro musicale, dove l'obiettivo è quello di manipolare il timbro di un campione di suono da uno strumento per abbinare un altro strumento, preservando altri contenuti musicali, come l'altezza, il ritmo e la loudness.In linea di principio, si potrebbero applicare tecniche di trasferimento di stile basate sulle immagini a una rappresentazione tempo-frequenza di un segnale audio, ma questo dipende dall'avere una rappresentazione che permette la manipolazione indipendente del timbro così come la generazione di forme d'onda di alta qualità. Introduciamo TimbreTron, un metodo per il trasferimento del timbro musicale che applica il trasferimento di stile nel dominio dell'immagine a una rappresentazione tempo-frequenza del segnale audio, e poi produce una forma d'onda di alta qualità usando un sintetizzatore WaveNet condizionato. Abbiamo dimostrato che la rappresentazione Constant Q Transform (CQT) è particolarmente adatta alle architetture convoluzionali grazie alla sua equivarianza approssimativa dell'intonazione. Sulla base di valutazioni percettive umane, abbiamo confermato che TimbreTron ha trasferito in modo riconoscibile il timbro preservando il contenuto musicale, sia per campioni monofonici che polifonici. Abbiamo realizzato un video dimostrativo di accompagnamento qui: https://www.cs.toronto.edu/~huang/TimbreTron/index.html che vi invitiamo caldamente a guardare prima di leggere il documento.
L'hardware neuromorfico tende a porre dei limiti alla connettività delle reti profonde che si possono eseguire su di esse, ma anche le implementazioni hardware e software generiche dell'apprendimento profondo funzionano in modo più efficiente per le reti rade.Esistono diversi metodi per potare le connessioni di una rete neurale dopo che è stata addestrata senza vincoli di connettività.Presentiamo un algoritmo, DEEP R, che ci permette di addestrare direttamente una rete neurale scarsamente collegata. DEEP R riscrive automaticamente la rete durante l'addestramento supervisionato in modo che le connessioni siano lì dove sono più necessarie per il compito, mentre il loro numero totale è sempre strettamente limitato. Dimostriamo che DEEP R può essere usato per addestrare reti neurali feedforward e ricorrenti molto rade su compiti standard di riferimento con solo una piccola perdita di prestazioni.
Il successo dell'apprendimento profondo ha portato a modelli sempre più grandi per gestire compiti sempre più complessi; i modelli addestrati possono contenere milioni di parametri. Questi modelli di grandi dimensioni sono ad alta intensità di calcolo e di memoria, il che rende una sfida distribuirli con una latenza ridotta al minimo, il throughput e i requisiti di archiviazione.Alcuni metodi di compressione dei modelli sono stati applicati con successo alla classificazione e al rilevamento delle immagini o ai modelli linguistici, ma c'è stato pochissimo lavoro di compressione delle reti generative avversarie (GAN) che svolgono compiti complessi. In questa carta, mostriamo che una tecnica standard di compressione del modello, la potatura del peso, non può essere applicata a GANs usando i metodi esistenti. Poi sviluppiamo una tecnica di compressione auto-supervisionata che usa il discriminatore addestrato per sorvegliare la formazione di un generatore compresso. Mostriamo che questa struttura ha una prestazione irresistibile agli alti gradi di sparsità, generalizza bene ai nuovi compiti e modelli e permette i confronti significativi fra le granularità di potatura differenti.
La formazione distribuita su larga scala richiede una significativa larghezza di banda di comunicazione per lo scambio di gradiente che limita la scalabilità della formazione multi-nodo, e richiede costose infrastrutture di rete ad alta larghezza di banda. In questo articolo, troviamo che il 99,9% dello scambio di gradiente in SGD distribuito è ridondante, e proponiamo la Deep Gradient Compression (DGC) per ridurre notevolmente la larghezza di banda di comunicazione.Per preservare la precisione durante la compressione, DGC impiega quattro metodi: correzione del momento, ritaglio del gradiente locale, mascheramento del fattore di momento, e formazione di riscaldamento. Abbiamo applicato la Deep Gradient Compression alla classificazione delle immagini, al riconoscimento vocale e alla modellazione del linguaggio con diversi set di dati, tra cui Cifar10, ImageNet, Penn Treebank e Librispeech Corpus. Su questi scenari, Deep Gradient Compression raggiunge un rapporto di compressione del gradiente da 270x a 600x senza perdere precisione, tagliando la dimensione del gradiente di ResNet-50 da 97MB a 0. 35MB, e per DeepSpeech Corpus la dimensione del gradiente di ResNet-50 è di 0MB. 35MB, e per DeepSpeech da 488MB a 0.74MB.Deep gradient compression permette l'addestramento distribuito su larga scala su commodity 1Gbps Ethernet a basso costo e facilita l'addestramento distribuito su mobile.
La maggior parte dei lavori si concentra sull'apprendimento di una mappatura uno-a-uno in modo non supervisionato o di una mappatura molti-a-molti in modo supervisionato. Tuttavia, un'impostazione più pratica è la mappatura molti-a-molti in modo non supervisionato, che è più difficile a causa della mancanza di supervisione e delle complesse variazioni interne e tra domini. Per alleviare questi problemi, proponiamo la rete Exemplar Guided & Semantically Consistent Image-to-image Translation (EGSC-IT) che condiziona il processo di traduzione su un'immagine esemplare nel dominio di destinazione. Sotto la guida di un esemplare del dominio di destinazione, applichiamo l'Adaptive Instance Normalization alla componente di contenuto condivisa, che ci permette di trasferire le informazioni di stile del dominio di destinazione al dominio di origine. Per evitare incoerenze semantiche durante la traduzione che appaiono naturalmente a causa delle grandi variazioni interne e tra i domini, introduciamo il concetto di maschere di caratteristiche che forniscono una guida semantica grossolana senza richiedere l'uso di etichette semantiche. I risultati sperimentali su vari set di dati mostrano che EGSC-IT non solo traduce l'immagine sorgente in diverse istanze nel dominio di destinazione, ma conserva anche la coerenza semantica durante il processo.
Le reti neurali profonde possono imparare rappresentazioni significative dei dati, ma queste rappresentazioni sono difficili da interpretare. Per esempio, la visualizzazione di uno strato latente è generalmente possibile solo per un massimo di tre dimensioni. Le reti neurali sono in grado di imparare e beneficiare di rappresentazioni dimensionali molto più alte, ma queste non sono interpretabili visivamente perché i nodi hanno un ordine arbitrario all'interno di uno strato. Qui, utilizziamo la capacità dell'osservatore umano di identificare i modelli nelle rappresentazioni strutturate per visualizzare le dimensioni più alte. Per fare ciò, proponiamo una classe di regolarizzazioni che chiamiamo \textit{Graph Spectral Regularizations} che impongono una struttura a grafo sugli strati latenti. Questo si ottiene trattando le attivazioni come segnali su un grafico predefinito e vincolando quelle attivazioni usando filtri a grafo, come i filtri passa basso e wavelet-like. Questa struttura permette qualsiasi tipo di grafo e di filtro per ottenere una vasta gamma di regolarizzazioni strutturate a seconda delle esigenze di inferenza dei dati.In primo luogo, mostriamo un esempio sintetico che lo strato strutturato a grafo può rivelare le caratteristiche topologiche dei dati.Successivamente, mostriamo che una regolarizzazione di smoothing può imporre un ordinamento semanticamente coerente dei nodi quando applicata alle reti di capsule. In altre parole, la mappatura tra lo strato latente, i neuroni e lo spazio di uscita diventa chiara grazie alla localizzazione delle attivazioni. Infine, mostriamo che quando sono strutturate come una griglia, le rappresentazioni creano immagini coerenti che consentono tecniche di elaborazione delle immagini come le convoluzioni.
La generazione del testo è onnipresente in molti compiti di PNL, dal riassunto al dialogo e alla traduzione automatica. L'approccio parametrico dominante è basato su modelli localmente normalizzati che prevedono una parola alla volta. Mentre questi funzionano notevolmente bene, sono afflitti da bias di esposizione dovuti alla natura avida del processo di generazione. Inoltre, poiché l'EBM funziona a livello di sequenza, possiamo sfruttare le rappresentazioni contestuali bidirezionali preaddestrate, come BERT e RoBERTa.I nostri esperimenti su due grandi set di dati di modellazione linguistica mostrano che gli EBM residui producono una perplessità inferiore rispetto ai modelli di base normalizzati localmente.Inoltre, la generazione tramite campionamento per importanza è molto efficiente e di qualità superiore ai modelli di base secondo la valutazione umana.
Indaghiamo le proprietà di robustezza dei modelli di riconoscimento delle immagini dotati di due caratteristiche ispirate alla visione umana, una memoria episodica esplicita e un bias di forma, su scala ImageNet.Come riportato nel lavoro precedente, dimostriamo che una memoria episodica esplicita migliora la robustezza dei modelli di riconoscimento delle immagini contro le perturbazioni avversarie a piccola norma sotto alcuni modelli di minaccia. Non migliora, tuttavia, la robustezza contro perturbazioni più naturali, e tipicamente più grandi.Imparare caratteristiche più robuste durante l'addestramento sembra essere necessario per la robustezza in questo secondo senso.Mostriamo che le caratteristiche derivate da un modello che è stato incoraggiato a imparare rappresentazioni globali, basate sulla forma (Geirhos et al, 2019) non solo migliorano la robustezza contro le perturbazioni naturali, ma quando vengono utilizzate insieme a una memoria episodica, forniscono anche un'ulteriore robustezza contro le perturbazioni avversarie.Infine, affrontiamo tre importanti scelte di progettazione per la memoria episodica: la dimensione della memoria, la dimensionalità delle memorie e il metodo di recupero.Mostriamo che per rendere la memoria episodica più compatta, è preferibile ridurre il numero di memorie raggruppandole, invece di ridurre la loro dimensionalità.
Le reti neurali convoluzionali di gruppo (G-CNNs) possono essere usate per migliorare le CNN classiche dotandole della struttura geometrica dei gruppi.Centrale nel successo delle G-CNNs è il sollevamento delle mappe di caratteristiche a rappresentazioni disentangled di dimensione superiore, in cui le caratteristiche dei dati sono efficacemente apprese, i dati geometrici-augmentati sono resi obsoleti, e il comportamento prevedibile sotto trasformazioni geometriche (equivarianza) è garantito tramite la teoria dei gruppi. Attualmente, tuttavia, le implementazioni pratiche delle G-CNN sono limitate o a gruppi discreti (che lasciano la griglia intatta) o a gruppi compatti continui come le rotazioni (che permettono l'uso della teoria di Fourier).In questo articolo eliminiamo queste limitazioni e proponiamo una struttura modulare per la progettazione e l'implementazione di G-CNN per gruppi di Lie arbitrari. Nel nostro approccio la struttura differenziale dei gruppi di Lie è usata per espandere i kernel di convoluzione in una base generica di B-spline che è definita sull'algebra di Lie. Questo porta a un quadro flessibile che permette convoluzioni localizzate, atre e deformabili nelle G-CNNs per mezzo di espansioni B-spline rispettivamente localizzate, rade e non uniformi. L'impatto e il potenziale del nostro approccio sono studiati su due set di dati di riferimento: il rilevamento del cancro nei vetrini istopatologici (dataset PCam) in cui l'equivarianza di rotazione gioca un ruolo chiave e la localizzazione dei punti di riferimento facciali (dataset CelebA) in cui l'equivarianza di scala è importante. In entrambi i casi, le architetture G-CNN superano le loro classiche controparti 2D e il valore aggiunto delle convoluzioni di gruppo atre e localizzate è studiato in dettaglio.
 Il pooling globale delle caratteristiche è una variante moderna del pooling delle caratteristiche che fornisce una migliore interpretabilità e regolarizzazione.Sebbene esistano metodi alternativi di pooling (es. max, lp norm, stocastico), l'operazione di media è ancora lo schema di pooling globale dominante nei modelli popolari.Poiché il riconoscimento a grana fine richiede l'apprendimento di caratteristiche sottili e discriminanti, consideriamo la domanda: il pooling medio è la strategia ottimale? La visualizzazione e l'analisi quantitativa mostrano che il max pooling incoraggia l'apprendimento di caratteristiche di diverse scale spaziali, quindi ci chiediamo: "c'è una singola variante di pooling delle caratteristiche globali che è più adatta al riconoscimento a grana fine? Una valutazione approfondita di nove algoritmi di pooling rappresentativi trova che: il max pooling supera il pooling medio in modo consistente in tutti i modelli, set di dati e risoluzioni di immagini; lo fa riducendo il gap di generalizzazione; e le prestazioni del pooling generalizzato aumentano quasi monotonamente quando si passa dalla media al max.Ci chiediamo infine: ``quale è il modo migliore per combinare due schemi di pooling eterogenei? Le strategie comuni lottano a causa del potenziale conflitto di gradiente, ma il trucco ``freeze-and-train'' funziona meglio.Troviamo anche che la normalizzazione post-globale del batch aiuta una convergenza più veloce e migliora le prestazioni del modello in modo coerente.
Presentiamo una tecnica per migliorare la generalizzazione delle rappresentazioni profonde apprese su piccoli set di dati etichettati introducendo compiti auto-supervisionati come funzioni di perdita ausiliarie.Sebbene la ricerca recente abbia mostrato i benefici dell'apprendimento auto-supervisionato (SSL) su grandi set di dati non etichettati, la sua utilità su piccoli set di dati è sconosciuta.Troviamo che SSL riduce il tasso di errore relativo dei meta-apprendisti a pochi colpi del 4%-27%, anche quando i set di dati sono piccoli e utilizzano solo immagini all'interno dei set di dati.I miglioramenti sono maggiori quando il set di allenamento è più piccolo o il compito è più difficile. Anche se i benefici di SSL possono aumentare con set di allenamento più grandi, osserviamo che SSL può avere un impatto negativo sulle prestazioni quando c'è uno spostamento di dominio tra la distribuzione delle immagini utilizzate per il meta-apprendimento e SSL.Sulla base di questa analisi presentiamo una tecnica che seleziona automaticamente le immagini per SSL da un grande e generico pool di immagini senza etichetta per un dato set di dati utilizzando un classificatore di dominio che fornisce ulteriori miglioramenti.Presentiamo i risultati utilizzando diversi meta-apprendisti e compiti auto-supervisionati su set di dati con vari gradi di spostamento di dominio e dimensioni delle etichette per caratterizzare l'efficacia di SSL per l'apprendimento a pochi colpi.
L'astrazione dei processi decisionali di Markov è uno strumento utile per risolvere problemi complessi, in quanto può ignorare aspetti non importanti di un ambiente, semplificando il processo di apprendimento di una politica ottimale. Dimostriamo la capacità del nostro algoritmo di imparare astrazioni dall'esperienza raccolta e mostriamo come riutilizzare le astrazioni per guidare l'esplorazione nei nuovi compiti che l'agente incontra.Il nostro nuovo metodo di trasferimento dei compiti batte una linea di base basata su una rete Q profonda.
Un certo numero di metodi recenti per comprendere le reti neurali si sono concentrati sulla quantificazione del ruolo delle singole caratteristiche.  Uno di questi metodi, NetDissect, identifica le caratteristiche interpretabili di un modello utilizzando il dataset Broden di etichette semantiche visive (colori, materiali, texture, oggetti e scene).  Dato il recente aumento di un certo numero di dataset di riconoscimento delle azioni, proponiamo di estendere il dataset Broden per includere le azioni per analizzare meglio i modelli di azione appresi.  Descriviamo il processo di annotazione, i risultati dell'interpretazione dei modelli di riconoscimento delle azioni sul dataset Broden esteso ed esaminiamo i percorsi delle caratteristiche interpretabili per aiutarci a capire la gerarchia concettuale usata per classificare un'azione.
La generazione automatica di melodie per la musica pop è stata a lungo un'aspirazione sia per i ricercatori di IA che per i musicisti. Tuttavia, imparare a generare melodie eufoniche si è rivelato altamente impegnativo a causa di una serie di fattori. la rappresentazione della proprietà multivariata delle note è stata una delle sfide principali. è anche difficile rimanere nello spettro ammissibile della varietà musicale, al di fuori del quale sarebbe percepita come una semplice riproduzione casuale senza piacevolezza uditiva. In questo lavoro, proponiamo di rappresentare ogni nota e le sue proprietà come un'unica "parola", riducendo così la prospettiva di disallineamenti tra le proprietà, oltre a ridurre la complessità dell'apprendimento; inoltre applichiamo politiche di regolarizzazione sulla gamma delle note, incoraggiando così la melodia generata a rimanere vicina a ciò che gli umani troverebbero facile da seguire. I risultati sperimentali dimostrano che il nostro modello può generare canzoni piacevoli all'udito che sono più indistinguibili da quelle scritte dall'uomo rispetto ai modelli precedenti.
La profondità è una componente chiave delle reti neurali profonde (DNN), tuttavia, la progettazione della profondità è euristica e richiede molti sforzi umani.Proponiamo AutoGrow per automatizzare la scoperta della profondità nelle DNN: partendo da un'architettura di semi poco profonda, AutoGrow fa crescere nuovi strati se la crescita migliora la precisione; altrimenti, smette di crescere e quindi scopre la profondità.Proponiamo politiche robuste di crescita e arresto per generalizzare a diverse architetture di rete e dataset. I nostri esperimenti mostrano che applicando la stessa politica a diverse architetture di rete, AutoGrow può sempre scoprire una profondità quasi ottimale su vari set di dati MNIST, FashionMNIST, SVHN, CIFAR10, CIFAR100 e ImageNet.Per esempio, in termini di trade-off accuratezza-computazione, AutoGrow scopre una migliore combinazione di profondità in ResNets rispetto agli esperti umani.Il nostro AutoGrow è efficiente.
Per affrontare questo problema e per accelerare l'innovazione in questo dominio, forniamo un accesso semplificato a 5 diversi set di dati di telerilevamento in una forma standardizzata. Esploriamo specificamente l'apprendimento della rappresentazione nel dominio e affrontiamo la questione di "quali caratteristiche dovrebbe avere un set di dati per essere una buona fonte per l'apprendimento della rappresentazione del telerilevamento".Le linee di base stabilite raggiungono prestazioni all'avanguardia su questi set di dati. 
I sistemi di dialogo generativi seq2seq sono addestrati a predire la parola successiva nei dialoghi che si sono già verificati. Possono imparare da grandi set di dati di conversazione non etichettati, costruire una profonda comprensione del contesto di conversazione e generare un'ampia varietà di risposte.Questa flessibilità arriva al costo del controllo. Le risposte indesiderate nei dati di formazione saranno riprodotte dal modello al momento dell'inferenza, e le generazioni più lunghe spesso non hanno senso.Invece di generare risposte una parola alla volta, addestriamo un classificatore a scegliere da una lista predefinita di risposte complete.Il classificatore è addestrato su coppie (contesto di conversazione, classe di risposta), dove ogni classe di risposta è un gruppo rumorosamente etichettato di risposte intercambiabili. Al momento dell'inferenza, generiamo la risposta esemplare associata alla classe di risposta prevista.Gli esperti possono modificare e migliorare queste risposte esemplari nel tempo senza riqualificare il classificatore o invalidare i vecchi dati di formazione.La valutazione umana di 775 conversazioni medico/paziente non viste mostra che questo compromesso migliora le risposte.Solo il 12% delle risposte del nostro approccio discriminativo sono peggiori della risposta del medico nello stesso contesto di conversazione, rispetto al 18% per il modello generativo.Un modello discriminativo addestrato senza alcuna etichettatura manuale delle classi di risposta raggiunge prestazioni uguali al modello generativo.
C'è un'equivalenza precedentemente identificata tra le reti neurali completamente connesse (FCN) e i processi gaussiani (GP); questa equivalenza permette, per esempio, di calcolare le previsioni del test set che sarebbero risultate da una FCN addestrata completamente bayesiana e infinitamente ampia senza mai istanziare la FCN, ma valutando invece la GP corrispondente. In questo lavoro, deriviamo un'equivalenza analoga per le reti neurali convoluzionali multistrato (CNN) sia con che senza strati di pooling, e raggiungiamo risultati allo stato dell'arte su CIFAR10 per le GP senza kernel addestrabili. Introduciamo anche un metodo Monte Carlo per stimare la GP corrispondente a una data architettura di rete neurale, anche nei casi in cui la forma analitica ha troppi termini per essere computazionalmente fattibile. Sorprendentemente, in assenza di strati di pooling, le GP corrispondenti alle CNN con e senza condivisione dei pesi sono identiche. Di conseguenza, l'equivarianza di traduzione, vantaggiosa nelle CNN a canale finito addestrate con la discesa del gradiente stocastico (SGD), è garantita per non giocare alcun ruolo nel trattamento bayesiano del limite a canale infinito - una differenza qualitativa tra i due regimi che non è presente nel caso FCN. Confermiamo sperimentalmente che, mentre in alcuni scenari le prestazioni delle CNN finite addestrate con SGD si avvicinano a quelle delle GP corrispondenti all'aumentare del numero di canali, con un'attenta messa a punto le CNN addestrate con SGD possono superare significativamente le loro GP corrispondenti, suggerendo vantaggi dall'addestramento SGD rispetto alla stima completamente bayesiana dei parametri.
L'inferenza bayesiana promette di fondare e migliorare le prestazioni delle reti neurali profonde, di essere robusta all'overfitting, di semplificare la procedura di addestramento e lo spazio degli iperparametri, e di fornire una misura calibrata dell'incertezza che può migliorare il processo decisionale, l'esplorazione degli agenti e la correttezza della previsione. I metodi Markov Chain Monte Carlo (MCMC) permettono l'inferenza bayesiana generando campioni dalla distribuzione posteriore dei parametri del modello. Nonostante i vantaggi teorici dell'inferenza bayesiana e la somiglianza tra MCMC e i metodi di ottimizzazione, le prestazioni dei metodi di campionamento sono finora rimaste indietro rispetto ai metodi di ottimizzazione per compiti di apprendimento profondo su larga scala. Il nostro obiettivo è quello di colmare questa lacuna e introdurre ATMC, un algoritmo MCMC adattivo di rumore che stima ed è in grado di campionare dal posteriore di una rete neurale. ATMC regola dinamicamente la quantità di slancio e di rumore applicata ad ogni aggiornamento dei parametri al fine di compensare l'uso di gradienti stocastici. Usiamo un'architettura ResNet senza normalizzazione batch per testare ATMC sul benchmark Cifar10 e sul benchmark ImageNet su larga scala e mostriamo che, nonostante l'assenza di normalizzazione batch, ATMC supera una forte baseline di ottimizzazione sia in termini di accuratezza di classificazione che di log-likelihood di test.Mostriamo che ATMC è intrinsecamente robusto all'overfitting sui dati di training e che ATMC fornisce una migliore misura calibrata di incertezza rispetto alla baseline di ottimizzazione.
Ora le GAN possono generare immagini facciali sempre più realistiche che possono facilmente ingannare gli esseri umani.  Al contrario, una comune rete neurale convoluzionale (CNN), ad esempio ResNet-18, può raggiungere più del 99,9% di accuratezza nel discernere i volti falsi/reali se i volti di allenamento e di test provengono dalla stessa fonte. In questo articolo, abbiamo eseguito sia studi umani che esperimenti CNN, che ci hanno portato a due importanti scoperte. Una scoperta è che le texture dei volti falsi sono sostanzialmente diverse da quelle reali. Sulla base dei risultati di cui sopra, proponiamo una nuova architettura coniata come Gram-Net, che incorpora "Gram Block" in livelli semantici multipli per estrarre rappresentazioni globali di texture dell'immagine. I risultati sperimentali dimostrano che la nostra Gram-Net funziona meglio degli approcci esistenti per il rilevamento di volti falsi.  In particolare, il nostro Gram-Net Ã¨ piÃ¹ robusto alla modifica dell'immagine, ad esempio il downsampling, la compressione JPEG, la sfocatura e il rumore.  Ancora più importante, il nostro Gram-Net generalizza significativamente meglio nel rilevamento di volti falsi da modelli GAN non visti nella fase di addestramento.
La metrica di probabilità di Wasserstein ha ricevuto molta attenzione dalla comunità dell'apprendimento automatico. A differenza della divergenza di Kullback-Leibler, che misura strettamente il cambiamento di probabilità, la metrica di Wasserstein riflette la geometria sottostante tra i risultati. Il valore di essere sensibili a questa geometria è stato dimostrato, tra gli altri, nella regressione ordinale e nella modellazione generativa, e più recentemente nel reinforcement learning. In questo articolo descriviamo tre proprietà naturali delle divergenze di probabilità che crediamo riflettano i requisiti dell'apprendimento automatico: invarianza di somma, sensibilità di scala e gradienti campione imparziali. Sfruttando le intuizioni della previsione probabilistica proponiamo un'alternativa alla metrica di Wasserstein, la distanza di CramÃ©r. Mostriamo che la distanza di CramÃ©r possiede tutte e tre le proprietÃ desiderate, combinando il meglio delle divergenze di Wasserstein e di Kullback-Leibler. Per illustrare la rilevanza pratica della distanza di CramÃ©r, progettiamo un nuovo algoritmo, il CramÃ©r Generative Adversarial Network (GAN), e dimostriamo che ha una serie di proprietÃ desiderabili rispetto al Wasserstein GAN correlato.
Noi esseri umani abbiamo una comprensione innata della progressione asimmetrica del tempo, che usiamo per percepire e manipolare in modo efficiente e sicuro il nostro ambiente.traendo ispirazione da questo, ci avviciniamo al problema dell'apprendimento di una freccia del tempo in un processo di Markov (decisione).illustriamo come una freccia imparata del tempo puÃ² catturare informazioni salienti sull'ambiente, che a sua volta puÃ² essere usato per misurare la raggiungibilitÃ , rilevare gli effetti collaterali e ottenere un segnale intrinseco di ricompensa. Infine, proponiamo un algoritmo semplice ma efficace per parametrizzare il problema a portata di mano e imparare una freccia del tempo con un approssimatore di funzioni (qui, una rete neurale profonda). I nostri risultati empirici coprono una selezione di ambienti discreti e continui, e dimostrano per una classe di processi stocastici che la freccia del tempo appresa concorda ragionevolmente bene con una nozione ben nota di freccia del tempo dovuta a Jordan, Kinderlehrer e Otto (1998).
Formuliamo la discesa del gradiente stocastico (SGD) come un nuovo problema di filtraggio bayesiano fattorizzato, in cui ogni parametro è dedotto separatamente, condizionato dal gradiente backpropagated corrispondente.  L'inferenza in questa impostazione dà naturalmente origine a BRMSprop e BAdam: varianti bayesiane di RMSprop e Adam.  Notevolmente, l'approccio bayesiano recupera molte caratteristiche dei metodi SGD adattivi allo stato dell'arte, tra cui la normalizzazione root-mean-square, l'accelerazione di Nesterov e AdamW.  Come tale, l'approccio bayesiano fornisce una spiegazione per l'efficacia empirica degli algoritmi SGD adattivi allo stato dell'arte.  Confrontando empiricamente BRMSprop e BAdam con RMSprop ingenuo e Adam su MNIST, troviamo che i metodi bayesiani hanno il potenziale per ridurre considerevolmente la perdita di test e l'errore di classificazione.
L'aumento dei dati (DA) è stato ampiamente utilizzato per migliorare la generalizzazione nell'addestramento delle reti neurali profonde.Recentemente, l'aumento dei dati progettato dall'uomo è stato gradualmente sostituito dalla politica di aumento appresa automaticamente.Attraverso la ricerca della migliore politica nello spazio di ricerca ben progettato di aumento dei dati, AutoAugment (Cubuk et al, 2019) può migliorare significativamente l'accuratezza di convalida su compiti di classificazione delle immagini.Tuttavia, questo approccio non è computazionalmente pratico per problemi su larga scala.In questo documento, sviluppiamo un metodo adversariale per arrivare a una soluzione computazionalmente accessibile chiamata Adversarial AutoAugment, che può contemporaneamente ottimizzare l'oggetto correlato all'obiettivo e la perdita di ricerca della politica di aumento.La rete della politica di aumento cerca di aumentare la perdita di formazione di una rete di destinazione attraverso la generazione di politiche di aumento adversariali, mentre la rete di destinazione può imparare caratteristiche più robuste da esempi più difficili per migliorare la generalizzazione. In contrasto con i lavori precedenti, riutilizziamo il calcolo nell'addestramento della rete di destinazione per la valutazione della politica, e rinunciamo alla riqualificazione della rete di destinazione. Rispetto ad AutoAugment, questo porta a circa 12 volte la riduzione del costo di calcolo e 11 volte la riduzione del tempo di overhead su ImageNet. Mostriamo i risultati sperimentali del nostro approccio su CIFAR-10/CIFAR-100, ImageNet, e dimostriamo significativi miglioramenti delle prestazioni rispetto allo stato dell'arte. Su CIFAR-10, raggiungiamo un errore di prova top-1 dell'1,36%, che è il modello singolo attualmente più performante. Su ImageNet, raggiungiamo una performance leader di accuratezza top-1 del 79,40% su ResNet-50 e 80,00% su ResNet-50-D senza dati extra.
In questo studio ci concentriamo sugli algoritmi di meta-apprendimento del primo ordine che mirano ad apprendere un'inizializzazione dei parametri di una rete che può adattarsi rapidamente a nuovi concetti, dati pochi esempi.Indaghiamo due approcci per migliorare la generalizzazione e la velocità di apprendimento di tali algoritmi, espandendo in particolare il Reptile (Nichol et al, Introduciamo una nuova tecnica di regolarizzazione chiamata "meta-step gradient pruning" e studiamo anche gli effetti dell'aumento della profondità delle architetture di rete nel meta-apprendimento di primo ordine. Presentiamo una valutazione empirica di entrambi gli approcci, dove eguagliamo i risultati di classificazione di immagini a pochi scatti con 10 volte meno iterazioni usando il dataset Mini-ImageNet e con l'uso di reti più profonde, raggiungiamo accuratezze che superano gli attuali benchmark di classificazione di immagini a pochi scatti usando il dataset Omniglot.
Utilizzando la fattorizzazione della matrice di addestramento, le matrici dei parametri possono essere decomposte nei prodotti di matrici più piccole, che possono comprimere grandi architetture di traduzione automatica riducendo notevolmente il numero di parametri apprendibili. Applichiamo la fattorizzazione della matrice di addestramento a diversi livelli di architetture neurali standard e dimostriamo che la fattorizzazione di addestramento è in grado di ridurre quasi il 50% dei parametri apprendibili senza alcuna perdita associata nel punteggio BLEU. Inoltre, troviamo che la fattorizzazione della matrice di addestramento è particolarmente potente sui livelli di incorporazione, fornendo un metodo semplice ed efficace per ridurre il numero di parametri con un impatto minimo sulle prestazioni del modello e, a volte, un aumento delle prestazioni.
Anche se i modelli di rappresentazione della frase allo stato dell'arte possono eseguire compiti che richiedono una conoscenza significativa della grammatica, è una questione aperta come valutare al meglio la loro conoscenza grammaticale.Esploriamo cinque metodi sperimentali ispirati da lavori precedenti che valutano i modelli di rappresentazione della frase preaddestrati.Usiamo un singolo fenomeno linguistico, l'elemento di polarità negativa (NPI) di licenza, come caso di studio per i nostri esperimenti.NPI come 'any' sono grammaticali solo se appaiono in un ambiente di licenza come la negazione ('Sue non ha nessun gatto' vs. Introduciamo un set di dati generato artificialmente che manipola le caratteristiche chiave delle licenze NPI per gli esperimenti.Troviamo che il BERT ha una conoscenza significativa di queste caratteristiche, ma il suo successo varia ampiamente attraverso diversi metodi sperimentali.Concludiamo che una varietà di metodi è necessaria per rivelare tutti gli aspetti rilevanti della conoscenza grammaticale di un modello in un dato dominio.
Il sistema visivo dei primati costruisce rappresentazioni robuste e polivalenti del mondo esterno per supportare diversi processi corticali a valle. Tali rappresentazioni devono essere invarianti alle incongruenze sensoriali causate da un'illuminazione che varia dinamicamente, dalla distorsione della trama locale, ecc. Una caratteristica architettonica chiave che combatte tali irregolaritÃ ambientali Ã¨ rappresentata dalle connessioni orizzontali a lungo raggio che aiutano la percezione della forma globale degli oggetti. In questo lavoro, esploriamo l'introduzione di tali connessioni orizzontali nelle reti convoluzionarie profonde standard; presentiamo V1Net -- una nuova unitÃ convoluzionaria-recorrente che modella le connessioni inibitorie ed eccitatorie orizzontali lineari e non lineari ispirate alla connettivitÃ corticale visiva dei primati.Introduciamo il Texturized Challenge -- un nuovo benchmark per valutare le prestazioni di riconoscimento degli oggetti sotto rumore percettivo -- che usiamo per valutare V1Net contro una serie di modelli di controllo attentamente selezionati con/senza elaborazione ricorrente. Inoltre, presentiamo i risultati di uno studio di ablazione di V1Net che dimostra l'utilità di diverse connessioni orizzontali neuralmente ispirate per i sistemi AI allo stato dell'arte sul compito di rilevazione dei confini degli oggetti da immagini naturali. Presentiamo anche l'emergere di diversi modelli di connettività orizzontale biologicamente plausibili, vale a dire centro-su surround-off, campi di associazione e modelli di connettività di proprietà del confine in un modello V1Net addestrato per eseguire la rilevazione dei confini su immagini naturali dal Berkeley Segmentation Dataset 500 (BSDS500). I nostri risultati suggeriscono una maggiore somiglianza rappresentazionale tra V1Net e i sistemi visivi biologici, ed evidenziano l'importanza dei principi di elaborazione contestuale ricorrente di ispirazione neuronale per l'apprendimento di rappresentazioni visive che sono robuste al rumore percettivo e per promuovere lo stato dell'arte della computer vision.
Gli esseri umani comprendono le frasi nuove componendo i significati e i ruoli dei componenti principali del linguaggio, mentre i modelli di rete neurale per la modellazione del linguaggio naturale falliscono quando è richiesta una tale generalizzazione compositiva. Attraverso una serie di esperimenti sui compiti SCAN, analizziamo il comportamento dei modelli esistenti sotto la lente dell'equivarianza e dimostriamo che la nostra architettura equivariante è in grado di raggiungere il tipo di generalizzazione compositiva richiesta nella comprensione del linguaggio umano.
L'inferenza variazionale (VI) è un approccio popolare per l'inferenza bayesiana approssimativa che è particolarmente promettente per modelli altamente parametrizzati come le reti neurali profonde.  Una sfida chiave dell'inferenza variazionale è quella di approssimare il posteriore sui parametri del modello con una distribuzione che sia più semplice e trattabile ma sufficientemente espressiva. In questo lavoro, proponiamo un metodo per addestrare distribuzioni variazionali altamente flessibili iniziando con un'approssimazione grossolana e raffinandola in modo interattivo. Ogni passo di raffinamento fa aggiustamenti locali a basso costo e richiede solo l'ottimizzazione di semplici famiglie variazionali.  Negli esperimenti, il nostro metodo supera costantemente i recenti metodi di inferenza variazionale per l'apprendimento profondo in termini di log-likelihood e ELBO.  Vediamo che i guadagni sono ulteriormente amplificati su modelli di scala più grande, superando significativamente il VI standard e gli ensemble profondi su reti residuali su CIFAR10.
In questo articolo, proponiamo una rete di attenzione residua non locale per il restauro delle immagini di alta qualità.Senza considerare la distribuzione non uniforme delle informazioni nelle immagini corrotte, i metodi precedenti sono limitati dal funzionamento convoluzionale locale e dal trattamento uguale delle caratteristiche spaziali e di canale. Per affrontare questo problema, progettiamo blocchi di attenzione locali e non locali per estrarre le caratteristiche che catturano le dipendenze a lungo raggio tra i pixel e prestano maggiore attenzione alle parti impegnative.In particolare, progettiamo un ramo tronco e un ramo maschera (non-)locale in ogni blocco di attenzione (non-)locale.Il ramo tronco viene utilizzato per estrarre le caratteristiche gerarchiche.I rami maschera locali e non locali mirano a ridimensionare in modo adattivo queste caratteristiche gerarchiche con attenzioni miste. Il ramo della maschera locale si concentra su strutture più locali con operazioni di convoluzione, mentre l'attenzione non locale considera di più le dipendenze a lungo raggio nell'intera mappa delle caratteristiche.Inoltre, proponiamo l'apprendimento dell'attenzione residua locale e non locale per allenare la rete molto profonda, che migliora ulteriormente la capacità di rappresentazione della rete.Il nostro metodo proposto può essere generalizzato per varie applicazioni di restauro delle immagini, come il denoising delle immagini, demosaicizzazione, riduzione degli artefatti di compressione e super-risoluzione.Gli esperimenti dimostrano che il nostro metodo ottiene risultati comparabili o migliori rispetto ai metodi leader recenti quantitativamente e visivamente.
La maggior parte degli approcci all'apprendimento di modelli di pianificazione delle azioni si basa pesantemente su un volume significativamente grande di campioni di allenamento o di osservazioni del piano.In questo articolo, adottiamo un approccio diverso basato sull'apprendimento deduttivo dalla conoscenza specifica del dominio, in particolare dalle formule logiche che specificano i vincoli sugli stati possibili di un dato dominio.L'osservabilità minima di input richiesta dal nostro approccio è un singolo esempio composto da uno stato iniziale completo e uno stato parziale dell'obiettivo.Mostreremo che lo sfruttamento della conoscenza specifica del dominio permette di vincolare lo spazio dei possibili modelli di azione così come di completare le osservazioni parziali, entrambi i quali si rivelano utili per imparare modelli di azione di buona qualità.
Rilasciamo il più grande set di dati ECG pubblico di segnali grezzi continui per l'apprendimento della rappresentazione che contiene oltre 11k pazienti e 2 miliardi di battiti etichettati.Il nostro obiettivo è quello di consentire la realizzazione di modelli ECG semi-supervisionati e di scoprire sottotipi sconosciuti di aritmia ed eventi anomali del segnale ECG.A tal fine, proponiamo un compito di apprendimento della rappresentazione non supervisionato, valutato in modo semi-supervisionato.  Forniamo una serie di linee di base per diversi estrattori di caratteristiche che possono essere costruite su.  Inoltre, eseguiamo valutazioni qualitative sui risultati delle incorporazioni PCA, dove identifichiamo alcuni raggruppamenti di sottotipi noti che indicano il potenziale per l'apprendimento della rappresentazione nella scoperta dei sottotipi di aritmia.
Come il blocco di base delle reti neurali convoluzionali (CNN), lo strato convoluzionale è progettato per estrarre i modelli locali e manca la capacità di modellare il contesto globale nella sua natura.Molti sforzi sono stati fatti recentemente per integrare CNN con la capacità di modellazione globale, soprattutto da una famiglia di lavori sull'interazione globale delle caratteristiche. Tuttavia, la ricerca sulle neuroscienze rivela che, oltre alle influenze che cambiano gli input ai nostri neuroni, la capacità dei neuroni di modificare dinamicamente le loro funzioni in base al contesto è essenziale per i compiti percettivi, cosa che è stata trascurata nella maggior parte delle CNN. Come tale, essendo consapevole del contesto globale, il kernel di convoluzione modulato della nostra proposta CGC può estrarre meglio i modelli locali rappresentativi e comporre caratteristiche discriminanti. Inoltre, la nostra proposta CGC è leggera, adattabile alle moderne architetture CNN e migliora costantemente le prestazioni delle CNN secondo ampi esperimenti sulla classificazione delle immagini, sul riconoscimento delle azioni e sulla traduzione automatica.
Analizziamo il trade-off tra il rumore di quantizzazione e la distorsione di clipping nelle reti a bassa precisione, identifichiamo le statistiche di vari tensori e deriviamo espressioni esatte per la degradazione dell'errore quadratico medio dovuta al clipping. ottimizzando queste espressioni, mostriamo miglioramenti marcati rispetto agli schemi di quantizzazione standard che normalmente evitano il clipping. Per esempio, solo scegliendo i valori di ritaglio accurati, più del 40% di miglioramento della precisione è ottenuto per la quantizzazione di VGG-16 a 4-bit di precisione.I nostri risultati hanno molte applicazioni per la quantizzazione delle reti neurali sia a tempo di formazione che di inferenza. 
La normalizzazione dei lotti (BN) è una delle tecniche più utilizzate nel campo dell'apprendimento profondo, ma le sue prestazioni possono degradare terribilmente con batch di dimensioni insufficienti. Questa debolezza limita l'uso di BN in molti compiti di computer vision come il rilevamento o la segmentazione, dove la dimensione del batch è solitamente piccola a causa del vincolo del consumo di memoria. Perciò sono state proposte molte tecniche di normalizzazione modificate, che o non riescono a ripristinare completamente le prestazioni di BN, o devono introdurre ulteriori operazioni non lineari nella procedura di inferenza e aumentare il consumo enorme.In questo articolo, riveliamo che ci sono due statistiche extra batch coinvolte nella propagazione all'indietro di BN, su cui non è mai stato ben discusso prima. Sulla base della nostra analisi, proponiamo un nuovo metodo di normalizzazione, chiamato Moving Average Batch Normalization (MABN).MABN può ripristinare completamente le prestazioni di vaniglia BN in casi di piccoli lotti, senza introdurre ulteriori operazioni non lineari nella procedura di inferenza.Dimostriamo i benefici di MABN sia dall'analisi teorica che dagli esperimenti.I nostri esperimenti dimostrano l'efficacia di MABN in più compiti di computer vision tra cui ImageNet e COCO.Il codice è stato rilasciato in https://github.com/megvii-model/MABN.
In particolare presentiamo una sequenza di problemi di classificazione f_i tali che (a) per qualsiasi rete rettificata a profondità fissa possiamo trovare un indice m tale che i problemi con indice > m richiedono una larghezza di rete esponenziale per rappresentare completamente la funzione f_m; e (b) per qualsiasi problema f_m nella famiglia, presentiamo una rete neurale concreta con profondità lineare e larghezza limitata che la rappresenta completamente. Mentre ci sono diversi lavori precedenti che mostrano risultati simili, la nostra dimostrazione utilizza strumenti e tecniche sostanzialmente più semplici, e dovrebbe essere accessibile agli studenti universitari di informatica e alle persone con un background simile.
I dati etichettati ricchi e accessibili alimentano il successo rivoluzionario dell'apprendimento profondo.Tuttavia, la supervisione massiccia rimane un lusso per molte applicazioni reali, aumentando il grande interesse per le tecniche con poche etichette come l'apprendimento a pochi colpi (FSL).Un approccio intuitivamente fattibile per FSL è quello di condurre l'aumento dei dati attraverso la sintesi di campioni di formazione aggiuntivi.La chiave di questo approccio è come garantire sia la discriminabilità che la diversità dei campioni sintetizzati. In questo articolo, proponiamo un nuovo modello FSL, chiamato $\textrm{D}^2$GAN, che sintetizza caratteristiche diverse e discriminative basate su Generative Adversarial Networks (GAN).$\textrm{D}^2$GAN assicura la discriminabilità delle caratteristiche sintetizzate costringendole ad avere un'alta correlazione con le caratteristiche reali delle stesse classi mentre una bassa correlazione con quelle di classi diverse.  Basandosi sull'osservazione che i vettori di rumore che sono più vicini nello spazio dei codici latenti hanno più probabilità di essere collassati nello stesso modo quando vengono mappati nello spazio delle caratteristiche, $\textrm{D}^2$GAN incorpora un nuovo termine di regolarizzazione anti-collasso, che incoraggia la diversità delle caratteristiche penalizzando il rapporto tra la somiglianza logaritmica di due caratteristiche sintetizzate e la somiglianza logaritmica dei codici latenti che le generano. Gli esperimenti su tre set di dati di riferimento comuni verificano l'efficacia di $\textrm{D}^2$GAN confrontandosi con lo stato dell'arte.
La mancanza di modelli matematici precisi che catturino la struttura dei set di dati del mondo reale è uno dei maggiori ostacoli alla comprensione teorica dettagliata delle reti neurali profonde. Qui dimostriamo per la prima volta l'effetto dei set di dati strutturati confrontando sperimentalmente la dinamica e le prestazioni di due reti a strati addestrate su due diversi set di dati: (i) un set di dati sintetico non strutturato contenente input casuali i.i.d., e (ii) un semplice set di dati canonici come le immagini MNIST. La nostra analisi rivela due fenomeni relativi alla dinamica delle reti e alla loro capacità di generalizzare che appaiono solo quando ci si allena su set di dati strutturati. In secondo luogo, introduciamo un modello generativo per i set di dati, in cui gli input ad alta densità si trovano su un collettore a bassa densità e hanno etichette che dipendono solo dalla loro posizione all'interno di questo collettore, che chiamiamo modello del collettore nascosto e dimostriamo sperimentalmente che l'allenamento delle reti su set di dati tratti da questo modello riproduce entrambi i fenomeni osservati durante l'allenamento su MNIST.
In questo articolo, studiamo le reti neurali diagonali circolanti profonde, cioè le reti neurali profonde in cui le matrici dei pesi sono il prodotto di quelle diagonali e circolanti. Oltre a fare un'analisi teorica della loro espressività, abbiamo introdotto tecniche di principio per l'addestramento di questi modelli: abbiamo ideato uno schema di inizializzazione e proposto un uso intelligente delle funzioni di non linearità per addestrare reti diagonali circolanti profonde. Abbiamo condotto uno studio sperimentale approfondito per confrontare le prestazioni delle reti diagonali circolanti profonde con lo stato dell'arte dei modelli basati su matrici strutturate e con modelli densi, dimostrando che i nostri modelli raggiungono una migliore accuratezza rispetto ad altri approcci strutturati, pur richiedendo 2 volte meno pesi rispetto all'approccio successivo, infine abbiamo addestrato reti diagonali circolanti profonde per costruire modelli compatti e accurati su un dataset di classificazione video del mondo reale con oltre 3,8 milioni di esempi di formazione.
Queste spiegazioni sono interessanti per la loro semplicità e fedeltà locale, ma non forniscono informazioni sul comportamento generale del modello. Noi proponiamo di sfruttare la distillazione del modello per imparare spiegazioni additive globali che descrivono la relazione tra le caratteristiche di input e le previsioni del modello. Queste spiegazioni globali prendono la forma di forme di caratteristiche, che sono più espressive delle attribuzioni di caratteristiche. Attraverso un'attenta sperimentazione, mostriamo qualitativamente e quantitativamente che le spiegazioni additive globali sono in grado di descrivere il comportamento del modello e di produrre intuizioni su modelli come le reti neurali. Una visualizzazione del nostro approccio applicato a una rete neurale mentre viene addestrata è disponibile su https://youtu.be/ErQYwNqzEdc
Molto del recente successo nell'elaborazione del linguaggio naturale (NLP) è stato guidato da rappresentazioni vettoriali distribuite di parole addestrate su grandi quantità di testo in modo non supervisionato. Queste rappresentazioni sono in genere utilizzate come caratteristiche generali per le parole in una serie di problemi NLP. Il lavoro recente ha esplorato tecniche di apprendimento non supervisionato e supervisionato con diversi obiettivi di formazione per imparare rappresentazioni generiche di frasi di lunghezza fissa. In questo lavoro, presentiamo una semplice ed efficace struttura di apprendimento multitasking per le rappresentazioni di frasi che combina i pregiudizi induttivi di diversi obiettivi di formazione in un unico modello. Addestriamo questo modello su diverse fonti di dati con obiettivi di formazione multipli su oltre 100 milioni di frasi. esperimenti estesi dimostrano che la condivisione di un singolo codificatore di frasi ricorrenti attraverso compiti debolmente correlati porta a miglioramenti coerenti rispetto ai metodi precedenti. presentiamo miglioramenti sostanziali nel contesto dell'apprendimento di trasferimento e delle impostazioni a bassa risorsa utilizzando le nostre rappresentazioni per scopi generali apprese.
In un'epoca in cui le reti neurali sono sempre più adottate in applicazioni sensibili, il bias algoritmico è emerso come un problema con implicazioni morali.Mentre ci sono miriadi di modi in cui un sistema può essere compromesso dal bias, isolare e valutare sistematicamente i sistemi esistenti su tali scenari non è banale, cioè, A tal fine, questo articolo propone il primo studio sistematico di benchmarking dei modelli neurali allo stato dell'arte contro gli scenari distorti.Più concretamente, postuliamo che il problema degli annotatori distorti possa essere approssimato con modelli neurali, cioè Proponiamo modelli generativi di bias latenti per associare deliberatamente e ingiustamente le caratteristiche latenti a una classe specifica.Nel complesso, il nostro quadro fornisce un nuovo modo per la quantificazione e la valutazione di principio dei modelli contro set di dati distorti.Di conseguenza, troviamo che i modelli NLP all'avanguardia (ad esempio, BERT, RoBERTa, XLNET) sono facilmente compromessi da dati distorti.
Consideriamo il problema della modellazione di argomenti in un'impostazione debolmente semi-supervisionata: in questo scenario, assumiamo che l'utente conosca a priori un sottoinsieme degli argomenti che vuole che il modello impari e sia in grado di fornire alcuni documenti esemplari per quegli argomenti; inoltre, mentre ogni documento può tipicamente consistere in più argomenti, non assumiamo che l'utente identifichi tutti gli argomenti in modo esaustivo.      Dopo aver analizzato l'effetto dei priori informativi, proponiamo una semplice modifica del modello NVDM utilizzando un posteriore logit-normale che dimostra un migliore allineamento agli argomenti desiderati dall'utente rispetto ad altri modelli NTM.
L'analisi delle reti neurali profonde (DNN) attraverso la teoria del piano di informazione (IP) ha guadagnato un'enorme attenzione di recente come strumento per comprendere, tra l'altro, la loro capacità di generalizzazione. Tuttavia, non è affatto ovvio come stimare l'informazione reciproca (MI) tra ogni strato nascosto e l'ingresso/uscita desiderata, per costruire l'IP. Per esempio, gli strati nascosti con molti neuroni richiedono stimatori MI con robustezza verso l'alta dimensionalità associata a tali strati.Gli stimatori MI dovrebbero anche essere in grado di gestire naturalmente gli strati convoluzionali, e allo stesso tempo essere computazionalmente trattabili per scalare a grandi reti.Nessuno dei metodi IP esistenti fino ad oggi è stato in grado di studiare reti neurali convoluzionali (CNN) veramente profonde, come ad es. In questo articolo, proponiamo un'analisi IP utilizzando la nuova matrice basata sull'entropia di R'enyi accoppiata con kernel tensori su strati convoluzionali, sfruttando la potenza dei metodi kernel per rappresentare le proprietà della distribuzione di probabilità indipendentemente dalla dimensionalità dei dati. I risultati ottenuti gettano nuova luce sulla letteratura precedente riguardante le DNN su piccola scala, tuttavia utilizzando un approccio completamente nuovo. Importante, il nuovo quadro ci permette di fornire la prima analisi completa dell'IP di DNN e CNN contemporanee su larga scala, indagando le diverse fasi di formazione e fornendo nuove intuizioni sulle dinamiche di formazione delle reti neurali su larga scala.
Lo sviluppo di agenti che possono imparare a seguire istruzioni in linguaggio naturale è stata una direzione di ricerca emergente: pur essendo accessibili e flessibili, le istruzioni in linguaggio naturale possono essere talvolta ambigue anche per gli esseri umani, e per risolvere questo problema proponiamo di utilizzare i programmi, strutturati in un linguaggio formale, come un modo preciso ed espressivo per specificare i compiti. Abbiamo poi ideato una struttura modulare che impara ad eseguire un compito specificato da un programma - dato che diverse circostanze danno origine a diversi modi per realizzare il compito, la nostra struttura puÃ² percepire quale circostanza Ã¨ attualmente sotto, e istruire una politica multitask di conseguenza per soddisfare ogni sottocompito del compito complessivo. I risultati sperimentali su un ambiente Minecraft 2D dimostrano non solo che la struttura proposta impara ad eseguire in modo affidabile le istruzioni del programma e raggiunge una generalizzazione a zero colpi per istruzioni più complesse, ma verificano anche l'efficienza del meccanismo di modulazione proposto per l'apprendimento della politica multitask.conduciamo anche un'analisi che confronta vari modelli che imparano da programmi e istruzioni in linguaggio naturale in un modo end-to-end.
Analizziamo la convergenza dell'algoritmo di discesa del gradiente (stocastico) per l'apprendimento di un filtro convoluzionario con funzione di attivazione Rectified Linear Unit (ReLU).La nostra analisi non si basa su alcuna forma specifica della distribuzione di input e le nostre prove utilizzano solo la definizione di ReLU, in contrasto con i lavori precedenti che sono limitati all'input gaussiano standard. Mostriamo che la discesa (stocastica) del gradiente con inizializzazione casuale può imparare il filtro convoluzionale in tempo polinomiale e il tasso di convergenza dipende dalla morbidezza della distribuzione di input e dalla vicinanza delle patch.Per quanto ne sappiamo, questa è la prima garanzia di recupero degli algoritmi basati sul gradiente per il filtro convoluzionale su distribuzioni di input non gaussiane.La nostra teoria giustifica anche la strategia del tasso di apprendimento a due stadi nelle reti neurali profonde.Mentre la nostra attenzione è teorica, presentiamo anche esperimenti che giustificano i nostri risultati teorici.
Le reti neurali profonde (DNN) sono ampiamente adottate nelle applicazioni cognitive del mondo reale a causa della loro elevata accuratezza.La robustezza dei modelli DNN, tuttavia, è stata recentemente sfidata da attacchi avversari in cui piccoli disturbi sui campioni di input possono provocare errori di classificazione. Lo stato dell'arte degli algoritmi di difesa, come l'addestramento avversario o l'ottimizzazione robusta, migliorano la resilienza delle DNN agli attacchi avversari pagando alti costi computazionali.Inoltre, questi approcci sono solitamente progettati per difendere solo una o poche tecniche di attacco conosciute.L'efficacia per difendere altri tipi di metodi di attacco, specialmente quelli che non sono ancora stati scoperti o esplorati, non può essere garantita. In particolare, proponiamo Bamboo, il primo metodo di aumento dei dati progettato per migliorare la robustezza generale delle DNN senza alcuna ipotesi sugli algoritmi di attacco. Bamboo aumenta il set di dati di formazione con una piccola quantità di dati campionati uniformemente su una sfera di raggio fisso intorno a ciascun dato di formazione e quindi, aumentare efficacemente la distanza tra i punti di dati naturali e il confine della decisione. I nostri esperimenti dimostrano che Bamboo migliora sostanzialmente la robustezza generale contro tipi arbitrari di attacchi e rumori, ottenendo risultati migliori rispetto ai precedenti metodi di formazione avversaria, ai metodi di ottimizzazione robusta e ad altri metodi di aumento dei dati con la stessa quantità di punti dati.
La capacità di sintetizzare modelli realistici di attività neurale è cruciale per studiare l'elaborazione dell'informazione neurale. Qui abbiamo usato la struttura Generative Adversarial Networks (GANs) per simulare l'attività concertata di una popolazione di neuroni. Abbiamo adattato la variante Wasserstein-GAN per facilitare la generazione di modelli di attività della popolazione neurale senza vincoli, pur beneficiando della condivisione dei parametri nel dominio temporale. Dimostriamo che la nostra GAN proposta, che abbiamo chiamato Spike-GAN, genera treni di spike che corrispondono accuratamente alle statistiche del primo e del secondo ordine di serie di dati di decine di neuroni e approssima anche bene le loro statistiche di ordine superiore. Abbiamo applicato Spike-GAN a un set di dati reali registrati dalla retina di salamandra e abbiamo dimostrato che si comporta bene come gli approcci allo stato dell'arte basati sulla massima entropia e sulle strutture gaussiane dicotomizzate. È importante notare che Spike-GAN non richiede di specificare a priori le statistiche a cui il modello deve corrispondere, e quindi costituisce un metodo più flessibile di questi approcci alternativi. Spike-GAN fornisce una tecnica potente e facile da usare per generare un'attività neurale spike realistica e per descrivere le caratteristiche più rilevanti delle registrazioni di popolazioni neurali su larga scala studiate nella moderna neuroscienza dei sistemi.
I modelli profondi a variabili latenti sono diventati una scelta popolare grazie agli algoritmi di apprendimento scalabili introdotti da (Kingma & Welling 2013, Rezende et al. 2014).Questi approcci massimizzano un lower bound variazionale sulla log likelihood intrattabile dei dati osservati.Burda et al. (2015) hanno introdotto un limite variazionale multi-campione, IWAE, che è stretto almeno quanto il limite inferiore variazionale standard e diventa sempre più stretto all'aumentare del numero di campioni.Controintuitivamente, il tipico stimatore del gradiente della rete di inferenza per il limite IWAE funziona male all'aumentare del numero di campioni (Rainforth et al. 2018, Le et al. 2018).Roeder et a.(2017) propongono uno stimatore del gradiente migliorato, tuttavia, non sono in grado di dimostrare che è imparziale. Mostriamo che è in effetti distorto e che il bias può essere stimato in modo efficiente con una seconda applicazione del trucco della riparametrizzazione.Lo stimatore del gradiente doppiamente riparametrizzato (DReG) non soffre all'aumentare del numero di campioni, risolvendo i problemi precedentemente sollevati.La stessa idea può essere utilizzata per migliorare molte tecniche di addestramento recentemente introdotte per i modelli di variabili latenti. In particolare, mostriamo che questo stimatore riduce la varianza del gradiente IWAE, il reweighted wake-sleep update (RWS) (Bornschein & Bengio 2014), e il gradiente jackknife variational inference (JVI) (Nowozin 2018).
L'ottimizzazione di ordine zero è il processo di minimizzazione di un obiettivo $f(x)$, dato l'accesso all'oracolo alle valutazioni agli input $x$ scelti in modo adattivo.In questo articolo, presentiamo due semplici ma potenti algoritmi GradientLess Descent (GLD) che non si basano su una stima del gradiente sottostante e sono numericamente stabili. Analizziamo il nostro algoritmo da un nuovo punto di vista geometrico e mostriamo che per qualsiasi trasformazione monotona di un obiettivo liscio e fortemente convesso con dimensione latente $k \ge n$, presentiamo una nuova analisi che mostra la convergenza all'interno di una sfera di $ $epsilon$ dell'ottimo in $O(kQ\log(n)\log(R/\epsilon))$ valutazioni, dove la dimensione di input è $n$, $R$ è il diametro dello spazio di input e $Q$ è il numero di condizione. I nostri tassi sono i primi nel loro genere ad essere sia1) polilogaritmicamente dipendenti dalla dimensionalità e2) invarianti sotto trasformazioni monotone.Sfruttiamo ulteriormente la nostra prospettiva geometrica per dimostrare che la nostra analisi è ottimale.Sia l'invarianza monotona che la capacità di utilizzare una bassa dimensionalità latente sono la chiave del successo empirico dei nostri algoritmi, come dimostrato su benchmark sintetici e MuJoCo.
Molti processi possono essere rappresentati concisamente come una sequenza di eventi che portano da uno stato iniziale a uno stato finale; dati gli ingredienti grezzi e una torta finita, uno chef esperto può ipotizzare la ricetta; basandosi su questa intuizione, proponiamo una nuova classe di modelli generativi visivi: i predittori condizionati dall'obiettivo (GCP). I lavori precedenti sulla generazione di video si concentrano in gran parte su modelli di predizione che osservano solo i fotogrammi dall'inizio del video; i GCP invece trattano i video come trasformazioni di inizio e fine, rendendo la generazione di video più facile condizionando il contesto più informativo fornito dai primi e dai finali. Non solo gli attuali approcci di predizione in avanti sintetizzano video migliori e più lunghi quando vengono modificati per diventare condizionati dall'obiettivo, ma i modelli GCP possono anche utilizzare strutture che non sono lineari nel tempo, per realizzare la predizione gerarchica. A questo scopo, studiamo sia modelli GCP auto-regressivi che nuovi modelli GCP strutturati ad albero che generano fotogrammi in modo ricorsivo, dividendo iterativamente il video in segmenti sempre più fini delineati da sotto-obiettivi. Negli esperimenti condotti su set di dati simulati e reali, i nostri metodi GCP generano sequenze di alta qualità su orizzonti lunghi.  I GCP strutturati ad albero sono anche sostanzialmente più facili da parallelizzare rispetto ai GCP auto-regressivi, rendendo l'addestramento e l'inferenza molto efficienti, e permettendo al modello di addestrarsi su sequenze che sono migliaia di fotogrammi di lunghezza.Infine, dimostriamo l'utilità degli approcci GCP per l'apprendimento dell'imitazione nell'impostazione senza accesso alle azioni degli esperti. I video sono sul sito web supplementare: https://sites.google.com/view/video-gcp
I recenti progressi nella tecnologia informatica e nella progettazione dei sensori hanno reso più facile la raccolta di dati longitudinali o di serie temporali dai pazienti, dando luogo a una quantità gigantesca di dati medici disponibili. I lavori precedenti hanno sviluppato tecniche di elaborazione del linguaggio naturale per estrarre annotazioni concettuali e/o narrazioni cliniche dalle note del medico.Tuttavia, questi approcci sono lenti e non utilizzano i dati delle serie temporali mediche di accompagnamento.Per affrontare questo problema, introduciamo il problema dell'annotazione dei concetti per i dati delle serie temporali mediche, cioè, Proponiamo Relational Multi-Instance Learning (RMIL) - una struttura profonda di Multi-Instance Learning basata su reti neurali ricorrenti, che utilizza funzioni di pooling e meccanismi di attenzione per i compiti di annotazione dei concetti.I risultati empirici su set di dati medici mostrano che i nostri modelli proposti superano i vari modelli di apprendimento multi-instanza.
Gli strati di incorporazione che trasformano le parole di input in vettori reali sono i componenti chiave delle reti neurali profonde utilizzate nell'elaborazione del linguaggio naturale. Tuttavia, quando il vocabolario è grande, le matrici dei pesi corrispondenti possono essere enormi, il che preclude il loro impiego in un ambiente con risorse limitate. Introduciamo un nuovo modo di parametrizzare gli strati di incorporazione basato sulla decomposizione Tensor Train (TT), che permette di comprimere il modello in modo significativo al costo di un calo trascurabile o persino di un leggero guadagno nelle prestazioni.  Valutiamo il nostro metodo su una vasta gamma di benchmark nell'elaborazione del linguaggio naturale e analizziamo il trade-off tra prestazioni e rapporti di compressione per una vasta gamma di architetture, da MLPs a LSTMs e Transformers.
Notiamo che le comuni implementazioni degli algoritmi di gradiente adattivo, come Adam, limitano il potenziale beneficio della regolarizzazione del decadimento del peso, perché i pesi non decadono in modo moltiplicativo (come ci si aspetterebbe per il decadimento del peso standard) ma per un fattore costante additivo. Proponiamo un modo semplice per risolvere questo problema disaccoppiando il decadimento dei pesi e le fasi di ottimizzazione della funzione di perdita. Forniamo prove empiriche che la nostra modifica proposta (i) disaccoppia la scelta ottimale del fattore di decadimento dei pesi dall'impostazione del tasso di apprendimento sia per SGD standard che per Adam, e (ii) migliora sostanzialmente le prestazioni di generalizzazione di Adam, consentendogli di competere con SGD con slancio sui set di dati di classificazione delle immagini (sui quali in precedenza era tipicamente superato da quest'ultimo). Dimostriamo anche che le ottimizzazioni più lunghe richiedono valori di decadimento del peso più piccoli per ottenere risultati ottimali e introduciamo una variante normalizzata del decadimento del peso per ridurre questa dipendenza. Infine, proponiamo una versione di Adam con riavvii a caldo (AdamWR) che ha forti prestazioni in qualsiasi momento mentre raggiunge risultati all'avanguardia su CIFAR-10 e ImageNet32x32. Il nostro codice sorgente sarà disponibile dopo il processo di revisione.
L'apprendimento permanente è il problema dell'apprendimento di più compiti consecutivi in modo sequenziale, dove la conoscenza acquisita dai compiti precedenti viene conservata e utilizzata per l'apprendimento futuro, ed è essenziale per lo sviluppo di macchine intelligenti in grado di adattarsi all'ambiente circostante. In questo lavoro ci concentriamo su un approccio di apprendimento permanente alla modellazione generativa in cui incorporiamo continuamente nuove distribuzioni di flusso nel nostro modello appreso, attraverso un'architettura studente-insegnante che ci permette di imparare e conservare tutte le distribuzioni viste finora senza la necessità di conservare i dati passati né i modelli passati. Attraverso l'introduzione di un nuovo regolatore cross-model, il modello dello studente sfrutta le informazioni apprese dall'insegnante, che agisce come un riassunto di tutto ciò che è stato visto fino ad ora. Il regolatore ha l'ulteriore vantaggio di ridurre l'effetto dell'interferenza catastrofica che appare quando apprendiamo su dati in streaming, dimostrando la sua efficacia su distribuzioni in streaming e la sua capacità di apprendere una rappresentazione latente comune in un complesso scenario di apprendimento di trasferimento.
I dati geometrici tridimensionali offrono un dominio eccellente per studiare l'apprendimento delle rappresentazioni e la modellazione generativa. In questo articolo, esaminiamo i dati geometrici rappresentati come nuvole di punti e introduciamo una rete profonda di autoencoder (AE) con un'eccellente qualità di ricostruzione e capacità di generalizzazione. Le rappresentazioni apprese superano lo stato dell'arte nei compiti di riconoscimento 3D e consentono applicazioni di editing di forma di base attraverso semplici manipolazioni algebriche, come l'editing semantico delle parti, analogie di forma e interpolazione di forma. Eseguiamo anche uno studio approfondito di diversi modelli generativi tra cui GANs che operano sulle nuvole di punti grezzi, GANs significativamente migliorati addestrati nello spazio latente fisso dei nostri AEs e, modelli a miscela gaussiana (GMM).È interessante notare che i GMMs addestrati nello spazio latente dei nostri AEs producono campioni della migliore fedeltà e diversità.Per eseguire la nostra valutazione quantitativa dei modelli generativi, proponiamo semplici misure di fedeltà e diversità basate sulla corrispondenza ottimale tra set nuvole di punti.
Nonostante le notevoli prestazioni delle reti neurali profonde (DNN) su vari compiti, sono suscettibili di perturbazioni avversarie che rendono difficile il loro impiego in applicazioni critiche per la sicurezza nel mondo reale.In questo articolo, miriamo a ottenere reti robuste sparsificando le caratteristiche latenti delle DNN sensibili alle perturbazioni avversarie. In particolare, definiamo la vulnerabilità nello spazio delle caratteristiche latenti e poi proponiamo un quadro bayesiano per prioritizzare/prune le caratteristiche basate sul loro contributo sia alla perdita originale che a quella avversaria, suggerendo anche di regolarizzare la vulnerabilità delle caratteristiche durante l'addestramento per migliorare ulteriormente la robustezza. Mentre tale sparsificazione della rete è stata studiata principalmente in letteratura per l'efficienza computazionale e l'effetto di regolarizzazione delle DNN, confermiamo che è anche utile per progettare un meccanismo di difesa attraverso una valutazione quantitativa e un'analisi qualitativa. Convalidiamo il nostro metodo, \emph{Adversarial Neural Pruning (ANP)} su più set di dati di riferimento, che si traduce in un miglioramento dell'accuratezza del test e porta ad una robustezza allo stato dell'arte.ANP affronta anche il problema pratico di ottenere reti sparse e robuste allo stesso tempo, che potrebbe essere cruciale per garantire la robustezza adversariale su reti leggere distribuite su dispositivi con calcolo e memoria limitata.
Nel rilevamento delle anomalie (AD), si cerca di identificare se un campione di prova è anormale, dato un set di dati di campioni normali.   Un approccio recente e promettente all'AD si affida a modelli generativi profondi, come gli autocodificatori variazionali (VAE), per l'apprendimento non supervisionato della distribuzione dei dati normali.In AD semi-supervisionato (SSAD), i dati includono anche un piccolo campione di anomalie etichettate.In questo lavoro, proponiamo due metodi variazionali per addestrare i VAE per SSAD. L'idea intuitiva in entrambi i metodi è quella di addestrare il codificatore a 'separare' tra i vettori latenti per i dati normali e quelli anomali. Mostriamo che questa idea può essere derivata da formulazioni probabilistiche di principio del problema, e proponiamo algoritmi semplici ed efficaci.  I nostri metodi possono essere applicati a vari tipi di dati, come dimostriamo su dataset SSAD che vanno dalle immagini naturali all'astronomia e alla medicina, e possono essere combinati con qualsiasi architettura di modelli VAE.
Introduciamo la durezza dinamica dell'istanza (DIH) per facilitare l'addestramento dei modelli di apprendimento automatico.DIH è una proprietà di ogni campione di addestramento ed è calcolata come la media in esecuzione della durezza istantanea del campione misurata nella storia dell'addestramento.Usiamo DIH per valutare quanto bene un modello conserva la conoscenza di ogni campione di addestramento nel tempo.Troviamo che per le reti neurali profonde (DNN), la DIH di un campione nelle fasi relativamente iniziali di addestramento riflette la sua DIH nelle fasi successive e, di conseguenza, DIH può essere efficacemente utilizzata per ridurre il set di campioni di addestramento nelle epoche future. Specificamente, durante ogni epoca, solo i campioni con alto DIH sono addestrati (poiché sono storicamente difficili) mentre i campioni con basso DIH possono essere tranquillamente ignorati.DIH è aggiornato ogni epoca solo per i campioni selezionati, quindi non richiede ulteriori calcoli. Inoltre, poiché il modello si concentra sui campioni storicamente più impegnativi, i modelli risultanti sono più accurati.Quanto sopra, quando formulato come algoritmo, può essere visto come una forma di apprendimento del curriculum, quindi chiamiamo il nostro quadro DIH curriculum learning (o DIHCL).I vantaggi di DIHCL, rispetto ad altri approcci di apprendimento del curriculum, sono: (1) DIHCL non richiede ulteriori passi di inferenza sui dati non selezionati da DIHCL in ogni epoca, (2) la durezza dell'istanza dinamica, rispetto a quella statica (ad es, Facendo alcune assunzioni matematiche, formuliamo il problema di DIHCL come trovare un curriculum che massimizzi una funzione multi-set $f(\cdot)$, e deriviamo un limite di approssimazione per un curriculum prodotto da DIH rispetto al curriculum ottimale. Empiricamente, le DNN addestrate da DIHCL superano significativamente le prestazioni di SGD mini-batch casuale e di altri metodi di apprendimento del curriculum sviluppati di recente in termini di efficienza, convergenza nella fase iniziale e prestazioni finali, e questo è dimostrato nell'addestramento di diverse DNN allo stato dell'arte su 11 set di dati moderni.
Questo articolo esplora molte connessioni immediate tra il controllo adattivo e l'apprendimento automatico, sia attraverso leggi di aggiornamento comuni che attraverso concetti comuni. il controllo adattivo come campo si è concentrato sul rigore matematico e sulla convergenza garantita. i rapidi progressi nell'apprendimento automatico d'altra parte hanno portato a una pletora di nuove tecniche e problemi per l'apprendimento. questo articolo chiarisce molte delle numerose connessioni comuni tra entrambi i campi in modo che i risultati di entrambi possano essere sfruttati insieme per risolvere nuovi problemi. in particolare, un problema specifico relativo all'apprendimento di ordine superiore è risolto attraverso intuizioni ottenute da queste intersezioni.
La convoluzione ricorrente (RC) condivide gli stessi kernel di convoluzione e li srotola più volte, originariamente proposta per modellare segnali tempo-spazio.Suggeriamo che RC può essere vista come una strategia di compressione del modello per reti neurali convoluzionali profonde.RC riduce la ridondanza tra gli strati ed è complementare alla maggior parte degli approcci di compressione del modello esistenti.Tuttavia, le prestazioni di una rete RC non possono eguagliare le prestazioni della sua corrispondente rete standard, cioè con la stessa profondità ma kernel di convoluzione indipendenti.  Questo riduce il valore di RC per la compressione del modello.In questo articolo, proponiamo una semplice variante che migliora le reti RC: Gli strati di normalizzazione batch di un modulo RC sono appresi indipendentemente (non condivisi) per diversi passi di srotolamento.Forniamo approfondimenti sul perché questo funziona.Gli esperimenti su CIFAR mostrano che lo srotolamento di uno strato convoluzionale diversi passi può migliorare le prestazioni, quindi gioca indirettamente un ruolo nella compressione del modello.
Il mondo visivo è vasto e vario, ma le sue variazioni si dividono in fattori strutturati e non strutturati.I fattori strutturati, come la scala e l'orientamento, ammettono teorie chiare e un design di rappresentazione efficiente.I fattori non strutturati, come ciò che rende un gatto simile a un gatto, sono troppo complicati da modellare analiticamente, e quindi richiedono un apprendimento di rappresentazione a forma libera. I nostri esperimenti sulla struttura dinamica, in cui i filtri strutturati variano con l'input, eguagliano l'accuratezza dell'inferenza dinamica con più gradi di libertà migliorando l'efficienza.(Si veda https://arxiv.org/abs/1904.11487 per l'edizione completa).
È ampiamente noto che perturbazioni ben progettate possono indurre i classificatori di apprendimento automatico allo stato dell'arte ad etichettare erroneamente un'immagine, con perturbazioni sufficientemente piccole che sono impercettibili agli occhi umani.Tuttavia, rilevando l'incoerenza tra l'immagine e l'etichetta sbagliata, l'osservatore umano verrebbe avvisato dell'attacco.In questo articolo, ci proponiamo di progettare attacchi che non solo fanno generare ai classificatori etichette sbagliate, ma rendono anche le etichette sbagliate impercettibili agli osservatori umani. Per raggiungere questo obiettivo, proponiamo un algoritmo chiamato LabelFool che identifica un'etichetta di destinazione simile all'etichetta di verità e trova una perturbazione dell'immagine per questa etichetta di destinazione.Troviamo prima l'etichetta di destinazione per un'immagine di input tramite un modello di probabilità, quindi spostiamo l'input nello spazio delle caratteristiche verso l'etichetta di destinazione.Studi soggettivi su ImageNet mostrano che nello spazio delle etichette, il nostro attacco è molto meno riconoscibile dagli osservatori umani, mentre i risultati sperimentali oggettivi su ImageNet mostrano che manteniamo prestazioni simili nello spazio delle immagini così come i tassi di attacco agli algoritmi di attacco più all'avanguardia.
Questo articolo presenta la classificazione del tipo di rumore/posizione di vari rumori di impatto generati in un edificio, che è un serio problema di conflitto nei complessi di appartamenti. Per questo studio, una collezione di rumori di impatto del pavimento è registrata con un singolo microfono. i tipi di rumore/posizioni sono selezionati in base a un rapporto del Floor Management Center sotto Korea Environmental Corporation. utilizzando un classificatore basato su reti neurali convoluzionali, i segnali di rumore di impatto convertiti in log-scaled Mel-spectrograms sono classificati in tipi di rumore o posizioni. inoltre, il nostro modello è valutato su un dataset standard di suoni ambientali ESC-50 per mostrare estensibilità sulla classificazione dei suoni ambientali.
Le registrazioni dei circuiti neurali nel cervello rivelano una straordinaria ricchezza dinamica e un'alta variabilità. Allo stesso tempo, le tecniche di riduzione della dimensionalità generalmente scoprono strutture a bassa dimensionalità alla base di queste dinamiche. Cosa determina la dimensionalità dell'attività nei circuiti neurali? In questo lavoro affrontiamo queste domande utilizzando modelli di reti neurali ricorrenti (RNN) e scopriamo che, a seconda delle dinamiche della rete iniziale, le RNN imparano ad aumentare e ridurre la dimensionalità in un modo che corrisponde alle richieste dei compiti.
L'adattamento al dominio affronta il problema comune quando la distribuzione di destinazione che genera i nostri dati di test si allontana dalla distribuzione di origine (formazione).Mentre in assenza di ipotesi, l'adattamento al dominio è impossibile, condizioni rigorose, ad esempio lo spostamento di covariate o etichette, consentono algoritmi di principio.approcci di dominio-adversariale recentemente proposti consistono nell'allineamento delle codifiche di origine e destinazione, spesso motivando questo approccio come la minimizzazione di due (di tre) termini in un limite teorico sull'errore di destinazione. Sfortunatamente, questa minimizzazione può causare aumenti arbitrari nel terzo termine, ad esempio possono rompersi sotto distribuzioni di etichette mutevoli.Proponiamo l'allineamento asimmetrico-rilassato della distribuzione, un nuovo approccio che supera alcune limitazioni degli algoritmi domain-adversarial standard.Inoltre, caratterizziamo precise ipotesi sotto le quali il nostro algoritmo è teoricamente fondato e dimostriamo benefici empirici su dataset sia sintetici che reali.
Per evitare che i modelli sequence-to-sequence (seq2seq) degenerino in modelli linguistici e per controllare meglio il testo lungo da generare, proponiamo un approccio di generazione gerarchica che prima genera uno schizzo di lunghezza intermedia basato sul sommario e poi completa l'articolo arricchendo lo schizzo generato. Per mitigare la discrepanza tra lo schizzo ``oracolo'' usato durante l'addestramento e lo schizzo rumoroso generato durante l'inferenza, proponiamo un quadro di addestramento congiunto end-to-end basato sull'apprendimento di rinforzo multi-agente. Per la valutazione, usiamo corpora di riassunto del testo invertendo i loro input e output, e introduciamo un nuovo metodo di valutazione che impiega un sistema di riassunto per riassumere l'articolo generato e testare la sua corrispondenza con il riassunto dell'input originale. Gli esperimenti mostrano che il nostro approccio di generazione gerarchica proposto può generare un articolo coerente e rilevante basato sul riassunto dato, producendo miglioramenti significativi sui modelli seq2seq convenzionali.
Quando si addestra una rete neurale profonda per la classificazione supervisionata delle immagini, si può ampiamente distinguere tra due tipi di caratteristiche latenti delle immagini che guideranno la classificazione della classe Y. Seguendo la notazione di Gong et al. (2016), possiamo dividere le caratteristiche in generale nelle classi di (i) caratteristiche "nucleo" o "incondizionatamente invarianti" X^ci la cui distribuzione P(X^ci | Y) non cambia sostanzialmente attraverso i domini e (ii) caratteristiche "stile" o "ortogonali" X^orth la cui distribuzione P(X^orth | Y) può cambiare sostanzialmente attraverso i domini. Queste ultime caratteristiche ortogonali includono generalmente caratteristiche come la posizione, la rotazione, la qualità dell'immagine o la luminosità, ma anche altre più complesse come il colore dei capelli o la postura per le immagini di persone. Cerchiamo di proteggerci da futuri spostamenti di dominio avversari utilizzando idealmente solo le caratteristiche "incondizionatamente invarianti" per la classificazione. Assumiamo, tuttavia, che a volte possiamo osservare un cosiddetto identificatore o variabile ID.Potremmo sapere, per esempio, che due immagini mostrano la stessa persona, con ID che si riferisce all'identità della persona.Nell'aumento dei dati, generiamo diverse immagini dalla stessa immagine originale, con ID che si riferisce all'immagine originale rilevante. Il metodo richiede solo una piccola frazione di immagini per avere una variabile ID.Forniamo un quadro causale per il problema aggiungendo la variabile ID al modello di Gong et al. (2016).Tuttavia, siamo interessati a impostazioni in cui non possiamo osservare direttamente il dominio e trattiamo il dominio come una variabile latente. Se due o più campioni condividono la stessa classe e lo stesso identificatore, (Y, ID)=(y,i), allora trattiamo quei campioni come controfattuali sotto diversi interventi di stile sulle caratteristiche ortogonali o di stile. Questo ha dimostrato di migliorare sostanzialmente le prestazioni nelle impostazioni in cui i domini cambiano in termini di qualità dell'immagine, luminosità, cambiamenti di colore, e cambiamenti più complessi come i cambiamenti nel movimento e nella postura.Mostriamo collegamenti a questioni di interpretabilità, equità e apprendimento di trasferimento.
Gli algoritmi di meta-apprendimento basati sul gradiente richiedono diversi passi di discesa del gradiente per adattarsi ai nuovi compiti in arrivo.Questo processo diventa più costoso all'aumentare del numero di campioni.  Inoltre, gli aggiornamenti del gradiente soffrono di diverse fonti di rumore che portano a una performance degradata.   In questo lavoro, proponiamo un algoritmo di meta-apprendimento dotato di GradiEnt Component COrrections, una cella GECCO in breve, che genera una matrice moltiplicativa correttiva a basso rango che (dopo la vettorizzazione) corregge i gradienti stimati. GECCO contiene una semplice rete simile al decoder con parametri apprendibili, un modulo di attenzione e un cosiddetto parametro di input del contesto. Il parametro di contesto di GECCO viene aggiornato per generare un termine correttivo di basso rango per i gradienti della rete.   Come risultato, il meta-apprendimento richiede solo pochi aggiornamenti del gradiente per assorbire un nuovo compito (spesso, un singolo aggiornamento è sufficiente nello scenario di pochi colpi). Mentre gli approcci precedenti affrontano questo problema alterando i tassi di apprendimento, fattorizzando i parametri di rete o imparando direttamente le correzioni delle caratteristiche dalle caratteristiche e/o dai gradienti, GECCO è un'unità simile a un generatore che esegue le correzioni del gradiente elementare senza la necessità di osservare direttamente le caratteristiche e/o i gradienti.  Mostriamo che il nostro GECCO (i) accelera l'apprendimento, (ii) esegue correzioni robuste dei gradienti corrotti da un rumore, e (iii) porta a notevoli miglioramenti rispetto agli algoritmi di meta-apprendimento esistenti basati sul gradiente.
I modelli discriminativi di risposta alle domande possono adattarsi eccessivamente alle distorsioni superficiali dei set di dati, perché la loro funzione di perdita si satura quando qualsiasi indizio rende probabile la risposta.  Introduciamo modelli generativi della distribuzione congiunta di domande e risposte, che sono addestrati per spiegare l'intera domanda, non solo per rispondere. Il nostro modello di risposta alle domande (QA) è implementato imparando un priore sulle risposte, e un modello di linguaggio condizionale per generare la domanda data la risposta - permettendo un ragionamento scalabile e interpretabile a molti giri mentre la domanda viene generata parola per parola.  Il nostro modello raggiunge prestazioni competitive con i modelli discriminativi specializzati sui benchmark SQUAD e CLEVR, indicando che si tratta di un'architettura più generale per la comprensione e il ragionamento linguistico rispetto ai lavori precedenti. Il modello migliora notevolmente la generalizzazione sia dai dati di allenamento distorti che dai dati di test avversari, raggiungendo un nuovo state-of-the-art su ADVERSARIAL SQUAD.
In questo articolo, rivolgiamo la nostra attenzione all'interazione tra le funzioni di attivazione e la normalizzazione batch, che è una tecnica praticamente obbligatoria per addestrare le reti profonde attualmente.Proponiamo la funzione di attivazione Displaced Rectifier Linear Unit (DReLU) congetturando che estendere la funzione di identità di ReLU al terzo quadrante migliora la compatibilità con la normalizzazione batch. Inoltre, abbiamo usato test statistici per confrontare l'impatto dell'uso di funzioni di attivazione distinte (ReLU, LReLU, PReLU, ELU, e DReLU) sulla velocità di apprendimento e sulle prestazioni di accuratezza dei test dei modelli all'avanguardia VGG e Residual Networks standardizzati. Queste reti neurali convoluzionali sono state addestrate su CIFAR-100 e CIFAR-10, i set di dati di deep learning computer vision più comunemente usati. I risultati hanno mostrato che DReLU ha accelerato l'apprendimento in tutti i modelli e set di dati. Inoltre, valutazioni statistiche significative delle prestazioni (p<0,05) hanno mostrato che DReLU ha migliorato l'accuratezza del test presentato da ReLU in tutti gli scenari. Inoltre, DReLU ha mostrato una migliore accuratezza del test rispetto a qualsiasi altra funzione di attivazione testata in tutti gli esperimenti con una sola eccezione, nel qual caso ha presentato la seconda migliore performance.Pertanto, questo lavoro dimostra che è possibile aumentare le prestazioni sostituendo ReLU con una funzione di attivazione migliorata.
La codifica delle informazioni di scala dell'input esplicitamente nella rappresentazione appresa da una rete neurale convoluzionale (CNN) è vantaggiosa per molti compiti di visione, specialmente quando si tratta di segnali di input multiscala. Studiamo, in questo lavoro, un'architettura CNN scale-equivariant con convoluzioni congiunte attraverso lo spazio e il gruppo di scala, che si dimostra essere sia sufficiente che necessaria per ottenere rappresentazioni scale-equivariant. Per ridurre la complessità del modello e l'onere computazionale, decomponiamo i filtri convoluzionali sotto due basi separabili prefissate e tronchiamo l'espansione alle componenti a bassa frequenza. Un ulteriore vantaggio dell'espansione del filtro troncato è la migliore robustezza di deformazione della rappresentazione equivariante. Gli esperimenti numerici dimostrano che la rete neurale scala-equivariante proposta con filtri convoluzionali decomposti (ScDCFNet) raggiunge prestazioni significativamente migliori nella classificazione delle immagini multiscala e una migliore interpretabilità rispetto alle CNN regolari a una dimensione ridotta del modello.
In questo articolo, diagnostichiamo le reti neurali profonde per l'elaborazione di nuvole di punti 3D per esplorare l'utilità di diverse architetture di rete. Proponiamo una serie di ipotesi sugli effetti di architetture di rete specifiche sulla capacità di rappresentazione delle DNN. Al fine di dimostrare le ipotesi, progettiamo cinque metriche per diagnosticare vari tipi di DNN dalle seguenti prospettive, scarto di informazioni, concentrazione di informazioni, robustezza di rotazione, robustezza avversaria e incoerenza di vicinato. Conduciamo studi comparativi basati su tali metriche per verificare le ipotesi, che possono gettare nuove luci sulla progettazione architettonica delle reti neurali.Gli esperimenti hanno dimostrato l'efficacia del nostro metodo.Il codice sarà rilasciato quando questo articolo sarà accettato.
In questo lavoro costruiamo distribuzioni congiunte flessibili da distribuzioni condizionali semi-implicite a bassa dimensione, definendo esplicitamente la struttura dell'approssimazione si può rendere il limite inferiore variazionale più stretto, con conseguente inferenza più accurata.
L'apprendimento per imitazione da dimostrazioni umane-esperte ha dimostrato di essere molto utile per problemi impegnativi di apprendimento di rinforzo con ricompense ambientali sparse, ma è molto difficile ottenere un successo simile senza fare affidamento su dimostrazioni di esperti. Lavori recenti sull'apprendimento dell'auto-imitazione hanno mostrato che imitare la buona esperienza passata dell'agente potrebbe indirettamente guidare l'esplorazione in alcuni ambienti, ma questi metodi spesso portano a un comportamento sub-ottimale e miope.Per affrontare questo problema, sosteniamo che l'esplorazione in diverse direzioni imitando diverse traiettorie, invece di concentrarsi su buone traiettorie limitate, è più desiderabile per i compiti di esplorazione difficile. Proponiamo un nuovo metodo di apprendimento di una politica condizionata dalla traiettoria per imitare diverse traiettorie dalle esperienze passate dell'agente e mostriamo che tale auto-imitazione aiuta ad evitare il comportamento miope e aumenta la possibilità di trovare una soluzione globalmente ottimale per compiti di esplorazione difficile, specialmente quando ci sono ricompense fuorvianti. Il nostro metodo supera significativamente l'apprendimento dell'auto-imitazione esistente e i metodi di esplorazione basati sul conteggio su vari compiti di esplorazione difficili con ottimi locali. In particolare, riportiamo un punteggio allo stato dell'arte di più di 20.000 punti su Montezumas Revenge senza usare dimostrazioni di esperti o resettare a stati arbitrari.
Presentiamo un metodo che allena reti neurali di grande capacità con un'accuratezza significativamente migliorata e un costo computazionale dinamico più basso. Questo si ottiene regolando l'architettura di deep-learning a un livello fine-grained.Le mappe convoluzionali individuali sono attivate/disattivate in modo condizionale sulle caratteristiche della rete. Per raggiungere questo obiettivo, introduciamo una nuova architettura a blocchi residuali che gestisce i canali di convoluzione in modo a grana fine. Introduciamo anche uno strumento generalmente applicabile di batch-shaping che abbina i posteri marginali aggregati delle caratteristiche in una rete neurale a una distribuzione a priori prestabilita, utilizzando questa nuova tecnica per forzare i gate a essere più condizionati dai dati. Presentiamo i risultati sui dataset CIFAR-10 e ImageNet per la classificazione delle immagini, e Cityscapes per la segmentazione semantica. I nostri risultati mostrano che il nostro metodo può snellire le grandi architetture in modo condizionale, in modo che il costo computazionale medio sui dati sia alla pari con un'architettura più piccola, ma con una maggiore precisione. In particolare, su ImageNet, le nostre reti gated ResNet50 e ResNet34 ottengono il 74,60% e il 72,55% di accuratezza top-1 rispetto al 69,76% di accuratezza del modello base ResNet18, per una complessità simile.
Al fine di colmare il divario tra l'apprendimento profondo e l'IA simbolica, presentiamo una nuova architettura di rete neurale end-to-end che impara a formare rappresentazioni proposizionali con una struttura esplicitamente relazionale da dati pixel grezzi.Per valutare e analizzare l'architettura, introduciamo una famiglia di semplici compiti di ragionamento visivo relazionale di varia complessità. Mostriamo che l'architettura proposta, quando pre-addestrata su un curriculum di tali compiti, impara a generare rappresentazioni riutilizzabili che facilitano meglio l'apprendimento successivo su compiti precedentemente non visti, se confrontati con un certo numero di architetture di base.Il funzionamento di un modello addestrato con successo viene visualizzato per far luce su come funziona l'architettura.
Nell'inferenza del linguaggio naturale, la semantica di alcune parole non influisce sull'inferenza.Tali informazioni sono considerate superficiali e portano overfitting.Come possiamo rappresentare e scartare tali informazioni superficiali? In questo articolo, usiamo la logica del primo ordine (FOL) - una tecnica classica del linguaggio di rappresentazione del significato - per spiegare quali informazioni sono superficiali per una data coppia di frasi.Tale spiegazione suggerisce anche due bias induttivi secondo le sue proprietà.Abbiamo proposto un approccio basato su reti neurali che utilizza i due bias induttivi.Otteniamo miglioramenti sostanziali rispetto a esperimenti estesi.
Proponiamo un approccio per l'addestramento di modelli di apprendimento automatico che siano equi nel senso che la loro performance è invariante sotto certe perturbazioni alle caratteristiche, per esempio, la performance di un sistema di screening del curriculum dovrebbe essere invariante sotto cambiamenti al nome del candidato. formalizziamo questa nozione intuitiva di equità collegandola alla nozione originale di equità individuale esposta da Dwork et al e dimostriamo che l'approccio proposto raggiunge questa nozione di equità. dimostriamo anche l'efficacia dell'approccio su due compiti di apprendimento automatico che sono suscettibili di pregiudizi di genere e razziali.
In questo articolo, proponiamo una struttura Seed-Augment-Train/Transfer (SAT) che contiene una procedura di generazione di immagini sintetiche per lingue con diversi sistemi numerici utilizzando set di dati di file di font aperti e liberamente disponibili. Questo set di immagini viene poi aumentato per creare un set di dati di allenamento puramente sintetico, che viene a sua volta utilizzato per addestrare una rete neurale profonda e testare su un set di dati di cifre scritte a mano nel mondo reale che abbraccia cinque scritture indicali, Kannada, Tamil, Gujarati, Malayalam e Devanagari. Mostriamo l'efficacia di questo approccio sia qualitativamente, addestrando un Boundary-seeking GAN (BGAN) che genera immagini di cifre realistiche nelle cinque lingue, sia qualitativamente testando una CNN addestrata sui dati sintetici sui dataset del mondo reale. Questo stabilisce non solo un nesso interessante tra il font-datasets-world e il transfer learning ma fornisce anche una ricetta per la classificazione universale delle cifre in qualsiasi scrittura.
Un algoritmo di particolare successo è stato il Model Agnostic Meta-Learning (MAML), un metodo che consiste in due cicli di ottimizzazione, con il ciclo esterno che trova una meta-inizializzazione, dalla quale il ciclo interno può imparare in modo efficiente nuovi compiti. Nonostante la popolarità di MAML, rimane una questione aperta fondamentale: l'efficacia di MAML è dovuta al fatto che la meta-inizializzazione è innescata per un apprendimento rapido (grandi ed efficienti cambiamenti nelle rappresentazioni) o al riutilizzo delle caratteristiche, con la meta-inizializzazione che contiene già caratteristiche di alta qualità? Questo porta all'algoritmo ANIL (Almost No Inner Loop), una semplificazione di MAML in cui rimuoviamo il ciclo interno per tutti gli elementi tranne la testa (specifica del compito) della rete neurale sottostante. ANIL corrisponde alle prestazioni di MAML sulla classificazione di immagini a pochi scatti e RL e offre miglioramenti computazionali rispetto a MAML. Studiamo ulteriormente i contributi precisi della testa e del corpo della rete, mostrando che le prestazioni sui compiti di prova sono interamente determinate dalla qualità delle caratteristiche apprese, e possiamo rimuovere anche la testa della rete (l'algoritmo NIL).Concludiamo con una discussione sull'apprendimento rapido contro la questione del riutilizzo delle caratteristiche per gli algoritmi di meta-apprendimento più in generale.
L'addestramento del modello rimane un costo finanziario dominante e un investimento di tempo nelle applicazioni di apprendimento automatico. Lo sviluppo e il debugging dei modelli spesso coinvolgono l'addestramento iterativo, esacerbando ulteriormente questo problema. Con il crescente interesse per modelli sempre più complessi, c'è bisogno di tecniche che aiutino a ridurre lo sforzo complessivo di addestramento. Noi forniamo un algoritmo indipendente dal metodo per decidere quando addestrare in modo incrementale rispetto all'addestramento completo; chiamiamo questa impostazione di addestramento completo o incrementale non deterministico "Mixed Setting Training"; dopo una valutazione in compiti di riempimento di slot, troviamo che questo algoritmo fornisce un errore limitato, evita la dimenticanza catastrofica, e risulta in un significativo aumento della velocità rispetto a una politica di addestramento sempre completo.
Le reti neurali hanno avuto successo in molti compiti di ragionamento.Empiricamente, questi compiti richiedono strutture di rete specializzate, ad es, Noi sviluppiamo una struttura per caratterizzare quali compiti di ragionamento una rete può imparare bene, studiando quanto bene la sua struttura si allinei con la struttura algoritmica della procedura di ragionamento pertinente. Definiamo formalmente l'allineamento algoritmico e deriviamo un limite di complessità del campione che diminuisce con un migliore allineamento.Questa struttura spiega il successo empirico dei modelli di ragionamento popolari e suggerisce i loro limiti.Unifichiamo compiti di ragionamento apparentemente diversi, come la fisica intuitiva, la risposta alle domande visive e i percorsi più brevi, attraverso la lente di un potente paradigma algoritmico, la programmazione dinamica (DP).Mostriamo che le GNN possono imparare DP e quindi risolvere questi compiti.Su diversi compiti di ragionamento, la nostra teoria si allinea ai risultati empirici.
Le interazioni cellula-cellula hanno un ruolo integrale nella tumorigenesi in quanto sono critiche nel governare le risposte immunitarie. come tale, indagando le interazioni cellula-cellula specifiche ha il potenziale non solo per espandere sulla comprensione della tumorigenesi, ma anche guidare la gestione clinica delle risposte del paziente alle immunoterapie del cancro. Una recente tecnica di imaging per esplorare le interazioni cellula-cellula, l'imaging multiplexed del fascio ionico da time-of-flight (MIBI-TOF), consente di quantificare le cellule in 36 diversi marcatori di proteine a risoluzioni sub-cellulari in situ come immagini multiplexed ad alta risoluzione.Per esplorare le immagini MIBI, proponiamo un GAN per i dati multiplexed con attenzione specifica della proteina. Condizionando la generazione di immagini su tipi di cellule, dimensioni e quartieri attraverso mappe di segmentazione semantica, siamo in grado di osservare come questi fattori influenzano le interazioni cellula-cellula simultaneamente in diversi canali proteici.Inoltre, progettiamo un set di metriche e offriamo le prime intuizioni verso gli orientamenti spaziali delle cellule, le espressioni delle proteine cellulari e i quartieri delle cellule. Il nostro modello, l'interazione cellula-cellula GAN (CCIGAN), supera o eguaglia i metodi di sintesi di immagini esistenti su tutte le misure convenzionali e supera significativamente le metriche biologicamente motivate.A nostra conoscenza, siamo i primi a modellare sistematicamente più comportamenti e interazioni delle proteine cellulari in condizioni simulate attraverso la sintesi di immagini.
I modelli di apprendimento automatico per la domanda-risposta (QA), dove data una domanda e un passaggio, l'allievo deve selezionare qualche span nel passaggio come risposta, sono noti per essere fragili.Inserendo una singola frase fastidiosa nel passaggio, un avversario può ingannare il modello a selezionare lo span sbagliato. Un nuovo e promettente approccio per l'AQ scompone il compito in due fasi: (i) selezionare le frasi rilevanti dal brano; e (ii) selezionare un intervallo tra quelle frasi.Intuitivamente, se il selettore di frasi esclude la frase incriminata, allora il selettore di intervallo a valle sarà robusto. Mentre il lavoro recente ha accennato alla potenziale robustezza dell'AQ a due stadi, questi metodi non sono mai stati, a nostra conoscenza, esplicitamente combinati con l'addestramento avversario. Questo articolo offre un'indagine empirica approfondita della robustezza avversaria, dimostrando che anche se l'approccio a due stadi è in ritardo rispetto alla selezione di span a singolo stadio, l'addestramento avversario migliora notevolmente le sue prestazioni, portando a un miglioramento di oltre 22 punti nel punteggio F1 rispetto al modello a singolo stadio addestrato avversariamente.
Lo scopo di questo studio è quello di introdurre un quadro formale per l'analisi e la sintesi dei sistemi di assistenza alla guida, applicando metodi formali alla verifica di un modello stocastico di guidatore umano costruito utilizzando l'architettura cognitiva ACT-R, per poi avviare la sicurezza nei veicoli semi-autonomi attraverso la progettazione di sistemi avanzati di assistenza alla guida provabilmente corretti. I contributi principali includono l'integrazione di modelli probabilistici ACT-R nell'analisi formale dei sistemi semi-autonomi e una tecnica di astrazione che permette una rappresentazione finita di un sistema continuo di grandi dimensioni sotto forma di un modello di Markov.
In contrasto con il vecchio sistema di scrittura del 19° secolo, l'ortografia hawaiana moderna impiega caratteri per le vocali lunghe e gli arresti glottali.Questi caratteri extra rappresentano circa un terzo dei fonemi in hawaiano, quindi includerli fa una grande differenza per la comprensione della lettura e la pronuncia.Tuttavia, la traslitterazione tra testi vecchi e nuovi è un compito laborioso se eseguito manualmente.Introduciamo due metodi correlati per aiutare a risolvere questo problema di traslitterazione automaticamente, dato che non c'erano abbastanza dati per allenare un modello di deep learning end-to-end. Un approccio è implementato, end-to-end, utilizzando trasduttori a stati finiti (FST).L'altro è un approccio ibrido di deep learning che compone approssimativamente un FST con una rete neurale ricorrente (RNN).Troviamo che l'approccio ibrido supera l'end-to-end FST partizionando il problema originale in una parte che può essere modellata a mano, utilizzando un FST, e in un'altra parte, che è facilmente risolta da una RNN addestrata sui dati disponibili.
In molte impostazioni del mondo reale, un modello di apprendimento deve eseguire una classificazione a pochi colpi: imparare a classificare esempi da classi non viste usando solo pochi esempi etichettati per classe. Inoltre, per essere distribuito in modo sicuro, dovrebbe avere la capacità di rilevare input fuori distribuzione: esempi che non appartengono a nessuna delle classi. Mentre sia la classificazione a pochi colpi che il rilevamento di fuori distribuzione sono argomenti popolari, la loro combinazione non è stata studiata. In questo lavoro, proponiamo compiti per il rilevamento di fuori distribuzione nell'impostazione a pochi colpi e stabiliamo set di dati di riferimento, basati su quattro popolari set di dati di classificazione a pochi colpi.  Quindi, proponiamo due nuovi metodi per questo compito e analizziamo le loro prestazioni. In sintesi, stabiliamo risultati di rilevamento di out-of-distribution di base utilizzando metriche standard su nuovi set di dati di riferimento e mostriamo risultati migliori con i nostri metodi proposti.
Mentre i moderni modelli generativi sono in grado di sintetizzare immagini ad alta fedeltà e visivamente accattivanti, generare con successo esempi utili per i compiti di riconoscimento rimane un obiettivo sfuggente. A tal fine, la nostra intuizione chiave è che gli esempi dovrebbero essere sintetizzati per recuperare i confini decisionali del classificatore che verrebbero appresi da una grande quantità di esempi reali.Più concretamente, trattiamo un classificatore formato su esempi sintetici come "studente" e un classificatore formato su esempi reali come "insegnante". Introducendo la distillazione della conoscenza in una struttura di meta-apprendimento, incoraggiamo il modello generativo a produrre esempi in un modo che consenta al classificatore studente di imitare il comportamento dell'insegnante.Per mitigare il potenziale divario tra classificatori studenti e insegnanti, proponiamo inoltre di distillare la conoscenza in modo progressivo, sia rafforzando gradualmente l'insegnante che indebolendo lo studente.Dimostriamo l'uso del nostro approccio di distillazione indipendente dal modello per affrontare la scarsità di dati, migliorando significativamente le prestazioni di apprendimento a pochi scatti sui benchmark miniImageNet e ImageNet1K.
Le reti neurali profonde forniscono prestazioni allo stato dell'arte per molte applicazioni di interesse.Purtroppo sono note per essere vulnerabili agli esempi avversari, formati applicando piccole ma malevole perturbazioni agli input originali.Inoltre, le perturbazioni possono trasferirsi tra i modelli: gli esempi avversari generati per un modello specifico spesso fuorviano altri modelli non visti.Di conseguenza l'avversario può sfruttarli per attaccare i sistemi black-box distribuiti. In questo lavoro, dimostriamo che la perturbazione avversaria può essere decomposta in due componenti: quella specifica del modello e quella dipendente dai dati, ed è quest'ultima che contribuisce principalmente alla trasferibilità.Motivati da questa comprensione, proponiamo di creare esempi avversari utilizzando il gradiente ridotto al rumore (NRG) che approssima la componente dipendente dai dati. Gli esperimenti su vari modelli di classificazione addestrati su ImageNet dimostrano che il nuovo approccio migliora drasticamente la trasferibilità. Troviamo anche che i modelli a bassa capacità hanno una capacità di attacco più potente delle controparti ad alta capacità, a condizione che abbiano prestazioni di test comparabili.  Queste intuizioni danno origine a un metodo di principio per costruire esempi avversari con alte percentuali di successo e potrebbero potenzialmente fornirci una guida per la progettazione di approcci di difesa efficaci contro gli attacchi black-box.
Presentiamo il flusso iterativo di decomposizione a due passi per accelerare le reti neurali convoluzionali esistenti (CNN).  L'algoritmo di selezione del rango proposto può determinare efficacemente i ranghi appropriati degli strati convoluzionali di destinazione per l'approssimazione di rango basso. La nostra decomposizione CP a due passi aiuta a prevenire il problema dell'instabilità. Il flusso iterativo rende sistematica la decomposizione delle reti più profonde. I risultati dell'esperimento mostrano che VGG16 può essere accelerato con una accelerazione misurata di 6.2x mentre il calo di precisione rimane solo 1.2%.
Introduciamo LiPopt, un quadro di ottimizzazione polinomiale per il calcolo di un limite superiore sempre più stretto sulla costante di Lipschitz delle reti neurali.I problemi di ottimizzazione sottostanti si riducono alla programmazione lineare (LP) o semidefinita (SDP).Mostriamo come utilizzare la connettività sparsa di una rete, per ridurre significativamente la complessità del calcolo. Questo è particolarmente utile per le reti neurali convoluzionali e per le reti neurali sfrondate. Conduciamo esperimenti su reti con pesi casuali e su reti addestrate su MNIST, mostrando che nel caso particolare della costante $ell_\infty$-Lipschitz, il nostro approccio produce stime superiori rispetto ad altre linee di base disponibili in letteratura.
Sebbene la ricerca sull'apprendimento di pochi colpi sia progredita rapidamente con l'aiuto del meta-apprendimento, la sua utilità pratica è ancora limitata perché la maggior parte delle ricerche presuppone che tutti gli esempi di meta-formazione e meta-test provengano da un singolo dominio. Noi proponiamo un modo semplice ma efficace per la classificazione di pochi colpi in cui una distribuzione di compiti si estende su più domini, compresi quelli precedentemente non visti durante il meta-apprendimento. Questo semplifica l'adattamento specifico del compito su una distribuzione complessa del compito come un semplice problema di selezione piuttosto che modificare il modello con una serie di parametri al momento del meta-test. Ispirati dalle comuni tecniche di apprendimento multi-task, lasciamo che tutti i modelli nel pool condividano una rete di base e aggiungiamo un modulatore separato ad ogni modello per perfezionare la rete di base a modo suo. Gli esperimenti dimostrano che il nostro schema di selezione supera altri algoritmi di classificazione a pochi colpi quando i compiti di destinazione potrebbero provenire da molti domini diversi.Essi rivelano anche che l'aggregazione degli output di tutti i modelli costituenti è efficace per i compiti da domini non visti, mostrando l'efficacia del nostro quadro.
Sempre nel 2019, molti documenti scannerizzati arrivano nelle aziende in formato non digitale.Il testo da estrarre dai documenti del mondo reale è spesso annidato all'interno di una ricca formattazione, come strutture tabellari o moduli con caselle da riempire o sottolineature il cui inchiostro spesso tocca o addirittura colpisce l'inchiostro del testo stesso.Tali artefatti di inchiostro possono interferire gravemente con le prestazioni degli algoritmi di riconoscimento o altri compiti di elaborazione a valle.In questo lavoro, proponiamo DeepErase, un preprocessore neurale per cancellare gli artefatti di inchiostro dalle immagini di testo. Oltre all'elevata accuratezza della segmentazione, dimostriamo che le nostre immagini pulite ottengono una spinta significativa nell'accuratezza del riconoscimento a valle da parte di software OCR popolari come Tesseract 4.0. Testiamo DeepErase su set di dati fuori distribuzione (NIST SDB) di moduli di dichiarazione dei redditi IRS scansionati e otteniamo miglioramenti a due cifre nell'accuratezza del riconoscimento rispetto alla linea di base sia per il testo stampato che scritto a mano.
Gli approcci attuali che si basano sulla formazione di modelli sostitutivi, sulla stima del gradiente o su algoritmi genetici spesso richiedono un numero eccessivo di interrogazioni, quindi non sono adatti ai sistemi del mondo reale dove il numero massimo di interrogazioni è limitato a causa dei costi. Proponiamo un attacco black-box efficiente che utilizza l'ottimizzazione bayesiana in combinazione con la selezione del modello bayesiano per ottimizzare la perturbazione avversaria e il grado ottimale di riduzione della dimensione dello spazio di ricerca. Dimostriamo empiricamente che il nostro metodo può raggiungere tassi di successo comparabili con 2-5 volte meno query rispetto ai precedenti attacchi black-box allo stato dell'arte.
L'apprendimento di rappresentazioni multimodali è un problema di ricerca fondamentalmente complesso a causa della presenza di più fonti eterogenee di informazioni, anche se la presenza di più modalità fornisce ulteriori informazioni preziose, ci sono due sfide chiave da affrontare quando si impara dai dati multimodali: 1) i modelli devono imparare le complesse interazioni intra-modali e cross-modali per la previsione e 2) i modelli devono essere robusti alle modalità mancanti o rumorose impreviste durante il test. In questo articolo, proponiamo di ottimizzare per un obiettivo generativo-discriminativo congiunto attraverso dati ed etichette multimodali. Introduciamo un modello che fattorizza le rappresentazioni in due serie di fattori indipendenti: fattori discriminativi multimodali e fattori generativi specifici della modalità. I fattori discriminativi multimodali sono condivisi tra tutte le modalità e contengono caratteristiche multimodali congiunte necessarie per compiti discriminativi come la predizione del sentimento.I fattori generativi specifici della modalità sono unici per ogni modalità e contengono le informazioni necessarie per generare i dati.I risultati sperimentali mostrano che il nostro modello è in grado di imparare rappresentazioni multimodali significative che raggiungono lo stato dell'arte o prestazioni competitive su sei set di dati multimodali. Il nostro modello dimostra capacità generative flessibili condizionando su fattori indipendenti e può ricostruire le modalità mancanti senza un impatto significativo sulle prestazioni.Infine, interpretiamo le nostre rappresentazioni fattorizzate per capire le interazioni che influenzano l'apprendimento multimodale.
Per affrontare la sfida, i domini con più di un compito dominante di interesse incoraggiano la condivisione di informazioni tra i compiti per limitare il tempo necessario per l'esperimento. A tal fine, indaghiamo i bias induttivi compositivi sotto forma di politiche gerarchiche come meccanismo per il trasferimento di conoscenze tra i compiti nell'apprendimento per rinforzo (RL).dimostriamo che questo tipo di gerarchia consente il trasferimento positivo mentre attenua le interferenze negative. I nostri esperimenti dimostrano che questi incentivi sono dati naturalmente nell'apprendimento multitask e possono essere facilmente introdotti per i singoli obiettivi. Progettiamo un algoritmo RL che permette l'apprendimento stabile e veloce delle politiche strutturate e il riutilizzo efficace di entrambi i componenti del comportamento e dei dati di transizione attraverso i compiti in un'impostazione off-policy.Finally, valutiamo il nostro algoritmo in ambienti simulati e in esperimenti fisici del robot e dimostriamo miglioramenti sostanziali nell'efficienza dei dati rispetto alle linee base competitive.
In questo articolo, studiamo il potere di rappresentazione delle reti neurali profonde (DNN) che appartengono alla famiglia delle funzioni piecewise-lineari (PWL), basate su unità di attivazione PWL come il raddrizzatore o maxout.Indaghiamo la complessità di tali reti studiando il numero di regioni lineari della funzione PWL.Tipicamente, una funzione PWL di una DNN può essere vista come una grande famiglia di funzioni lineari che agiscono su milioni di tali regioni.Ci basiamo direttamente sul lavoro di MontÂ´ufar et al. (2014), MontÂ´ufar (2017), e Raghu et al. (2017) raffinando i limiti superiori e inferiori sul numero di regioni lineari per le reti rettificate e maxout.Oltre a raggiungere limiti piÃ¹ stretti, sviluppiamo anche un nuovo metodo per eseguire la numerazione esatta o il conteggio del numero di regioni lineari con una formulazione lineare mista-integrale che mappa lo spazio di input all'output.Usiamo questa nuova capacitÃ per visualizzare come il numero di regioni lineari cambia durante la formazione DNNs.  
Le reti neurali convoluzionali memorizzano parte dei loro dati di addestramento, ed Ã¨ per questo che strategie come lâ€™aumento dei dati e il drop-out sono impiegati per mitigare lâ€™adattamento eccessivo.Questo articolo considera la questione correlata della â€œinferenza di appartenenzaâ€, dove lâ€™obiettivo Ã¨ quello di determinare se unâ€™immagine Ã¨ stata utilizzata durante lâ€™addestramento.Consideriamo test di appartenenza sia su insiemi di campioni che su campioni individuali. In primo luogo, mostriamo come rilevare se un set di dati è stato utilizzato per addestrare un modello, e in particolare se alcune immagini di convalida sono state utilizzate al momento dell'addestramento.Poi, introduciamo un nuovo approccio per dedurre l'appartenenza quando alcuni degli strati superiori non sono disponibili o sono stati messi a punto, e dimostriamo che gli strati inferiori portano ancora informazioni sui campioni di addestramento.Per sostenere i nostri risultati, conduciamo esperimenti su larga scala su Imagenet e sottoinsiemi di YFCC-100M con architetture moderne come VGG e Resnet.
Mentre le Generative Adversarial Networks (GANs) hanno empiricamente prodotto risultati impressionanti nell'apprendimento di distribuzioni complesse del mondo reale, lavori recenti hanno dimostrato che soffrono di mancanza di diversitÃ o di collasso di modo.Il lavoro teorico di Arora et al. (2017a) suggerisce un dilemma sulle proprietÃ statistiche delle GANs: discriminatori potenti causano overfitting, mentre discriminatori deboli non possono rilevare il collasso di modo. Al contrario, noi mostriamo in questo articolo che le GAN possono in linea di principio imparare distribuzioni a distanza Wasserstein (o KL-divergenza in molti casi) con una complessità campionaria polinomiale, se la classe di discriminatori ha un forte potere distintivo contro la particolare classe di generatori (invece che contro tutti i possibili generatori). Per varie classi di generatori come miscele di Gaussiane, famiglie esponenziali e generatori di reti neurali invertibili e iniettive, progettiamo i corrispondenti discriminatori (che spesso sono reti neurali di architetture specifiche) in modo tale che la metrica di probabilità integrale (IPM) indotta dai discriminatori possa approssimare in modo dimostrabile la distanza di Wasserstein e/o la divergenza di KL. Questo implica che se l'addestramento ha successo, allora la distribuzione appresa è vicina alla vera distribuzione nella distanza di Wasserstein o nella divergenza KL, e quindi non può cadere di modalità.I nostri esperimenti preliminari mostrano che su set di dati sintetici l'IPM di prova è ben correlata con la divergenza KL o la distanza Wasserstein, indicando che la mancanza di diversità nei GAN può essere causata dalla sub-ottimalità nell'ottimizzazione invece che dall'inefficienza statistica.
Comprendere la traiettoria di ottimizzazione è fondamentale per comprendere l'addestramento delle reti neurali profonde. Mostriamo come gli iperparametri della discesa del gradiente stocastico influenzano la covarianza dei gradienti (K) e l'Hessiana della perdita di addestramento (H) lungo questa traiettoria. Sulla base di un modello teorico, prevediamo che l'uso di un alto tasso di apprendimento o di una piccola dimensione del batch nella fase iniziale dell'addestramento porta SGD a regioni dello spazio dei parametri con (1) una ridotta norma spettrale di K, e (2) un migliore condizionamento di K e H. Dimostriamo che il punto sulla traiettoria dopo il quale questi effetti si mantengono, a cui ci riferiamo come punto di pareggio, viene raggiunto presto durante l'addestramento. dimostriamo empiricamente questi effetti per una serie di reti neurali profonde applicate a più compiti diversi. infine, applichiamo la nostra analisi alle reti con livelli di normalizzazione batch (BN) e troviamo che è necessario utilizzare un alto tasso di apprendimento per ottenere effetti di smussamento delle perdite attribuiti in precedenza alla sola BN.
Graph Convolution Network (GCN) è stato riconosciuto come uno dei modelli di grafo più efficaci per l'apprendimento semi-supervisionato, ma estrae solo il primo ordine o poche informazioni di vicinato attraverso la propagazione delle informazioni, che soffre di calo delle prestazioni per la struttura più profonda.approcci esistenti che si occupano dei vicini di ordine superiore tendono a sfruttare la potenza della matrice di adiacenza.in questo documento, si assume una condizione apparentemente banale che le informazioni di ordine superiore quartiere può essere simile a quella dei vicini di primo ordine. Di conseguenza, presentiamo un approccio non supervisionato per descrivere tali somiglianze e imparare le matrici di peso dei vicini di ordine superiore automaticamente attraverso Lasso che minimizza la perdita di funzionalità tra il primo ordine e i vicini di ordine superiore, in base al quale formuliamo il nuovo filtro convoluzionale per GCN per imparare le migliori rappresentazioni del nodo.Il nostro modello, chiamato GCN ponderato di ordine superiore (HWGCN), ha raggiunto lo stato dell'arte dei risultati su una serie di compiti di classificazione dei nodi su Cora, Citeseer e Pubmed datasets.
La performance delle reti neurali profonde è spesso attribuita alla loro costruzione automatizzata di caratteristiche legate al compito, ma rimane una questione aperta sul perché questo porta a soluzioni con una buona generalizzazione, anche nei casi in cui il numero di parametri è più grande del numero di campioni. Negli anni '90, Hochreiter e Schmidhuber hanno osservato che la planarità della superficie di perdita intorno a un minimo locale è correlata a un basso errore di generalizzazione. Tuttavia, è stato recentemente dimostrato che le misure esistenti di planarità non possono essere teoricamente correlate alla generalizzazione: se una rete usa attivazioni ReLU, la funzione di rete può essere riparametrizzata senza cambiare il suo output in modo tale che la planarità sia cambiata quasi arbitrariamente.Questo articolo propone una modifica naturale delle misure di planarità esistenti che risulta nell'invarianza alla riparametrizzazione. Le misure proposte implicano una robustezza della rete ai cambiamenti nell'input e negli strati nascosti. Collegare questa robustezza alla generalizzazione porta a una definizione generalizzata della rappresentatività dei dati, per cui l'errore di generalizzazione di un modello addestrato su dati rappresentativi può essere limitato dalla sua robustezza che dipende dalla nostra nuova misura di flatness.
I metodi bayesiani sono stati applicati con successo per sparsificare i pesi delle reti neurali e per rimuovere le unità di struttura dalle reti, per esempio i neuroni. Noi applichiamo e sviluppiamo ulteriormente questo approccio per le architetture ricorrenti gated. In particolare, oltre alla sparsificazione dei singoli pesi e neuroni, proponiamo di sparsificare le preattivazioni dei cancelli e del flusso di informazioni in LSTM.
Migliorare l'accuratezza dei metodi numerici rimane una sfida centrale in molte discipline ed è particolarmente importante per i problemi di simulazione non lineare.Un esempio rappresentativo di tali problemi è il flusso fluido, che è stato studiato a fondo per arrivare a simulazioni efficienti di fenomeni di flusso complessi.Questo articolo presenta un approccio guidato dai dati che impara a migliorare l'accuratezza dei solutori numerici.Il metodo proposto utilizza uno schema numerico avanzato con una risoluzione di simulazione fine per acquisire dati di riferimento. Forniamo approfondimenti sul problema dell'apprendimento mirato con diversi approcci di apprendimento: metodi di apprendimento completamente supervisionati con un'acquisizione di dati ingenua e ottimizzata e un metodo di apprendimento non supervisionato con un solutore di Navier-Stokes differenziabile.Mentre il nostro approccio Ã¨ molto generale e applicabile a modelli arbitrari di equazioni differenziali parziali, evidenziamo specificamente i guadagni di precisione per le simulazioni di flusso dei fluidi.
Sebbene sia tecnicamente possibile unire i dati per l'analisi in modo da sostenere un sistema sanitario di apprendimento rapido, le preoccupazioni per la privacy e le barriere normative limitano la centralizzazione dei dati. L'apprendimento automatico puÃ² essere condotto in modo federato sui set di dati dei pazienti con lo stesso set di variabili, ma separati tra i siti di cura. Ma l'apprendimento federato non puÃ² gestire la situazione in cui diversi tipi di dati per un dato paziente sono separati verticalmente attraverso diverse organizzazioni. Chiamiamo i metodi che consentono l'addestramento del modello di apprendimento automatico su dati separati da due o piÃ¹ gradi â€œapprendimento automatico confederato.â€ Abbiamo costruito e valutato un modello di apprendimento automatico confederato per stratificare il rischio di cadute accidentali tra gli anziani.
Le reti neurali esistenti sono vulnerabili agli "esempi avversari" - creati aggiungendo piccole perturbazioni malignamente progettate negli ingressi per indurre una classificazione errata da parte delle reti. La strategia di difesa più studiata è l'addestramento avversario che aumenta i dati di formazione con esempi avversari. Tuttavia, l'applicazione di adversari a passo singolo nell'addestramento avversario non supporta la robustezza delle reti, invece, faranno addirittura sì che le reti siano overfitted.In contrasto con l'addestramento a passo singolo, i risultati dell'addestramento multi-step sono allo stato dell'arte delle prestazioni su MNIST e CIFAR10, ma richiedono una quantità enorme di tempo. Pertanto, proponiamo un metodo, Stochastic Quantized Activation (SQA) che risolve i problemi di overfitting nell'addestramento adversariale single-step e raggiunge velocemente una robustezza paragonabile al multi-step.SQA attenua gli effetti adversariali fornendo una selettività casuale alle funzioni di attivazione e permette alla rete di imparare la robustezza con un solo training single-step. Nel corso dell'esperimento, il nostro metodo dimostra la robustezza allo stato dell'arte contro uno dei più forti attacchi white-box come l'addestramento PGD, ma con molto meno costo computazionale.Infine, visualizziamo il processo di apprendimento della rete con SQA per gestire forti avversari, che è diverso dai metodi esistenti.
L'attività neurale è altamente variabile in risposta a stimoli ripetuti.Abbiamo usato un set di dati aperto, l'Allen Brain Observatory, per quantificare la distribuzione delle risposte alle presentazioni ripetute di filmati naturali.Una grande frazione di risposte si adatta meglio a distribuzioni log-normali o miscele gaussiane con due componenti.Queste distribuzioni sono simili a quelle delle unità nelle reti neurali profonde con dropout. Usando un set separato di registrazioni elettrofisiologiche, abbiamo costruito un modello di accoppiamento della popolazione come controllo per le fluttuazioni di attività dipendenti dallo stato e abbiamo scoperto che i residui del modello mostrano anche distribuzioni non gaussiane. Abbiamo poi analizzato le risposte attraverso prove da sezioni multiple di diversi filmati e osservato che il rumore nella corteccia si allinea meglio con le variazioni dello stimolo in-clip rispetto a quelle out-of-clip.
L'adattamento di dominio non supervisionato ha ricevuto un'attenzione significativa negli ultimi anni. La maggior parte dei lavori esistenti affronta lo scenario a set chiuso, assumendo che il dominio di origine e quello di destinazione condividano esattamente le stesse categorie, L'estensione dell'adattamento del dominio da un insieme chiuso a tale situazione di insieme aperto non è banale, poiché non ci si aspetta che i campioni di destinazione nella classe sconosciuta si allineino con la fonte. In questo articolo, affrontiamo questo problema aumentando la tecnica di adattamento del dominio allo stato dell'arte, Self-Ensembling, con cluster di categoria nel dominio di destinazione. In particolare, presentiamo Self-Ensembling con Cluster Categoria-agnostici (SE-CC) --- una nuova architettura che guida l'adattamento del dominio con la guida aggiuntiva di cluster categoria-agnostici che sono specifici per il dominio di destinazione.Queste informazioni di clustering forniscono spunti visivi specifici del dominio, facilitando la generalizzazione di Self-Ensembling per scenari sia chiusi che aperti. Tecnicamente, il clustering viene innanzitutto eseguito su tutti i campioni di destinazione non etichettati per ottenere i cluster categoria-agnostici, che rivelano la struttura sottostante dello spazio dei dati peculiare al dominio di destinazione.Un ramo di clustering viene capitalizzato per garantire che la rappresentazione appresa conservi tale struttura sottostante facendo corrispondere la distribuzione di assegnazione stimata sui cluster alla distribuzione intrinseca dei cluster per ogni campione di destinazione. Inoltre, SE-CC migliora la rappresentazione appresa con la massimizzazione dell'informazione reciproca. Vasti esperimenti sono condotti su set di dati Office e VisDA sia per l'adattamento del dominio a set aperti che a set chiusi, e vengono riportati risultati superiori rispetto agli approcci all'avanguardia.
Presentiamo Spectral Inference Networks, una struttura per l'apprendimento di autofunzioni di operatori lineari tramite ottimizzazione stocastica.Spectral Inference Networks generalizza la Slow Feature Analysis a generici operatori simmetrici, ed è strettamente correlata ai metodi Variational Monte Carlo della fisica computazionale.Come tale, può essere un potente strumento per l'apprendimento non supervisionato della rappresentazione da video o dati strutturati a grafo. I nostri risultati dimostrano che le reti di inferenza spettrale recuperano accuratamente le autofunzioni degli operatori lineari e possono scoprire rappresentazioni interpretabili dal video in modo completamente non supervisionato.
La fattorizzazione Tensor-Train (TTF) è un modo efficiente per comprimere le grandi matrici di peso degli strati completamente connessi e degli strati ricorrenti nelle reti neurali ricorrenti (RNNs).Tuttavia, gli alti ranghi Tensor-Train per tutti i tensori del nucleo dei parametri devono essere fissati per elementi, il che si traduce in una ridondanza non necessaria dei parametri del modello.Questo lavoro applica la discesa del gradiente stocastico Riemanniano (RSGD) per formare i tensori del nucleo dei parametri nel collettore Riemanniano prima di trovare vettori di ranghi Tensor-Train inferiori per i parametri. L'articolo presenta prima l'algoritmo RSGD con un'analisi della convergenza e poi lo testa su RNN Tensor-Train più avanzate come GRU/LSTM bidirezionali e RNN Encoder-Decoder con un modello di attenzione Tensor-Train. Gli esperimenti sul riconoscimento delle cifre e sui compiti di traduzione automatica suggeriscono l'efficacia dell'algoritmo RSGD per RNN Tensor-Train.
In questo articolo, consideriamo il problema dell'apprendimento delle politiche di controllo che ottimizzano la funzione di areward mentre soddisfano i vincoli dovuti a considerazioni di sicurezza, equità, o altri costi.Proponiamo un nuovo algoritmo - Projection Based ConstrainedPolicy Optimization (PCPO), un metodo iterativo per ottimizzare le politiche in un processo a due fasi - la prima fase esegue un aggiornamento non vincolato mentre la seconda fase concilia la violazione dei vincoli proiettando la politica sul set di vincoli. Analizziamo teoricamente PCPO e forniamo un limite inferiore al miglioramento della ricompensa, così come un limite superiore alla violazione dei vincoli per ogni aggiornamento della politica. caratterizziamo ulteriormente la convergenza di PCPO con la proiezione basata su due diverse metriche - norma L2 e divergenza di Kullback-Leibler. i nostri risultati empirici su diversi compiti di controllo dimostrano che il nostro algoritmo raggiunge prestazioni superiori, in media più di 3,5 volte meno violazione dei vincoli e circa il 15% di ricompensa superiore rispetto ai metodi all'avanguardia.
Le reti profonde devono affrontare la sfida di garantire la loro robustezza contro gli input che non possono essere efficacemente rappresentati dalle informazioni apprese dai dati di formazione. attribuiamo questa vulnerabilità alle limitazioni inerenti alla rappresentazione basata sull'attivazione. per integrare le informazioni apprese dalla rappresentazione basata sull'attivazione, proponiamo di utilizzare una rappresentazione basata sul gradiente che si concentra esplicitamente sulle informazioni mancanti. Per convalidare l'efficacia dell'approccio proposto, confrontiamo le prestazioni di rilevamento delle anomalie delle rappresentazioni basate sul gradiente e su quelle basate sull'attivazione. Mostriamo che la rappresentazione basata sul gradiente supera la rappresentazione basata sull'attivazione di 0,093 in CIFAR-10 e 0,361 nei dataset CURE-TSR in termini di AUROC mediato su tutte le classi. Inoltre, proponiamo un algoritmo di rilevamento delle anomalie che utilizza la rappresentazione basata sul gradiente, indicata come GradCon, e convalidiamo le sue prestazioni su tre set di dati di benchmarking. Il metodo proposto supera la maggior parte degli algoritmi all'avanguardia nei set di dati CIFAR-10, MNIST e fMNIST con un AUROC medio di 0,664, 0,973 e 0,934, rispettivamente.
Le immagini mediche possono contenere vari tipi di artefatti con diversi modelli e miscele, che dipendono da molti fattori come l'impostazione della scansione, le condizioni della macchina, le caratteristiche dei pazienti, l'ambiente circostante, ecc. Tuttavia, i metodi esistenti di riduzione degli artefatti basati sull'apprendimento profondo sono limitati dal loro set di allenamento con un tipo e un modello di artefatto specifico predeterminato, per cui hanno un'adozione clinica limitata. In particolare, utilizziamo la bassa entropia visiva interna di un'immagine e addestriamo una rete di riduzione degli artefatti specifica dell'immagine leggera per ridurre gli artefatti in un'immagine al test-time.Usiamo la tomografia computerizzata (CT) e la risonanza magnetica (MRI) come veicoli per dimostrare che ZSAR puÃ² ridurre gli artefatti meglio di state-of-the-art sia qualitativamente che quantitativamente, mentre utilizza un tempo di esecuzione piÃ¹ breve.Al meglio della nostra conoscenza, questo Ã¨ il primo quadro di apprendimento profondo che riduce gli artefatti nelle immagini mediche senza utilizzare un set di formazione priori.
I metodi di attribuzione forniscono intuizioni sul processo decisionale dei modelli di apprendimento automatico come le reti neurali artificiali. per un dato campione di input, assegnano un punteggio di rilevanza a ogni singola variabile di input, come i pixel di un'immagine. in questo lavoro adattiamo il concetto di collo di bottiglia informativo per l'attribuzione. aggiungendo il rumore alle mappe di caratteristiche intermedie, limitiamo il flusso di informazioni e possiamo quantificare (in bit) quante informazioni forniscono le regioni dell'immagine. Confrontiamo il nostro metodo con dieci linee di base utilizzando tre diverse metriche su VGG-16 e ResNet-50, e troviamo che il nostro metodo supera tutte le linee di base in cinque impostazioni su sei. Il fondamento teorico dell'informazione del metodo fornisce un quadro di riferimento assoluto per i valori di attribuzione (bit) e una garanzia che le regioni con punteggio vicino allo zero non sono necessarie per la decisione della rete.
Le reti neurali ricorrenti (RNN) sono utilizzate in modelli all'avanguardia in domini come il riconoscimento vocale, la traduzione automatica e la modellazione del linguaggio.La sparsità è una tecnica per ridurre i requisiti di calcolo e di memoria dei modelli di apprendimento profondo.Le RNN sparse sono più facili da distribuire su dispositivi e processori server di fascia alta. Anche se le operazioni sparse hanno bisogno di meno calcolo e memoria rispetto alle loro controparti dense, l'aumento di velocità osservato utilizzando le operazioni sparse è inferiore a quello previsto su diverse piattaforme hardware.Al fine di affrontare questo problema, si studiano due diversi approcci per indurre la sparsità dei blocchi nelle RNN: potando i blocchi di pesi in uno strato e utilizzando la regolarizzazione lasso di gruppo con potatura per creare blocchi di pesi con zeri. Usando queste tecniche, possiamo creare RNN a blocchi sparsi con una sparsità che va dall'80% al 90% con una piccola perdita di accuratezza.Questa tecnica ci permette di ridurre la dimensione del modello di circa 10x.Inoltre, possiamo potare una rete più grande e densa per recuperare questa perdita di accuratezza mantenendo un'alta sparsità dei blocchi e riducendo il numero complessivo dei parametri.La nostra tecnica funziona con una varietà di dimensioni dei blocchi fino a 32x32.Le RNN a blocchi sparsi eliminano le spese generali relative alla memorizzazione dei dati e agli accessi irregolari alla memoria mentre aumentano l'efficienza hardware rispetto alla sparsità non strutturata.
Le reti di iterazione del valore sono un'approssimazione dell'algoritmo di iterazione del valore (VI) implementato con reti neurali convoluzionali per rendere VI completamente differenziabile.In questo lavoro, studiamo queste reti nel contesto della pianificazione del movimento del robot, con particolare attenzione alle applicazioni ai rover planetari.Il compito chiave impegnativo nella pianificazione del movimento basata sull'apprendimento è quello di imparare una trasformazione dalle osservazioni del terreno a una funzione di ricompensa di navigazione adatta.Per affrontare le osservazioni complesse del terreno e l'apprendimento della politica, proponiamo una ricorrenza di iterazione del valore, indicata come la rete morbida di iterazione del valore (SVIN). SVIN è progettato per produrre gradienti di formazione più efficaci attraverso la rete di iterazione del valore.Si basa su un modello di politica morbida, dove la politica è rappresentata con una distribuzione di probabilità su tutte le azioni possibili, piuttosto che una politica deterministica che restituisce solo l'azione migliore.Dimostriamo l'efficacia del metodo proposto in scenari di pianificazione del movimento del robot.In particolare, studiamo l'applicazione di SVIN a problemi molto impegnativi nella navigazione del rover planetario e presentiamo i primi risultati di formazione sui dati raccolti dal rover Curiosity che è attualmente operativo su Marte.
Le reti Transformer hanno portato a importanti progressi nella modellazione del linguaggio e nella traduzione automatica. Questi modelli includono due moduli consecutivi, uno strato feed-forward e uno strato di auto-attenzione. Quest'ultimo permette alla rete di catturare le dipendenze a lungo termine e sono spesso considerati l'ingrediente chiave del successo dei Transformer. Più precisamente, aumentiamo gli strati di auto-attenzione con vettori di memoria persistente che svolgono un ruolo simile allo strato di feed-forward.Grazie a questi vettori, possiamo rimuovere lo strato di feed-forward senza degradare le prestazioni di un trasformatore.La nostra valutazione mostra i benefici apportati dal nostro modello su benchmark standard di modellazione linguistica a livello di caratteri e parole.
Questo lavoro vede le reti neurali come sistemi che generano dati e applica tecniche di rilevamento di pattern anomali su quei dati, al fine di rilevare quando una rete sta elaborando un gruppo di input anomali.  Rilevare le anomalie è una componente critica per molteplici problemi di apprendimento automatico, incluso il rilevamento della presenza di rumore avversario aggiunto agli input. Più in generale, questo lavoro è un passo verso la capacità delle reti neurali di rilevare gruppi di campioni fuori distribuzione.  Questo lavoro introduce i metodi di ``Subset Scanning'' dal dominio del rilevamento di pattern anomali al compito di rilevare input anomali per le reti neurali.  Il Subset Scanning ci permette di rispondere alla domanda: "``Quale sottoinsieme di ingressi ha attivazioni più grandi del previsto in quale sottoinsieme di nodi?  Inquadrare il problema della rilevazione avversaria in questo modo ci permette di identificare modelli sistematici nello spazio di attivazione che abbracciano più immagini rumorose avversarie.  Tali immagini sono "strane insieme".  Sfruttando questo modello anomalo comune, mostriamo un aumento del potere di rilevazione con l'aumentare della proporzione di immagini disturbate in un set di test.   Il potere di rilevazione e i risultati di accuratezza sono forniti per il rumore adversario mirato aggiunto alle immagini CIFAR-10 su una ResNet a 20 strati usando l'attacco Basic Iterative Method.
La stabilità è una proprietà fondamentale dei sistemi dinamici, ma fino ad oggi ha avuto poca importanza nella pratica delle reti neurali ricorrenti. In questo lavoro, conduciamo un'indagine approfondita sui modelli ricorrenti stabili. Teoricamente, dimostriamo che le reti neurali ricorrenti stabili sono ben approssimate dalle reti feed-forward sia per l'inferenza che per l'addestramento tramite discesa del gradiente. Empiricamente, dimostriamo che i modelli ricorrenti stabili spesso si comportano bene come le loro controparti instabili su compiti di sequenza di riferimento. Insieme, questi risultati fanno luce sul potere effettivo delle reti ricorrenti e suggeriscono che molto dell'apprendimento delle sequenze avviene, o può essere fatto avvenire, nel regime stabile.
La condivisione dei pesi gioca un ruolo significativo nel successo di molte reti neurali profonde, aumentando l'efficienza della memoria e incorporando utili priori induttivi sul problema nella rete.Ma capire come la condivisione dei pesi possa essere usata efficacemente in generale è un argomento che non è stato studiato estensivamente.Chen et al. (2015) hanno proposto HashedNets, che aumenta un perceptron multistrato con una tabella hash, come metodo per la compressione delle reti neurali. Noi generalizziamo questo metodo in una struttura (ArbNets) che permette un'efficiente condivisione dei pesi arbitraria, e la usiamo per studiare il ruolo della condivisione dei pesi nelle reti neurali.Mostriamo che le reti neurali comuni possono essere espresse come ArbNets con diverse funzioni hash.Presentiamo anche due nuove funzioni hash, la Dirichlet hash e la Neighborhood hash, e le usiamo per dimostrare sperimentalmente che la condivisione dei pesi equilibrata e deterministica aiuta le prestazioni di una rete neurale.
Introduciamo le Neural Markov Logic Networks (NMLNs), un sistema di apprendimento statistico relazionale che prende in prestito idee dalla logica di Markov.Come le Markov Logic Networks (MLNs), le NMLNs sono un modello di tipo esponenziale per modellare le distribuzioni sui mondi possibili, ma a differenza delle MLNs, non si basano su regole logiche del primo ordine esplicitamente specificate.Invece, le NMLNs imparano una rappresentazione implicita di tali regole come una rete neurale che agisce come una funzione potenziale sui frammenti della struttura relazionale. È interessante notare che qualsiasi MLN può essere rappresentata come una NMLN.Analogamente ai Neural theorem provers (NTPs) recentemente proposti (Rocktaschel at al. 2017), le NMLNs possono sfruttare embeddings di costanti ma, a differenza delle NTPs, le NMLNs funzionano bene anche in loro assenza.Questo è estremamente importante per la previsione in impostazioni diverse da quella trasduttiva.Mostriamo il potenziale delle NMLNs su compiti di completamento della knowledge-base e sulla generazione di dati molecolari (grafo).
Usando le reti neurali Bayes variazionali, sviluppiamo un algoritmo capace di accumulare conoscenza in un priore da più compiti diversi, il che si traduce in un ricco priore in grado di apprendere in pochi colpi su nuovi compiti, il posteriore può andare oltre l'approssimazione del campo medio e produce una buona incertezza sugli esperimenti eseguiti. L'analisi sui compiti giocattolo mostra che può imparare da compiti significativamente diversi trovando somiglianze tra loro.Gli esperimenti su Mini-Imagenet raggiungono lo stato dell'arte con il 74,5% di accuratezza sull'apprendimento a 5 colpi.Infine, forniamo due nuovi benchmark, ognuno dei quali mostra una modalità di fallimento degli algoritmi di meta apprendimento esistenti come MAML e Reti prototipiche.
Per imparare robuste descrizioni cross-ambientali di sequenze introduciamo modelli di spazio di stato disentangled (DSSM).Nello spazio latente di DSSM le dinamiche di stato invarianti l'ambiente sono esplicitamente disentangled dalle informazioni ambiente-specifiche che governano quelle dinamiche. Mostriamo empiricamente che tale separazione consente una previsione robusta, la manipolazione della sequenza e la caratterizzazione dell'ambiente.Proponiamo anche una procedura di formazione non supervisionata basata su VAE per imparare DSSM come filtri bayesiani.Nei nostri esperimenti, dimostriamo lo stato dell'arte delle prestazioni nella generazione controllata e la previsione di rimbalzo sequenze video palla attraverso varie influenze gravitazionali.
In questo lavoro, ci avviciniamo ai problemi di apprendimento one-shot e few-shot come metodi per trovare buoni prototipi per ogni classe, dove questi prototipi sono generalizzabili a nuovi campioni di dati e classi.Proponiamo un learner metrico che impara una divergenza di Bregman imparando la sua funzione convessa sottostante.Le divergenze di Bregman sono un buon candidato per questo quadro dato che sono l'unica classe di divergenze con la proprietà che il miglior rappresentante di un insieme di punti è dato dalla sua media. I nostri risultati preliminari sono paragonabili al lavoro precedente sui set di dati Omniglot e Mini-ImageNet, due benchmark standard per l'apprendimento one-shot e few-shot. Sosteniamo che il nostro modello può essere utilizzato per altri compiti che coinvolgono l'apprendimento metrico o compiti che richiedono una convessità approssimativa come la previsione strutturata e il completamento dei dati.
Motivati dalla flessibilità delle reti neurali biologiche la cui struttura di connettività cambia significativamente durante la loro vita, introduciamo la rete ricorsiva senza restrizioni (URN) e dimostriamo che può esibire una simile flessibilità durante l'addestramento tramite la discesa del gradiente. Mostriamo empiricamente che molte delle diverse strutture di rete neurale comunemente usate oggi nella pratica (incluse reti completamente connesse, localmente connesse e residuali di profondità e larghezze diverse) possono emergere dinamicamente dalla stessa URN. Queste diverse strutture possono essere derivate usando la discesa a gradiente su una singola funzione di perdita generale dove la struttura dei dati e le forze relative dei vari termini regolatori determinano la struttura della rete emergente. Mostriamo che questa funzione di perdita e i regolatori sorgono naturalmente quando si considerano le simmetrie della rete così come le proprietà geometriche dei dati di input.
Presentiamo CROSSGRAD, un metodo per utilizzare dati di allenamento multi-dominio per imparare un classificatore che si generalizza a nuovi domini.CROSSGRAD non ha bisogno di una fase di adattamento tramite dati etichettati o non etichettati, o caratteristiche di dominio nel nuovo dominio.La maggior parte dei metodi di adattamento di dominio esistenti tentano di cancellare i segnali di dominio utilizzando tecniche come l'addestramento avversario di dominio. Al contrario, CROSSGRAD è libero di utilizzare i segnali di dominio per predire le etichette, se può prevenire l'overfitting sui domini di formazione. Concettualizziamo il compito in un'impostazione bayesiana, in cui una fase di campionamento è implementata come aumento dei dati, basata su perturbazioni guidate dal dominio delle istanze di input. CROSSGRAD allena congiuntamente un classificatore di etichette e un classificatore di dominio su esempi perturbati dai gradienti di perdita di ogni altro obiettivo. Questo ci permette di perturbare direttamente gli input, senza separare e rimescolare i segnali di dominio facendo varie ipotesi distributive. La valutazione empirica su tre diverse applicazioni in cui questa impostazione è naturale stabilisce che (1) la perturbazione guidata dal dominio fornisce una generalizzazione costantemente migliore a domini non visti, rispetto ai metodi generici di perturbazione delle istanze, e (2) l'aumento dei dati è un metodo più stabile e accurato dell'addestramento avversario del dominio.
Presentiamo sketch-rnn, una rete neurale ricorrente in grado di costruire disegni basati sul tratto di oggetti comuni.Il modello è addestrato su un set di dati di immagini disegnate dall'uomo che rappresentano molte classi diverse.Delineiamo un quadro per la generazione di schizzi condizionali e incondizionati, e descriviamo nuovi metodi di formazione robusti per generare disegni di schizzi coerenti in un formato vettoriale.
Wilson et al. (2017) hanno dimostrato che, quando il programma di stepsize è progettato correttamente, il gradiente stocastico generalizza meglio di ADAM (Kingma & Ba, 2014).Alla luce del recente lavoro sui metodi ipergradienti (Baydin et al, 2018), rivisitiamo queste affermazioni per vedere se tali metodi chiudono il divario tra gli ottimizzatori più popolari.Come sottoprodotto, analizziamo il vero beneficio di questi metodi ipergradienti rispetto a programmi più classici, come il decadimento fisso di Wilson et al. (2017).In particolare, osserviamo che sono di aiuto marginale poiché le loro prestazioni variano significativamente quando si sintonizzano i loro iperparametri.Infine, poiché la robustezza è una qualità critica di un ottimizzatore, forniamo un'analisi della sensibilità di questi ottimizzatori basati sul gradiente per valutare quanto sia impegnativo il loro tuning.
Nonostante una letteratura sempre crescente sugli algoritmi di apprendimento di rinforzo e sulle applicazioni, molto meno si sa sulla loro inferenza statistica. In questo documento, indaghiamo i comportamenti a grandi campioni delle stime del valore Q con caratterizzazioni in forma chiusa delle varianze asintotiche. Questo ci permette di costruire in modo efficiente le regioni di confidenza per il valore Q e le funzioni di valore ottimale, e di sviluppare politiche per minimizzare i loro errori di stima.
Eseguiamo una traduzione unilaterale completamente non supervisionata da immagine a immagine tra un dominio sorgente $X$ e un dominio target $Y$ in modo da preservare la semantica condivisa sottostante (ad esempio, classe, dimensione, forma, ecc.). In particolare, siamo interessati a un caso più difficile di quelli tipicamente affrontati in letteratura, in cui la fonte e l'obiettivo sono abbastanza lontani da far fallire gli approcci in stile ricostruzione o pixel-wise. Sosteniamo che trasferire (cioè, tradurre) dette informazioni rilevanti dovrebbe comportare sia scartare le informazioni specifiche del dominio di origine che incorporare le informazioni specifiche del dominio di destinazione, queste ultime modellate con una distribuzione prioritaria rumorosa. Per evitare il caso degenerato in cui i campioni generati sono spiegati solo dalla distribuzione a priori, proponiamo di minimizzare una stima dell'informazione reciproca tra il campione generato e il campione della distribuzione a priori.Scopriamo che le scelte architetturali sono un fattore importante da considerare per preservare la semantica condivisa tra $X$ e $Y$. Mostriamo lo stato dell'arte dei risultati sul compito MNIST a SVHN per la traduzione non supervisionata da immagine a immagine.
L'identificazione dei punti salienti nelle immagini è una componente cruciale per gli algoritmi di odometria visiva, Structure-from-Motion o SLAM.  Tuttavia, la generazione di dati di formazione coerenti e accurati per il rilevamento dei punti di interesse nelle immagini naturali rimane ancora una sfida, soprattutto per gli annotatori umani. Introduciamo IO-Net (cioè InlierOutlierNet), un nuovo compito di delega per l'auto-supervisione del rilevamento, descrizione e corrispondenza dei punti chiave. Rendendo il campionamento degli insiemi inlier-outlier dalle corrispondenze punto-coppia completamente differenziabili all'interno della struttura di apprendimento dei punti chiave, dimostriamo che siamo in grado di auto-supervisionare simultaneamente la descrizione dei punti chiave e migliorare la corrispondenza dei punti chiave.In secondo luogo, introduciamo KeyPointNet, un'architettura di rete di punti chiave che è particolarmente adatta al rilevamento e alla descrizione robusti dei punti chiave. Progettiamo la rete per consentire l'aggregazione locale dei punti chiave per evitare gli artefatti dovuti alle discretizzazioni spaziali comunemente utilizzate per questo compito, e miglioriamo le prestazioni dei descrittori dei punti chiave a grana fine sfruttando le efficienti convoluzioni sub-pixel per sovracampionare le mappe delle caratteristiche dei descrittori a una risoluzione operativa più alta.Attraverso ampi esperimenti e analisi ablative, dimostriamo che il metodo di apprendimento dei punti chiave auto-supervisionato proposto migliora notevolmente la qualità della corrispondenza delle caratteristiche e la stima dell'omografia su benchmark impegnativi rispetto allo stato dell'arte.
Studiamo il ruolo della motivazione intrinseca come bias di esplorazione per l'apprendimento di rinforzo in compiti sinergici a ricompensa sparsa, che sono compiti in cui più agenti devono lavorare insieme per raggiungere un obiettivo che non potrebbero individualmente. La nostra idea chiave è che un buon principio guida per la motivazione intrinseca nei compiti sinergici è quello di intraprendere azioni che influenzano il mondo in modi che non sarebbero raggiunti se gli agenti stessero agendo da soli. Studiamo due istanziazioni di questa idea, una basata sugli stati reali incontrati, e un'altra basata su un modello dinamico addestrato in concomitanza con la politica.Mentre la prima è più semplice, la seconda ha il vantaggio di essere analiticamente differenziabile rispetto all'azione intrapresa. Convalidiamo il nostro approccio in compiti di manipolazione robotica bimanuale con ricompense sparse; troviamo che il nostro approccio produce un apprendimento più efficiente di entrambi1) formazione con solo la ricompensa sparse e2) utilizzando la tipica formulazione basata sulla sorpresa della motivazione intrinseca, che non si orienta verso il comportamento sinergico.I video sono disponibili sulla pagina web del progetto: https://sites.google.com/view/iclr2020-synergistic.
Un'architettura generale di rete neurale strutturata a grafo opera sui grafi attraverso due componenti fondamentali: (In questo documento presentiamo l'algoritmo Policy Message Passing, che assume una prospettiva probabilistica e riformula l'intera aggregazione delle informazioni come processi sequenziali stocastici. L'algoritmo lavora su uno spazio di ricerca molto più ampio, utilizza la storia del ragionamento per eseguire l'inferenza ed è robusto ai bordi rumorosi.
Le reti profonde multitask, in cui una rete neurale produce più output predittivi, sono più scalabili e spesso meglio regolarizzate rispetto alle loro controparti a compito singolo. Tali vantaggi possono potenzialmente portare a guadagni sia in termini di velocità che di prestazioni, ma le reti multitask sono anche difficili da allenare senza trovare il giusto equilibrio tra i compiti. Presentiamo una nuova tecnica di normalizzazione del gradiente (GradNorm) che bilancia automaticamente la funzione di perdita multitask sintonizzando direttamente i gradienti per equalizzare i tassi di formazione dei compiti. Mostriamo che per varie architetture di rete, per compiti di regressione e classificazione, e su set di dati sintetici e reali, GradNorm migliora la precisione e riduce l'overfitting rispetto alle reti singole, alle linee base statiche e ad altre tecniche adattive di bilanciamento della perdita multitask. GradNorm eguaglia o supera anche le prestazioni dei metodi di ricerca a griglia esaustiva, pur coinvolgendo solo un singolo iperparametro di asimmetria $\alfa$. Così, quello che una volta era un noioso processo di ricerca che sosteneva esponenzialmente più calcoli per ogni compito aggiunto può ora essere realizzato in poche sessioni di allenamento, indipendentemente dal numero di compiti.In definitiva, speriamo di dimostrare che la manipolazione del gradiente ci permette un grande controllo sulle dinamiche di formazione delle reti multitask e può essere una delle chiavi per sbloccare il potenziale dell'apprendimento multitask.
La segmentazione delle immagini ha lo scopo di raggruppare i pixel che appartengono allo stesso oggetto o alla stessa regione.Al cuore della segmentazione delle immagini si trova il problema di determinare se un pixel è dentro o fuori una regione, che denotiamo come il problema dell'"insideness".Molte varianti di Deep Neural Networks (DNNs) eccellono nei benchmark di segmentazione, ma per quanto riguarda l'insideness, non sono state ben visualizzate o comprese: Quali rappresentazioni usano le DNN per affrontare le relazioni a lungo raggio dell'insideness? Come influiscono le scelte architettoniche sull'apprendimento di queste rappresentazioni? In questo articolo, adottiamo un approccio riduzionista analizzando le DNN che risolvono il problema dell'insideness in modo isolato, cioè determinando l'interno delle curve chiuse (Jordan).dimostriamo analiticamente che le architetture feed-forward e ricorrenti allo stato dell'arte possono implementare soluzioni del problema dell'insideness per qualsiasi curva data. Tuttavia, solo le reti ricorrenti possono imparare queste soluzioni generali quando l'addestramento impone una specifica "routine" in grado di rompere le relazioni a lungo raggio. I nostri risultati evidenziano la necessità di nuove strategie di addestramento che scompongano l'apprendimento in fasi appropriate, e che portino alla classe generale di soluzioni necessarie alle DNN per comprendere l'insideness.
Affrontiamo il difficile problema dell'apprendimento delle rappresentazioni profonde - l'adattamento efficiente di una rete profonda pre-addestrata a diversi compiti. In particolare, proponiamo di esplorare le caratteristiche basate sul gradiente, che sono i gradienti dei parametri del modello rispetto a una perdita specifica del compito dato un campione di input. Mostriamo che il nostro modello fornisce un'approssimazione lineare locale a un modello profondo sottostante, e discutiamo un'importante intuizione teorica. Inoltre, presentiamo un algoritmo efficiente per l'addestramento e l'inferenza del nostro modello senza calcolare i gradienti effettivi. Il nostro metodo viene valutato attraverso una serie di compiti di apprendimento della rappresentazione su diversi set di dati e utilizzando diverse architetture di rete.
Recuperare la forma della geometria 3D, l'albedo e l'illuminazione da una singola immagine ha ampie applicazioni in molti settori, che è anche un tipico problema mal posto.Al fine di eliminare l'ambiguità, la conoscenza precedente faccia come modelli lineari 3D morphable (3DMM) imparato da dati di scansione limitata sono spesso adottate al processo di ricostruzione. Tuttavia, i metodi basati su modelli parametrici lineari non possono generalizzare bene per le immagini facciali in natura con varie età, etnie, espressioni, pose e illuminazioni.Metodi recenti mirano ad apprendere un modello parametrico non lineare utilizzando reti neurali convoluzionali (CNN) per regredire la forma e la struttura del viso direttamente.Tuttavia, i modelli sono stati addestrati solo su un set di dati che è generato da un 3DMM lineare. Inoltre, le rappresentazioni dell'identità e dell'espressione sono impigliate in questi modelli, il che ostacola molte applicazioni di editing facciale. In questo articolo, addestriamo il nostro modello con perdita avversaria in modo semi-supervisionato su lotti ibridi di immagini facciali etichettate e non etichettate per sfruttare il valore di grandi quantità di immagini facciali non etichettate da collezioni di foto non vincolate. Viene introdotta una nuova perdita centrale per assicurarsi che le diverse immagini facciali della stessa persona abbiano la stessa forma di identità e albedo.Inoltre, il nostro modello proposto separa le rappresentazioni di identità, espressione, posa e illuminazione, il che migliora le prestazioni generali di ricostruzione e facilita le applicazioni di editing facciale, ad es, Esperimenti completi dimostrano che il nostro modello produce una ricostruzione di alta qualità rispetto ai metodi all'avanguardia ed è robusto a varie condizioni di espressione, posa e illuminazione.
Le conversazioni umane si evolvono naturalmente intorno a entità correlate e concetti collegati, mentre possono anche spostarsi da un argomento all'altro.Questo articolo presenta ConceptFlow, che sfrutta i grafi di conoscenza commonsense per modellare esplicitamente tali flussi di conversazione per una migliore generazione di risposte di conversazione.ConceptFlow fonda gli input di conversazione nello spazio concettuale latente e rappresenta il flusso potenziale di conversazione come un flusso di concetto lungo le relazioni commonsense. Il concetto è guidato da un meccanismo di attenzione del grafico che modella la possibilità che la conversazione si evolva verso concetti diversi.La risposta alla conversazione viene quindi decodificata utilizzando le codifiche sia dei testi degli enunciati che dei flussi concettuali, integrando la struttura della conversazione appresa nello spazio concettuale.I nostri esperimenti sulle conversazioni Reddit dimostrano il vantaggio di ConceptFlow rispetto ai precedenti modelli di dialogo commonsense aware e ai modelli GPT-2 fine-tuned, pur utilizzando molti meno parametri ma con una modellazione esplicita delle strutture di conversazione.
Le reti neurali biologiche affrontano vincoli omeostatici e di risorse che limitano le configurazioni consentite dei pesi di connessione; se un vincolo è stretto, definisce uno spazio di soluzione molto piccolo, e la dimensione di questi spazi di vincolo determina la loro potenziale sovrapposizione con le soluzioni per i compiti computazionali. Studiamo la geometria degli spazi di soluzione per i vincoli sul peso sinaptico totale dei neuroni e sui pesi sinaptici individuali, caratterizzando i gradi di connessione (numeri di partner) che massimizzano la dimensione di questi spazi di soluzione. Abbiamo poi ipotizzato che la dimensione degli spazi di soluzione dei vincoli potrebbe servire come una funzione di costo che governa lo sviluppo dei circuiti neurali, sviluppando approssimazioni analitiche e limiti per la prova del modello delle distribuzioni dei gradi di massima entropia sotto queste funzioni di costo, che testiamo su un connettoma pubblicato al microscopio elettronico di un centro di apprendimento associativo nel cervello della mosca, trovando prove di una progressione di sviluppo nella struttura del circuito.
In questo lavoro preliminare, studiamo le proprietà di generalizzazione di insiemi infiniti di reti neurali infinitamente ampie.  Sorprendentemente, questa famiglia di modelli ammette calcoli trattabili per molte quantità teoriche dell'informazione.  Riportiamo indagini analitiche ed empiriche nella ricerca di segnali che correlano con la generalizzazione.
L'apprendimento di rappresentazioni multilingue del testo si è dimostrato un metodo di successo per molti compiti di apprendimento multilingue di trasferimento.Ci sono due paradigmi principali per l'apprendimento di tali rappresentazioni: (1) l'allineamento, che mappa diverse rappresentazioni monolingue addestrate indipendentemente in uno spazio condiviso, e (2) l'addestramento congiunto, che apprende direttamente rappresentazioni multilingue unificate utilizzando obiettivi monolingue e cross-lingue congiuntamente.In questo articolo, abbiamo prima condotto confronti diretti di rappresentazioni apprese utilizzando entrambi questi metodi attraverso diversi compiti cross-lingue.I nostri risultati empirici rivelano una serie di pro e contro per entrambi i metodi, e mostrano che le prestazioni relative di allineamento rispetto all'addestramento congiunto è dipendente dal compito. Da questa analisi, proponiamo una struttura semplice e innovativa che combina questi due approcci che in precedenza si escludevano a vicenda. esperimenti estesi su vari compiti dimostrano che la struttura proposta allevia i limiti di entrambi gli approcci e supera i metodi esistenti sul benchmark MUSE bilingual lexicon induction (BLI). dimostriamo inoltre che la struttura proposta può generalizzarsi alle rappresentazioni contestualizzate e raggiunge risultati allo stato dell'arte sul benchmark cross-lingual NER CoNLL.
Un gran numero di pesi nelle reti neurali profonde rende i modelli difficili da implementare in ambienti a bassa memoria come i telefoni cellulari, i dispositivi IOT e gli ambienti "inferencing as a service" sul cloud. Il lavoro precedente ha considerato la riduzione delle dimensioni dei modelli, attraverso tecniche di compressione come il weight pruning, filter pruning, ecc. o attraverso la decomposizione a basso rango degli strati di convoluzione. In questo documento, dimostriamo l'uso di più tecniche per ottenere non solo una maggiore compressione del modello ma anche ridurre le risorse di calcolo richieste durante l'inferenza. Dimostriamo che il nostro approccio raggiunge fino al 57% di compressione del modello in più rispetto alla decomposizione di Tucker o alla sola potatura dei filtri con una precisione simile per GoogleNet e riduce i flop fino al 48%, rendendo l'inferenza più veloce.
Esaminiamo i limiti di BLEU e ROUGE - le metriche più popolari usate per valutare i sommari di riferimento rispetto ai sommari di ipotesi, e introduciamo JAUNE: un insieme di criteri per come dovrebbe comportarsi una buona metrica e proponiamo modi concreti per usare i recenti modelli linguistici basati su Transformers per valutare i sommari di riferimento rispetto ai sommari di ipotesi.
Questo articolo presenta un nuovo tipo di Graph Neural Network (GNN) che utilizza la modulazione lineare feature-wise (FiLM).Molte varianti GNN standard propagano l'informazione lungo i bordi di un grafico calcolando ``messaggi'' basati solo sulla rappresentazione della fonte di ogni bordo.In GNN-FiLM, la rappresentazione del nodo di destinazione di un bordo viene inoltre utilizzata per calcolare una trasformazione che può essere applicata a tutti i messaggi in arrivo, permettendo la modulazione feature-wise dell'informazione passata. I risultati degli esperimenti che confrontano diverse architetture GNN su tre compiti dalla letteratura sono presentati, basati su re-implementazioni di metodi di base. Gli iperparametri per tutti i metodi sono stati trovati usando una ricerca estesa, dando risultati un po' sorprendenti: le differenze tra i modelli di base sono più piccole di quelle riportate in letteratura.
Per trattare simultaneamente con entrambi, l'incorporazione della rete attribuita e il clustering, proponiamo un nuovo modello che sfrutta sia le informazioni sul contenuto che quelle sulla struttura, capitalizzando il loro uso simultaneo. I risultati degli esperimenti dimostrano che l'algoritmo proposto ha prestazioni migliori, in termini di clustering e embedding, rispetto agli algoritmi allo stato dell'arte, compresi i metodi di deep learning dedicati a compiti simili per dataset di rete attribuiti con proprietà diverse.
Proponiamo una tecnica di rendering appresa guidata dalle immagini che combina i vantaggi del rendering basato sulle immagini e della sintesi delle immagini basata su GAN, Una componente centrale del nostro lavoro è la gestione degli effetti dipendenti dalla vista. In particolare, addestriamo direttamente una rete neurale profonda specifica per l'oggetto per sintetizzare l'aspetto dipendente dalla vista di un oggetto. Questo video viene utilizzato per ricostruire una geometria proxy dell'oggetto tramite la stereoscopia multi-vista.Sulla base di questo proxy 3D, l'aspetto di una vista catturata può essere deformato in una nuova vista di destinazione come nel classico rendering basato sulle immagini.Questo warping presuppone superfici diffuse, in caso di effetti dipendenti dalla vista, come le luci speculari, porta ad artefatti. A questo scopo, proponiamo EffectsNet, una rete neurale profonda che predice gli effetti dipendenti dalla vista.Sulla base di queste stime, siamo in grado di convertire le immagini osservate in immagini diffuse.Queste immagini diffuse possono essere proiettate in altre viste.Nella vista di destinazione, la nostra pipeline reinserisce i nuovi effetti dipendenti dalla vista. Per comporre più immagini riproiettate in un output finale, impariamo una rete di composizione che produce risultati foto-realistici. Usando questo approccio guidato dall'immagine, la rete non deve allocare capacità per "ricordare l'aspetto dell'oggetto", ma impara a combinare l'aspetto delle immagini catturate.
Valutiamo le capacità di apprendimento della distribuzione delle reti generative avversarie testandole su set di dati sintetici che includono distribuzioni comuni di punti nello spazio $R^n$ e immagini contenenti poligoni di varie forme e dimensioni. Troviamo che in generale le GAN non riescono a ricreare fedelmente i dataset di punti che contengono un supporto discontinuo o curve strette con rumore; inoltre, sui dataset di immagini, troviamo che le GAN non sembrano imparare a contare il numero di oggetti dello stesso tipo in un'immagine, evidenziando anche l'apparente tensione tra generalizzazione e apprendimento nelle GAN.
Questo articolo propone un nuovo approccio per l'adattamento della dimensione del passo nei metodi a gradiente. Il metodo proposto, chiamato ottimizzazione della dimensione del passo (SSO), formula l'adattamento della dimensione del passo come un problema di ottimizzazione che minimizza la funzione di perdita rispetto alla dimensione del passo per i parametri del modello e i gradienti dati, quindi la dimensione del passo è ottimizzata in base al metodo dei moltiplicatori a direzione alternata (ADMM). SSO non richiede informazioni del secondo ordine o modelli probabilistici per adattare la dimensione del passo, quindi è efficiente e facile da implementare.Inoltre, introduciamo anche SSO stocastico per ambienti di apprendimento stocastico.Negli esperimenti, abbiamo integrato SSO per vanigliare SGD e Adam, e hanno superato lo stato dell'arte dei metodi di gradiente adattivo tra cui RMSProp, Adam, L4-Adam, e AdaBound su ampi set di dati di riferimento.
Nonostante il fatto che i modelli generativi abbiano un grande successo nella pratica, la teoria alla base di questo fenomeno sta solo iniziando a mettersi al passo con la pratica. In questo lavoro affrontiamo la questione dell'universalità dei modelli generativi: è vero che le reti neurali possono approssimare arbitrariamente bene qualsiasi manifold di dati? Forniamo una risposta positiva a questa domanda e dimostriamo che sotto blande assunzioni sulla funzione di attivazione si può sempre trovare una rete neurale feedforward che mappa lo spazio latente su un insieme situato entro la distanza Hausdorff specificata dal manifold di dati desiderato. dimostriamo anche teoremi simili per il caso di modelli generativi multiclasse e modelli generativi a ciclo, addestrati per mappare i campioni da un manifold all'altro e viceversa.
L'apprendimento di rinforzo basato sul modello (RL) è considerato un approccio promettente per ridurre la complessità del campione che ostacola il RL senza modello. Tuttavia, la comprensione teorica di tali metodi è stata piuttosto limitata. Questo articolo introduce una nuova struttura algoritmica per la progettazione e l'analisi di algoritmi RL basati sul modello con garanzie teoriche. Il meta-algoritmo costruisce iterativamente un limite inferiore della ricompensa attesa basato sul modello dinamico stimato e sulle traiettorie campione, e poi massimizza il limite inferiore congiuntamente sulla politica e sul modello. La struttura estende il principio dell'ottimismo di fronte all'incertezza ai modelli dinamici non lineari in un modo che non richiede una quantificazione esplicita dell'incertezza. Istanziando la nostra struttura con la semplificazione si ottiene una variante degli algoritmi RL basati sul modello Stochastic Lower Bounds Optimization (SLBO). Gli esperimenti dimostrano che SLBO raggiunge le prestazioni più avanzate quando sono consentiti solo 1M o meno campioni su una serie di compiti di controllo continuo.
Studiamo l'uso della distillazione della conoscenza per comprimere l'architettura della rete U. Mostriamo che, mentre la distillazione standard non è sufficiente per addestrare in modo affidabile una rete U compressa, l'introduzione di altri metodi di regolarizzazione, come la normalizzazione dei lotti e la riponderazione delle classi, nella distillazione della conoscenza migliora significativamente il processo di formazione, il che ci permette di comprimere una rete U di oltre 1000 volte, cioè allo 0,1% del suo numero originale di parametri, con un calo trascurabile delle prestazioni.
L'apprendimento delle reti neurali con la discesa del gradiente su una lunga sequenza di compiti è problematico perché la loro messa a punto per i nuovi compiti sovrascrive i pesi di rete che sono importanti per i compiti precedenti, il che porta ad una scarsa performance sui vecchi compiti - un fenomeno inquadrato come dimenticanza catastrofica.  Mentre i primi approcci utilizzano la prova dei compiti e le reti in crescita che limitano la scalabilità della sequenza di compiti, gli approcci ortogonali si basano sulla regolarizzazione.  Sulla base della matrice di informazione di Fisher (FIM) i cambiamenti ai parametri che sono rilevanti per i vecchi compiti sono penalizzati, il che costringe il compito ad essere mappato nella capacità rimanente disponibile della rete.Questo richiede di calcolare l'Hessiano intorno ad un modo, che rende l'apprendimento tractable.In questo documento, introduciamo stime di curvatura Hessian-free come un metodo alternativo al calcolo effettivo dell'Hessiano.  In contrasto con il lavoro precedente, sfruttiamo il fatto che la maggior parte delle regioni nella superficie di perdita sono piatte e quindi calcoliamo solo un prodotto vettoriale Hessiano intorno alla superficie che è rilevante per il compito corrente.I nostri esperimenti dimostrano che su una varietà di sequenze di compiti ben noti o superiamo significativamente o siamo alla pari con il lavoro precedente.
C'è stato un recente interesse nel migliorare le prestazioni dei modelli semplici per molteplici ragioni come l'interpretabilità, l'apprendimento robusto da piccoli dati, la distribuzione in impostazioni di memoria limitata, nonché considerazioni ambientali. Il nostro metodo sfrutta anche la stima di durezza per campione del modello semplice, il che non è il caso dei lavori precedenti che considerano principalmente le confidenze/previsioni del modello complesso ed è quindi concettualmente nuovo. Inoltre, generalizziamo e formalizziamo il concetto di attaccare le sonde agli strati intermedi di una rete neurale, che era una delle idee principali nel lavoro precedente \citep{profweight}, ad altri classificatori comunemente usati e lo incorporiamo nel nostro metodo. Il beneficio di questi contributi è testimoniato negli esperimenti dove su 6 dataset UCI e CIFAR-10 superiamo i concorrenti in una maggioranza (16 su 27) dei casi e pareggiamo per la migliore performance nei casi rimanenti. In effetti, in un paio di casi, ci avviciniamo persino alle prestazioni del modello complesso. Inoltre, conduciamo ulteriori esperimenti per convalidare le affermazioni e capire intuitivamente perché il nostro metodo funziona. Teoricamente, motiviamo il nostro approccio mostrando che la perdita ponderata minimizzata dai modelli semplici utilizzando la nostra ponderazione limita la perdita del modello complesso.
Proponiamo un metodo di principio per l'apprendimento del kernel, che si basa su una caratterizzazione Fourier-analitica dei kernel invarianti alla traslazione o alla rotazione.Il nostro metodo produce una sequenza di mappe di caratteristiche, raffinando iterativamente il margine SVM.Forniamo garanzie rigorose per l'ottimalità e la generalizzazione, interpretando il nostro algoritmo come dinamica di ricerca dell'equilibrio online in un certo gioco min-max a due giocatori.Le valutazioni su set di dati sintetici e del mondo reale dimostrano scalabilità e miglioramenti coerenti rispetto ai metodi basati su caratteristiche casuali correlati.
Abbiamo elaborato l'uso del campionamento di importanza per il ragionamento causale, in particolare per l'inferenza controfattuale.Mostriamo come questo può essere implementato nativamente nella programmazione probabilistica.Considerando la struttura della query controfattuale, si può ottimizzare significativamente il processo di inferenza.Consideriamo anche scelte di design per consentire ulteriori ottimizzazioni.Introduciamo MultiVerse, un prototipo di motore di programmazione probabilistica per il ragionamento causale approssimativo.Forniamo risultati sperimentali e confrontiamo con Pyro, un framework di programmazione probabilistica esistente con alcuni strumenti di ragionamento causale.
Consideriamo il problema di rappresentare il comportamento collettivo di grandi popolazioni e di prevedere l'evoluzione di una distribuzione di popolazione su uno spazio di stato discreto.Un gioco di campo medio a tempo discreto (MFG) è motivato come un modello interpretabile fondato sulla teoria dei giochi per comprendere l'effetto aggregato delle azioni individuali e prevedere l'evoluzione temporale delle distribuzioni di popolazione. Il nostro metodo impara sia la funzione di ricompensa che la dinamica in avanti di un MFG dai dati reali, e riportiamo il primo test empirico di un modello di gioco di campo medio di una popolazione reale di social media.
Studiamo il problema dell'addestramento di modelli generativi sequenziali per catturare il comportamento coordinato di traiettorie multi-agente, come il gioco offensivo del basket.  Quando si modellano tali impostazioni, è spesso vantaggioso progettare modelli gerarchici che possono catturare la coordinazione a lungo termine utilizzando variabili intermedie.  Inoltre, queste variabili intermedie dovrebbero catturare interessanti semantiche comportamentali di alto livello in un modo interpretabile e manipolabile. Presentiamo un quadro gerarchico che può imparare efficacemente tali modelli generativi sequenziali.  Oltre alle impostazioni sintetiche, mostriamo come istanziare la nostra struttura per modellare efficacemente le interazioni complesse tra i giocatori di basket e generare traiettorie realistiche multi-agente del gioco del basket su lunghi periodi di tempo.Convalidiamo il nostro approccio utilizzando valutazioni sia quantitative che qualitative, compreso un confronto di studi utente condotto con analisti sportivi professionisti.
Molti metodi di apprendimento automatico delle macchine, come quelli per l'ottimizzazione dell'iperparametro e dell'architettura neurale, sono computazionalmente costosi perché comportano l'addestramento di molte configurazioni diverse del modello.In questo lavoro, presentiamo un nuovo metodo che risparmia il budget computazionale terminando le configurazioni scadenti all'inizio della formazione.In contrasto con i metodi esistenti, consideriamo questo compito come un problema di apprendimento di classifica e di trasferimento. Dimostriamo qualitativamente che ottimizzando una perdita di ranking a coppie e sfruttando le curve di apprendimento da altri set di dati, il nostro modello è in grado di classificare efficacemente le curve di apprendimento senza dover osservare molte o molto lunghe curve di apprendimento.Dimostriamo inoltre che il nostro metodo può essere utilizzato per accelerare la ricerca di un'architettura neurale di un fattore fino a 100 senza un significativo degrado delle prestazioni dell'architettura scoperta.In ulteriori esperimenti analizziamo la qualità del ranking, l'influenza dei diversi componenti del modello così come il comportamento predittivo del modello.
L'apprendimento continuo è il problema dell'apprendimento di nuovi compiti o conoscenze mentre si proteggono le vecchie conoscenze e si generalizza idealmente dalla vecchia esperienza per imparare nuovi compiti più velocemente.Le reti neurali addestrate con la discesa del gradiente stocastico spesso degradano su vecchi compiti quando vengono addestrate successivamente su nuovi compiti con diverse distribuzioni di dati. Questo fenomeno, indicato come dimenticanza catastrofica, è considerato un grande ostacolo all'apprendimento con dati non stazionari o sequenze di nuovi compiti, e impedisce alle reti di accumulare continuamente conoscenze e abilità.Esaminiamo questo problema nel contesto dell'apprendimento di rinforzo, in un contesto in cui un agente è esposto a compiti in una sequenza.A differenza della maggior parte degli altri lavori, non forniamo un'indicazione esplicita al modello dei confini dei compiti, che è la circostanza più generale per un agente di apprendimento esposto all'esperienza continua. Mentre recentemente sono stati proposti vari metodi per contrastare la dimenticanza catastrofica, noi esploriamo una soluzione semplice, generale e apparentemente trascurata - quella di usare buffer di riproduzione dell'esperienza per tutti gli eventi passati - con una miscela di apprendimento on e off-policy, sfruttando la clonazione comportamentale. Dimostriamo che questa strategia può ancora imparare rapidamente nuovi compiti e può ridurre sostanzialmente la dimenticanza catastrofica in entrambi i domini Atari e DMLab, eguagliando persino le prestazioni dei metodi che richiedono identità dei compiti.Quando la memoria del buffer è limitata, confermiamo che un semplice meccanismo per scartare casualmente i dati permette a un buffer di dimensioni limitate di funzionare quasi bene come uno senza limiti.
Presentiamo un metodo che impara a integrare le informazioni temporali, da un modello dinamico appreso, con informazioni visive ambigue, da un modello di visione appreso, nel contesto di agenti interagenti.Il nostro metodo è basato su una rete neurale ricorrente variazionale strutturata a grafo, che è addestrata end-to-end per dedurre lo stato corrente del mondo (parzialmente osservato), così come per prevedere gli stati futuri.Mostriamo che il nostro metodo supera varie baseline su due dataset sportivi, uno basato su traiettorie reali di basket, e uno generato da un motore di gioco di calcio.
In questo articolo studiamo il problema dell'apprendimento dei pesi di una rete neurale convoluzionale profonda.Consideriamo una rete in cui le convoluzioni sono effettuate su patch non sovrapposte con un singolo kernel in ogni strato.Sviluppiamo un algoritmo per l'apprendimento simultaneo di tutti i kernel dai dati di allenamento.Il nostro approccio soprannominato Deep Tensor Decomposition (DeepTD) è basato su una decomposizione tensoriale rank-1. Indaghiamo teoricamente DeepTD sotto un modello realizzabile per i dati di formazione in cui gli ingressi sono scelti i.i.d. da una distribuzione gaussiana e le etichette sono generate secondo i kernel convoluzionali piantati.Mostriamo che DeepTD è data-efficiente e funziona provabilmente non appena la dimensione del campione supera il numero totale di pesi convoluzionali nella rete.I nostri esperimenti numerici dimostrano l'efficacia di DeepTD e verificare i nostri risultati teorici.
Le tecniche di pruning delle reti neurali possono ridurre il numero di parametri delle reti addestrate di oltre il 90%, diminuendo i requisiti di archiviazione e migliorando le prestazioni computazionali dell'inferenza senza compromettere l'accuratezza.Tuttavia, l'esperienza contemporanea è che le architetture sparse prodotte dal pruning sono difficili da addestrare fin dall'inizio, il che migliorerebbe analogamente le prestazioni di addestramento. Troviamo che una tecnica di potatura standard scopre naturalmente le sottoreti le cui inizializzazioni le hanno rese capaci di addestrare efficacemente.Sulla base di questi risultati, articoliamo "l'ipotesi del biglietto della lotteria:" le reti dense, inizializzate a caso, feed-forward contengono sottoreti ("biglietti vincenti") che - quando addestrate in isolamento - raggiungono l'accuratezza della prova paragonabile alla rete originale in un numero simile di iterazioni. I biglietti vincenti che troviamo hanno vinto la lotteria dell'inizializzazione: le loro connessioni hanno pesi iniziali che rendono l'addestramento particolarmente efficace.Presentiamo un algoritmo per identificare i biglietti vincenti e una serie di esperimenti che supportano l'ipotesi del biglietto della lotteria e l'importanza di queste inizializzazioni fortuite.Troviamo costantemente biglietti vincenti che sono meno del 10-20% della dimensione di diverse architetture feed-forward completamente connesse e convoluzionali per MNIST e CIFAR10.Sopra questa dimensione, i biglietti vincenti che troviamo imparano più velocemente della rete originale e raggiungono una maggiore precisione di test.
Indaghiamo le difficoltà di addestramento delle reti neurali sparse e facciamo nuove osservazioni sulle dinamiche di ottimizzazione e sul paesaggio energetico all'interno del regime sparso.Un recente lavoro di \citep{Gale2019, Liu2018} ha dimostrato che le architetture sparse ResNet-50 addestrate sul dataset ImageNet-2012 convergono a soluzioni che sono significativamente peggiori di quelle trovate dal pruning.Noi dimostriamo che, nonostante il fallimento degli ottimizzatori, esiste un percorso lineare con un obiettivo monotonicamente decrescente dall'inizializzazione alla soluzione ``buona''. Inoltre, i nostri tentativi di trovare un percorso obiettivo decrescente dalle soluzioni ``cattivo'' a quelle ``buone'' nel sottospazio sparso falliscono. Tuttavia, se permettiamo al percorso di attraversare il sottospazio denso, allora troviamo coerentemente un percorso tra due soluzioni.Questi risultati suggeriscono che attraversare dimensioni extra può essere necessario per sfuggire ai punti stazionari trovati nel sottospazio sparso.
L'addestramento delle reti neurali dipende dalla struttura del paesaggio di perdita sottostante, cioè minimi locali, punti di sella, altipiani piatti e barriere di perdita. In relazione alla struttura del paesaggio, studiamo la simmetria di permutazione dei neuroni in ogni strato di una rete neurale profonda, che dà luogo non solo a più minimi globali equivalenti della funzione di perdita ma anche a punti critici tra i minimi partner. In una rete di $d-1$ strati nascosti con $n_k$ neuroni negli strati $k = 1, \ldots, d$, costruiamo percorsi continui tra minimi globali equivalenti che portano attraverso un `punto di permutazione' dove i vettori di peso di ingresso e uscita di due neuroni nello stesso strato nascosto $k$ si scontrano e si scambiano. Mostriamo che tali punti di permutazione sono punti critici che si trovano all'interno di sottospazi ad alta densità di perdita uguale, contribuendo alla planarità globale del paesaggio. Troviamo anche che un punto di permutazione per lo scambio di neuroni $i$ e $j$ transita in un altopiano piatto ad alta densità che permette tutte le $n_k!$permutazioni di neuroni in un dato strato $k$ allo stesso valore di perdita. Inoltre, introduciamo punti di permutazione di ordine superiore sfruttando la struttura gerarchica nei paesaggi di perdita delle reti neurali, e troviamo che il numero di punti di permutazione di ordine $K$-esimo è molto più grande del numero (già enorme) di minimi globali equivalenti -- almeno per un fattore polinomiale di ordine $K$. In due compiti, dimostriamo numericamente con il nostro metodo di ricerca dei percorsi che esistono percorsi continui tra i minimi dei partner: in primo luogo, in una rete giocattolo con un singolo strato nascosto su un compito di approssimazione di funzioni e, in secondo luogo, in una rete multistrato sul compito MNIST. Il nostro approccio geometrico fornisce un limite inferiore al numero di punti critici generati dalle simmetrie dello spazio dei pesi e fornisce un semplice collegamento intuitivo tra i precedenti risultati teorici e le osservazioni numeriche.
L'addestramento di modelli di reti neurali stocastiche con pesi e attivazioni binarie ($\pm1$) attraverso reti surrogate continue viene studiato e, utilizzando la teoria del campo medio, si ricava un insieme di equazioni scalari che descrivono come i segnali di input si propagano attraverso le reti surrogate. Le equazioni rivelano che, a seconda della scelta del modello surrogato, le reti possono esibire o meno una transizione da ordine a caos, e la presenza di scale di profondità che limitano la profondità massima addestrabile. In particolare, nel risolvere le equazioni per il bordo delle condizioni di caos, mostriamo che i surrogati derivati usando il trucco di riparametrizzazione locale gaussiana non hanno inizializzazione critica, mentre un surrogato deterministico basato sull'integrazione analitica gaussiana lo fa. La teoria è applicata a una serie di scelte di progettazione di neuroni binari e pesi, come diversi modelli di rumore dei neuroni, permettendo la categorizzazione degli algoritmi in termini di comportamento all'inizializzazione. Inoltre, prevediamo teoricamente e confermiamo numericamente che i comuni schemi di inizializzazione dei pesi utilizzati nelle reti continue standard, se applicati ai valori medi dei pesi binari stocastici, producono scarse prestazioni di addestramento. Questo studio dimostra che, contrariamente all'intuizione comune, le medie dei pesi binari stocastici dovrebbero essere inizializzate vicino a $\pm 1$ per reti più profonde per essere addestrabili.
Il parsing delle dipendenze semantiche, che mira a trovare ricche relazioni bi-lessicali, permette alle parole di avere più teste di dipendenza, risultando in rappresentazioni strutturate a grafo.Proponiamo un approccio all'apprendimento semi-supervisionato dei parser delle dipendenze semantiche basato sul framework CRF autoencoder.Il nostro encoder è un parser neurale discriminativo delle dipendenze semantiche che predice il grafico latente della frase di input. Il nostro decodificatore è un modello neurale generativo che ricostruisce la frase di input condizionata dal grafo latente di parsing.Il nostro modello è arc-factored e quindi il parsing e l'apprendimento sono entrambi tractable.Experiments mostrano il nostro modello raggiunge un miglioramento significativo e coerente rispetto alla linea di base supervisionata.
In questo lavoro, descriviamo un nuovo metodo, DeFINE, per l'apprendimento di rappresentazioni profonde a livello di parola in modo efficiente. La nostra architettura utilizza una struttura gerarchica con nuove connessioni a salto che permette l'uso di livelli di input e output a bassa dimensione, riducendo i parametri totali e il tempo di formazione e fornendo prestazioni simili o migliori rispetto ai metodi esistenti. Rispetto ai metodi all'avanguardia che includono rappresentazioni adattive dell'input, questa tecnica si traduce in un calo dal 6% al 20% della perplessità.Su WikiText-103, DeFINE riduce i parametri totali di Transformer-XL della metà con un impatto minimo sulle prestazioni.Sulla Penn Treebank, DeFINE migliora AWD-LSTM di 4 punti con una riduzione del 17% dei parametri, raggiungendo prestazioni comparabili ai metodi all'avanguardia con meno parametri.Per la traduzione automatica, DeFINE migliora un modello Transformer del 2%, riducendo contemporaneamente i parametri totali del 26%
In questo articolo, presentiamo una riproduzione dell'articolo di Bertinetto et al. [2019] "Meta-learning con solutori a forma chiusa differenziabili" come parte della ICLR 2019 Reproducibility Challenge.Nel riprodurre con successo la parte più cruciale dell'articolo, raggiungiamo una performance che è paragonabile o superiore all'articolo originale su due benchmark per diverse impostazioni.Valutiamo nuovi risultati di base, utilizzando un nuovo set di dati presentato nell'articolo.Tuttavia, forniamo anche molteplici osservazioni e raccomandazioni sulla riproducibilità e la comparabilità.  Dopo aver portato il nostro lavoro di riproducibilità all'attenzione degli autori, essi hanno aggiornato l'articolo originale su cui si basa questo lavoro e hanno rilasciato anche il codice.Il nostro contributo consiste principalmente nel riprodurre i risultati più importanti del loro articolo originale, nel dare un'idea della riproducibilità e nel fornire una prima implementazione open-source.
La potatura della rete è emersa come una tecnica potente per ridurre le dimensioni delle reti neurali profonde, che scopre sottoreti ad alte prestazioni prendendo una rete densa addestrata e rimuovendo gradualmente le connessioni non importanti. Recentemente, sono emerse tecniche alternative per addestrare direttamente le reti sparse senza dover addestrare un grande modello denso in precedenza, ottenendo così piccole impronte di memoria sia durante l'addestramento che l'inferenza. La riallocazione dinamica dei parametri converge precocemente durante l'addestramento verso una sottorete altamente addestrabile e dimostriamo che né la struttura, né l'inizializzazione della sottorete ad alte prestazioni scoperta sono sufficienti a spiegare le sue buone prestazioni. Piuttosto, è la dinamica della riallocazione dei parametri che è responsabile del successo dell'apprendimento. La riallocazione dinamica dei parametri migliora quindi l'addestrabilità delle reti convoluzionali profonde, giocando un ruolo simile alla sovraparametrizzazione, senza incorrere nella memoria e nel costo computazionale di quest'ultima.
In questo articolo presentiamo una spinta in tre direzioni di sviluppo visivo utilizzando tecniche supervisionate e semi-supervisionate. La prima è un'implementazione di rilevamento e riconoscimento semi-supervisionato di oggetti utilizzando i principi di Soft At- tention e Generative Adversarial Networks (GANs). La seconda e la terza sono reti supervisionate che apprendono i concetti di base della localizzazione spaziale e della quantità, rispettivamente, utilizzando le reti neurali convoluzionali (CNN). Le tre spinte, insieme, si basano sull'approccio dell'apprendimento esperienziale dei robot, introdotto nella precedente pubblicazione, mentre i risultati sono acerbi per l'implementazione, crediamo che costituiscano un passo avanti verso lo sviluppo autonomo di moduli vi- suali robotici.
La caratterizzazione delle rappresentazioni apprese negli strati intermedi delle reti profonde può fornire preziose informazioni sulla natura di un compito e può guidare lo sviluppo di strategie di apprendimento ben calibrate.Qui studiamo modelli acustici basati su reti neurali convoluzionali nel contesto del riconoscimento automatico del parlato.Adattando un metodo proposto da Yosinski et al. [2014], misuriamo la trasferibilità di ogni strato tra tedesco e inglese per valutare la loro lingua-specificità.Osserviamo tre regioni distinte di trasferibilità: (1) i primi due strati sono interamente trasferibili tra le lingue, (2) gli strati 2-8 sono anche altamente trasferibili, ma troviamo prove di una certa specificità linguistica, (3) i successivi strati completamente connessi sono più specifici della lingua, ma possono essere messi a punto con successo per la lingua di destinazione.Per sondare ulteriormente l'effetto del congelamento dei pesi, abbiamo eseguito esperimenti di follow-up utilizzando il freeze-training [Raghu et al., 2017].
I metodi di gradienti di politica spesso ottengono prestazioni migliori quando il cambiamento di politica è limitato a una piccola divergenza di Kullback-Leibler.Deriviamo gradienti di politica in cui il cambiamento di politica è limitato a una piccola distanza di Wasserstein (o regione di fiducia).Questo viene fatto nelle impostazioni discrete e continue di bandito multi-armato con regolarizzazione dell'entropia. Mostriamo che nel limite dei piccoli passi rispetto alla distanza di Wasserstein $W_2$, la dinamica della politica è governata dall'equazione del calore, seguendo il risultato di Jordan-Kinderlehrer-Otto. Ciò significa che le politiche subiscono diffusione e avvezione, concentrandosi vicino alle azioni con alta ricompensa. Questo aiuta a chiarire la natura della convergenza nella configurazione di corrispondenza delle probabilità, e fornisce una giustificazione per le pratiche empiriche come i priori gaussiani della politica e il rumore additivo del gradiente.
La funzione softmax è ampiamente utilizzata per addestrare reti neurali profonde per la classificazione multiclasse.Nonostante le sue eccezionali prestazioni in compiti di classificazione, le caratteristiche derivate dalla supervisione di softmax sono di solito sub-ottimali in alcuni scenari in cui le distanze euclidee si applicano negli spazi delle caratteristiche.Per affrontare questo problema, proponiamo una nuova perdita, soprannominata la perdita isotropica, nel senso che la distribuzione complessiva dei punti dati è regolarizzata per avvicinarsi a quella normale isotropica. In combinazione con la vaniglia softmax, formalizziamo un nuovo criterio chiamato isotropic softmax, o isomax in breve, per l'apprendimento supervisionato di reti neurali profonde.In virtù dell'isomax, le caratteristiche intra-classe sono penalizzate dalla perdita isotropica mentre le distanze inter-classe sono ben mantenute dalla perdita softmax originale.Inoltre, la perdita isomax non richiede alcuna modifica aggiuntiva alla rete, ai mini-batch o al processo di formazione.Vasti esperimenti di classificazione e clustering sono effettuati per dimostrare la superiorità e la solidità della perdita isomax.
Una domanda fondamentale nell'apprendimento del rinforzo è se gli algoritmi senza modello sono efficienti per il campione.Recentemente, Jin et al. (2018) hanno proposto un algoritmo di Q-learning con politica di esplorazione UCB, e hanno dimostrato che ha un limite di rammarico quasi ottimale per MDP episodico a orizzonte finito.In questo articolo, adattiamo Q-learning con bonus di esplorazione UCB a MDP a orizzonte infinito con ricompense scontate \emph{senza} accedere a un modello generativo. Mostriamo che la complessità campionaria dell'esplorazione del nostro algoritmo è delimitata da $ ¼tilde{O}({frac{SA}{{epsilon^2(1-\gamma)^7}})$. Questo migliora il risultato precedentemente noto di $ ¼tilde{O}({\frac{SA}{epsilon^4(1-\gamma)^8})$ in questa impostazione raggiunto dal Q-learning ritardato (Strehlet al., 2006), ed eguaglia il limite inferiore in termini di $ $epsilon$ così come $S$ e $A$ fino a fattori logaritmici.
Il backpropagation sta guidando le reti neurali artificiali (ANNs) di oggi.Tuttavia, nonostante la ricerca estesa, rimane poco chiaro se il cervello implementa questo algoritmo.Tra i neuroscienziati, gli algoritmi di apprendimento di rinforzo (RL) sono spesso visti come un'alternativa realistica: i neuroni possono introdurre casualmente il cambiamento, e utilizzare segnali di feedback non specifici per osservare il loro effetto sul costo e quindi approssimare il loro gradiente.Tuttavia, il tasso di convergenza di tale apprendimento scala male con il numero di neuroni coinvolti.Qui proponiamo un approccio ibrido di apprendimento. Ogni neurone usa una strategia di tipo RL per imparare come approssimare i gradienti che la backpropagation fornirebbe.Forniamo la prova che il nostro approccio converge al vero gradiente per certe classi di reti.In entrambe le reti feedforward e convoluzionali, dimostriamo empiricamente che il nostro approccio impara ad approssimare il gradiente, e può eguagliare le prestazioni dell'apprendimento basato sul gradiente.L'apprendimento dei pesi di feedback fornisce un meccanismo biologicamente plausibile per ottenere buone prestazioni, senza la necessità di regole di apprendimento precise e pre-specificate.
Questo articolo propone e dimostra un modello sorprendente nell'addestramento delle reti neurali: c'è una relazione uno a uno tra i valori di qualsiasi coppia di perdite (come l'entropia incrociata, l'errore quadratico medio, l'errore 0/1, ecc.) valutati per un modello che nasce in (qualsiasi punto di) una sessione di addestramento. Questo modello è universale, nel senso che questa relazione uno a uno è identica tra architetture (come VGG, Resnet, Densenet, ecc.), algoritmi (SGD e SGD con momentum) e funzioni di perdita (entropia incrociata e errore quadratico medio).
